{"posts":[{"title":"19个例子学习Oracle","text":"19个学习Oracle的例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369--p1begindbms_output.put_line('你好 世界');end;--p2 引入变量declare age number default 90; height number := 175;begin dbms_output.put_line('年龄'||age||'身高'||height);end;--p3 变量开始运算declare age number default 90; height number := 175;begin dbms_output.put_line('年龄'||age||'身高'||height); age := age + 20; dbms_output.put_line('20年后年龄'||age||'岁');end;--p4 引入表达式declare age number default 90; height number := 175;begin if age&gt;70 then dbms_output.put_line('古稀之年'); else dbms_output.put_line('风华正茂'); end if;end;--p5 流程控制declare age number default 90; height number := 175; gender char(2) := '男';begin if gender='男' then dbms_output.put_line('你可以和女性结婚'); end if; if height&gt;170 then dbms_output.put_line('可以打篮球'); else dbms_output.put_line('可以踢足球'); end if; if age&lt;20 then dbms_output.put_line('年轻小伙'); elsif age &lt;= 50 then dbms_output.put_line('年轻有为'); elsif age &lt;=70 then dbms_output.put_line('安享天伦'); else dbms_output.put_line('佩服佩服'); end if;end;--p6 计算1-100的和declare i number :=0; total number :=0;begin loop i := i+1; total := total + i; if i=100 then exit; end if; end loop; dbms_output.put_line('总和'||total);end;-- p7: 跳出loop的方法declare i number :=0; total number :=0;begin loop i := i+1; total := total + i; exit when i&gt;=100; end loop; dbms_output.put_line('总和'||total);end;--p8 whlie循环declare i number :=0; total number :=0;begin while i&lt;100 loop i := i+1; total := total + i; end loop; dbms_output.put_line('总和'||total);end;--p9 for 循环begin --for 循环变量 in 起始值..结束值 loop --xxxxx --end loop; for i in 1..9 loop dbms_output.put_line(i); end loop; for i in reverse 1..9 loop dbms_output.put_line(i); end loop;end;--p10 没有返回值的&quot;函数&quot;--做一个求面积的过程--declare-- area number;-- procedure 过程名(参数名 类型,...) is-- begin-- 主体-- end;--begin--end;declare area number; procedure mian(a number,b number) is begin area := a * b; dbms_output.put_line(a||'乘'||b||'的面积是'||area); end;begin mian(5,4); mian(6,7); mian(3,7);end;--p11 做一个求面积的函数--declare-- area number;-- function 过程名(参数名 类型,...) return 类型 is-- begin-- 主体-- end;--begin--end;declare area number; function mian(a number,b number) return number is begin area := a * b; return area; end;begin dbms_output.put_line(mian(5,4)); dbms_output.put_line(mian(3,7)); dbms_output.put_line(mian(6,9));end;--p12 自定义变量类型 之记录类型declare type student is record ( sno char(5), name varchar2(10), age number ); lisi student;begin lisi.sno := 's1008'; lisi.name := '李四'; lisi.age := 19; dbms_output.put_line('我叫'||lisi.name||',我'||lisi.age||'岁,学号是'||lisi.sno);end;--p13 自定义类型之集合类型declare type answer is table of char(2); ans answer := answer('a','b','c','d');begin dbms_output.put_line('共有'||ans.count()||'答案,分别是:'); dbms_output.put_line(ans(1)); dbms_output.put_line(ans(2)); dbms_output.put_line(ans(3)); dbms_output.put_line(ans(4));end;--p14 声明数据类型的第3个方法declare age number; 变量名 另一个变量%type; age 表名.列名%type; --声明和列一样的类型 --简化声明record类型 变量名 表名%rowtype;beginend;--p15 测试一下rowtypedeclare xg student%rowtype;begin xg.sno := 123; xg.name := '小刚'; dbms_output.put_line(xg.sno||xg.name);end;--p16 pl/sql操作数据库中的数据--查询部门的名称及地区，及部门的总薪水与奖金declare depart dept%rowtype; total_sal number; total_comm number; procedure deptinfo(dno number) is begin select dname,loc into depart.dname,depart.loc from dept where deptno=dno; select sum(sal),sum(comm) into total_sal,total_comm from emp where deptno=dno; dbms_output.put_line('部门名称：'||depart.dname||'在'||depart.loc); dbms_output.put_line('这个部门每月工资及奖金各是'||total_sal||'和'||total_comm); end;begin deptinfo(80); deptinfo(30); end;--p17 引入异常处理declare depart dept%rowtype; total_sal number; total_comm number; procedure deptinfo(dno number) is begin select dname,loc into depart.dname,depart.loc from dept where deptno=dno; select sum(sal),sum(comm) into total_sal,total_comm from emp where deptno=dno; dbms_output.put_line('部门名称：'||depart.dname||'在'||depart.loc); dbms_output.put_line('这个部门每月工资及奖金各是'||total_sal||'和'||total_comm); end;begin deptinfo(80); deptinfo(30);exception when NO_DATA_FOUND then dbms_output.put_line('没有数据'); when others then dbms_output.put_line('其他错误');end;--p18:递归过程或函数--求1-&gt;N的和,N允许输入declare m number; total number; function qiuhe(n number) return number is begin if n&gt;1 then return n + qiuhe(n-1); else return 1; end if; end;begin dbms_output.put_line(qiuhe(10));end;--p19 存储过程/存储函数create function qiuhe(n number) return numberisbegin if n&gt;1 then return n + qiuhe(n-1); else return 1; end if;end;","link":"/2021/11/25/19%E4%B8%AA%E4%BE%8B%E5%AD%90%E5%AD%A6%E4%B9%A0Oracle/"},{"title":"ActiveMQ、RabbitMQ、RocketMQ、Kafka有什么优点和缺点","text":"ActiveMQ 单机吞吐量：万级 topic数量都吞吐量的影响： 时效性：ms级 可用性：高，基于主从架构实现高可用性 消息可靠性：有较低的概率丢失数据 功能支持：MQ领域的功能极其完备 总结： 非常成熟，功能强大，在早些年业内大量的公司以及项目中都有应用 偶尔会有较低概率丢失消息 现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.x维护越来越少，几个月才发布一个版本 主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用 RabbitMQ 单机吞吐量：万级 topic数量都吞吐量的影响： 时效性：微秒级，延时低是一大特点。 可用性：高，基于主从架构实现高可用性 消息可靠性： 功能支持：基于erlang开发，所以并发能力很强，性能极其好，延时很低 总结： erlang语言开发，性能极其好，延时很低； 吞吐量到万级，MQ功能比较完备 开源提供的管理界面非常棒，用起来很好用 社区相对比较活跃，几乎每个月都发布几个版本分 在国内一些互联网公司近几年用rabbitmq也比较多一些 但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。 erlang开发，很难去看懂源码，基本职能依赖于开源社区的快速维护和修复bug。 rabbitmq集群动态扩展会很麻烦，不过这个我觉得还好。其实主要是erlang语言本身带来的问题。很难读源码，很难定制和掌控。 RocketMQ 单机吞吐量：十万级 topic数量都吞吐量的影响：topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降。可支持大量topic是一大优势。 时效性：ms级 可用性：非常高，分布式架构 消息可靠性：经过参数优化配置，消息可以做到0丢失 功能支持：MQ功能较为完善，还是分布式的，扩展性好 总结： 接口简单易用，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景 而且一个很大的优势在于，源码是java，我们可以自己阅读源码，定制自己公司的MQ，可以掌控 社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码 Kafka 单机吞吐量：十万级，最大的优点，就是吞吐量高。 topic数量都吞吐量的影响：topic从几十个到几百个的时候，吞吐量会大幅度下降。所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源 时效性：ms级 可用性：非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性：经过参数优化配置，消息可以做到0丢失 功能支持：功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用 总结： kafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展 同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量 kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略 最后 一般的业务系统要引入MQ，最早大家都用ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃 后来大家开始用RabbitMQ，但是确实erlang语言阻止了大量的java工程师去深入研究和掌控他，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高； 不过现在确实越来越多的公司，会去用RocketMQ，确实很不错，但是要想好社区万一突然黄掉的风险 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用RabbitMQ是不错的选择；大型公司，基础架构研发实力较强，用RocketMQ是很好的选择 如果是大数据领域的实时计算、日志采集等场景，用Kafka是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范","link":"/2021/04/07/ActiveMQ%E3%80%81RabbitMQ%E3%80%81RocketMQ%E3%80%81Kafka%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E7%82%B9%E5%92%8C%E7%BC%BA%E7%82%B9/"},{"title":"CURL命令用法介绍","text":"输出状态码1curl -I -m 10 -o /dev/null -s -w %{http_code} www.baidu.com -I 仅测试HTTP头 -m 10 最多查询10s -o /dev/null 屏蔽原有输出信息 -s silent 模式，不输出任何东西 -w %{http_code} 控制额外输出 -w 参数如下 url_effective 最终获取的url地址，尤其是当你指定给curl的地址存在301跳转，且通过-L继续追踪的情形。 http_code http状态码，如200成功,301转向,404未找到,500服务器错误等。(The numerical response code that was found in the last retrieved HTTP(S) or FTP(s) transfer. In 7.18.2 the alias response_code was added to show the same info.) http_connect The numerical code that was found in the last response (from a proxy) to a curl CONNECT request. (Added in 7.12.4) time_total 总时间，按秒计。精确到小数点后三位。 （The total time, in seconds, that the full operation lasted. The time will be displayed with millisecond resolution.） time_namelookup DNS解析时间,从请求开始到DNS解析完毕所用时间。(The time, in seconds, it took from the start until the name resolving was completed.) time_connect 连接时间,从开始到建立TCP连接完成所用时间,包括前边DNS解析时间，如果需要单纯的得到连接时间，用这个time_connect时间减去前边time_namelookup时间。以下同理，不再赘述。(The time, in seconds, it took from the start until the TCP connect to the remote host (or proxy) was completed.) time_appconnect 连接建立完成时间，如SSL/SSH等建立连接或者完成三次握手时间。(The time, in seconds, it took from the start until the SSL/SSH/etc connect/handshake to the remote host was completed. (Added in 7.19.0)) time_pretransfer 从开始到准备传输的时间。(The time, in seconds, it took from the start until the file transfer was just about to begin. This includes all pre-transfer commands and negotiations that are specific to the particular protocol(s) involved.) time_redirect 重定向时间，包括到最后一次传输前的几次重定向的DNS解析，连接，预传输，传输时间。(The time, in seconds, it took for all redirection steps include name lookup, connect, pretransfer and transfer before the final transaction was started. time_redirect shows the complete execution time for multiple redirections. (Added in 7.12.3)) time_starttransfer 开始传输时间。在发出请求之后，Web 服务器返回数据的第一个字节所用的时间(The time, in seconds, it took from the start until the first byte was just about to be transferred. This includes time_pretransfer and also the time the server needed to calculate the result.) size_download 下载大小。(The total amount of bytes that were downloaded.) size_upload 上传大小。(The total amount of bytes that were uploaded.) size_header 下载的header的大小(The total amount of bytes of the downloaded headers.) size_request 请求的大小。(The total amount of bytes that were sent in the HTTP request.) speed_download 下载速度，单位-字节每秒。(The average download speed that curl measured for the complete download. Bytes per second.) speed_upload 上传速度,单位-字节每秒。(The average upload speed that curl measured for the complete upload. Bytes per second.) content_type 就是content-Type，不用多说了，这是一个访问我博客首页返回的结果示例(text/html; charset=UTF-8)；(The Content-Type of the requested document, if there was any.) num_connects 最近的的一次传输中创建的连接数目。Number of new connects made in the recent transfer. (Added in 7.12.3) num_redirects 在请求中跳转的次数。Number of redirects that were followed in the request. (Added in 7.12.3) redirect_url When a HTTP request was made without -L to follow redirects, this variable will show the actual URL a redirect would take you to. (Added in 7.18.2) ftp_entry_path 当连接到远程的ftp服务器时的初始路径。The initial path libcurl ended up in when logging on to the remote FTP server. (Added in 7.15.4) ssl_verify_result ssl认证结果，返回0表示认证成功。( The result of the SSL peer certificate verification that was requested. 0 means the verification was successful. (Added in 7.19.0)) 使用案例以下是使用curl诊断服务器到微信api服务器的网络访问情况 1curl -o /dev/null -s -w &quot;time_connect: %{time_connect}\\ntime_starttransfer: %{time_starttransfer}\\ntime_nslookup:%{time_namelookup}\\ntime_total: %{time_total}\\n&quot; &quot;https://api.weixin.qq.com&quot; 结果如下： 1234time_connect: 0.154time_starttransfer: 0.243time_nslookup:0.150time_total: 0.243 说明: 以上显示网络连接时间为0.154秒（其中DNS解析为0.150秒），总体请求0.243秒。DNS解析出现故障的概率在正式环境中比较高，所以在诊断时候千万别漏了time_namelookup这个参数。 参考：https://curl.haxx.se/docs/manpage.htmlhttp://digdeeply.org/archives/05102012.html","link":"/2021/04/19/CURL%E5%91%BD%E4%BB%A4%E7%94%A8%E6%B3%95%E4%BB%8B%E7%BB%8D/"},{"title":"Call Stack（调用栈）是什么？","text":"今天我们来讲一下 call stack 是什么。相信有了上一篇文章对 virtual memory 的介绍之后，同学们理解起 call stack 来会相对容易一些。 回顾：Virtual Memory（虚拟内存）是什么？ Call Stack 是什么？Call stack（通常译作&amp;ldquo;调用栈&amp;rdquo;）也是计算机系统中的一个重要概念。在介绍 call stack 之前，我们首先来回顾一下 procedure 是什么。 在计算机程序当中，一个 procedure（通常译作&amp;ldquo;过程&amp;rdquo;）吃进来一些参数，干一些事情，再吐出去一个返回值（或者什么也不吐）。我们熟悉的 function、method、handler 等等其实都是 procedure。当一个 procedure A 调用另一个 procedure B 的时候，计算机其实需要干好几件事。 一. 是转移控制&amp;mdash;&amp;mdash;计算机要暂停 A 并开始执行 B，并让 B 在执行完之后还能回到 A 继续执行。 二. 是转移数据&amp;mdash;&amp;mdash;A 要能够传递参数给 B，并且 B 也能返回值给 A。 三. 分配和释放内存&amp;mdash;&amp;mdash;在 B 开始执行时为它的局部变量分配内存，并在 B 返回时释放这部分内存。 同学们想一下，假设 A 调用 B，B 再调用 C，C 执行完返回给 B，B 再执行完返回给 A，哪种数据结构最适合管理它们所使用的内存？没错，是 stack，因为过程调用具有 last-in first-out 的特点。当 A 调用 B 的时候，A 只要将它需要传递给 B 的参数 push 进这个 stack，再把将来 B 返回之后 A 应当继续执行的指令的地址（学名叫 return address）也 push 进这个 stack，就万事大吉了。之后 B 可以继续在这个 stack 上面保存一些寄存器的值，分配局部变量，进而继续构造调用 C 时需要传递的参数等等。 这个 stack 其实就是我们所说的 call stack。（这里的描述有些简化，实际当中计算机会做一些优化，如果参数和局部变量不太多的话就懒得放在 call stack 里，而是直接使用寄存器了。） Call stack 在 virtual memory 里其实就是一段连续的地址空间，靠一个叫做 SP 的寄存器（32-bit 叫 ESP，64-bit 叫 RSP）来指向栈顶。既然是连续的，于是它在使用上比我们理论课上讲的抽象的 stack 要更灵活一些，更接近 array 而不是 linked list，可以访问任意元素，而不仅仅是栈顶元素。（当然进栈出栈还是只能在栈顶进行。）这也就是为什么尽管它叫做 call stack，我们依然可以同时有不止一个参数和不止一个局部变量的原因。 Example举个例子吧。假设我们有这样一段求阶乘的代码： 00 int fact(int n) { 01 int result; 02 if (n &amp;lt;= 1) 03 result = 1; 04 else 05 result = n * fact(n - 1); 06 return result; 07 } 当 main() 调用了 fact(n)，fact(n) 又调用了 fact(n-1)，fact(n-1) 即将调用 fact(n-2) 的时候，它的 call stack 差不多是这样：（具体情况大同小异，和编译器优化有关。） 其中每个 procedure 分配的内存区域叫做它的 stack frame（通常译作&amp;ldquo;栈帧&amp;rdquo;，类似于电影《盗梦空间》中的&amp;ldquo;梦境&amp;rdquo;）。这也就解释了为什么当我们分析递归函数调用的空间复杂度时，既需要考虑 recursion tree 的深度，也需要考虑每层所分配的局部变量的大小。 对于上述 fact() 函数，它的 recursion tree 的深度是 n，这就意味着总共有 n 个 stack frame。每个 stack frame 里面除了保存 return address 和一些寄存器的值之外，还需要保存参数 n 和局部变量 result，它们都是 O(1) 的。所以 fact() 总的空间复杂度是 O(n) 的。 希望同学们能够通过了解 call stack 进一步理解空间复杂度的计算，在面试的时候一通百通。 我们下篇文章再见。 （本文在写作过程中参考了 Randal E. Bryant 和 David R. O’’Hallaron 所著的 Computer Systems: A Programmer’’s Perspective 第二版和第三版。） 文章来源：https://zhuanlan.zhihu.com/p/71168084","link":"/2020/07/05/Call%20Stack%EF%BC%88%E8%B0%83%E7%94%A8%E6%A0%88%EF%BC%89%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/"},{"title":"Centos7.x 防火墙","text":"CentOS 7.x 默认使用的是firewall作为防火墙，取代6.x的iptables 1. 查看防火墙状态 命令如下 1firewall-cmd --state 该命令有两种结果：running、not running；前者代表是开启状态，后者代表是关闭状态 在 vmware 上安装的centos7最小化镜像防火墙默认是开机自启的 2. 修改防火墙状态的相关命令（后缀 .service 可以省略） 开启防火墙 1systemctl start firewalld.service 关闭防火墙 1systemctl stop firewalld.service 防火墙开机自启 1systemctl enable firewalld.service 重启防火墙 1systemctl restart firewalld.service 禁止防火墙开机自启 1systemctl disable firewalld.service 3. 测试以上命令时可能会用到关机重启命令，在此也写下吧 重启 1reboot 关机（其实有很多方式，这里只写一种） 1init 0 文章来源：http://www.itqaq.com/index/art/126.html","link":"/2021/11/14/Centos7.x%20%E9%98%B2%E7%81%AB%E5%A2%99/"},{"title":"Docker部署LNMP运行MaxPHP","text":"环境 linux[腾讯云ubuntu20.04] 也可以手动安装docker 1apt install docker.io 安装软件lnmp指的是linux，nginx，mysql，php。 MaxPHP是运行在php的cli模式下的框架，所以不需要安装fpm。下面介绍docker安装lnmp的一些步骤，来运行MaxPHP类似的框架，这里软件均选择最新版本 为了多个容器可以通信，需要新建一个网桥 1docker network create -d bridge lnmp 安装nginx1docker pull nginx 拉取镜像后使用下面的命令运行容器 1docker run -itd --name nginx -v /www:/www -p 80:80 -p 443:443 --network lnmp &lt;镜像id&gt; 这里我做了http和https默认两个端口的映射，下面是我的网站配置文件，具体需要代理的主机需要使用下面的命令查看 1docker network inspect lnmp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103server{ listen 80; listen 443 ssl http2; server_name 1kmb.com www.1kmb.com; index index.php index.html index.htm default.php default.htm default.html; root /www/wwwroot/1kmb.com.main/public; location / { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; if (!-f $request_filename ) { proxy_pass http://127.0.0.1:9999; } } #SSL-START SSL相关配置，请勿删除或修改下一行带注释的404规则 #error_page 404/404.html; #limit_conn perserver 50; #limit_conn perip 15; #limit_rate 256k; #HTTP_TO_HTTPS_START if ($host !~ &quot;www&quot;) { rewrite ^(/.*)$ https://www.$host$1 permanent; } if ($server_port !~ 443){ rewrite ^(/.*)$ https://$host$1 permanent; } #HTTP_TO_HTTPS_END ssl_certificate /www/server/panel/vhost/cert/1kmb.com.main/fullchain.pem; ssl_certificate_key /www/server/panel/vhost/cert/1kmb.com.main/privkey.pem; ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; add_header Strict-Transport-Security &quot;max-age=31536000&quot;; error_page 497 https://$host$request_uri; #SSL-END #ERROR-PAGE-START 错误页配置，可以注释、删除或修改 #error_page 404 /404.html; #error_page 502 /502.html; #ERROR-PAGE-END #PHP-INFO-START PHP引用配置，可以注释或修改 # include enable-php-00.conf; #PHP-INFO-END #REWRITE-START URL重写规则引用,修改后将导致面板设置的伪静态规则失效 # include /www/server/panel/vhost/rewrite/1kmb.com.main.conf; #REWRITE-END #禁止访问的文件或目录 location ~ ^/(\\.user.ini|\\.htaccess|\\.git|\\.svn|\\.project|LICENSE|README.md) { return 404; } #一键申请SSL证书验证目录相关设置 location ~ \\.well-known{ allow all; } location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ { expires 30d; error_log /dev/null; access_log /dev/null; } location ~ .*\\.(js|css)?$ { expires 12h; error_log /dev/null; access_log /dev/null; } access_log /www/wwwlogs/1kmb.com.main.log; error_log /www/wwwlogs/1kmb.com.main.error.log;}server { listen 443 ssl; server_name ws.1kmb.com; location / { proxy_pass http://127.0.0.1:8787; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_http_version 1.1; proxy_set_header Sec-Websocket-Version 13; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } ssl_certificate /www/wwwroot/7328958_ws.1kmb.com.pem; ssl_certificate_key /www/wwwroot/7328958_ws.1kmb.com.key; ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m;} 我开启了websocket服务，所以配置了$connection_upgrade变量，配置方法如下 配置 “$connection_upgrade” 变量连接升级通常与 WebSockets 结合使用。 在 nginx 中，我们可以根据 $http_upgrade 变量将 HTTP 连接升级为 WebSocket 连接。 我们可以使用 map 块在 nginx 中定义连接和 http 升级之间的依赖关系： 1234map $http_upgrade $connection_upgrade { default upgrade; '' close;} 如果 Upgrade 标头设置为 ‘’，此 map 块告诉 nginx 正确设置相关的 Connection 标头来关闭连接。 将 map 块放入 nginx 配置的 http 块中。 nginx 配置的默认文件路径是 /etc/nginx/nginx.conf 。 这是一个使用定义 $connection_upgrade 变量的 map 块的 nginx 配置示例。 12345678910111213141516171819202122user www-data; worker_processes auto; pid /run/nginx.pid;events { multi_accept on; worker_connections 65535;}http { sendfile on; tcp_nopush on; tcp_nodelay on; … # Connection header for WebSocket reverse proxy map $http_upgrade $connection_upgrade { default upgrade; '' close; } # further configurations …} 保存更新的 nginx 配置文件。 然后，使用 nginx -t 再次检查配置文件： 1234$ sudo nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful 如果配置文件出错导致容器不能启动，则可以使用下面命令拷贝配置文件到容器外部修改后再拷贝进去 1docker cp /nginx.conf &lt;容器id&gt;:/etc/nginx/nginx.conf 安装php1docker pull php 运行容器 1docker run -itd --name php81 --network lnmp -v /www:/www &lt;容器id&gt; 添加pcntl（maxphp的切面实现使用了子进程扫描），redis，pdo，pdo_mysql扩展，从官网下载对应版本的源码包，解压后进入ext目录的对应扩展目录，执行 123phpize./configure --enable-pcntl --with-php-config=/usr/local/php-config make &amp;&amp; make install 然后将扩展添加到配置文件中，配置文件可以通过php –ini查看 如果出现下面的报错 1error: openssl/ssl.h: No such file or directory 就执行下下面的命令 12sudo apt-get install opensslsudo apt-get install libssl-dev build-essential zlibc zlib-bin libidn11-dev libidn11 安装mysql1docker pull mysql 1docker run -itd --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root &lt;容器id&gt;","link":"/2022/04/06/Docker%E9%83%A8%E7%BD%B2LNMP%E8%BF%90%E8%A1%8CMaxPHP/"},{"title":"FastCGI","text":"#什么是CGI CGI全称”通用网关接口”（Common Gateway Interface），用于HTTP服务器与其它机器上的程序服务通信交流的一种工具，CGI程序须运行在网络服务器上。 传统CGI接口方式的主要缺点是性能较差，因为每次HTTP服务器遇到动态程序时都需要重启解析器来执行解析，然后结果被返回给HTTP服务器。这在处理高并发访问几乎是不可用的，因此就诞生了FastCGI。另外传统的CGI接口方式安全性也很差。 什么是FastCGIFastCGI是一个可伸缩地、高速地在HTTP服务器和动态脚本语言间通信的接口（FastCGI接口在Linux下是socket（可以是文件socket，也可以是ip socket）），主要优点是把动态语言和HTTP服务器分离开来。多数流行的HTTP服务器都支持FastCGI，包括Apache、Nginx和lightpd。 同时，FastCGI也被许多脚本语言所支持，比较流行的脚本语言之一为PHP。FastCGI接口方式采用C/S架构，可以将HTTP服务器和脚本解析服务器分开，同时在脚本解析服务器上启动一个或多个脚本解析守护进程。当HTTP服务器每次遇到动态程序时，可以将其直接交付给FastCGI进程执行，然后将得到的结构返回给浏览器。这种方式可以让HTTP服务器专一地处理静态请求或者将动态脚本服务器的结果返回给客户端，这在很大程度上提高了整个应用系统的性能。 FastCGI的重要特点： 1、FastCGI是HTTP服务器和动态脚本语言间通信的接口或者工具。 2、FastCGI优点是把动态语言解析和HTTP服务器分离开来。 3、Nginx、Apache、Lighttpd以及多数动态语言都支持FastCGI。 4、FastCGI接口方式采用C/S架构，分为客户端（HTTP服务器）和服务端（动态语言解析服务器）。 5、PHP动态语言服务端可以启动多个FastCGI的守护进程。 6、HTTP服务器通过FastCGI客户端和动态语言FastCGI服务端通信。 Nginx FastCGI的运行原理Nginx不支持对外部动态程序的直接调用或者解析，所有的外部程序（包括PHP）必须通过FastCGI接口来调用。FastCGI接口在Linux下是socket（可以是文件socket，也可以是ip socket）。为了调用CGI程序，还需要一个FastCGI的wrapper，这个wrapper绑定在某个固定socket(套接字)上，如端口或者文件socket。当Nginx将CGI请求发送给这个socket的时候，通过FastCGI接口，wrapper接收到请求，然后派生出一个新的线程，这个线程调用解释器或者外部程序处理脚本并读取返回数据；接着，wrapper再将返回的数据通过FastCGI接口，沿着固定的socket传递给Nginx；最后，Nginx将返回的数据发送给客户端，这就是Nginx+FastCGI的整个运作过程。 Nginx+FastCGI运作过程 FastCGI的主要优点是把动态语言和HTTP服务器分离开来，是Nginx专一处理静态请求和向后转发动态请求，而PHP/PHP-FPM服务器专一解析PHP动态请求。 附： ngnix配置解释","link":"/2021/04/03/FastCGI/"},{"title":"Docker学习笔记","text":"Docker 官方文档地址:https://www.docker.com/get-started 中文参考手册:https://docker_practice.gitee.io/zh-cn/ 1.什么是 Docker1.1 官方定义 最新官网首页 1234# 1.官方介绍- We have a complete container solution for you - no matter who you are and where you are on your containerization journey.- 翻译: 我们为你提供了一个完整的容器解决方案,不管你是谁,不管你在哪,你都可以开始容器的的旅程。- 官方定义: docker是一个容器技术。 1.2 Docker的起源12345Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目 已经超过 5 万 7 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 OverlayFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。 2.为什么是Docker 在开发的时候，在本机测试环境可以跑，生产环境跑不起来 这里我们拿java Web应用程序举例，我们一个java Web应用程序涉及很多东西，比如jdk、tomcat、mysql等软件环境。当这些其中某一项版本不一致的时候，可能就会导致应用程序跑不起来这种情况。Docker则将程序以及使用软件环境直接打包在一起，无论在那个机器上保证了环境一致。 优势1: 一致的运行环境,更轻松的迁移 服务器自己的程序挂了，结果发现是别人程序出了问题把内存吃完了，自己程序因为内存不够就挂了 这种也是一种比较常见的情况，如果你的程序重要性不是特别高的话，公司基本上不可能让你的程序独享一台服务器的，这时候你的服务器就会跟公司其他人的程序共享一台服务器，所以不可避免地就会受到其他程序的干扰，导致自己的程序出现问题。Docker就很好解决了环境隔离的问题，别人程序不会影响到自己的程序。 优势2：对进程进行封装隔离,容器与容器之间互不影响,更高效的利用系统资源 公司要弄一个活动，可能会有大量的流量进来，公司需要再多部署几十台服务器 在没有Docker的情况下，要在几天内部署几十台服务器，这对运维来说是一件非常折磨人的事，而且每台服务器的环境还不一定一样，就会出现各种问题，最后部署地头皮发麻。用Docker的话，我只需要将程序打包到镜像，你要多少台服务，我就给力跑多少容器，极大地提高了部署效率。 优势3: 通过镜像复制N多个环境一致容器 3.Docker和虚拟机区别 关于Docker与虚拟机的区别，我在网上找到的一张图，非常直观形象地展示出来，话不多说，直接上图。 比较上面两张图，我们发现虚拟机是携带操作系统，本身很小的应用程序却因为携带了操作系统而变得非常大，很笨重。Docker是不携带操作系统的，所以Docker的应用就非常的轻巧。另外在调用宿主机的CPU、磁盘等等这些资源的时候，拿内存举例，虚拟机是利用Hypervisor去虚拟化内存，整个调用过程是虚拟内存-&gt;虚拟物理内存-&gt;真正物理内存，但是Docker是利用Docker Engine去调用宿主的的资源，这时候过程是虚拟内存-&gt;真正物理内存。 传统虚拟机 Docker容器 磁盘占用 几个GB到几十个GB左右 几十MB到几百MB左右 CPU内存占用 虚拟操作系统非常占用CPU和内存 Docker引擎占用极低 启动速度 （从开机到运行项目）几分钟 （从开启容器到运行项目）几秒 安装管理 需要专门的运维技术 安装、管理方便 应用部署 每次部署都费时费力 从第二次部署开始轻松简捷 耦合性 多个应用服务安装到一起，容易互相影响 每个应用服务一个容器，达成隔离 系统依赖 无 需求相同或相似的内核，目前推荐是Linux 4.Docker的安装4.1 安装docker(centos7.x) 卸载原始docker 12345678$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 安装docker依赖 123$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 设置docker的yum源 123$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 安装最新版的docker 1$ sudo yum install docker-ce docker-ce-cli containerd.io 指定版本安装docker 123$ yum list docker-ce --showduplicates | sort -r$ sudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io$ sudo yum install docker-ce-18.09.5-3.el7 docker-ce-cli-18.09.5-3.el7 containerd.io 启动docker 12$ sudo systemctl enable docker$ sudo systemctl start docker 关闭docker 1$ sudo systemctl stop docker 测试docker安装 1$ sudo docker run hello-world 4.2 bash安装(通用所有平台) 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，CentOS 系统上可以使用这套脚本安装，另外可以通过 --mirror 选项使用国内源进行安装：执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 的稳定(stable)版本安装在系统中。 12$ curl -fsSL get.docker.com -o get-docker.sh$ sudo sh get-docker.sh --mirror Aliyun 启动docker 12$ sudo systemctl enable docker$ sudo systemctl start docker 创建docker用户组 1$ sudo groupadd docker 将当前用户加入docker组 1$ sudo usermod -aG docker $USER 测试docker安装是否正确 1$ docker run hello-world 5.Docker 的核心架构 镜像: 一个镜像代表一个应用环境,他是一个只读的文件,如 mysql镜像,tomcat镜像,nginx镜像等 容器: 镜像每次运行之后就是产生一个容器,就是正在运行的镜像,特点就是可读可写 仓库:用来存放镜像的位置,类似于maven仓库,也是镜像下载和上传的位置 dockerFile:docker生成镜像配置文件,用来书写自定义镜像的一些配置 tar:一个对镜像打包的文件,日后可以还原成镜像 6. Docker 配置阿里镜像加速服务6.1 docker 运行流程 6.2 docker配置阿里云镜像加速 访问阿里云登录自己账号查看docker镜像加速服务 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;EOF{ &quot;registry-mirrors&quot;: [&quot;https://lz2nib3q.mirror.aliyuncs.com&quot;]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker 验证docker的镜像加速是否生效 1234567[root@localhost ~]# docker info .......... 127.0.0.0/8 Registry Mirrors: 'https://lz2nib3q.mirror.aliyuncs.com/' Live Restore Enabled: false Product License: Community Engine 7.Docker的入门应用7.1 docker 的第一个程序 docker run hello-world 12345678910111213141516171819202122[root@localhost ~]# docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 8.常用命令6.1 辅助命令1234# 1.安装完成辅助命令 docker version -------------------------- 查看docker的信息 docker info -------------------------- 查看更详细的信息 docker --help -------------------------- 帮助命令 6.2 Images 镜像命令12345678910111213141516# 1.查看本机中所有镜像 docker images -------------------------- 列出本地所有镜像 -a 列出所有镜像（包含中间映像层） -q 只显示镜像id# 2.搜索镜像 docker search [options] 镜像名 ------------------- 去dockerhub上查询当前镜像 -s 指定值 列出收藏数不少于指定值的镜像 --no-trunc 显示完整的镜像信息# 3.从仓库下载镜像 docker pull 镜像名[:TAG|@DIGEST] ----------------- 下载镜像# 4.删除镜像 docker rmi 镜像名 -------------------------- 删除镜像 -f 强制删除 6.3 Contrainer 容器命令12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 1.运行容器 docker run 镜像名 -------------------------- 镜像名新建并启动容器 --name 别名为容器起一个名字 -d 启动守护式容器（在后台启动容器） -p 映射端口号：原始端口号 指定端口号启动 --rm 这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 --rm 可以避免浪费空间。 例：docker run -it --name myTomcat -p 8888:8080 tomcat docker run -d --name myTomcat -P tomcat# 2.查看运行的容器 docker ps -------------------------- 列出所有正在运行的容器 -a 正在运行的和历史运行过的容器 -q 静默模式，只显示容器编号# 3.停止|关闭|重启容器 docker start 容器名字或者容器id --------------- 开启容器 docker restart 容器名或者容器id --------------- 重启容器 docker stop 容器名或者容器id ------------------ 正常停止容器运行 docker kill 容器名或者容器id ------------------ 立即停止容器运行# 4.删除容器 docker rm -f 容器id和容器名 docker rm -f $(docker ps -aq) -------------------------- 删除所有容器# 5.查看容器内进程 docker top 容器id或者容器名 ------------------ 查看容器内的进程# 6.查看查看容器内部细节 docker inspect 容器id ------------------ 查看容器内部细节# 7.查看容器的运行日志 docker logs [OPTIONS] 容器id或容器名 ------------------ 查看容器日志 -t 加入时间戳 -f 跟随最新的日志打印 --tail 数字 显示最后多少条# 8.进入容器内部 docker exec [options] 容器id 容器内命令 ------------------ 进入容器执行命令 -i 以交互模式运行容器，通常与-t一起使用 -t 分配一个伪终端 shell窗口 bash # 9.容器和宿主机之间复制文件 docker cp 文件|目录 容器id:容器路径 ----------------- 将宿主机复制到容器内部 docker cp 容器id:容器内资源路径 宿主机目录路径 ----------------- 将容器内资源拷贝到主机上# 10.数据卷(volum)实现与宿主机共享目录 docker run -v 宿主机的路径|任意别名:/容器内的路径 镜像名 注意: 1.如果是宿主机路径必须是绝对路径,宿主机目录会覆盖容器内目录内容 2.如果是别名则会在docker运行容器时自动在宿主机中创建一个目录,并将容器目录文件复制到宿主机中 3.如果宿主机是windows,则映射目录例如`-v /d/max:/home/mnt` 其中/d/max表示d盘的max目录# 11.打包镜像 docker save 镜像名 -o 名称.tar# 12.载入镜像 docker load -i 名称.tar# 13.容器打包成新的镜像 docker commit -m &quot;描述信息&quot; -a &quot;作者信息&quot; （容器id或者名称）打包的镜像名称:标签 7.docker的镜像原理7.1 镜像是什么？ 镜像是一种轻量级的，可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时所需的库、环境变量和配置文件。 7.2 为什么一个镜像会那么大？ 镜像就是花卷 UnionFS（联合文件系统）: Union文件系统是一种分层，轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。Union文件系统是Docker镜像的基础。这种文件系统特性:就是一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 。 7.3 Docker镜像原理 docker的镜像实际是由一层一层的文件系统组成。 bootfs（boot file system）主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统。在docker镜像的最底层就是bootfs。这一层与Linux/Unix 系统是一样的，包含boot加载器（bootloader）和内核（kernel）。当boot加载完,后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时会卸载bootfs。 rootfs（root file system），在bootfs之上，包含的就是典型的linux系统中的/dev，/proc，/bin，/etc等标准的目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu/CentOS等等。 我们平时安装进虚拟机的centos都有1到几个GB，为什么docker这里才200MB？对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令，工具，和程序库就可以了，因为底层直接使用Host的Kernal，自己只需要提供rootfs就行了。由此可见不同的linux发行版，他们的bootfs是一致的，rootfs会有差别。因此不同的发行版可以共用bootfs。 7.4 为什么docker镜像要采用这种分层结构呢? 最大的一个好处就是资源共享 比如：有多个镜像都是从相同的base镜像构建而来的，那么宿主机只需在磁盘中保存一份base镜像。同时内存中也只需要加载一份base镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。Docker镜像都是只读的。当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称为容器层，容器层之下都叫镜像层。 8.Docker安装常用服务8.1 安装mysql12345678910111213141516171819202122232425262728# 1.拉取mysql镜像到本地 docker pull mysql:tag (tag不加默认最新版本) # 2.运行mysql服务 docker run --name mysql -e MYSQL_ROOT_PASSWORD=root -d mysql:tag --没有暴露外部端口外部不能连接 docker run --name mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:tag --没有暴露外部端口# 3.进入mysql容器 docker exec -it 容器名称|容器id bash# 4.外部查看mysql日志 docker logs 容器名称|容器id# 5.使用自定义配置参数 docker run --name mysql -v /root/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -d mysql:tag# 6.将容器数据位置与宿主机位置挂载保证数据安全 docker run --name mysql -v /root/mysql/data:/var/lib/mysql -v /root/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:tag# 7.通过其他客户端访问 如在window系统|macos系统使用客户端工具访问 # 8.将mysql数据库备份为sql文件 docker exec mysql|容器id sh -c 'exec mysqldump --all-databases -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &gt; /root/all-databases.sql --导出全部数据 docker exec mysql sh -c 'exec mysqldump --databases 库表 -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &gt; /root/all-databases.sql --导出指定库数据 docker exec mysql sh -c 'exec mysqldump --no-data --databases 库表 -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &gt; /root/all-databases.sql --导出指定库数据不要数据# 9.执行sql文件到mysql中 docker exec -i mysql sh -c 'exec mysql -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;' &lt; /root/xxx.sql 8.2 安装Redis服务12345678910111213141516171819202122232425262728# 1.在docker hub搜索redis镜像 docker search redis# 2.拉取redis镜像到本地 docker pull redis# 3.启动redis服务运行容器 docker run --name redis -d redis:tag (没有暴露外部端口) docker run --name redis -p 6379:6379 -d redis:tag (暴露外部宿主机端口为6379进行连接) # 4.查看启动日志 docker logs -t -f 容器id|容器名称# 5.进入容器内部查看 docker exec -it 容器id|名称 bash # 6.加载外部自定义配置启动redis容器 默认情况下redis官方镜像中没有redis.conf配置文件 需要去官网下载指定版本的配置文件 1. wget http://download.redis.io/releases/redis-5.0.8.tar.gz 下载官方安装包 2. 将官方安装包中配置文件进行复制到宿主机指定目录中如 /root/redis/redis.conf文件 3. 修改需要自定义的配置 bind 0.0.0.0 开启远程权限 appenonly yes 开启aof持久化 4. 加载配置启动 docker run --name redis -v /root/redis:/usr/local/etc/redis -p 6379:6379 -d redis redis-server /usr/local/etc/redis/redis.conf # 7.将数据目录挂在到本地保证数据安全 docker run --name redis -v /root/redis/data:/data -v /root/redis/redis.conf:/usr/local/etc/redis/redis.conf -p 6379:6379 -d redis redis-server /usr/local/etc/redis/redis.conf 8.3 安装Nginx123456789101112131415161718192021222324252627# 1.在docker hub搜索nginx docker search nginx# 2.拉取nginx镜像到本地 [root@localhost ~]# docker pull nginx Using default tag: latest latest: Pulling from library/nginx afb6ec6fdc1c: Pull complete b90c53a0b692: Pull complete 11fa52a0fdc0: Pull complete Digest: sha256:30dfa439718a17baafefadf16c5e7c9d0a1cde97b4fd84f63b69e13513be7097 Status: Downloaded newer image for nginx:latest docker.io/library/nginx:latest# 3.启动nginx容器 docker run -p 80:80 --name nginx01 -d nginx# 4.进入容器 docker exec -it nginx01 /bin/bash 查找目录: whereis nginx 配置文件: /etc/nginx/nginx.conf# 5.复制配置文件到宿主机 docker cp nginx01(容器id|容器名称):/etc/nginx/nginx.conf 宿主机名录# 6.挂在nginx配置以及html到宿主机外部 docker run --name nginx02 -v /root/nginx/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/html:/usr/share/nginx/html -p 80:80 -d nginx 8.4 安装Tomcat123456789101112131415# 1.在docker hub搜索tomcat docker search tomcat# 2.下载tomcat镜像 docker pull tomcat# 3.运行tomcat镜像 docker run -p 8080:8080 -d --name mytomcat tomcat# 4.进入tomcat容器 docker exec -it mytomcat /bin/bash# 5.将webapps目录挂载在外部 docker run -p 8080:8080 -v /root/webapps:/usr/local/tomcat/webapps -d --name mytomcat tomcat 8.5 安装MongoDB数据库12345678910111213141516171819# 1.运行mongDB docker run -d -p 27017:27017 --name mymongo mongo ---无须权限 docker logs -f mymongo --查看mongo运行日志# 2.进入mongodb容器 docker exec -it mymongo /bin/bash 直接执行mongo命令进行操作# 3.常见具有权限的容器 docker run --name mymongo -p 27017:27017 -d mongo --auth# 4.进入容器配置用户名密码 mongo use admin 选择admin库 db.createUser({user:&quot;root&quot;,pwd:&quot;root&quot;,roles:[{role:'root',db:'admin'}]}) //创建用户,此用户创建成功,则后续操作都需要用户认证 exit# 5.将mongoDB中数据目录映射到宿主机中 docker run -d -p 27017:27017 -v /root/mongo/data:/data/db --name mymongo mongo 8.6 安装ElasticSearch 注意:调高JVM线程数限制数量 0.拉取镜像运行elasticsearch123456# 1.dockerhub 拉取镜像 docker pull elasticsearch:6.4.2# 2.查看docker镜像 docker images# 3.运行docker镜像 docker run -p 9200:9200 -p 9300:9300 elasticsearch:6.4.2 启动出现如下错误 1. 预先配置123456789# 1.在centos虚拟机中，修改配置sysctl.conf vim /etc/sysctl.conf# 2.加入如下配置 vm.max_map_count=262144 # 3.启用配置 sysctl -p 注：这一步是为了防止启动容器时，报出如下错误： bootstrap checks failed max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 2.启动EleasticSearch容器1234# 0.复制容器中data目录到宿主机中 docker cp 容器id:/usr/share/share/elasticsearch/data /root/es# 1.运行ES容器 指定jvm内存大小并指定ik分词器位置 docker run -d --name es -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=&quot;-Xms128m -Xmx128m&quot; -v /root/es/plugins:/usr/share/elasticsearch/plugins -v /root/es/data:/usr/share/elasticsearch/data elasticsearch:6.4.2 3.安装IK分词器123456789101112131415161718192021222324252627# 1.下载对应版本的IK分词器 wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.4.2/elasticsearch-analysis-ik-6.4.2.zip# 2.解压到plugins文件夹中 yum install -y unzip unzip -d ik elasticsearch-analysis-ik-6.4.2.zip# 3.添加自定义扩展词和停用词 cd plugins/elasticsearch/config vim IKAnalyzer.cfg.xml &lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=&quot;ext_dict&quot;&gt;ext_dict.dic&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=&quot;ext_stopwords&quot;&gt;ext_stopwords.dic&lt;/entry&gt; &lt;/properties&gt;# 4.在ik分词器目录下config目录中创建ext_dict.dic文件 编码一定要为UTF-8才能生效 vim ext_dict.dic 加入扩展词即可# 5. 在ik分词器目录下config目录中创建ext_stopword.dic文件 vim ext_stopwords.dic 加入停用词即可# 6.重启容器生效 docker restart 容器id# 7.将此容器提交成为一个新的镜像 docker commit -a=&quot;xiaochen&quot; -m=&quot;es with IKAnalyzer&quot; 容器id xiaochen/elasticsearch:6.4.2 4. 安装Kibana12345# 1.下载kibana镜像到本地 docker pull kibana:6.4.2# 2.启动kibana容器 docker run -d --name kibana -e ELASTICSEARCH_URL=http://10.15.0.3:9200 -p 5601:5601 kibana:6.4.2 10.Docker中出现如下错误解决方案12[root@localhost ~]# docker search mysql 或者 docker pull 这些命令无法使用Error response from daemon: Get https://index.docker.io/v1/search?q=mysql&amp;n=25: x509: certificate has expired or is not yet valid 注意:这个错误的原因在于是系统的时间和docker hub时间不一致,需要做系统时间与网络时间同步 1234567# 1.安装时间同步 sudo yum -y install ntp ntpdate# 2.同步时间 sudo ntpdate cn.pool.ntp.org# 3.查看本机时间 date# 4.从新测试 9.Dockerfile9.1 什么是DockerfileDockerfile可以认为是Docker镜像的描述文件，是由一系列命令和参数构成的脚本。主要作用是用来构建docker镜像的构建文件。 通过架构图可以看出通过DockerFile可以直接构建镜像 9.2 Dockerfile解析过程 9.3 Dockerfile的保留命令官方说明:https://docs.docker.com/engine/reference/builder/ 保留字 作用 FROM 当前镜像是基于哪个镜像的 第一个指令必须是FROM MAINTAINER 镜像维护者的姓名和邮箱地址 RUN 构建镜像时需要运行的指令 EXPOSE 当前容器对外暴露出的端口号 WORKDIR 指定在创建容器后，终端默认登录进来的工作目录，一个落脚点 ENV 用来在构建镜像过程中设置环境变量 ADD 将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar包 COPY 类似于ADD，拷贝文件和目录到镜像中将从构建上下文目录中&lt;原路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置 VOLUME 容器数据卷，用于数据保存和持久化工作 CMD 指定一个容器启动时要运行的命令Dockerfile中可以有多个CMD指令，但只有最后一个生效，CMD会被docker run之后的参数替换 ENTRYPOINT 指定一个容器启动时要运行的命令ENTRYPOINT的目的和CMD一样，都是在指定容器启动程序及其参数 9.3.1 FROM 命令 基于那个镜像进行构建新的镜像,在构建时会自动从docker hub拉取base镜像 必须作为Dockerfile的第一个指令出现 语法: 123FROM &lt;image&gt;FROM &lt;image&gt;[:&lt;tag&gt;] 使用版本不写为latestFROM &lt;image&gt;[@&lt;digest&gt;] 使用摘要 9.3.2 MAINTAINER 命令 镜像维护者的姓名和邮箱地址[废弃] 语法: 1MAINTAINER &lt;name&gt; 9.3.3 RUN 命令 RUN指令将在当前映像之上的新层中执行任何命令并提交结果。生成的提交映像将用于Dockerfile中的下一步 语法: 12345RUN &lt;command&gt; (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows)RUN echo helloRUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form)RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;] 9.3.4 EXPOSE 命令 用来指定构建的镜像在运行为容器时对外暴露的端口 语法: 12EXPOSE 80/tcp 如果没有显示指定则默认暴露都是tcpEXPOSE 80/udp 9.3.5 CMD 命令 用来为启动的容器指定执行的命令,在Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。 注意: Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。 语法: 123CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (exec form, this is the preferred form)CMD [&quot;param1&quot;,&quot;param2&quot;] (as default parameters to ENTRYPOINT)CMD command param1 param2 (shell form) 9.3.6 WORKDIR 命令 用来为Dockerfile中的任何RUN、CMD、ENTRYPOINT、COPY和ADD指令设置工作目录。如果WORKDIR不存在，即使它没有在任何后续Dockerfile指令中使用，它也将被创建。 语法: 123456WORKDIR /path/to/workdirWORKDIR /aWORKDIR bWORKDIR c`注意:WORKDIR指令可以在Dockerfile中多次使用。如果提供了相对路径，则该路径将与先前WORKDIR指令的路径相对` 9.3.7 ENV 命令 用来为构建镜像设置环境变量。这个值将出现在构建阶段中所有后续指令的环境中。 语法： 12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key&gt;=&lt;value&gt; ... 9.3.8 ADD 命令 用来从context上下文复制新文件、目录或远程文件url，并将它们添加到位于指定路径的映像文件系统中。 语法: 12345ADD hom* /mydir/ 通配符添加多个文件ADD hom?.txt /mydir/ 通配符添加ADD test.txt relativeDir/ 可以指定相对路径ADD test.txt /absoluteDir/ 也可以指定绝对路径ADD url 9.3.9 COPY 命令 用来将context目录中指定文件复制到镜像的指定目录中 语法: 12COPY src destCOPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] 9.3.10 VOLUME 命令 用来定义容器运行时可以挂在到宿主机的目录 语法: 1VOLUME [&quot;/data&quot;] 9.3.11 ENTRYPOINT命令 用来指定容器启动时执行命令和CMD类似 语法: 12 [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]ENTRYPOINT command param1 param2 ENTRYPOINT指令，往往用于设置容器启动后的第一个命令，这对一个容器来说往往是固定的。CMD指令，往往用于设置容器启动的第一个命令的默认参数，这对一个容器来说可以是变化的。 9.3.11 ENTRYPOINT命令9.4 Dockerfile构建springboot项目部署1.准备springboot可运行项目 2.将可运行项目放入linux虚拟机中 3.编写Dockerfile123456FROM openjdk:8WORKDIR /emsADD ems.jar /emsEXPOSE 8989ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;]CMD [&quot;ems.jar&quot;] 4.构建镜像1[root@localhost ems]# docker build -t ems . 5.运行镜像1[root@localhost ems]# docker run -p 8989:8989 ems 6.访问项目1http://10.15.0.8:8989/ems/login.html 10.高级网络配置10.1 说明当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。 同时，Docker 随机分配一个本地未占用的私有网段（在 RFC1918 中定义）中的一个地址给 docker0 接口。比如典型的 172.17.42.1，掩码为 255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段（172.17.0.0/16）的地址。 当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头（例如 vethAQI2QT）。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。 10.2 查看网络信息1# docker network ls 10.3 创建一个网桥1# docker network create -d bridge 网桥名称 10.4 删除一个网桥1# docker network rm 网桥名称 10.5 容器之前使用网络通信12# 1.查询当前网络配置- docker network ls 1234NETWORK ID NAME DRIVER SCOPE8e424e5936b7 bridge bridge local17d974db02da docker_gwbridge bridge locald6c326e433f7 host host local 12# 2.创建桥接网络- docker network create -d bridge info 12345678[root@centos ~]# docker network create -d bridge info6e4aaebff79b1df43a064e0e8fdab08f52d64ce34db78dd5184ce7aaaf550a2f[root@centos ~]# docker network lsNETWORK ID NAME DRIVER SCOPE8e424e5936b7 bridge bridge local17d974db02da docker_gwbridge bridge locald6c326e433f7 host host local6e4aaebff79b info bridge local 1234# 3.启动容器指定使用网桥- docker run -d -p 8890:80 --name nginx001 --network info nginx - docker run -d -p 8891:80 --name nginx002 --network info nginx `注意:一旦指定网桥后--name指定名字就是主机名,多个容器指定在同一个网桥时,可以在任意一个容器中使用主机名与容器进行互通` 12345678910111213141516[root@centos ~]# docker run -d -p 8890:80 --name nginx001 --network info nginx c315bcc94e9ddaa36eb6c6f16ca51592b1ac8bf1ecfe9d8f01d892f3f10825fe[root@centos ~]# docker run -d -p 8891:80 --name nginx002 --network info nginxf8682db35dd7fb4395f90edb38df7cad71bbfaba71b6a4c6e2a3a525cb73c2a5[root@centos ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf8682db35dd7 nginx &quot;/docker-entrypoint.…&quot; 3 seconds ago Up 2 seconds 0.0.0.0:8891-&gt;80/tcp nginx002c315bcc94e9d nginx &quot;/docker-entrypoint.…&quot; 7 minutes ago Up 7 minutes 0.0.0.0:8890-&gt;80/tcp nginx001b63169d43792 mysql:5.7.19 &quot;docker-entrypoint.s…&quot; 7 minutes ago Up 7 minutes 3306/tcp mysql_mysql.1.s75qe5kkpwwttyf0wrjvd2cda[root@centos ~]# docker exec -it f8682db35dd7 /bin/bashroot@f8682db35dd7:/# curl http://nginx001&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;..... 11.高级数据卷配置11.1 说明数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性： 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。 11.2 创建数据卷12[root@centos ~]# docker volume create my-volmy-vol 11.3 查看数据卷123456789101112[root@centos ~]# docker volume inspect my-vol [ { &quot;CreatedAt&quot;: &quot;2020-11-25T11:43:56+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: {}, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/my-vol/_data&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Options&quot;: {}, &quot;Scope&quot;: &quot;local&quot; }] 11.4 挂载数据卷1234567891011121314[root@centos ~]# docker run -d -P --name web -v my-vol:/usr/share/nginx/html nginx[root@centos ~]# docker inspect web &quot;Mounts&quot;: [ { &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/my-vol/_data&quot;, &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;z&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; } ], 11.5 删除数据卷1docker volume rm my-vol 12.Docker Compose12.1 简介Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。 其代码目前在 https://github.com/docker/compose 上开源。 Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。 通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 12.2 安装与卸载1.linux 在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。例如，在 Linux 64 位系统上直接下载对应的二进制包。 12$ sudo curl -L https://github.com/docker/compose/releases/download/1.25.5/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose$ sudo chmod +x /usr/local/bin/docker-compose 2.macos、window Compose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。Docker Desktop for Mac/Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。 3.bash命令补全1$ curl -L https://raw.githubusercontent.com/docker/compose/1.25.5/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose 4.卸载 如果是二进制包方式安装的，删除二进制文件即可。 1$ sudo rm /usr/local/bin/docker-compose 5.测试安装成功12$ docker-compose --version docker-compose version 1.25.5, build 4667896b 12.3 docker compose使用1# 1.相关概念 首先介绍几个术语。 服务 (service)：一个应用容器，实际上可以运行多个相同镜像的实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元。∂一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理。 1# 2.场景 最常见的项目是 web 网站，该项目应该包含 web 应用和缓存。 springboot应用 mysql服务 redis服务 elasticsearch服务 ……. 12# 3.docker-compose模板- 参考文档:https://docker_practice.gitee.io/zh-cn/compose/compose_file.html 12345678910111213141516171819202122232425262728293031version: &quot;3.0&quot;services: mysqldb: image: mysql:5.7.19 container_name: mysql ports: - &quot;3306:3306&quot; volumes: - /root/mysql/conf:/etc/mysql/conf.d - /root/mysql/logs:/logs - /root/mysql/data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: root networks: - ems depends_on: - redis redis: image: redis:4.0.14 container_name: redis ports: - &quot;6379:6379&quot; networks: - ems volumes: - /root/redis/data:/data command: redis-server networks: ems: 12# 4.通过docker-compose运行一组容器- 参考文档:https://docker_practice.gitee.io/zh-cn/compose/commands.html 12[root@centos ~]# docker-compose up //前台启动一组服务[root@centos ~]# docker-compose up -d //后台启动一组服务 12.4 docker-compose 模板文件模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。 默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。 123456789version: &quot;3&quot;services: webapp: image: examples/web ports: - &quot;80:80&quot; volumes: - &quot;/data&quot; 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。 如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中重复设置。 下面分别介绍各个指令的用法。 build指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。 12345version: '3'services: webapp: build: ./dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。 使用 dockerfile 指令指定 Dockerfile 文件名。 使用 arg 指令指定构建镜像时的变量。 123456789version: '3'services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 command覆盖容器启动后默认执行的命令。 1command: echo &quot;hello world&quot; container_name指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。 1container_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。 depends_on解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web 1234567891011121314version: '3'services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。 env_file从文件中获取环境变量，可以为单独的文件路径或列表。 如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。 如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 123456env_file: .envenv_file: - ./common.env - ./apps/web.env - /opt/secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。 12# common.env: Set development environmentPROG_ENV=development environment设置环境变量。你可以使用数组或字典两种格式。 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。 1234567environment: RACK_ENV: development SESSION_SECRET:environment: - RACK_ENV=development - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括 1y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF healthcheck通过命令检查容器是否健康运行。 12345healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] interval: 1m30s timeout: 10s retries: 3 image指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 123image: ubuntuimage: orchardup/postgresqlimage: a4bc65fd networks配置容器连接的网络。 1234567891011version: &quot;3&quot;services: some-service: networks: - some-network - other-networknetworks: some-network: other-network: ports暴露端口信息。 使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 12345ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; 注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 sysctls配置容器内核参数。 1234567sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits指定容器的 ulimits 限制值。 例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 12345ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes数据卷所挂载路径设置。可以设置为宿主机路径(HOST:CONTAINER)或者数据卷名称(VOLUME:CONTAINER)，并且可以设置访问模式 （HOST:CONTAINER:ro）。 该指令中路径支持相对路径。 1234volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro 如果路径为数据卷名称，必须在文件中配置数据卷。 12345678910version: &quot;3&quot;services: my_src: image: mysql:8.0 volumes: - mysql_data:/var/lib/mysqlvolumes: mysql_data: 12.5 docker-compose 常用命令1. 命令对象与格式对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。 执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。 docker-compose 命令的基本的使用格式是 1docker-compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS...] 2. 命令选项 -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 --x-networking 使用 Docker 的可拔插网络后端特性 --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge --verbose 输出更多调试信息。 -v, --version 打印版本并退出。 3.命令使用说明up格式为 docker-compose up [options] [SERVICE...]。 该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。 链接的服务都将会被自动启动，除非已经处于运行状态。 可以说，大部分时候都可以直接通过该命令来启动一个项目。 默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。 当通过 Ctrl-C 停止命令时，所有容器将会停止。 如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。 默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容 down 此命令将会停止 up 命令所启动的容器，并移除网络 exec 进入指定的容器。 ps格式为 docker-compose ps [options] [SERVICE...]。 列出项目中目前的所有容器。 选项： -q 只打印容器的 ID 信息。 restart格式为 docker-compose restart [options] [SERVICE...]。 重启项目中的服务。 选项： -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm格式为 docker-compose rm [options] [SERVICE...]。 删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 选项： -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 start格式为 docker-compose start [SERVICE...]。 启动已经存在的服务容器。 stop格式为 docker-compose stop [options] [SERVICE...]。 停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top查看各个服务容器内运行的进程。 unpause格式为 docker-compose unpause [SERVICE...]。 恢复处于暂停状态中的服务。 13.docker可视化工具13.1 安装Portainer官方安装说明：https://www.portainer.io/installation/ 123456789[root@ubuntu1804 ~]#docker pull portainer/portainer[root@ubuntu1804 ~]#docker volume create portainer_dataportainer_data[root@ubuntu1804 ~]#docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer20db26b67b791648c2ef6aee444a5226a9c897ebcf0160050e722dbf4a4906e3[root@ubuntu1804 ~]#docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES20db26b67b79 portainer/portainer &quot;/portainer&quot; 5 seconds ago Up 4 seconds 0.0.0.0:8000-&gt;8000/tcp, 0.0.0.0:9000-&gt;9000/tcp portainer 13.2 登录和使用Portainer 用浏览器访问：http://localhost:9000 更换docker源国内镜像源总览 名称 路径 中国官方镜像 https://registry.docker-cn.com 网易163镜像 http://hub-mirror.c.163.com 中科大镜像 https://docker.mirrors.ustc.edu.cn 阿里云镜像 https://[xxx].mirror.aliyuncs.com DaoCloud镜像 http://[xxx].m.daocloud.io 阿里云镜像源 访问：https://cr.console.aliyun.com/#/accelerator DaoCloud镜像源 访问：https://www.daocloud.io/ 配置镜像源123456789101112131415161718192021vi /etc/docker/daemon.json# 内容如下：{ &quot;registry-mirrors&quot;: [ &quot;https://xx4bwyg2.mirror.aliyuncs.com&quot;, &quot;http://f1361db2.m.daocloud.io&quot;, &quot;https://registry.docker-cn.com&quot;, &quot;http://hub-mirror.c.163.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot; ]}{}# 退出并保存:wq# 使配置生效systemctl daemon-reload# 重启Dockersystemctl restart docker 更换debian源首先我们需要知道发行版本 输入uname -a,可显示电脑以及操作系统的相关信息 输入cat /etc/issue, 显示的是发行版本信息 输入cat /proc/version,说明正在运行的内核版本。 当然你可以直接使用 1cat /etc/apt/sources.list 来查看，然后打开阿里云源复制相应源 https://developer.aliyun.com/mirror/ 然后修改成下面的样子 12345678echo &quot;deb http://mirrors.aliyun.com/debian/ bullseye main non-free contrib&quot; &gt; /etc/apt/sources.listecho &quot;deb-src http://mirrors.aliyun.com/debian/ bullseye main non-free contrib&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb http://mirrors.aliyun.com/debian-security/ bullseye-security main&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb-src http://mirrors.aliyun.com/debian-security/ bullseye-security main&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb http://mirrors.aliyun.com/debian/ bullseye-updates main non-free contrib&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb-src http://mirrors.aliyun.com/debian/ bullseye-updates main non-free contrib&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb http://mirrors.aliyun.com/debian/ bullseye-backports main non-free contrib&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb-src http://mirrors.aliyun.com/debian/ bullseye-backports main non-free contrib&quot; &gt;&gt; /etc/apt/sources.list 贴入执行即可，你可以用()将命令括起来。 或者执行 12345678910tee /etc/apt/sources.list &lt;&lt;-'ET'deb http://mirrors.aliyun.com/debian/ bullseye main non-free contribdeb-src http://mirrors.aliyun.com/debian/ bullseye main non-free contribdeb http://mirrors.aliyun.com/debian-security/ bullseye-security maindeb-src http://mirrors.aliyun.com/debian-security/ bullseye-security maindeb http://mirrors.aliyun.com/debian/ bullseye-updates main non-free contribdeb-src http://mirrors.aliyun.com/debian/ bullseye-updates main non-free contribdeb http://mirrors.aliyun.com/debian/ bullseye-backports main non-free contribdeb-src http://mirrors.aliyun.com/debian/ bullseye-backports main non-free contribET 你也可以直接复制到容器 1docker cp /etc/apt/sources.list 容器id:/etc/apt/sources.list 容器管理容器是镜像运行后的一种状态，一个镜像可以创建多个容器，镜像是不可写的，一旦运行后成容器就变成可写的状态；容器也可以导出、导入。 容器的命令选项 选项 描述 -i,–interactive 交互式 -t,–tty 分配一个伪终端 -d,–detach 运行容器到后台 -e,–env 设置环境变量 -p,–publish list 发布容器端口到主机 -P,–publish-all 发布容器所有EXPOSE的端口到宿主机随机端口 –name string 指定容器名称 -h,–hostname 设置容器主机名 –ip string 指定容器IP,只能用于自定义网络 –network 连接容器到一个网络 –mount mount 将文件系统附加到容器 -v ,–vloume list 绑定挂载一个卷 –restart string 容器退出时重启策略，默认no,可选值[always on-failure] 例：docker run -itd -e hello=123 -e abc=123 -p 88:80 –name=nginx-v1 -h nginx-test –restart=always nginx解析：-itd 交互、伪终端、后台运行-e 环境变量-p 宿主机的88端口映射容器的80端口–name 定义容器名字为nginx-v1-h 定义容器主机名为nginx-test–restart=always 当容器退出时，尝试重启，开机启动的意思nginx 最后跟镜像名称 三、容器资源限制 选项 描述 -m,–memory 容器可以使用的最大内存量 –memory-swap 允许交换到磁盘的内存量 –memory-swappiness=&lt;0-100&gt; 容器使用SWAP分区的百分比 –oom-lill-disable 禁用OOM Killer –cpus 可以使用的CPU数量 –cpuset-cpus 限制容器使用特定的CPU核心，如（0-3,0,1） –cpu-shares cpu共享（相对权重） 例：#docker run -d -m 512M nginx-v1#docker run -d –cpus=’1.5’ nginx内存限额允许容器最多使用500M内存和100M的Swap,并禁用OOM Killer:docker run -d –name nginx03 –nemory=”500m” –memory-swap=”600m” –oom-kill-disable nginxCPU限额：允许容器最多使用一个半CPUdocker run -d –name nginx04 –cpus=”1.5” nginx允许容器最多使用50%的CPUdocker run -d –name nginx05 –cpus=”0.5” nginx 查看docker容器占用宿主机资源#docker stats nginx-v1这样是交互式显示，不易来监控指标#docker stats –help#docker stats –no stream nginx-v1 四、管理容器的常用命令 选项 描述 ls 列出容器 inspect 查看一个或多个容器详细信息 exec 在运行容器中执行命令 commit 创建一个新镜像来自一个容器 cp 拷贝文件、文件夹到一个容器 logs 获取一个容器日志 port 列出或指定容器端口映射 top 显示一个容器运行的进程 stats 显示容器资源使用统计 stop/start/restart 停止/启动一个或多个容器 rm 删除一个或多个容器 查看容器中的目录#docker exec id ls进入容器docker exec -it id bash 其他命令用法 查看镜像，容器，数据卷占用的空间 1docker system df","link":"/2021/12/12/Docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"ElasticSearch 使用笔记","text":"Docker 启动拉取镜像1docker pull elasticsearch 启动容器1docker run -d --name elasticsearch --net somenetwork -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elasticsearch:tag Elasticsearch 8.0报错：received plaintext http traffic on an https channel, closing connection原因：是因为ES8默认开启了 ssl 认证。 修改elasticsearch.yml配置文件，改为flase 1xpack.security.enabled: false 基本概念 近实时（NRT）数据写入到可被搜索有大概1秒小延时 Cluster 包含多个节点 Node 节点 Document 文档，es最小数据单元，每个index的type下都可以存储多个document Index 索引，一个index可以有type，表示逻辑上的分类，一个type下的document都有相同field（字段） Shard (primary shard) 分片：index会被拆分为多个shard，每个shard会存放部分数据，shard会散落在多台服务器 （横向扩展：比如数据由1t增加到4t，则可以重新建立有4个shard的索引，数据分布在多台服务器上，所有的操作会在多台服务器上分布式并行执行。可以提高吞吐量）建立索引时设置，不能修改，默认5个。 replica （replica shard）副本：某一个node宕机，在另外一个节点会有replica，用户依然可以搜索，请求直接打到replica。高可用，提高搜索吞吐量和性能。可以修改，默认1个。 index和type区别以及如何选择对于 ES 的新用户来说，有一个常见的问题：要存储一批新数据时，应该在已有 index 里新建一个 type，还是给它新建一个 index？要想回答这个问题，我们必须先理解这两者是怎么实现的。 在过去，我们试图通过与关系数据库建立类比来使弹性搜索更容易理解：索引index就像数据库一样，类型type似于数据库中的表。这是一个错误：数据的存储方式是如此不同，以至于任何比较几乎都没有意义，这最终会导致在有害的情况下过度使用类型。 index 是什么索引index存储在一系列分片中，它们本身就是Lucene index。所以使用新索引应该注意：Lucene索引在磁盘空间，内存使用和使用的文件描述符方面有一个小而固定的开销。因此，单个大index比几个小index效率更高，Lucene index的固定开销更好地摊销在多个文档中。 另一个重要因素是如何搜索数据,虽然每个分片都是独立搜索的，但Elasticsearch最终需要合并所有搜索分片的结果。例如，搜索10个index,每个index有5个分片，则协调搜索请求执行的节点将需要合并5x10 = 50个分片结果。在这里需要注意：如果有太多的分片结果要合并，或者运行了一个产生大量分片响应的大量请求，合并这些分片结果的任务会非常消耗CPU和内存资源。这也是提倡少用index的原因。 type是什么使用type允许我们在一个index里存储多种类型的数据，这样就可以减少index的数量了。在使用时，向每个文档加入_type 字段，在指定type搜索时就会被用于过滤。使用type的一个好处是，搜索一个index下的多个type，和只搜索一个type相比没有额外的开销 —— 需要合并结果的分片数量是一样的。 但是，这也是有限制的： 不同type里的字段需要保持一致。例如，一个index下的不同type里有两个名字相同的字段，他们的类型（string, date 等等）和配置也必须相同。 只在某个type里存在的字段，在其他没有该字段的 type 中也会消耗资源。这是Lucene Index带来的常见问题：它不喜欢稀疏。由于连续文档之间的差异太大，稀疏的 posting list 的压缩效率不高。这个问题在 doc value 上更为严重：为了提高速度，doc value 通常会为每个文档预留一个固定大小的空间，以便文档可以被高速检索。这意味着，如果 Lucene 确定它需要一个字节来存储某个数字类型的字段，它同样会给没有这个字段的文档预留一个字节。未来版本的 ES 会在这方面做一些改进，但是我仍然建议你在建模的时候尽量避免稀疏。[1] 得分是由index内的统计数据来决定的。也就是说，一个 type 中的文档会影响另一个 type 中的文档的得分。 这意味着，只有同一个index的中的 type 都有类似的映射 (mapping) 时，才应该使用 type。否则，使用多个type可能比使用多个index消耗的资源更多。 如何选择这是个困难的问题，它的答案取决于你用的硬件、数据和用例。首先你要明白 type 是有用的，因为它能减少 ES 需要管理的Lucene Index的数量。但是也有另外一种方式可以减少这个数量：创建 index 的时候让它的分片少一些。例如，与其在一个 index 里塞上 5 个 type，不如创建 5 个只有一个分片的 index。 在你做决定的时候可以问自己下面几个问题： 你需要使用父子文档吗？如果需要，只能在一个 index 里建立多个 type。 你的文档的映射是否相似？如果不相似，使用多个 index。 如果你的每个 type 都有足够多的文档，Lucene Index 的开销可以被分摊掉，你就可以安全的使用多个 index 了。如果有必要的话，可以把分片数量设小一点。 如果文档不够多，你可以考虑把文档放进一个 index 里的多个 type 里，甚至放进一个 type 里。 总之，你可能有点惊讶，因为 type 的使用场景没有你想象的多，这是正确的。由于我们上面提到原因，在一个 index 中使用多个 type 的情景其实很少。如果你的数据有不同的映射，那就给他们分配不同的 index。但是请记住，如果不需要很高的写入吞吐量，或者存储的文档数量不多，你可以通过减少 index 的分片来使集群中的分片数量保持合理。 [1] posting list 和 doc value 都是 Lucene 的压缩技术，原理是保存后一个文档和前一个文档的差异，而不是完整的文档。 数据类型 ElasticSearch“真正用于分隔数据的结构“只有index，而没有type，type实际上作为了一个元数据（类似SQL中的id，作为额外的标识数据）来实现逻辑划分。 ES常用的数据类型可分为3大类：核⼼数据类型、复杂数据类型、专⽤数据类型 核心数据类型 text, keywordtext支持分词，全文索引，模糊查询，不支持聚合，排序。 特点是最大长度无限制，可以用来存储邮箱，地址，代码块，博客内容等，默认结合standard analyzer对文本分词，倒排索引，进行词命中，词频相关度打分 keyword不分词，直接u偶姻，支持模糊、精确匹配，支持聚合、排序。最大长度32766个utf-8编码的字符，可以通过设置ignore_above指定自持字符长度，超过长度的数据不被索引，无法通过term精确匹配，可以存储邮箱、手机、主机名、标签、年龄等。直接将完整的文本数据保存到倒排索引中 数字类型：long, integer, short, byte, double, float, half_float, scaled_float 日期：date 日期 纳秒：date_nanos 布尔型：boolean Binary：binary Range: integer_range, float_range, long_range, double_range, date_range RestApi 请求须指定文档的索引名称，唯一的文档 ID，以及请求体中一个或多个键值对, 带用户名密码查询需要加参数 –user user:passwd 列出所有 _cat命令 GET _cat/ 显示所有索引并按照存储大小排序 GET _cat/indices?v&amp;s=store.size:desc 获取集群状态 GET _cat/health 当使用v参数是 会显示列名的详细信息 GET _cat/health?v 显示所有的node信息 GET _cat/nodes?v 只显示ip和load_5m这两列 GET _cat/nodes?v&amp;h=ip,load_5m 通过json格式显示输出 GET _cat/indices?v&amp;format=json&amp;pretty 修改密码1curl -H &quot;Content-Type:application/json&quot; -XPOST -u elastic 'http://127.0.0.1:9200/_xpack/security/user/elastic/_password' -d '{ &quot;password&quot; : &quot;123456&quot; }' 创建索引1PUT /user 12345678910111213{ &quot;settings&quot;: { &quot;number_of_shards&quot;: 3, &quot;number_of_replicas&quot;: 2 }, &quot;mappings&quot;: { &quot;properties&quot;: { &quot;name&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }} 可以设置分片数量和副本数量，定义mappings 修改索引设置 PUT /index/_settings 123{ &quot;number_of_replicas&quot;: 3} 查看映射 GET /user/_mapping 1234567891011121314151617181920{ &quot;user&quot;: { &quot;mappings&quot;: { &quot;properties&quot;: { &quot;name&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } }, &quot;age&quot;: { &quot;type&quot;: &quot;long&quot; } } } }} 查看单个字段 GET /user/_mapping/field/address 1234567891011121314151617181920{ &quot;user&quot;: { &quot;mappings&quot;: { &quot;address&quot;: { &quot;full_name&quot;: &quot;address&quot;, &quot;mapping&quot;: { &quot;address&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 25 } } } } } } }} 新建映射 PUT /user/_mapping 1234567891011121314{ &quot;properties&quot;: { &quot;address&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } } }} 修改映射text类型不能转为long类型 新增文档 PUT /index/_doc/1 如果ID相同则更新 请求 123{ &quot;name&quot;: &quot;john&quot;} 响应 1234567891011121314{ &quot;_index&quot;: &quot;index&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 3, &quot;result&quot;: &quot;deleted&quot;, &quot;_shards&quot;: { &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 }, &quot;_seq_no&quot;: 2, &quot;_primary_term&quot;: 1} 索引index不存在则自动创建 bulk bulk是es提供的一种批量增删改的操作API。 bulk对JSON串的有着严格的要求。每个JSON串不能换行，只能放在同一行，同时，相邻的JSON串之间必须要有换行（Linux下是\\n；Window下是\\r\\n）。bulk的每个操作必须要一对JSON串（delete语法除外）。 12345{ action: { metadata }}{ request body }{ action: { metadata }}{ request body } 例如： POST http://127.0.0.1:9200/_bulk 12345{&quot;create&quot;: {&quot;_index&quot;: &quot;index&quot;, &quot;_type&quot;: &quot;doc&quot;, &quot;_id&quot;: 1}}{&quot;name&quot;: &quot;张三&quot;}{&quot;create&quot;: {&quot;_index&quot;: &quot;index&quot;, &quot;_type&quot;: &quot;doc&quot;, &quot;_id&quot;: 2}}{&quot;name&quot;: &quot;李四&quot;} 上面的请求也可以使用 POST http://127.0.0.1:9200/index/doc/_bulk {“_id”: 1} 12345678910111213141516171819202122232425262728293031323334353637383940{ &quot;took&quot;: 151, &quot;errors&quot;: false, &quot;items&quot;: [ { &quot;create&quot;: { &quot;_index&quot;: &quot;index&quot;, &quot;_type&quot;: &quot;doc&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: { &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 }, &quot;_seq_no&quot;: 0, &quot;_primary_term&quot;: 1, &quot;status&quot;: 201 } }, { &quot;create&quot;: { &quot;_index&quot;: &quot;index&quot;, &quot;_type&quot;: &quot;doc&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: { &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 }, &quot;_seq_no&quot;: 1, &quot;_primary_term&quot;: 1, &quot;status&quot;: 201 } } ]} 常用操作 create 如果文档不存在就创建，但如果文档存在就返回错误 index 如果文档不存在就创建，如果文档存在就更新 [常用] update 更新一个文档，如果文档不存在就返回错误 delete 删除一个文档，如果要删除的文档id不存在，就返回错误 某一个操作失败，是不会影响其他文档的操作的，它会在返回结果中告诉你失败的详细的原因。 更新操作 POST example/docs/_bulk 123456789{&quot;update&quot;: {&quot;_id&quot;: 1}}{&quot;doc&quot;: {&quot;id&quot;:1, &quot;name&quot;: &quot;admin-02&quot;, &quot;counter&quot;:&quot;11&quot;}}{&quot;update&quot;: {&quot;_id&quot;: 2}}{&quot;script&quot;:{&quot;lang&quot;:&quot;painless&quot;,&quot;source&quot;:&quot;ctx._source.counter += params.num&quot;,&quot;params&quot;: {&quot;num&quot;:2}}}{&quot;update&quot;:{&quot;_id&quot;: 3}}{&quot;doc&quot;: {&quot;name&quot;: &quot;test3333name&quot;, &quot;counter&quot;: 999}}{&quot;update&quot;:{&quot;_id&quot;: 4}}{&quot;doc&quot;: {&quot;name&quot;: &quot;test444name&quot;, &quot;counter&quot;: 888}, &quot;doc_as_upsert&quot; : true} 返回结果 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475{ &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 4, &quot;max_score&quot;: 1, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;example&quot;, &quot;_type&quot;: &quot;docs&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;id&quot;: 2, &quot;name&quot;: &quot;张三&quot;, &quot;counter&quot;: &quot;202&quot;, &quot;tags&quot;: [ &quot;green&quot;, &quot;purple&quot; ] } }, { &quot;_index&quot;: &quot;example&quot;, &quot;_type&quot;: &quot;docs&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;id&quot;: 4, &quot;name&quot;: &quot;test444name&quot;, &quot;counter&quot;: 888, &quot;tags&quot;: [ &quot;orange&quot; ] } }, { &quot;_index&quot;: &quot;example&quot;, &quot;_type&quot;: &quot;docs&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;id&quot;: 1, &quot;name&quot;: &quot;admin-02&quot;, &quot;counter&quot;: &quot;11&quot;, &quot;tags&quot;: [ &quot;red&quot;, &quot;black&quot; ] } }, { &quot;_index&quot;: &quot;example&quot;, &quot;_type&quot;: &quot;docs&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;id&quot;: 3, &quot;name&quot;: &quot;test3333name&quot;, &quot;counter&quot;: 999, &quot;tags&quot;: [ &quot;red&quot;, &quot;blue&quot; ] } } ] }} 由上面示例我们可以看出，批量更新支持参数选项：doc（部分文档），upsert，doc_as_upsert，脚本，``params（用于脚本），lang（用于脚本）和_source。 批量删除12345POST example/docs/_bulk{&quot;delete&quot;: {&quot;_id&quot;: 1}}{&quot;delete&quot;: {&quot;_id&quot;: 2}}{&quot;delete&quot;: {&quot;_id&quot;: 3}}{&quot;delete&quot;: {&quot;_id&quot;: 4}} 支持混合操作，index + delete 等，但是不推荐 查询文档 GET /index/_doc/1 响应 123456789101112{ &quot;_index&quot;: &quot;index&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_version&quot;: 1, &quot;_seq_no&quot;: 4, &quot;_primary_term&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: { &quot;name&quot;: 123 }} 删除 DELETE /index/_doc/2 响应 1234567891011121314{ &quot;_index&quot;: &quot;index&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_version&quot;: 2, &quot;result&quot;: &quot;deleted&quot;, &quot;_shards&quot;: { &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 }, &quot;_seq_no&quot;: 5, &quot;_primary_term&quot;: 1} 删除索引下的数据 POST /index/_delete_by_query 12345{ &quot;query&quot;: { &quot;match_all&quot;: {} }} 搜索 默认情况返回前10个符合查询的文档 GET /user/_search 简单查询分词检索match/match_all 按照age正序，查询前10个 12345678{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;age&quot;: &quot;asc&quot; } ], &quot;from&quot;: 0, &quot;size&quot;: 10,} 查询name包含包含zhang或者zhao的文档 1234567{ &quot;query&quot;: { &quot;match&quot;: { &quot;name&quot;: &quot;zhang zhao&quot; } }} 如果需要完全匹配，查询name同时包含zhang和zhao的文档，可以使用match_phrase 复杂查询 使用布尔查询组合多个查询条件，must、should、must_not , filter， 检索结果会根据luence的评分机制(TF/IDF)来评分 must 返回文档必须满足must子句条件，并参与计算分值 filter 返回文档必须满足filter子句的条件，不计算分值，可以缓存使用 如果需要计算分值用must，否则用filter 123456789101112131415161718192021222324{ &quot;query&quot; { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot;: { &quot;name&quot;: &quot;zhang&quot; } }, &quot;must_not&quot;: { &quot;match&quot;: { &quot;scool&quot;: &quot;shifan&quot; } }, &quot;filter&quot;: { &quot;range&quot;: { &quot;age&quot;: { &quot;lte&quot;: 10, &quot;gte&quot;: 5 } } } } }} must 返回的文档必须满足must子句的条件,并且参与计算分值 filter 返回的文档必须满足filter子句的条件,但是不会像must一样,参与计算分值 should 返回的文档可能满足should子句的条件.在一个bool查询中,如果没有must或者filter,有一个或者多个should子句,那么只要满足一个就可以返回. 布尔查询中每个 must，should,must_not 都被称为查询子句。每个must 或者 should 查询子句中的条件都会影响文档的相关得分。得分越高，文档跟搜索条件匹配得越好。默认情况下，Elasticsearch 返回的文档会根据相关性算分倒序排列，must_not 子句中认为是过滤条件。它会过滤返回结果，但不会影响文档的相关性算分， 你还可以明确指定任意过滤条件去筛选结构化数据文档，如上查询中的filter match_phrase12345678910{ &quot;query&quot;: { &quot;match_phrase&quot;: { &quot;content&quot;: { &quot;query&quot;: &quot;宝马多少钱&quot;, &quot;slop&quot;: 1 } } }} 其中slop是一个可调节因子，表示少匹配1个也满足 match_phrase_prefix1234567{ &quot;query&quot;: { &quot;match_phrase_prefix&quot;: {&quot;name&quot;: &quot;张伟&quot;} }, &quot;size&quot;: 10, &quot;from&quot;: 0} multi_matchhttps://www.elastic.co/guide/en/elasticsearch/reference/7.14/query-dsl-multi-match-query.html Type: 我们希望完全匹配的文档占的评分比较高，则需要使用best_fields 我们希望越多字段匹配的文档评分越高，就要使用most_fields 我们会希望这个词条的分词词汇是分配到不同字段中的，那么就使用cross_fields 12345678910{ &quot;_source&quot;: [&quot;title&quot;,&quot;desc&quot;], &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;高端婚礼邀请函&quot;, &quot;fields&quot;: [&quot;title&quot;,&quot;desc&quot;], &quot;operator&quot;: &quot;and&quot; } }} 其匹配逻辑为：(title:高端 + title:婚礼 + title:邀请函) || (desc:高端 + desc:婚礼 + desc:邀请函) 多条查询123456789101112131415161718192021222324{ &quot;query&quot;: { &quot;bool&quot;: { &quot;should&quot;: [ { &quot;match&quot;: { &quot;字段1&quot;: &quot;待查询句子&quot; } }, { &quot;match&quot;: { &quot;字段3&quot;: &quot;待查询句子&quot; } }, { &quot;match&quot;: { &quot;字段3&quot;: &quot;待查询句子&quot; } } ] } }} filter12345678910111213141516171819202122232425262728293031323334353637{ &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: [ { &quot;terms&quot;: { &quot;age&quot;: [ 1,2 ] } &quot;term&quot;: { &quot;id&quot;: 120 } }, { &quot;range&quot;: { &quot;age&quot;: { &quot;gte&quot;: 110, &quot;lte&quot;: 120, &quot;boost&quot;: 2.0 // 设置得分的权重值（提升值），默认是1.0 } } }, { &quot;exists&quot;: { &quot;field&quot;: &quot;email&quot; } }, { &quot;ids&quot;: { &quot;values&quot;: [&quot;1&quot;, &quot;2&quot;] } } ] } }} 布尔过滤 123456789101112131415{ &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot;: { &quot;hobby&quot;: &quot;k8s运维大佬&quot; } } } } } }} 其中的range有：gte,gt,lte,lt分别表示大于或等于，大于，小于或等于，小于。term不进行分词，完全匹配，文档中必须包含整个搜索的词汇，exists过滤指定字段不为空的 精确查找 123456789{ &quot;query&quot; : { &quot;term&quot;: { &quot;id&quot;: { &quot;value&quot;: 120 } } }} filter也可以使用单个 删除索引1234567//删除指定索引DELETE /indexDELETE /index1,index2DELETE /index_*// 删除全部DELETE /_all DELETE /* 删除全部索引操作非常危险，禁止措施，elasticsearch.yml 做如下配置： 1action.destructive_requires_name: true 这个设置使删除只限于特定名称指向的数据, 而不允许通过指定 _all 或通配符来删除指定索引库 聚合查询 GET /user/_search 1234567891011121314151617181920{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;group_by_country&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;country.keyword&quot;, &quot;order&quot;: { &quot;average_age&quot;: &quot;desc&quot; } }, &quot;aggs&quot;: { &quot;average_age&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;age&quot; } } } } }} 其中size为0，所以只返回聚合数据，请求使用 terms 聚合 索引中对所有国家进行分组，使用组合聚合，查询分组内所有age字段平均数，还可以使用聚合字段进行排序 分词器中文分词standard/simple/whitespace https://github.com/medcl/elasticsearch-analysis-ik 测试分词1POST /_analyze 请求体 1234{ &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;I bought a computer.&quot;} analyzer是分词器，默认是standard，支持中文按字分词 备份恢复工具推荐；elasticdump 常见报错 Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [interests] in order to load field data by uninverting the inverted index. Note that this can use significant memory. 因为interests的类型type是text，text或annotated_text字段doc_values默认为false，也就是说，text字段作为整体，默认没有索引 no [query] registered for [filtered] 过滤查询ES5.0已经废弃，应当使用bool / must / filter查询","link":"/2022/07/31/ElasticSearch%20%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"},{"title":"GDB简单调试","text":"1234567package mainfunc main() { for i := 0; i &lt; 10; i++ { fmt.Println(i) }} 编译 1go build -o main main.go 调试 1gdb main 如下 123456789101112131415161718192021222324252627GNU gdb (Ubuntu 9.2-0ubuntu1~20.04) 9.2Copyright (C) 2020 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Type &quot;show copying&quot; and &quot;show warranty&quot; for details.This GDB was configured as &quot;x86_64-linux-gnu&quot;.Type &quot;show configuration&quot; for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type &quot;help&quot;.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;...Reading symbols from test...warning: File &quot;/usr/local/go/src/runtime/runtime-gdb.py&quot; auto-loading has been declined by your `auto-load safe-path' set to &quot;$debugdir:$datadir/auto-load&quot;.To enable execution of this file add add-auto-load-safe-path /usr/local/go/src/runtime/runtime-gdb.pyline to your configuration file &quot;/root/.gdbinit&quot;.To completely disable this security protection add set auto-load safe-path /line to your configuration file &quot;/root/.gdbinit&quot;.For more information about this security protection see the&quot;Auto-loading safe path&quot; section in the GDB manual. E.g., run from the shell: info &quot;(gdb)Auto-loading safe path&quot;(gdb) 输入l回车查看源码，可以使用l &lt;line&gt; 跳到某一行查看 123456789101112(gdb) l1 package main23 import (4 &quot;fmt&quot;5 )67 func main() {8 for i := 0; i &lt; 10; i++ {9 fmt.Print(i)10 }(gdb) 设置断点b &lt;line&gt;，例如 b 9 123(gdb) b 9Breakpoint 1 at 0x49766a: file /mnt/c/Users/ChengYao/Desktop/Web/Go/test.go, line 9.(gdb) 运行run 1234567891011(gdb) runStarting program: /mnt/c/Users/ChengYao/Desktop/Web/Go/test [New LWP 10861][New LWP 10862][New LWP 10863][New LWP 10864][New LWP 10865]Thread 1 &quot;test&quot; hit Breakpoint 1, main.main () at /mnt/c/Users/ChengYao/Desktop/Web/Go/test.go:99 fmt.Print(i)(gdb) 打印变量p &lt;var&gt;， 例如 p i 123(gdb) p i$1 = 0(gdb) 下一行n 123(gdb) n08 for i := 0; i &lt; 10; i++ {(gdb)","link":"/2022/07/04/GDB%E7%AE%80%E5%8D%95%E8%B0%83%E8%AF%95/"},{"title":"GMT时间和Cookie","text":"今天给MaxPHP开发兼容Swoole的Cookie的时候设置了Cookie，大眼一看感觉不是很对 1set-cookie: MAXPHP_SESSION_ID=a9917035968c0e125179b4b949558e64; expires=Wed, 13-Oct-2021 16:34:24 GMT; Max-Age=3600; path=/ 我这边明明才23：40， 而Cookie又没有过期，于是 123php &gt; echo strtotime('Wed, 13-Oct-2021 16:34:24 GMT') - time();3182php &gt; 证明确实时间是正确的，但是时间却是14：34：24秒。于是想起GMT时间和北京时间是不一样的。百度了一下，贴在下面： https://zhidao.baidu.com/question/558694182487723652.htmlGMT是中央时区，北京在东8区，相差8个小时，所以为2008年08月29日 11点52分19秒。 北京时间是中国采用国际时区东八时区的区时作为标准时间。北京时间并不是北京（东经116.4°）地方的时间，而是东经120°地方的地方时间。因为北京处于国际时区划分中的东八区，同格林威治时间(世界时)整整相差8小时，（即北京时间=世界时+8小时）而中国东西相跨5个时区（即东五区、东六区、东七区、东八区、东九区5个时区）授时台必须建在中心地带，从而也就产生了长短波授。“北京时间”的发播不在北京，而在陕西蒲城。而东经120度的地方太阳时要比北京的地方时早约14分半钟。 中国科学院国家授时中心台本部位于陕西西安临潼区。中国科学院国家授时中心授时部（二部）位于陕西省渭南市蒲城县，负责发布北京时间（中国标准时间）。","link":"/2021/10/13/GMT%E6%97%B6%E9%97%B4%E5%92%8CCookie/"},{"title":"Golang fmt.Scan获取命令行输入（八）｜Go主题月","text":"Golang 本身十分轻量级，运行效率极高，同时对并发编程有着原生的支持，从而能更好的利用多核处理器。 这使得Golang对微服务开发具有先天的优势 常见的程序触发形式有api 调用，命令行执行。而在命令行执行中，用户输入执行参数的获取至关重要。 下面就来详细讲一讲 Golang 语言fmt包下有fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，可以在程序运行过程中从标准输入获取用户的输入。 fmt.Scan函数调用语法： func Scan(a …interface{}) (n int, err error) Scan 从命令行输入扫描文本，读取由空白符分隔的值 传递到本函数参数中，换行符视为空白符。 函数返回成功扫描数据个数和执行遇到的任何错误。如果读取的数据个数比参数少，会抛出错误。 具体代码示例如下： 1234567891011func main() { var ( name string age int is_marry bool ) fmt.Scan(&amp;name, &amp;age, &amp;is_marry) fmt.Printf(&quot;获取结果 name:%s age:%d is_marry:%t \\n&quot;, name, age, is_marry)}复制代码 将上面的代码编译后在终端执行，在终端依次输入韩韩、18、false使用空格分隔。 1234$ ./scan_demo 韩韩 18 false获取结果 name:韩韩 age:18 is_marry:false复制代码 fmt.Scan从命令行输入中扫描用户输入的数据，将以空白符分隔的数据分别存入指定的参数。 fmt.Scanf函数调用语法： func Scanf(format string, a …interface{}) (n int, err error) Scanf 从命令行输入扫描文本，根据 format参数 指定格式去读取由 空白符分隔的值 保存到传递给本函数参数中。 函数返回成功扫描数据个数和执行遇到的任何错误。 代码示例如下： 1234567891011func main() { var ( name string age int is_marry bool ) fmt.Scanf(&quot;1:%s 2:%d 3:%t&quot;, &amp;name, &amp;age, &amp;is_marry) fmt.Printf(&quot;扫描结果 name:%s age:%d is_marry:%t \\n&quot;, name, age, is_marry)}复制代码 将上面代码编译执行后，在终端按照指定的格式依次输入 韩韩、18、false。 1234$ ./scan_demo 1:韩韩 2:18 3:false获取结果 name:韩韩 age:18 is_marry:false复制代码 fmt.Scanf不同于fmt.Scan简单的以空格作为输入数据的分隔符，fmt.Scanf为输入数据指定了具体的输入内容格式，只有按照格式输入数据才会被扫描并存入对应变量。 fmt.Scanln函数调用语法： func Scanln(a …interface{}) (n int, err error) Scanln类似Scan，它在遇到换行时才停止扫描。最后一个数据后面必须有换行或者到达结束位置。 函数返回成功扫描数据个数和执行遇到的任何错误。 具体代码示例如下： 12345678910 func main() { var ( name string age int is_marry bool ) fmt.Scanln(&amp;name, &amp;age, &amp;is_marry) fmt.Printf(&quot;获取结果 name:%s age:%d is_marry:%t \\n&quot;, name, age, is_marry) }复制代码 将上面代码编译执行后，在终端依次输入韩韩、18、false使用空格分隔。 1234$ ./scan_demo 韩韩 18 false获取结果 name:韩韩 age:18 is_marry:false复制代码 fmt.Scanln遇到回车就结束扫描了，这个比较常用。 Fscan系列函数功能分别对应上述 fmt.Scan、fmt.Scanf、fmt.Scanln 函数， 只不过它们并不从命令行输入中读取数据而是从io.Reader中读取数据。 1234func Fscan(r io.Reader, a ...interface{}) (n int, err error)func Fscanln(r io.Reader, a ...interface{}) (n int, err error)func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error)复制代码 Sscan系列函数功能分别对应上述 fmt.Scan、fmt.Scanf、fmt.Scanln 函数， 只不过它们并不从命令行输入中读取数据而是从 指定字符串 中读取数据。 123func Sscan(str string, a ...interface{}) (n int, err error)func Sscanln(str string, a ...interface{}) (n int, err error)func Sscanf(str string, format string, a ...interface{}) (n int, err error) 来源： https://juejin.cn/post/6945631500335480839","link":"/2022/06/14/Golang%20fmt.Scan%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%BE%93%E5%85%A5%EF%BC%88%E5%85%AB%EF%BC%89%EF%BD%9CGo%E4%B8%BB%E9%A2%98%E6%9C%88/"},{"title":"Golang 通道(channel)","text":"单纯地将函数并发执行是没有意义的。函数与函数间需要交换数据才能体现并发执行函数的意义。 虽然可以使用共享内存进行数据交换，但是共享内存在不同的goroutine中容易发生竞态问题。为了保证数据交换的正确性，必须使用互斥量对内存进行加锁，这种做法势必造成性能问题。 Go语言的并发模型是CSP（Communicating Sequential Processes），提倡通过通信共享内存而不是通过共享内存而实现通信。 如果说goroutine是Go程序并发的执行体，channel就是它们之间的连接。channel是可以让一个goroutine发送特定值到另一个goroutine的通信机制。 Go 语言中的通道（channel）是一种特殊的类型。通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。每一个通道都是一个具体类型的导管，也就是声明channel的时候需要为其指定元素类型。 操作通道创建channel12var ch chan intmake(chan 元素类型, [缓冲大小]) 例如 1ch := make(chan uint8, 1) 我们在将一个 channel 变量传递到一个函数时，可以通过将其指定为单向 channel 变量，从而限制该函数中可以对此 channel 的操作，比如只能往这个 channel 中写入数据，或者只能从这个 channel 读取数据。 可以使用len,cap获取通道内元素数量和容量 无缓冲通道1ch := make(chan bool) 无缓冲通道也叫阻塞通道，同步通道，无缓冲的通道只有在有接收值的时候才能发送值，无缓冲通道上的发送操作会阻塞，直到另一个goroutine在该通道上执行接收操作，这时值才能发送成功，两个goroutine将继续执行。相反，如果接收操作先执行，接收方的goroutine将阻塞，直到另一个goroutine在该通道上发送一个值。使用无缓冲通道进行通信将导致发送和接收的goroutine同步化 单向通道单向 channel 变量的声明非常简单，只能写入数据的通道类型为chan&lt;-，只能读取数据的通道类型为&lt;-chan，格式如下： 12var 通道实例 chan&lt;- 元素类型 // 只能写入数据的通道var 通道实例 &lt;-chan 元素类型 // 只能读取数据的通道 元素类型：通道包含的元素类型。 通道实例：声明的通道变量。 time包中的单向通道time 包中的计时器会返回一个 timer 实例，代码如下： 1timer := time.NewTimer(time.Second) timer的Timer类型定义如下： 1234type Timer struct { C &lt;-chan Time r runtimeTimer} 第 2 行中 C 通道的类型就是一种只能读取的单向通道。如果此处不进行通道方向约束，一旦外部向通道写入数据，将会造成其他使用到计时器的地方逻辑产生混乱。 因此，单向通道有利于代码接口的严谨性。 发送接收通道有发送（send）、接收(receive）和关闭（close）三种操作。发送和接收都使用&lt;-符号。 12&lt;- chch &lt;- 1 接收12345678910111213141516channel := make(chan bool, 1)for v, ok := range channel { if ok { // 通道未关闭 }}for { select { case v := &lt;-channel: // 接收到值 default: // 其他 }} 关闭1close(ch) close 函数官方定义如下：close函数是一个内建函数， 用来关闭channel，这个channel要么是双向的， 要么是只写的（chan&lt;- Type）。 关于关闭通道需要注意的事情是，只有在通知接收方goroutine所有的数据都发送完毕的时候才需要关闭通道。通道是可以被垃圾回收机制回收的，它和关闭文件是不一样的，在结束操作之后关闭文件是必须要做的，但关闭通道不是必须的。 关闭后的通道有以下特点： ​ 1.对一个关闭的通道再发送值就会导致panic。​ 2.对一个关闭的通道进行接收会一直获取值直到通道为空。​ 3.对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值。 1`v, ok := &lt;-c`，中`ok`为false 标识通道已经被成功关闭 ​ 4.关闭一个已经关闭的通道会导致panic。 总结 参考文章： channel","link":"/2022/06/26/Golang%20%E9%80%9A%E9%81%93(channel)/"},{"title":"Centos Linux 运维级基础教学","text":"命令终端字段含义介绍 [root@localhost ~]# 解释：当前用户名为root@主机名为localhost 当前所在目录为 ~ 家目录 # 当前用户身份是超级管理员，root超级管理员家目录：/root 普通用户提示符为 $，普通用户的家目录：/homt/用户名同名，lisi用户的家目录：/home/lisi [lisi@localhost ~]$ Linux系统基本概念 Linux系统而言： 多用户的系统：允许同时有很多个用户登录系统，使用系统里的资源 多任务的系统：允许同时执行多个任务 严格区分大小写：命令，选项，参数，文件名，目录名都严格区分大小写 一切皆文件：硬件设备（内存、CPU、网卡、显示器、硬盘等等）都是以文件的形式存在的 不管是文件还是目录都是以倒挂的树形结构，存在于系统的“/”根目录下，根目录是Linux系统的起点 对于Linux系统而言，目录/文件没有扩展名一说，扩展名如：.sh（脚本文件) .conf（配置文件） .log（日志文件） .rpm（软件包）.tar（压缩包）是易于用户方便识别 没有提示就是最好的提示（成功了） 命令行编辑技巧键盘上下键调出历史命令 Ctrl + c：取消当前执行的命令 Ctrl + l：清屏 tab建自动补齐：可补齐命令、选项、参数、文件路径、软件名、服务名 Ctrl + a：将当前光标移动至行首 Ctrl + e：将当前光标移动至行尾 Ctrl + u 清空至行首 Ctrl + w 删除一个单词 exit：退出系统 命令行一般命令格式 命令字 [-选项…] [参数…] 命令字：命令本身（功能） 选项：调整命令功能的 短选项：-l -a -d -h（单个字符），短选项可以合并使用：-lad -lh 长选项：–help（单词），长选项通常是不能合并使用的 参数：命令的执行对象，文件/目录/程序等 []：可选的 …：可以同时有多个选项或参数 学习方法 遇到问题：前期不要求你们有排错的能力 思考自己能不能决绝：百度、Google、最后在问老师 主动学习的爱好，不要被动学习 不要死磕一个技术点，低头学习的时候不要忘了抬头看路 Linux系统辨别目录与文件的方法蓝色表示目录（windows系统里的文件夹） 白色表示文件 浅蓝色表示链接文件（类似于windows系统的快捷方式） 绿色表示可执行文件（如脚本，命令程序文件） 红色表示压缩文件 黄色表示设备文件（硬盘、键盘、鼠标、网卡、CPU硬件设备都是以文件的形式存在的） 红色闪动文件——&gt;表示链接文件不可用 ls 查看目录/文件命令 ls命令（英文全拼：list）：用于查看目录下内容及目录和文件详细属性信息 命令格式：ls [-选项…] [参数…] 常用选项： -a 显示目录下所有内容，包含隐藏的内容 -l 以长格式显示目录下的内容及详细属性 -h 人性化显示目录下内容大小（kB、MB、GB） -d 仅显示目录本身而不显示目录下的内容 -i 查看inode号（系统任何的文件或目录都有一个唯一的编号） -R：递归查看目录下所有内容（从头到尾） Linux 系统文件类型- 文件： d 目录： l 链接文件 b 跨设备文件 c 字符设备文件 p 管道设备文件 s 套接字 Linux 系统下的归属关系 在Linux系统下，文件给用户分成了三类 u 所有者：文件或目录的拥有者，拥有者的权限通常是最大的 g 所属组：文件或目录属于哪一个组，所属组的权限略微比所有者小 o 其他人：既不是文件或目录的所有者，也不属于文件或目录组内的成员，其他人的权限通常最小的权限 ls命令示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#显示当前所在目录下的所有内容[root@localhost ~]# ls #查看根目录下所有内容[root@localhost ~]# ls /bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var#查看/etc目录下所有内容[root@localhost ~]# ls /etc#查看/bin目录下所有内容[root@localhost ~]# ls /bin#查看/dev目录下所有内容[root@localhost ~]# ls /dev#查看目录下所有目录和文件，包括隐藏的内容[root@localhost ~]# ls -a#以长格式显示目录下所有内容，包括详细的属性信息[root@localhost ~]# ls -l-rw-r--r--. 1 root root 1831 3月 13 17:45 initial-setup-ks.cfgdrwxr-xr-x. 2 root root 6 3月 13 17:47 公共#解释-：文件类型1：代表文件的引用次数，只针对与做了硬连接的文件才有效root：文件的所有者root：文件的所属组1831：文件的大小，默认以字节为单位显示大小3月 13 17:45：文件最近一次的修改时间initial-setup-ks.cfg：文件名#以长格式显示目录所有内容，以人性化的方式显示详细的属性信息[root@localhost ~]# ls -l -h#短选项合并使用[root@localhost ~]# ls -lh#以长格式显示目录所有内容，以人性化的方式显示详细的属性信息，包括隐藏的内容[root@localhost ~]# ls -lha#以长格式显示根目录下所有内容，包括详细的属性信息[root@localhost ~]# ls -l /lrwxrwxrwx. 1 root root 7 3月 13 17:15 bin -&gt; usr/bin#创建hello.txt文件[root@localhost ~]# touch hello.txt#查看文件的元数据信息[root@localhost ~]# stat hello.txt 文件：&quot;hello.txt&quot; 大小：0 块：0 IO 块：4096 普通空文件设备：fd00h/64768d Inode：33575020 硬链接：1权限：(0644/-rw-r--r--) Uid：( 0/ root) Gid：( 0/ root)环境：unconfined_u:object_r:admin_home_t:s0最近访问：2021-03-14 16:38:14.349861770 +0800最近更改：2021-03-14 16:38:14.349861770 +0800最近改动：2021-03-14 16:38:14.349861770 +0800创建时间：- Linux 基本权限的类别 r 读取 w 写入 x 执行 - 没有权限 权限顺序：rwxrwxrwx 123456789101112131415161718192021222324252627282930[root@localhost ~]# ls -l-rw-r--r--. 1 root root 1831 3月 13 17:45 initial-setup-ks.cfg#解释-：文件类型rw- r-- r--：所有者u、所属组g、其他人o的权限u g o1：代表文件的引用次数，只针对与做了硬连接的文件才有效root：文件的所有者root：文件的所属组1831：文件的大小，默认以字节为单位显示大小3月 13 17:45：文件最近一次的修改时间initial-setup-ks.cfg：文件名#查看/root目录本身详细属性信息[root@localhost ~]# ls -ld /rootdr-xr-x---. 14 root root 4096 3月 14 16:38 /root#查看当前目录下所有内容的inode号[root@localhost ~]# ls -i33574979 anaconda-ks.cfg 33574984 initial-setup-ks.cfg 33575035 模板 33575036 图片 17470701 下载 17470702 音乐33575020 hello.txt 51909391 公共 51909392 视频 3204374 文档 33575017 新建文件夹.zip 3204373 桌面#查看hello.txt文件的inode号[root@localhost ~]# ls -i hello.txt33575020 hello.txt#查看/etc/目录本身的inode号[root@localhost ~]# ls -id /etc16777281 /etc 课后练习1.命令行以$作为结尾代表什么含义？ 普通用户 2.请写出Linux系统一般的命令格式？ 命令字 [-选项…] [参数…] 3.在Linux系统下，如何辨别目录与文件及其他的文件？ 白色：文件 蓝色：目录 浅蓝色：链接文件 绿色：可执行文件 红色：压缩文件 红色带闪动的文件：链接文件不可用 黄色：设备文件（硬盘，网卡，CPU，鼠标，键盘） 4.如何查看一个文件的详细属性？ ls -l 文件名 5.如何查看一个目录本身的详细属性？ ls -dl 目录名字 6.查看文件详细属性，并以KB、MB、GB的方式显示文件的大小？ ls -lh 文件名 7.如何查看一个文件的inode号？ ls -i 文件名 8.请写出Linux下文件和目录的三个归属关系？ u 所有者 g 所属组 o 其他人 9.请写出Linux下基本权限的表示方式？ r：读取，w写入，x执行 10.命令行以#作为结尾代表什么含义？ 超级管理员 mkdir 创建目录命令 mkdir（英文全拼：make directory）用于创建新目录 命令格式：mkdir [-选项] 目录名 常用选项： -p 递归创建多个目录 注意事项： 目录还是文件的名字，除了以“/”以外的任意名称，“/”根目录，路径分隔符 文件或目录的名字长度不能超过255个字符 mkdir命令示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#在当前所在目录创建test目录[root@localhost ~]# mkdir test[root@localhost ~]# ls#在当前所在目录同时创建多个目录[root@localhost ~]# mkdir test1 test2 test3[root@localhost ~]# ls#指定在/tmp目录下创建abc目录[root@localhost ~]# mkdir /tmp/abc[root@localhost ~]# ls /tmpabc#在指定目录下同时创建多个目录[root@localhost ~]# mkdir /tmp/abc1 /tmp/abc2 /tmp/abc3[root@localhost ~]# ls /tmp#在/opt目录下创建student，在当前目录创建student1..3[root@localhost ~]# mkdir /opt/student student1 student2 student3[root@localhost ~]# ls /optrh student#mkdir默认无法在一个不存在的目录下创建目录，需要通过-p选项[root@localhost ~]# mkdir /opt/xx/oomkdir: 无法创建目录&quot;/opt/xx/oo&quot;: 没有那个文件或目录[root@localhost ~]# mkdir /opt/a/b/c/dmkdir: 无法创建目录&quot;/opt/a/b/c/d&quot;: 没有那个文件或目录#在/opt目录下递归创建目录[root@localhost ~]# mkdir -p /opt/xx/oo[root@localhost ~]# ls /optrh student xx[root@localhost ~]# mkdir -p /opt/a/b/c/d[root@localhost ~]# ls /opta rh student xx#ls -R选项可以递归目录下所有内容[root@localhost ~]# ls -R /opt/a/opt/a:b/opt/a/b:c/opt/a/b/c:d cd 切换工作目录命令 cd（英文全拼：change directory）切换目录 命令格式：cd [-选项] [目录名] 提示：目录名称可以是绝对路径或相对路径，如果不指定目录名称，则切换到当前用户的家目录~ 常用快捷操作： ~ 表示为家目录- . 表示为当前目录 .. 表示上一级目录 -可在两路径之间来回切换 pwd 打印当前所在目录命令 pwd（英文全拼：print work directory）打印当前所在的工作目录，执行pwd命令后，可显示当前所在的工作目录的绝对路径名称 命令格式：pwd [-选项] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485[root@localhost ~]# cd /opt/a/b/c/d#打印当前所在目录绝对路径[root@localhost d]# pwd/opt/a/b/c/d#切换到用户家目录[root@localhost d]# cd ~[root@localhost ~]# pwd/root[root@localhost ~]# cd /opt/a/b/c/d[root@localhost d]# pwd/opt/a/b/c/d[root@localhost d]# cd[root@localhost ~]# pwd/root[root@localhost ~]# cd /bin[root@localhost bin]# pwd/bin[root@localhost bin]# cd /boot[root@localhost boot]# pwd/boot[root@localhost boot]# ls[root@localhost boot]# cd /dev[root@localhost dev]# pwd/dev[root@localhost dev]# ls[root@localhost dev]# cd /etc[root@localhost etc]# pwd/etc[root@localhost etc]# ls[root@localhost etc]# ls /bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var#“.”表示当前所在目录，对于cd命令而言作用不大[root@localhost etc]# cd .[root@localhost etc]# cd /opt/a/b/c/d[root@localhost d]# pwd/opt/a/b/c/d#“..”切换到当前目录的上一级目录[root@localhost d]# cd ..[root@localhost c]# pwd/opt/a/b/c[root@localhost c]# cd ..[root@localhost b]# pwd/opt/a/b[root@localhost b]# cd ..[root@localhost a]# cd ..[root@localhost opt]# pwd/opt[root@localhost opt]# cd ..[root@localhost /]# cd ..[root@localhost /]# cd[root@localhost ~]# ls[root@localhost ~]# cd /opt/a/b/c/d[root@localhost d]# pwd/opt/a/b/c/d#&quot;-&quot;可在两个路径之间来回切换[root@localhost d]# cd /etc/yum[root@localhost yum]# cd -/opt/a/b/c/d[root@localhost d]# pwd/opt/a/b/c/d[root@localhost d]# cd -/etc/yum[root@localhost yum]# cd -/opt/a/b/c/d[root@localhost d]# cd -/etc/yum 绝对路径与相对路径 绝对路径：以/（根）为起点，到达你想去的目标目录称为绝对路径 相对路径：以当前路径为起点，到达你想去的目标目录 123456789101112131415161718192021#绝对路径以“/”作为起点，到达目标路径[root@localhost ~]# cd /opt/a/b/c/d[root@localhost d]# pwd/opt/a/b/c/d#切换到上一级目录[root@localhost c]# cd ..[root@localhost b]# pwd/opt/a/b[root@localhost b]# lsc#相对路径以当前路径作为起点到达目标路径[root@localhost b]# cd c/[root@localhost c]# pwd/opt/a/b/c[root@localhost c]# cd ..[root@localhost b]# cd ..[root@localhost a]# cd ..[root@localhost opt]# pwd/opt rmdir 删除空目录命令 rmdir（英文全拼：remove directory）删除空目录 命令格式：rmdir [-选项] 目录名 123456789101112131415161718192021222324252627282930313233343536373839#rmdir只能删除空目录，如果目录下存在数据无法删除[root@localhost ~]# rmdir /opt/armdir: 删除 &quot;/opt/a&quot; 失败: 目录非空[root@localhost ~]# ls -R /opt/a/opt/a:b/opt/a/b:c/opt/a/b/c:d/opt/a/b/c/d:[root@localhost ~]# rmdir /opt/a/b/c/d[root@localhost ~]# ls -R /opt/a/opt/a:b/opt/a/b:c/opt/a/b/c:[root@localhost ~]# rmdir /opt/a/b/c[root@localhost ~]# ls -R /opt/a/b/opt/a/b:[root@localhost ~]# rmdir /opt/a/b[root@localhost ~]# ls -R /opt/a/opt/a:[root@localhost ~]# rmdir /opt/a[root@localhost ~]# ls /optrh student xx[root@localhost ~]# rmdir /opt/rmdir: 删除 &quot;/opt/&quot; 失败: 目录非空 touch 创建文件命令 touch 命令用于创建新的空白文件 命令格式：touch [-选项] 文件名 1234567891011121314151617181920212223242526272829303132333435#在当前路径创建空文件[root@localhost ~]# touch hello[root@localhost ~]# ls#在当前路径同时创建多个文件[root@localhost ~]# touch t1 t2 t3 t4[root@localhost ~]# ls#在指定路径同时创建多个文件[root@localhost ~]# touch /opt/test1 /opt/test2 /opt/test3[root@localhost ~]# ls /optrh student test1 test2 test3 xx#如果存在同名目录时，无法创建[root@localhost ~]# mkdir testmkdir: 无法创建目录&quot;test&quot;: 文件已存在#如果存在同名文件时，touch命令没有提示，但原有文件不会被覆盖[root@localhost ~]# touch t1#对于目录而言，只有单个目录的时候，“/”可有可无[root@localhost ~]# ls /opt/rh student test1 test2 test3 xx[root@localhost ~]# ls /optrh student test1 test2 test3 xx#对于目录而言，查看目录下的内容时，必须要有“/”[root@localhost ~]# ls /opt/xxoo#对于文件而言，后边绝对不能有“/”[root@localhost ~]# ls /opt/test1/opt/test1[root@localhost ~]# ls /opt/test1/ls: 无法访问/opt/test1/: 不是目录 cp 复制命令 cp（英文全拼：copy file）用于复制文件或目录，cp命令在复制时也可修改目录或文件名字 命令格式：cp [-选项] 源文件或目录 目标目录 常用选项： -p 保留源文件属性不变（如：修改时间、归属关系、权限） -r 复制目录（包含该目录下所有的子目录和文件） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#复制当前目录文件到/opt目录（相对路径方式复制）[root@localhost ~]# cp t1 /opt/[root@localhost ~]# ls /optrh student t1 test1 test2 test3 xx#复制文件到/opt目录（绝对路径方式复制）[root@localhost ~]# cp /root/t2 /opt[root@localhost ~]# ls /optrh student t1 t2 test1 test2 test3 xx#同时复制多个文件[root@localhost ~]# cp t3 t4 /opt/[root@localhost ~]# ls /opt#创建目录[root@localhost ~]# mkdir abc#使用-r对目录执行复制[root@localhost ~]# cp -r abc /opt[root@localhost ~]# ls /opt#同时复制多个目录[root@localhost ~]# mkdir abc1 abc2 abc3[root@localhost ~]# cp -r abc1 abc2 abc3 /opt[root@localhost ~]# ls /opt#复制hello文件到/opt并改名为hello.txt[root@localhost ~]# cp hello /opt/hello.txt[root@localhost ~]# ls /opt#复制xxxx目录到/opt并改名xxoo[root@localhost ~]# mkdir xxxx[root@localhost ~]# cp -r xxxx /opt/xxoo[root@localhost ~]# ls /opt#使用“.”配合cp命令执行复制[root@localhost ~]# cd /etc/sysconfig/network-scripts/[root@localhost network-scripts]# pwd/etc/sysconfig/network-scripts[root@localhost network-scripts]# cp /root/t1 .[root@localhost network-scripts]# ls#操持属性不变复制文件[root@localhost ~]# cp -p anaconda-ks.cfg /optcp：是否覆盖&quot;/opt/anaconda-ks.cfg&quot;？ y [root@localhost ~]# ls -l /opt/anaconda-ks.cfg -rw-------. 1 root root 1800 3月 13 17:34 /opt/anaconda-ks.cfg#对比以上两个文件的详细属性信息（最后一次修改时间）[root@localhost ~]# ls -l anaconda-ks.cfg -rw-------. 1 root root 1800 3月 13 17:34 anaconda-ks.cfg#这两个操作代表什么意思？[root@localhost ~]# cp -r xxxx /mnt/oooo #拷贝并改名[root@localhost ~]# cp -r xxxx /mnt/oooo #拷贝 mv 移动命令 mv（英文全拼：move file）用于移动文件或目录到其他位置，也可用于修改目录或文件名 命令格式：mv [-选项] 源文件… 目标路径 1234567891011121314151617181920212223242526272829#移动当前路径hello文件到/mnt目录[root@localhost ~]# mv hello /mnt[root@localhost ~]# ls /mnthello home oooo test#同时移动多个文件[root@localhost ~]# mv t1 t2 t3 t4 /mnt[root@localhost ~]# ls /mnthello home oooo student1 t1 t2 t3 t4 test#移动/opt目录下文件到/mntroot@localhost ~]# mv /opt/test1 /opt/test2 /opt/test3 /mnt/[root@localhost ~]# ls /mnthello home oooo student1 t1 t2 t3 t4 test test1 test2 test3#移动目录[root@localhost ~]# mv student1 /mnt[root@localhost ~]# ls /mnthello home oooo student1 test#移动文件并改名[root@localhost ~]# mv hello.txt /media/hello[root@localhost ~]# ls /media/hello#移动目录并改名[root@localhost ~]# mv test /media/testxx[root@localhost ~]# ls /media/hello testxx cat 查看文件内容命令 cat （英文全拼：concatenate）命令用于查看文本文件内容 命令格式：cat [选项] 文件名 常用选项 -n #查看文件时以行号的形式显示文件内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445#查看文件内容[root@localhost ~]# cat anaconda-ks.cfg [root@localhost ~]# cat initial-setup-ks.cfg [root@localhost ~]# cat /etc/hosts#查看网卡文件内容[root@localhost ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens32 ...NAME=&quot;ens32&quot; //网卡名UUID=&quot;16085f4c-f690-4058-b29e-d55c73387026&quot;DEVICE=&quot;ens32&quot;ONBOOT=&quot;yes&quot;IPADDR=&quot;192.168.0.50&quot; //网卡IP地址PREFIX=&quot;24&quot; //子网掩码GATEWAY=&quot;192.168.0.254&quot; //网管DNS1=&quot;114.114.114.114&quot; //DNS#查看当前系统用户基本信息文件内容[root@localhost ~]# cat /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin#查看当前系统主机名配置文件内容[root@localhost ~]# cat /etc/hostnamelocalhost.localdomain#查看当前系统版本信息文件内容[root@localhost ~]# cat /etc/redhat-release CentOS Linux release 7.6.1810 (Core) #查看当前系统开机自动挂载配置文件内容[root@localhost ~]# cat /etc/fstab#查看系统组基本信息文件内容[root@localhost ~]# cat /etc/group#使用“-n”以行号形式显示文件内容[root@localhost ~]# cat -n /etc/passwd[root@localhost ~]# cat -n /etc/hostname[root@localhost ~]# cat -n /etc/fstab[root@localhost ~]# cat -n /etc/group[root@localhost ~]# cat -n /etc/services less命令 less工具是对文件的输出进行分页显示的工具，常用于查看内容量较大的文件 命令格式：less [-选项] 文件 常用选项： -N #以行号形式显示文件内容 使用技巧： 键盘上下键逐行查看 pgdn ：向上翻一页（Fn + 上键） pgup ：向下翻一页（Fn + 下键） /字符串 ：搜索指定字符串（n从上向下搜索，N从下向上搜索） G：直接跳转到文件最后一行 gg：直接跳转到文件行首 q ：退出 1[root@localhost ~]# less -N /etc/services head与tail命令 head命令：用来显示文件开头部分内容，默认显示文件开头10行内容 命令格式：head [选项] 参数 常用选项： -n&lt;行数&gt; 指定显示的行数 -f 动态显示 123456789101112131415[root@localhost ~]# head /etc/passwd[root@localhost ~]# head /etc/fstab[root@localhost ~]# head /etc/group[root@localhost ~]# head /etc/hostname[root@localhost ~]# head /etc/hosts[root@localhost ~]# head /etc/sysconfig/network-scripts/ifcfg-ens32 #查看存放DNS配置文件信息[root@localhost ~]# head /etc/resolv.conf #使用-n指定显示文件前多少行内容[root@localhost ~]# head -n 5 /etc/passwd[root@localhost ~]# head -n 6 /etc/passwd[root@localhost ~]# head -n 15 /etc/passwd[root@localhost ~]# head -n 20 /etc/passwd tail命令：用来显示文件末尾部分内容，默认显示文件末尾10行内容 命令格式：tail [选项] 参数 常用选项：-n&lt;行数&gt; 指定显示的行数 -f 动态显示 1234567891011121314151617[root@localhost ~]# tail /etc/passwd#使用“-n”指定显示文件末尾多少行内容[root@localhost ~]# tail -n 5 /etc/passwd[root@localhost ~]# tail -n 5 /etc/sysconfig/network-scripts/ifcfg-ens32 IPADDR=&quot;192.168.0.50&quot;PREFIX=&quot;24&quot;GATEWAY=&quot;192.168.0.254&quot;DNS1=&quot;114.114.114.114&quot;IPV6_PRIVACY=&quot;no&quot;#动态查看文件内容[root@localhost ~]# touch t1root@localhost ~]# tail -f t1#另开一个终端向文件写入内容[root@localhost ~]# echo 123 &gt; t1 rm删除命令 rm（英文全拼：remove）命令用于删除文件或者目录。 命令格式：rm [-选项…] 目录或文件… 常用选项 -f 强制删除 -r 删除目录 “*”特殊字符：系统常用符号，用来代表任意字符 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374[root@localhost ~]# ls /optabc abc1 abc2 abc3 anaconda-ks.cfg hello.txt home rh student t1 t2 t3 t4 xx xxoo[root@localhost ~]# ls /mnthello home oooo student1 t1 t2 t3 t4 test test1 test2 test3#删除指定目录下文件[root@localhost ~]# rm /opt/anaconda-ks.cfg rm：是否删除普通文件 &quot;/opt/anaconda-ks.cfg&quot;？y #默认需要确认（y|n）#查看文件是否被成功删除[root@localhost ~]# ls /optabc abc1 abc2 abc3 hello.txt home rh student t1 t2 t3 t4 xx xxoo[root@localhost ~]# rm /opt/hello.txt rm：是否删除普通空文件 &quot;/opt/hello.txt&quot;？y#同时删除目录下指定文件[root@localhost ~]# rm /opt/t1 /opt/t2 /opt/t3 /opt/t4rm：是否删除普通空文件 &quot;/opt/t1&quot;？yrm：是否删除普通空文件 &quot;/opt/t2&quot;？yrm：是否删除普通空文件 &quot;/opt/t3&quot;？yrm：是否删除普通空文件 &quot;/opt/t4&quot;？y#查看文件是否被成功删除[root@localhost ~]# ls /optabc abc1 abc2 abc3 home rh student xx xxoo#使用“-f”强制删除文件（无需确认，直接删除）[root@localhost ~]# rm -f /mnt/hello[root@localhost ~]# ls /mnthome oooo student1 t1 t2 t3 t4 test test1 test2 test3#同时强制删除多个文件[root@localhost ~]# rm -f /mnt/t1 /mnt/t2 /mnt/t3 /mnt/t4[root@localhost ~]# ls /mnt#删除目录[root@localhost ~]# rm -r /opt/abcrm：是否删除目录 &quot;/opt/abc&quot;？y[root@localhost ~]# ls /optabc1 abc2 abc3 home rh student xx xxoo#同时删除多个目录[root@localhost ~]# rm -r /opt/abc1 /opt/abc2 /opt/abc3rm：是否删除目录 &quot;/opt/abc1&quot;？yrm：是否删除目录 &quot;/opt/abc2&quot;？yrm：是否删除目录 &quot;/opt/abc3&quot;？y[root@localhost ~]# ls /opthome rh student xx xxoo#同时强制删除多个目录[root@localhost ~]# rm -rf /opt/home /opt/student /opt/xx /opt/xxoo[root@localhost ~]# ls /optrh#创建目录与文件[root@localhost ~]# touch /opt/t1[root@localhost ~]# mkdir /opt/test[root@localhost ~]# ls /optrh t1 test#rm命令在删除目录时，包含改目录及目录下所有数据全部删除[root@localhost ~]# rm -rf /opt/[root@localhost ~]# ls /[root@localhost ~]# ls /mnthome oooo student1 test test1 test2 test3#使用“*”通配任意所有字符，删除/mnt目录下所有数据[root@localhost ~]# rm -rf /mnt/*[root@localhost ~]# ls /mnt 软连接与硬连接 Linux中的链接文件类似于windows中的快捷方式 软连接特点：软连接可以跨分区，可以对目录进行链接，源文件删除后，链接文件不可用 软连接命令格式：ln -s 源文件路径 目标路径 注意：创建链接时一定要写目录或文件的绝对路径，哪怕是在当前路径下，也要写绝对路径· 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@localhost ~]# touch hello.soft[root@localhost ~]# ls#创建软连接（必须要绝对路径创建）[root@localhost ~]# ln -s /root/hello.soft /opt[root@localhost ~]# ls /opt#查看连接文件详细属性[root@localhost ~]# ls -l /opt/hello.soft lrwxrwxrwx. 1 root root 16 3月 21 14:28 /opt/hello.soft -&gt; /root/hello.soft#提示：链接文件的权限最终取决于源文件的权限#普通用户验证[lisi@localhost ~]$ ls /opthello.soft[lisi@localhost ~]$ ls -l /opt/hello.soft lrwxrwxrwx. 1 root root 16 3月 21 14:28 /opt/hello.soft -&gt; /root/hello.soft[lisi@localhost ~]$ cat /opt/hello.soft cat: /opt/hello.soft: 权限不够#提示：由于源文件存放于/root目录下，而普通用户对/root目录没有任何权限，所以普通用户无法查看#删除源文件[root@localhost ~]# rm -f /root/hello.soft [root@localhost ~]# ls#山粗源文件后，软链接文件不可用[root@localhost ~]# ls -l /opt/hello.soft lrwxrwxrwx. 1 root root 16 3月 21 14:28 /opt/hello.soft -&gt; /root/hello.soft#创建文件并创建软连接[root@localhost ~]# touch hello.soft[root@localhost ~]# ln -s /root/hello.soft /opt[root@localhost ~]# ls -l /opt/hello.soft lrwxrwxrwx. 1 root root 16 3月 21 14:39 /opt/hello.soft -&gt; /root/hello.soft#删除链接文件后，源文件仍然可用[root@localhost ~]# rm -f /opt/hello.soft [root@localhost ~]# ls[root@localhost ~]# cat hello.soft #对目录创建软连接[root@localhost ~]# ln -s /root/test1 /opt/[root@localhost ~]# ls -ld /opt/test1lrwxrwxrwx. 1 root root 11 3月 21 14:44 /opt/test1 -&gt; /root/test13创建链接时一定要写目录或文件的绝对路径，哪怕是在当前路径下，也要写绝对路径[root@localhost ~]# ln -s hello.soft /opt[root@localhost ~]# ls /opthello.soft test1[root@localhost ~]# ls -l /opt/hello.soft lrwxrwxrwx. 1 root root 10 3月 21 14:47 /opt/hello.soft -&gt; hello.soft 硬链接特点：硬连接不可以跨分区，不可以对目录进行链接，源文件删除后，链接文件仍然可用 硬连接命令格式：ln 源文件路径 目标路径 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#创建文件，并创建硬连接[root@localhost ~]# touch hello.hard[root@localhost ~]# ln /root/hello.hard /opt/[root@localhost ~]# ls /opthello.hard hello.soft test1#向硬连接的源文件写入内容root@localhost ~]# echo 123 &gt; /root/hello.hard #查看源文件内容[root@localhost ~]# cat /root/hello.hard 123#查看链接文件内容，以同步更新[root@localhost ~]# cat /opt/hello.hard 123#向链接文件写入内容，查看源文件以同步更新[root@localhost ~]# echo xx &gt;&gt; /opt/hello.hard #擦看源文件，以同步更新[root@localhost ~]# cat /root/hello.hard 123xx#硬连接文件的特点可以保持文件属性不发生改变[root@localhost ~]# ls -l /root/hello.hard -rw-r--r--. 2 root root 7 3月 21 14:55 /root/hello.hard[root@localhost ~]# ls -l /opt/hello.hard -rw-r--r--. 2 root root 7 3月 21 14:55 /opt/hello.hard#并且硬连接文件的i节点号相同[root@localhost ~]# ls -i /root/hello.hard 33711090 /root/hello.hard[root@localhost ~]# ls -i /opt/hello.hard 33711090 /opt/hello.hard#硬连接不允许对目录进行连接root@localhost ~]# ln /root/test1 /optln: &quot;/root/test1&quot;: 不允许将硬链接指向目录#硬连接源文件删除后，链接文件仍然可用[root@localhost ~]# rm -f /root/hello.hard [root@localhost ~]# cat /opt/hello.hard 123xx#向硬连接文件写入内容[root@localhost ~]# echo abc &gt;&gt; /opt/hello.hard [root@localhost ~]# cat /opt/hello.hard 123xxabc#硬连接不允许跨分区[root@localhost ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot└─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP]sr0 11:0 1 4.3G 0 rom [root@localhost ~]# ln /root/hello.soft /bootln: 无法创建硬链接&quot;/boot/hello.soft&quot; =&gt; &quot;/root/hello.soft&quot;: 无效的跨设备连接 内部命令与外部命令 什么是命令：用来实现某一种功能的指令或程序 命令的执行依赖于解释器（例如：/bin/bash），/etc/shells文件存放系统可用的shell 用户——解释器（shell外壳）——内核 [[root@localhost]# shell 终端 交互接口 用户接口 12345678910111213141516171819#搜索命令所在的绝对路径[root@localhost ~]# which lsalias ls='ls --color=auto' /usr/bin/lsroot@localhost ~]# ls /usr/bin/ls/usr/bin/ls#直接运行程序文件[root@localhost ~]# /usr/bin/ls[root@localhost ~]# /usr/bin/ls /opthello.hard hello.soft t1 test1 test.txt[root@localhost ~]# which cat[root@localhost ~]# ls /usr/bin/cat/usr/bin/cat[root@localhost ~]# which pwd/usr/bin/pwd Linux命令的分类 内部命令：shell程序自带的基本管理命令 外部命令：有独立的外部可执行程序文件命令 type 用于区别内部命令与外部命令 which 用于查找可以执行程序文件位置 12345678910111213141516171819202122232425[root@localhost opt]# type ls[root@localhost opt]# type cat[root@localhost opt]# type hash[root@localhost ~]# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin[root@localhost ~]# hash命中 命令 1 /usr/bin/cat 1 /usr/bin/ls[root@localhost opt]# hash -r[root@localhost opt]# [root@localhost opt]# hashhash: 哈希表为空[root@localhost opt]# lshello.hard hello.soft t1 test1 test.txt[root@localhost opt]# hash命中 命令 1 /usr/sbin/ls 总结： shell程序是用户和系统之间的接口，用于解释用户的命令 查找命令对应的程序文件所在位置：which 命令 shell程序大多数存放在/etc/shells文件中 系统默认使用的shell为/bin/bash 查看当前使用的shell：echo $SHELL 区别内部命令与外部命令的方式：typt 命令 shell程序查找可执行程序文件路径定义在$PATH环境变量中 shell查找的外部命令路径结果会记录到缓存的hash表中 help 命令帮助手册 help命令用于查看shell内部命令的帮助信息，包括使用方法、选项等… 命令格式：help [选项] 命令 12345678910111213141516171819202122#获取内部命令帮助信息[root@localhost etc]# help cd#help无法获取外部命令的帮助信息root@localhost etc]# help lsbash: help: 没有与 `ls' 匹配的帮助主题。尝试 `help help' 或者 `man -k ls' 或者 `info ls'。[root@localhost etc]# type helphelp 是 shell 内嵌#获取help命令本身的帮助信息[root@localhost etc]# help help[root@localhost etc]# type catcat 是 /usr/bin/cat[root@localhost etc]# help catbash: help: 没有与 `cat' 匹配的帮助主题。尝试 `help help' 或者 `man -k cat' 或者 `info cat'。#查看命令帮助手册（命令自带）[root@localhost etc]# cat --help[root@localhost etc]# ls --help man 获取命令帮助手册 man 命令用于查看系统命令的帮助信息，包括使用方法、选项、使用例子等…，对比–help ，mna 输出的信息更加详细 命令格式：man [-选项] 命令 常用快捷操作 向下键向下移一行 向上键向上移一行 [Page Down] 向下翻一页 [Page Up] 向上翻一页 /关键字 #搜索关键字，配合n（向下查询）、N（向上查询） q 退出 12345[root@localhost etc]# man ls[root@localhost etc]# man cat[root@localhost etc]# man touch[root@localhost etc]# man mkdir[root@localhost etc]# info ls Google/百度（Google，算法） Linux系统的运行级别Linux系统运行级别：linux系统有7个运行级别，不同的运行级别运行的程序和功能都不一样，而Linux系统默认是运行在一个标准的级别上，系统运行级别文件/etc/inittab文件 运行级别 0：所有进程被终止，机器将有序的停止，关机时系统处于这个运行级别（关机） 运行级别 1：单用户模式，（root用户进行系统维护），系统里运行的所有服务也都不会启动 运行级别 2：多用户模式（网络文件系统NFS服务没有被启动） 运行级别 3：完全多用户模式，（有NFS网络文件系统）标准的运行级别 运行级别 4：系统未使用 运行级别 5：登录后，进入带GUI的图形化界面，标准的运行级别 运行级别 6：系统正常关闭并重启 1234567891011121314151617181920212223242526272829303132333435363738394041#查看当前系统运行级别[root@localhost etc]# runlevelN 5#解释；当前系统处于的运行级别#解释：N代表没有从任何级别跳转过来#切换系统运行级别[root@localhost ~]# init N#查看运行级别文件内容[root@localhost ~]# cat /etc/inittab # inittab is no longer used when using systemd.## ADDING CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM.## Ctrl-Alt-Delete is handled by /usr/lib/systemd/system/ctrl-alt-del.target## systemd uses 'targets' instead of runlevels. By default, there are two main targets:## multi-user.target: analogous to runlevel 3 #运行级别3# graphical.target: analogous to runlevel 5 #运行级别5## To view current default target, run:# systemctl get-default #查看当前系统默认的运行级别## To set a default target, run:# systemctl set-default TARGET.target #修改当前系统默认运行级别 #查看默认运行级别[root@localhost ~]# systemctl get-defaultgraphical.target #默认运行级别为5 #修改默认运行级别为3[root@localhost ~]# systemctl set-default multi-user.target [root@localhost ~]# systemctl get-defaultmulti-user.target#修改默认运行级别为5[root@localhost ~]# systemctl set-default graphical.target[root@localhost ~]# systemctl get-defaultgraphical.target 关机与重启 linux下常用的关机命令有：shutdown、halt、poweroff、init init 0 关机 halt #立刻关机 poweroff #立刻关机 （记这个） shutdown –h now #立刻关机 shutdown -h 10 #10分钟后自动关机 1[root@localhost ~]# poweroff 重启命令：reboot shutdown reboot #立刻重启 （记这个） shutdown -r now #立刻重启 shutdown -r 10 #过十分钟后重启 1[root@localhost ~]# reboot 课后作业1.请在/tmp目录下创建student目录，并在student目录下同时创建t1、t2、t3文件 mkdir /tmp/student cd /tmp/student/ touch t1 t2 t3 touch /tmp/student/t1 /tmp/student/t2 /tmp/student/t3 2.请在/tmp目录下递归创建test1/test2/test3目录 mkdir -p /tmp/test1/test2/test3 3.切换到/tmp/test1/test2/test3目录下，并打印(查看)当前所在目录 cd /tmp/test1/test2/test3 pwd 4.请同时在/opt、/media目录下创建upload文件 touch /opt/upload /media/upload 5.请将/opt目录下的upload文件移动至/tmp/test1/test2/test3目录下，并改名为upload.bak mv /opt/upload /tmp/test/1/test/2/test3/upload.bak 6.请将/etc/passwd文件拷贝至/opt目录下，改名为passwd.bak，并保持属性不变 cp -p /etc/passwd /opt/passwd.bak 7.请将/etc/fstab文件拷贝至/opt目录下，并改名为fstab.bak cp -p /etc/fstab /opt/fstab.bak 8.请将/etc/sysconfig/network-scripts/ifcfg-ens32 文件拷贝至/opt目录下，并改名为ens32.bak cp /etc/sysconfig/network-scripts/ifcfg-ens32 /opt/ens32.bak 9.请删除/etc/yum.repos.d/目录下所有内容 rm -rf /etc/yum.repos.d/* 10.请在/etc/yum.repos.d/目录下创建local.repo文件 touch /etc/yum.repos.d/local.repo 11.请查看/etc/sysconfig/network-scripts/ifcfg-ens32文件末尾5行内容 tail -5 /etc/sysconfig/network-scripts/ifcfg-ens32 tail -n 5 /etc/sysconfig/network-scripts/ifcfg-ens32 12.请查看/etc/passwd文件第1行内容 head -n 1 /etc/passwd head -1 /etc/passwd 13.请查看/etc/hostname文件内容 cat /etc/hostname 14.请查看/etc/hosts文件内容 cat /etc/hosts 15.请说出软连接与硬连接的特点 软连接：可以跨分区，可以对目录链接，源文件删除后链接文件不可用 硬连接：不可以跨分区，不可以对目录进行连接，源文件删除后，链接文件以然可用 16.请在/opt目录下创建hello.soft文件，并创建软连接到/tmp目录下 touch /opt/hello.soft ln -s /opt/hello.soft /tmp 17.请在/opt目录下创建hello.hard文件，并创建硬连接到/tmp目录下，并查看连接文件详细属性 touch /opt/hello.hard ln /opt/hello.hard /tmp 18.如何获取ls命令的帮助信息？ man ls ls –help 19.请说出Linux系统的运行级别 0：关机 1：单用户模式 2：多用户模式（没有NFS） 3：完全多用户模式，标准运行级别 4：保留 5：带GUI图形化界面，标准的运行级别 6：系统关闭并重启 20.如何重启Linux系统？ reboot init 6 计算机硬件组成部分 输入设备：键盘、鼠标、触控屏等 主机设备：主板、中央处理器（CPU）、主存储器（内存）、网卡、声卡、显示卡等 输出设备：屏幕、耳机、打印机、投影仪等 外部存储设备：硬盘、软盘、光盘、U盘等、蓝光光驱 硬盘：传统硬盘(HDD)==固态硬盘(SSD) CPU缓存 CPU比较主流的厂商 AMD公司 Interl公司 CPU架构 x86架构，8086架构，80286，80386，x86称号 8位、16位、32位、64位，CPU一次可以处理的数据量， 32位CPU一次可以从内存中读取大约3.25G左右的数据量 64位CPU一次可以从内存中读取大约128G左右的数据量 CPU核心 单核心，一颗CPU只能有一个运算单元 多核心，一颗CPU里边有两个以上的运算单元 计算机什么最重要？想要让计算机运行起来，足够的电力 Linux系统目录介绍 /（根）:系统所有数据都存放在根目录下 /bin：存放用户和管理员必备的可执行的二进制程序文件 /boot：存放Linux系统内核及引导系统程序所需要的文件目录 /dev：存放硬件设备的目录，如键盘、鼠标、硬盘、光盘等等 /etc：存放服务的配置文件，用户信息文件 /root：超级管理员的家目录 /home：系统普通用户的家目录 /lib：存放系统中的程序运行所需要的共享库及内核模块 /opt：额外安装的可选应用程序包所放置的位置 /srv：服务启动之后需要访问的数据目录 /tmp：一般用户或正在执行的程序临时存放文件的目录,任何人都可以访问,重要数据不可放置在此目录下 /var：存放系统执行过程中经常变化的文件，如随时都在变化的日志文件就存放/var/log/下 /mnt、/media ：光盘和镜像等预设的挂载点 /proc：Linux伪文件系统，该目录下的数据存在于内存当中，不占用磁盘空间 /lib64 ：存放函式库 /run ：程序或服务启动后，存放PID的目录 /sys：存放被建立在内存中的虚拟文件系统 /usr：操作系统软件资源所放置的目录 /usr/bin：与/bin目录相同，存放用户可以使用的命令程序 /usr/lib：与/lib目录相同，存放系统中的程序运行所需要的共享库及内核模块 /usr/etc：用于存放安装软件时使用的配置文件 /usr/games：与游戏比较相关的数据放置处 /usr/include：c/c++等程序语言的档头(header)与包含档(include)放置处 /usr/lib64：与/lib64目录相同，存放函式库 /usr/libexec：不经常被使用的执行程序或脚本会放置在此目录中 /usr/local： 额外安装的软件存放目录 /usr/sbin：该目录与/sbin目录相同，存放用户可执行的二进制程序文件 /usr/share： 放置只读架构的杂项数据文件 /usr/src：一般软件源代码建议存放该目录下 查看内核信息 uname 命令用于显示系统内核信息 命令格式：uname [-选项…] 常用选项： -s ：显示内核名称 -r ：显示内核版本 12345678910111213141516[root@localhost ~]# unameLinux[root@localhost ~]# uname -rsLinux 3.10.0-957.el7.x86_64#解释：Linux #内核名称3 #主版本10 #次版本0 #修改版本957 #补丁次数el7 #Enterprise Linux（企业版Linux）x86_64 #CPU架构#Linux内核官网https://www.kernel.org/ 查看CPU信息 /proc/cpuinfo文件用于存放系统CPU信息 lscpu 用于显示CPU架构信息 命令格式：lscpu [-选项] 1234567891011121314151617181920212223242526272829303132333435363738394041#查看/proc/cpuinfo文件内容[root@localhost ~]# cat /proc/cpuinfo processor ：#系统中逻辑处理核的编号。对于单核处理器，则可认为是其CPU编号，对于多核处理器则可以是物理核、或者使用超线程技术虚拟的逻辑核vendor_id ： #CPU制造商 cpu family ： #CPU产品系列代号model ： #CPU属于其系列中的哪一代的代号model name： #CPU属于的名字及其编号、标称主频stepping ： #CPU属于制作更新版本cpu MHz ： #CPU的实际使用主频cache size ： #CPU二级缓存大小physical id ： #单个CPU的标号siblings ：#单个CPU逻辑物理核数core id ：#当前物理核在其所处CPU中的编号，这个编号不一定连续cpu cores ： #该逻辑核所处CPU的物理核数apicid ：#用来区分不同逻辑核的编号，系统中每个逻辑核的此编号必然不同，此编号不一定连续fpu ： #是否具有浮点运算单元（Floating Point Unit）fpu_exception ： #是否支持浮点计算异常cpuid level ： #执行cpuid指令前，eax寄存器中的值，根据不同的值cpuid指令会返回不同的内容wp ： #表明当前CPU是否在内核态支持对用户空间的写保护（Write Protection）flags ： #当前CPU支持的功能bogomips ： #在系统内核启动时粗略测算的CPU速度（Million Instructions Per Second）clflush size ： #每次刷新缓存的大小单位cache_alignment ： #缓存地址对齐单位address sizes ：#可访问地址空间位数power management ： #对能源管理的支持，有以下几个可选支持功能：#使用lscpu查看cpu信息[root@localhost ~]# lscpu Architecture: #架构 CPU(s): #逻辑cpu颗数 Thread(s) per core: #每个核心线程 Core(s) per socket: #每个cpu插槽核数/每颗物理cpu核数 CPU socket(s): #cpu插槽数 Vendor ID: #cpu厂商ID CPU family: #cpu系列 Model: #型号 Stepping: #步进 CPU MHz: #cpu主频 Virtualization: #cpu支持的虚拟化技术 L1d cache: #一级缓存（google了下，这具体表示表示cpu的L1数据缓存） L1i cache: #一级缓存（具体为L1指令缓存） L2 cache: #二级缓存 查看系统内存信息 /proc/meminfo文件用于存放系统内存信息 free 用于查看内存使用情况 命令格式：free [-选项] 常用选项：-h #以人类易读方式显示大小（KB，MB，GB） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#查看/proc/meminfo文件内容[root@localhost ~]# cat /proc/meminfo MemTotal: 995896 kB #所有可用的内存大小，物理内存减去预留位和内核使用。系统从加电开始到引导完成，firmware/BIOS要预留一些内存，内核本身要占用一些内存，最后剩下可供内核支配的内存就是MemTotal。这个值在系统运行期间一般是固定不变的，重启会改变。MemFree: 244196 kB #表示系统尚未使用的内存。MemAvailable: 435080 kB #真正的系统可用内存，系统中有些内存虽然已被使用但是可以回收的，比如cache/buffer、slab都有一部分可以回收，所以这部分可回收的内存加上MemFree才是系统可用的内存Buffers: 2132 kB #用来给块设备做缓存的内存，(文件系统的 metadata、pages)Cached: 314632 kB #分配给文件缓冲区的内存,例如vi一个文件，就会将未保存的内容写到该缓冲区SwapCached: 0 kB #被高速缓冲存储用的交换空间（硬盘的swap）的大小Active: 295908 kB #经常使用的高速缓冲存储器页面文件大小Inactive: 271552 kB #不经常使用的高速缓冲存储器文件大小Active(anon): 251528 kB #活跃的匿名内存Inactive(anon): 13044 kB #不活跃的匿名内存Active(file): 44380 kB #活跃的文件使用内存Inactive(file): 258508 kB #不活跃的文件使用内存Unevictable: 0 kB #不能被释放的内存页Mlocked: 0 kB #系统调用 mlock 家族允许程序在物理内存上锁住它的部分或全部地址空间。这将阻止Linux 将这个内存页调度到交换空间（swap space），即使该程序已有一段时间没有访问这段空间SwapTotal: 0 kB #交换空间总内存SwapFree: 0 kB #交换空间空闲内存Dirty: 4 kB #等待被写回到磁盘的Writeback: 0 kB #正在被写回的AnonPages: 15100 kB #未映射页的内存/映射到用户空间的非文件页表大小Mapped: 7160 kB #映射文件内存Shmem: 100 kB #已经被分配的共享内存Slab: 9236 kB #内核数据结构缓存SReclaimable: 2316 kB #可收回slab内存SUnreclaim: 6920 kB #不可收回slab内存KernelStack: 2408 kB #内核消耗的内存PageTables: 1268 kB #管理内存分页的索引表的大小NFS_Unstable: 0 kB #不稳定页表的大小Bounce: 0 kB #在低端内存中分配一个临时buffer作为跳转，把位于高端内存的缓存数据复制到此处消耗的内存WritebackTmp: 0 kB #FUSE用于临时写回缓冲区的内存CommitLimit: 22980 kB #系统实际可分配内存Committed_AS: 536244 kB #系统当前已分配的内存VmallocTotal: 892928 kB #预留的虚拟内存总量VmallocUsed: 29064 kB #已经被使用的虚拟内存VmallocChunk: 860156 kB #可分配的最大的逻辑连续的虚拟内存#使用free命令查看内存使用情况[root@localhost ~]# free -h total used free shared buff/cache availableMem: 972M 344M 238M 13M 389M 424MSwap: 2.0G 0B 2.0G#解释：Mem 物理内存统计信息total： #物理内存总量used： #以使用的内存总量free： #空闲内存总量shared： #共享内存总量buff/cache： #块设备与普通文件占用的缓存数量available： #还可以被应用程序使用的物理内存大小#解释：Swap 内存交换空间，当物理内存不足时，可以使用硬盘空间充当内存使用total： #交换分区内存总量used： #正在使用的交换分区内存free： #空闲交换分区内存 查看网卡信息 网卡配置文件地址： /etc/sysconfig/network-scripts/网卡名 ifconfig 用于显示和设置网卡的参数 命令格式： ifconfig [网卡名] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657[root@localhost ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens32TYPE=“Ethernet“ #网卡类型=以太 ※PROXY_METHOD=“none“ #代理方式=关闭BROWSER_ONLY=&quot;no“ #只是浏览器=否BOOTPROTO=“none“ #获取IP地址的方式=固定IP ※DEFROUTE=“yes“ #是否设置默认路由=是IPV4_FAILURE_FATAL=“no“ #是否开启ipv4致命检测=否（如果ipv4配置失败禁用设备）NAME=“ens32“ #物理网卡设备名字 ※UUID=“3ef0d258-f9a4-49e5-a9da-7b47bc98daa0 “#网卡UUIDDEVICE=“ens32“ #网卡名字 ※ONBOOT=“yes“ #开机或重启时是否启动网卡 ※IPADDR=“192.168.0.210“ #IP地址 ※PREFIX=“24“ #子网掩码 ※GATEWAY=“192.168.0.254“ #网关 ※DNS1=“8.8.8.8“ #dns服务器IP地址 ※DNS2=8.8.4.4 #备用dns服务器IP地址 ※#使用ifconfig命令查看网卡信息[root@localhost ~]# ifconfigens32: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.0.29 netmask 255.255.255.0 broadcast 192.168.0.255 inet6 fe80::8d50:c4d5:97b0:9d64 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:b0:cf:c8 txqueuelen 1000 (Ethernet) RX packets 3948 bytes 1811465 (1.7 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 2538 bytes 459113 (448.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0#解释：ens32: #网卡名称 ※flags=4163： #标志UP： #网卡处于活跃状态 ※BROADCAST： #支持广播RUNNING： #网线已接入MULTICAST： #支持组播mtu 1500： #最大传输单元（字节），表示此网卡一次能传输的最大数据包 ※inet 192.168.0.29 #IPV4地址 ※netmask 255.255.255.0 #子网掩码 ※broadcast 192.168.0.255 #广播地址 ※inet6 fe80::8d50:c4d5:97b0:9d64 #IPV6地址prefixlen 64 scopeid 0x20&lt;link&gt; #前缀 64 作用域 0x20ether 00:0c:29:b0:cf:c8 #网卡MAC地址 ※xqueuelen 1000 #网卡设置的传送队列长度(Ethernet) #网卡连接类型RX packets 3948 #接收正确的数据包 ※bytes 1811465 (1.7 MiB) #接收的数据量与字节 ※RX errors 0 dropped 0 overruns 0 frame 0 #接收到的错误包、丢弃的数据包数、由于速度过快而丢失的数据包、发生frame错误而丢失的数据包数 ※TX packets 100 #发送的正确的数据包数 ※bytes 8116 (7.9 KiB)#发送的数据量、字节 ※TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 #发送时产生错误的数据包数、丢弃的数据包数、由于速度过快而丢失的数据包数、发生carrier错误而丢失的数据包数、冲突信息包的数目 ※#只查看指定的网卡[root@localhost ~]# ifconfig ens32lo: 本地回环网卡，不是物理网卡，通过软件虚拟出来的一个网卡，127.0.0.1，用于测试本机的联通性[root@localhost ~]# ping 127.0.0.1virbr0: 虚拟化的网络接口，通过软件技术虚拟出来的一个网卡，192.168.122.1，KVM虚拟化技术的时候 查看主机名及修改主机名 /etc/hostname文件用于存放主机名 hostname 命令用于显示和设置主机名 命令格式：hostname [-选项] [新名称] 123456789101112131415161718192021222324252627#查看主机名[root@localhost ~]# hostnamelocalhost.localdomain#查看主机名配置文件[root@localhost ~]# cat /etc/hostname localhost.localdomain#临时修改主机名（立刻生效，服务器重启以后失效）[root@localhost ~]# hostname test[root@localhost ~]# hostnametest#exit/loguot登出系统[root@localhost ~]# exit[c:\\~]$ ssh 192.168.0.50[root@test ~]# [root@test ~]# hostname fhsd.jhglshdjkghjkdfhgkjhgdsahgjklhdsfjghsdhgjlhsd[root@test ~]# logout[root@fhsd ~]# hostname sdhjghsdfjkhgkjdfshkgljhsdjfhgjksdhgjkhsdjgjkl[root@fhsd ~]# exit#命令行永久修改主机名（立刻生效，不需要重启系统）[root@localhost ~]# hostnamectl set-hostname test[root@localhost ~]# exit vi/vim文本编辑器 Vim是从 vi 发展出来的一个文本编辑器，vim 具有程序编辑的能力，可以主动的以字体颜色辨别语法的正确性 vi/vim 共分为三种模式：命令模式、输入模式、底线命令模式（末行模式） 命令模式：刚刚启动 vi/vim，便进入了命令模式 输入模式：在命令模式下按 a/i/o 就进入了输入模式 ESC，退出输入模式，切换到命令模式 底线命令模式：在命令模式下按下:（英文冒号）就进入了底线命令模式 命令格式：vim 文件名 若目标文件不存在，则新创建文件并编辑 若目标文件以存在，则打开文件并编辑 命令模式：刚刚启动 vi/vim，便进入了命令模式 i 切换到输入模式，在当前光标所在字符前插入 a 切换到输入模式，在当前光标所在字符后插入 o 切换到输入模式，在当前光标所在行下插入新行 : 切换到底线命令模式，以在最底一行输入命令 x 在命令模式下删除当前光标所在的单字符 dd 删除一整行内容，配合数字可删除指定范围内的行 C 删除当前光标及光标后所有内容并进入输入模式 u 恢复上一次修改内容，一次恢复一个操作，可多次恢复，直到恢复本次操作初始状态为止 $ 将光标移动至行尾 0（零） 将光标移动至行首 gg 跳转至文件第一行 G 跳转至文件最后一行 yy 复制当前行，配合数字可以同时复制多行 p 粘贴当前光标所在行下 /关键字 搜索文件内关键字，n从上向下快速定位关键字，N从下向上快速定位关键字 底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。 :w 保存 :q 退出 :wq 保存并退出 :q! 强制退出不保存 :wq! 强制保存并退出 :set nu 以行号形式显示文件内容 :set nonu 取消行号显示 :行号 快速跳转到指定行 :r 读入另一个文件的数据 , 文件内容填加到光标的下一行 :nohl 取消高亮显示 1[root@test ~]# vim /etc/services 修改网卡IP地址 网卡配置文件地址： /etc/sysconfig/network-scripts/网卡名 ifconfig #用于显示和设置网卡的参数 systemctl restart network #重启网络 ifup 网卡名 #启动该网卡设备 ifdown 网卡名 #禁用该网卡设备 1234567891011121314151617181920212223242526272829303132#修改IP地址[root@test ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens32 TYPE=&quot;Ethernet&quot;PROXY_METHOD=&quot;none&quot;BROWSER_ONLY=&quot;no&quot;BOOTPROTO=&quot;none&quot;DEFROUTE=&quot;yes&quot;IPV4_FAILURE_FATAL=&quot;no&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;IPV6_DEFROUTE=&quot;yes&quot;IPV6_FAILURE_FATAL=&quot;no&quot;IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot;NAME=&quot;ens32&quot;UUID=&quot;16085f4c-f690-4058-b29e-d55c73387026&quot;DEVICE=&quot;ens32&quot;ONBOOT=&quot;yes&quot;IPADDR=&quot;192.168.0.60&quot; #修改IP地址PREFIX=&quot;24&quot;GATEWAY=&quot;192.168.0.254&quot;DNS1=&quot;114.114.114.114&quot;IPV6_PRIVACY=&quot;no&quot;~ #重启网络（IP地址发生改变，当前终端会断开）[root@test ~]# systemctl restart network[c:\\~]$ ssh 192.168.0.60#启动该网卡[root@test ~]# ifup ens32#查看所有网卡信息[root@test ~]# ip a 使用命令修改网卡IP地址 nmcli connection modify 网卡名 ipv4.method manual ipv4.addresses Ip地址/掩码 connection.autoconnect yes 解释： nmcli connection modify（修改） 网卡名 ipv4.method（配置ipv4地址方法） manual （手动配置） ipv4.addresses（ipv4地址） Ip地址/掩码 connection.autoconnect yes（开机自动连接） 激活网卡：nmcli connection up 网卡名 关闭网卡：nmcli connection down 网卡名 重启网卡：nmcli connection reload 网卡名 123456#使用命令修改网卡IPV地址[root@test ~]# nmcli connection modify ens32 ipv4.method manual ipv4.addresses 192.168.0.50/24 connection.autoconnect yes#激活网卡[root@test ~]# nmcli connection up ens32[c:\\~]$ ssh 192.168.0.50 host命令 host用于将一个域名解析到一个IP地址 12345[root@test ~]# host www.baidu.comwww.baidu.com has address 110.242.68.3www.baidu.com has address 110.242.68.4www.baidu.com is an alias for www.a.shifen.com.www.baidu.com is an alias for www.a.shifen.com. nslookup命令 nslookup用于查询域名解析是否正常，在网络故障时用来诊断网络问题 123456789[root@test ~]# nslookup www.baidu.comServer: 114.114.114.114Address: 114.114.114.114#53Non-authoritative answer:Name: www.baidu.comAddress: 110.242.68.4Name: www.baidu.comAddress: 110.242.68.3 alias别名管理 alias命令用于设置命令别名，用户可以使用alias自定义命令别名来简化命令的复杂度 .bashrc 文件存放命令别名 命令格式：aliasi [别名]=[命令] #注意事项：等号（=）前后不能有空格 unalias 别名 #取消别名 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#定义别名[root@test ~]# alias lsnet='ls /etc/sysconfig/network-scripts/'[root@test ~]# lsnet[root@test ~]# alias myls='ls -ldh'[root@test ~]# myls /opt#查看当前系统可用命令别名[root@test ~]# aliasalias cp='cp -i'alias egrep='egrep --color=auto'alias fgrep='fgrep --color=auto'alias grep='grep --color=auto'alias l.='ls -d .* --color=auto'alias ll='ls -l --color=auto'alias ls='ls --color=auto'alias lsnet='ls /etc/sysconfig/network-scripts/'alias mv='mv -i'alias myls='ls -ldh'alias rm='rm -i'alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'#两条命令效果相同[root@test ~]# ls -l hello-rw-r--r--. 1 root root 426 3月 28 15:00 hello[root@test ~]# ll hello-rw-r--r--. 1 root root 426 3月 28 15:00 hello[root@test ~]# which lsalias ls='ls --color=auto' /usr/sbin/ls[root@test ~]# /usr/sbin/ls[root@test ~]# ls#取消本次命令的别名功能“\\”[root@test ~]# \\ls#取消命令别名[root@test ~]# unalias myls[root@test ~]# mylsbash: myls: 未找到命令...#定义别名不要跟系统命令发生冲突[root@test ~]# alias ls=hostname[root@test ~]# lstest#取消命令别名[root@test ~]# unalias ls[root@test ~]# alias#重新定义别名[root@test ~]# alias ls='ls --color=auto'[root@test ~]# ls history 管理历史 history命令用于显示历史记录和执行过的命令，登录shell时会读取~./bash_history历史文件中记录下的命令，当退出或登出shell时，会自动保存到历史命令文件，该命令单独使用时，仅显示历史命令 历史命令默认只能存储1000条，可以通过/etc/profile文件修改 命令格式：history [-选项] [参数] 常用选项： -a 追加本次新执行的命令至历史命令文件中 -d 删除历史命令中指定的命令 -c 清空历史命令列表 快捷操作： !# 调用命令历史中第N条命令 !string 调用命令历史中以strind开头的命令 !! 重复执行上一条命令 123456789101112131415161718192021222324252627282930313233343536373839#获取命令帮助[root@test ~]# help history #查看历史命令[root@test ~]# history#查看记录历史命令文件[root@test ~]# cat .bash_history #将历史命令同步至历史命令配置文件中[root@test ~]# history -a[root@test ~]# cat .bash_history #删除历史命令中655条命令历史[root@test ~]# history -d 655[root@test ~]# history -d 637#清空缓存中所有历史命令[root@test ~]# history -c[root@test ~]# history 1 history#删除历史命令配置文件（该文件删除后系统会再次自动创建）[root@test ~]# rm -rf .bash_history #快速调用历史命令中第1条[root@test ~]# !1[root@test ~]# !3#调用历史命令中以cat开头的命令（只调用最近使用的cat历史命令）[root@test ~]# !cat#重复执行上一条命令[root@test ~]# !!#历史命令默认只能记录1000条，可以通过/etc/profile文件修改[root@test ~]# vim /etc/profile...46 HISTSIZE=100 date日期时间管理 date命令用于显示或设置系统日期与时间 命令格式：date [-选项] [+格式符] #查看系统日期时间 date [-选项] [MMDDhhmm[[CC]YY][.ss]] #设置日期时间 常用选项：-s 设置日期时间 格式符： +%Y 年份 +%B 月份 +%d 日 +%H 时 +%M 分 +%S 秒 +%F 年-月-日 +%X 时：分：秒 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#显示系统日期与时间[root@test ~]# date2021年 03月 28日 星期日 17:08:34 CST#只显示年分[root@test ~]# date +%Y2021#只显示月份[root@test ~]# date +%B三月#只显示几号[root@test ~]# date +%d28#只显示小时[root@test ~]# date +%H17#只显示分钟[root@test ~]# date +%M10#只显示秒[root@test ~]# date +%S24#显示年月日[root@test ~]# date +%F2021-03-28#显示时分秒[root@test ~]# date +%X17时12分10秒#显示年月日时分秒[root@test ~]# date +%F%X2021-03-2817时12分39秒#可以自定义分隔符“-”[root@test ~]# date +%F-%X2021-03-28-17时13分38秒[root@test ~]# date +%F:%X2021-03-28:17时13分55秒#修改系统年月日[root@test ~]# date -s 2020-03-282020年 03月 28日 星期六 00:00:00 CST#修改系统时分秒[root@test ~]# date -s 17:16:002020年 03月 28日 星期六 17:16:00 CST#修改年月日时分秒[root@test ~]# date -s '2021-03-28 17:17:00'2021年 03月 28日 星期日 17:17:00 CST#解释：''单引号：引用整体，屏蔽特殊符号的功能&quot;&quot;双引号：引用整体，不会屏蔽特殊符号的功能#Linux的两种时钟系统时钟：内核通过CPU的工作频率去计算的时间硬件时钟：#显示硬件时间[root@test ~]# clock2021年03月28日 星期日 17时23分42秒 -0.945549 秒#显示并同步系统与硬件时钟[root@test ~]# man hwclock-s：把系统时间设置成与硬件时间相同-w：把硬件时间设置成与系统时间相同[root@test ~]# hwclock -w[root@test ~]# date2021年 03月 28日 星期日 17:27:18 CST#cal显示日历[root@test ~]# cal 三月 2021 日 一 二 三 四 五 六 1 2 3 4 5 6 7 8 9 10 11 12 1314 15 16 17 18 19 2021 22 23 24 25 26 2728 29 30 31#显示指定的全年月份[root@test ~]# cal 2021 wc统计命令 wc 用于统计文件的字节数、行数，并将统计的结果输出到屏幕 命令格式：wc [-选项] 文件名 常用选项： -c #统计字节数 -l #统计行数 1234567891011121314[root@test ~]# wc /etc/passwd43 87 2259 /etc/passwd行数 单词 字节 文件名#统计文件字节数[root@test ~]# wc -c /etc/passwd2259 /etc/passwd#统计文件行数[root@test ~]# wc -l /etc/passwd43 /etc/passwd[root@test ~]# wc -l /etc/fstab11 /etc/fstab 管道符 管道符“|”：将命令的输出结果交给另外一条命令作为参数继续处理 123456789101112131415[root@test ~]# head -10 /etc/passwd |tail -5[root@test ~]# head -10 /etc/passwd |tail -5 |wc -l5root@test ~]# cat -n /etc/passwd |head -10|tail -5 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 8 halt:x:7:0:halt:/sbin:/sbin/halt 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 10 operator:x:11:0:operator:/root:/sbin/nologin[root@test ~]# ifconfig ens32 |head -2ens32: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.0.50 netmask 255.255.255.0 broadcast 192.168.0.255 重定向操作 重定向操作:将前面命令的输出结果，写入到其他的文本文件中 重定向的表示符号 &gt; #重定向输出（覆盖） &gt;&gt; #重定向输出（追加） &lt; #输入重定向（覆盖） &lt;&lt; **#**输入重定向（追加） &gt; 只收集正确的输出结果 2&gt; 只收集错误的输出结果 &amp;&gt; 正确错误都收集 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#将命令的输出结果以覆盖的方式重定向到文件中，（&gt;附带创建文件功能）[root@test ~]# ifconfig ens32 |head -2 &gt; /opt/ens32.bakens32: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.0.50 netmask 255.255.255.0 broadcast 192.168.0.255[root@test ~]# cat /etc/hostname &gt; /opt/ens32.bak [root@test ~]# cat /opt/ens32.bak test[root@test ~]# free -h &gt; /opt/free.bak[root@test ~]# cat /opt/free.bak total used free shared buff/cache availableMem: 972M 414M 123M 15M 435M 336MSwap: 2.0G 0B 2.0G#将命令的输出结果以追加的方式重定向到文件中[root@test ~]# cat /etc/hostname &gt;&gt; /opt/free.bak [root@test ~]# cat /opt/free.bak #“&gt;”只收集正确的输出结果，不收集错误的输出结果[root@test ~]# ls xxooooxx &gt; /opt/xx.txtls: 无法访问xxooooxx: 没有那个文件或目录#“2&gt;”只收集错误的输出结果，不收集正确的输出结果[root@test ~]# ls xxooooxx 2&gt; /opt/xx.txt[root@test ~]# cat /opt/xx.txt ls: 无法访问xxooooxx: 没有那个文件或目录#“2&gt;”以覆盖的方式将输出结果重定向到文件中[root@test ~]# cat /etc/abc 2&gt; /opt/ens32.bak [root@test ~]# cat /opt/ens32.bak cat: /etc/abc: 没有那个文件或目录#“2&gt;&gt;”以追加的方式将输出结果重定向到文件中[root@test ~]# ls /etc/abcd 2&gt;&gt; /opt/ens32.bak [root@test ~]# cat /opt/ens32.bak cat: /etc/abc: 没有那个文件或目录ls: 无法访问/etc/abcd: 没有那个文件或目录#“&amp;&gt;”以覆盖的方式将正确输出与错误输出重定向到文件中[root@test ~]# lscat &amp;&gt; /opt/abc.txt[root@test ~]# cat /opt/abc.txt [root@test ~]# ls /etc/passwd &amp;&gt; /opt/pass.bak[root@test ~]# cat /opt/pass.bak [root@test ~]# free -h &amp;&gt; /opt/pass.bak [root@test ~]# cat /opt/pass.bak #“&amp;&gt;”以追加的方式将正确输出与错误输出重定向到文件中[root@test ~]# ifconfig ens32 | head -2 &amp;&gt;&gt; /opt/pass.bak [root@test ~]# cat /opt/pass.bak #以覆盖方式将正确输出与错误输出重定向到不同文件中[root@test ~]# ll -d /root/ bcd &gt;a.txt 2&gt;b.txt[root@test ~]# cat a.txt dr-xr-x---. 24 root root 4096 3月 28 18:07 /root/[root@test ~]# cat b.txt ls: 无法访问bcd: 没有那个文件或目录 echo命令与sleep命令 echo命令用于输出指定的字符串和变量 命令格式：echo [-选项] [参数] 123456789101112131415161718192021[root@test ~]# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin[root@test ~]# echo xxooxxoo[root@test ~]# echo abcabc[root@test ~]# echo 男人好难男人好难[root@test ~]# echo 123123[root@test ~]# cat /etc/hostname test[root@test ~]# echo localhost &gt; /etc/hostname[root@test ~]# cat /etc/hostname localhost sleep命令可以用来将目前动作延迟一段时间 命令格式：sleep 时间 常用选项： s 秒 m 分钟 h 小时 d 日 1[root@test ~]# sleep 3 课后作业1.查看当前系统内核名称及版本信息 uname -sr 2.请写系统存放cpu配置文件 /proc/cpuinfo 3.请写出查看cpu信息命令 cat /proc/cpuinfo lscpu 4.请写出系统存放内存配置文件 /proc/meminfo 5.请写出查看内存命令（以人类易读方式显示） free -h 6.请写出系统存放网卡配置文件路径 /etc/sysconfig/network-scripts/ 7.请写出查看网卡配置信息命令 ifconfig（如果系统最小化安装，需要安装net-tools） ip a （ip address） 8.请写出系统存放主机名配置文件 /etc/hostname 9.请写出查看主机名命令 cat /etc/hostname hostname 10.将主机名修改为student（永久修改） hostnamectl set-hostname student vim /etc/hostname echo student &gt; /etc/hostname 11.请写出vim的三种模式 命令模式 输入模式 底线命令模式（末行模式） 12.将/etc/passwd文件复制到/opt目录，使用vim打开文件并显示行号 cp /etc/passwd /opt vim /opt/passwd :set nu 13.使用vim在/opt/passwd文件中搜索包含root关键字的行 /root 14.使用vim在/opt/passwd文件中将光标快速跳转到第10行，并将光标跳转到行尾 :10 $ 15.使用vim在/opt/passwd文件中快速跳转到文件最后一行并删除，在将光标跳转到文件第一行，将刚刚删除的行复制到文件第二行 G dd p 16.使用vim将/etc/hostname文件内容读入到/opt/passwd文件最后一行下 :r /etc/hostname 17.使用vim在/opt/passwd文件中复制前5行内容并粘贴到文件最后一行下 5yy p 18.将本次vim的修改恢复至初始状态，并保存退出 u :wq 19.将本机IP地址修改为192.168.0.100，并重启动网卡 vim /etc/sysconfig/network-scripts/ifcfg-ens32 systemctl restart network 20.如何获取一个域名所对应的IP地址 host www.baidu.com 21.如何检测本机使用的DNS是否可用 nslookup www.jd.com 22.请将hostname命令设置别名为hn（临时设置） alias hn=hostname 23.取消hostname命令别名 unalias hn 24.如何查看本机历史命令 history 25.执行命令历史中第20条命令 !20 26.删除命令历史中第5条命令 history -d 5 27.清空所有历史命令 history -c rm -rf .bash_history 28.查看本机当前系统日期与时间 date 29.将本机日期时间设置与你当前时间一致 date -s ‘2021-04-10 14:32:00’ 30.统计/etc/passwd文件行数，并将命令输出结果重定向至/opt/pass.bak文件中 wc -l /etc/passwd &gt; /opt/pass.bak 31.显示/etc/passwd文件末尾10行的前5行内容，并将输出结果追加至/opt/pass.bak文件中 tail -10 /etc/passwd | head -5 &gt; /opt/pass.bak cat -n /etc/passwd | tail -10 | head -5 &gt;&gt; /opt/pass.bak 用户账号管理 用户账号的作用：用户账号可用来登录系统，可以实现访问控制 用户模板目录：/etc/skel/ 12345[root@localhost ~]# ls -a /etc/skel/. .. .bash_logout .bash_profile .bashrc .mozilla[root@localhost ~]# cd /etc/skel/[root@localhost skel]# vim prompt useradd创建用户 useradd 命令用于创建新的用户 命令格式：useradd [-选项] 用户名 常用选项： -u 指定用户UID -d 指定用户家目录 -c 用户描述信息 -g 指定用户基本组 -G 指定用户附加组 -s 指定用户的shell 1234567891011121314151617181920212223242526[root@localhost ~]# useradd user1#创建用户并指定用户的UID[root@localhost ~]# useradd -u 1100 user2#创建用户并指定用户的家目录root@localhost ~]# useradd -d /opt/user3 user3#创建用户并指定UID与用户描述信息[root@localhost ~]# useradd -u 1400 -c yunwei user4#创建test组[root@localhost ~]# groupadd test#创建用户指定用户UID、描述信息、基本组[root@localhost ~]# useradd -u 1500 -c xxoo@163.com -g test user5[root@localhost ~]# id user5#创建用户指定用户UID、描述信息、附加组[root@localhost ~]# useradd -u 1600 -c yunwei -G test xiaozhang[root@localhost ~]# id xiaozhanguid=1600(xiaozhang) gid=1600(xiaozhang) 组=1600(xiaozhang),1401(test)#/sbin/nologin ：禁止用户登录系统[root@localhost ~]# useradd -u 1800 -c test -s /sbin/nologin user8user8:x:1800:1800:test:/home/user8:/sbin/nologin id命令 id 命令用于查看系统用户和用户所在组的信息 命令格式：id [-选项] [用户名] 12[root@localhost ~]# id user1uid=1001(user1) gid=1001(user1) 组=1001(user1) /etc/passwd用户信息文件用户的基本信息存放在/etc/passwd文件 123456[root@localhost ~]# vim /etc/passwdroot:x:0:0:root:/root:/bin/bash#每个字段含义解释：用户名:密码占位符:UID:基本组GID:用户描述信息:家目录:解释器程序UID：0 超级用户UID：1-499 系统伪用户，不能登录系统并且没有家目录UID：500-65535 普通用户 组： 基本组（初始组）：一个用户只允许有一个基本组 附加组（在基本组之外组）：一个用户可以允许有多个附加组 用户—&gt;shell程序—&gt;内核—&gt;硬件 /etc/default/useradd文件/etc/default/useradd 存放用户默认值信息 123456789[root@localhost ~]# vim /etc/default/useradd# useradd defaults fileGROUP=100 #用户默认组HOME=/home #用户家目录INACTIVE=-1 #密码过期宽限天数（/etc/shadow文件第7个字段）EXPIRE= #密码失效时间（/etc/shadow文件第8个字段）SHELL=/bin/bash #默认使用的shellSKEL=/etc/skel #模板目录CREATE_MAIL_SPOOL=yes #是否建立邮箱 /var/spool/mail/用户邮件目录12[root@localhost ~]# ls /var/spool/mail/laowang lisi rpc user1 user2 user3 user4 user5 user8 xiaozhang passwd设置用户密码 passwd命令用于设置用户密码 命令格式：passwd [-选项] [用户名] 密码规范：长度不能少于8个字符，复杂度（数字、字母区分大小写，特殊字符），普通用户 密码规范：本次修改的密码不能和上次修改的密码太相近 123xxoo…A 常用选项 -S 查看密码信息 -l 锁定用户密码 -u 解锁用户密码 -d 删除密码 –stdin 通过管道方式设置用户密码 非交互设置用户密码 命令格式：echo “密码” | passwd –stdin 用户名 12345678910111213141516171819202122232425262728293031323334353637383940#设置用户密码[root@localhost ~]# passwd user1更改用户 user1 的密码 。新的 密码：1无效的密码： 密码是一个回文重新输入新的 密码：1passwd：所有的身份验证令牌已经成功更新。#使用user1用户登录系统[user1@localhost ~]$ lsprompt[user1@localhost ~]$ cat prompt 不允许随便修改系统xx文件！有问题可联系管理员邮箱：xxoo@163.com#查看用户密码信息[root@localhost ~]# passwd -S user1#锁定用户当密码[root@localhost ~]# passwd -l user2锁定用户 user2 的密码 。passwd: 操作成功[root@localhost ~]# passwd -S user2user2 LK 2021-04-10 0 99999 7 -1 (密码已被锁定。)#解锁用户密码[root@localhost ~]# passwd -u user2解锁用户 user2 的密码。passwd: 操作成功#删除用户密码[root@localhost ~]# passwd -d user2清除用户的密码 user2。passwd: 操作成功#非交互设置用户密码[root@localhost ~]# echo 1 | passwd --stdin laowang更改用户 laowang 的密码 。passwd：所有的身份验证令牌已经成功更新。 /etc/shadow用户密码文件 用户的密码信息存放在/etc/shadow文件中，该文件默认任何人都没有任何权限（不包括root） 123456789101112131415[root@localhost ~]# vim /etc/shadowroot:$6$1ji5e8yglrZWAcI6$FONKr3qebZufQ.u0Mf/MbipzGw/MVvxS.vgXcy/duc4b/GU0U7tfe37wPQ4XJEXstqBuwvaJqq2/kY/g/783u/::0:99999:7:::#每个字段含义解释：第一字段：用户名第二字段：密码加密字符串，加密算法为SHA512散列加密算法，如果密码位是“*”或者“!!”表示密码已过期第三个字段：密码最后一次修改日期，日期从1970年1月1日起，每过一天时间戳加1第四个字段：密码修改的期限，如果该字段为0表示随时可以修改密码，例如：该字段为10，代表10天之内不可以修改密第五个字段：密码有效期第六个字段：密码到期前警告时间（和第五个字段相比）第七个字段：密码过期后的宽限天数（和第五个字段相比）第八个字段：账号失效时间，日期从1970年1月1日起第九个字段：保留#chage命硬用于修改/etc/shadow文件信息，修改文件内容第三个字段（密码最后一次修改时间）[root@localhost ~]# chage -d 0 user8 su命令 su命令用于切换当前用户身份到其他用户身份 命令格式：su [-选项] [用户名] 123456789101112131415161718#只切换用户身份，环境没有改变[root@localhost ~]# su user1[user1@localhost root]$ lsls: 无法打开目录.: 权限不够[user1@localhost root]$ cd[user1@localhost ~]$ exitexit#切换用户身份，连同环境一起切换[root@localhost ~]# su - user1上一次登录：六 4月 10 16:54:40 CST 2021pts/1 上[user1@localhost ~]$ pwd/home/user1#普通用户切换为root（需要输入root用户的密码）[user1@localhost ~]$ su - root密码：上一次登录：六 4月 10 16:05:17 CST 2021从 192.168.0.1pts/2 上 usermod修改用户属性 usermod 命令用于修改已存在用户的基本信息 命令格式：usermod [-选项] 用户名 常用选项： -u 修改用户UID -d 修改用户家目录 -g 修改用户基本组 -c 修改用户描述信息 -G 添加用户附加组 -s 修改用户shell 123456789101112131415#修改用户UID（用户如果以登录系统，不允许修改）[root@localhost ~]# usermod -u 1111 user1[root@localhost ~]# id user1uid=1111(user1) gid=1001(user1) 组=1001(user1)#修改用户描述信息[root@localhost ~]# usermod -c xxoo@163.com user8#修改用户的附加组[root@localhost ~]# usermod -G test user8[root@localhost ~]# id user8uid=1800(user8) gid=1800(user8) 组=1800(user8),1401(test)#修改用户的解释器[root@localhost ~]# usermod -s /bin/bash user8 userdel删除用户 userdel 用于删除给定的用户以及与用户相关的文件，该命令若不加选项仅删除用户账号，不删除用户相关文件 命令格式：userdel [-选项] 用户名 常用选项： -r 删除用户同时，删除与用户相关的所有文件 12345678910111213#删除用户，仅删除账号，不删除家目录[root@localhost ~]# userdel user8[root@localhost ~]# ls /homelaowang lisi user1 user2 user4 user5 user8 xiaozhang[root@localhost ~]# id user8id: user8: no such user#删除用户，连同用户家目录一并删掉[root@localhost ~]# userdel -r user4[root@localhost ~]# ls /homelaowang lisi user1 user2 user5 user8 xiaozhang[root@localhost ~]# id user4id: user4: no such user groupadd添加新组 groupadd 用于创建一个新的工作组，新组的信息将被添加到/etc/group文件中 命令格式：groupadd [-选项] 组名 常用选项： -g GID #指定组的GID 123#创建组[root@localhost ~]# groupadd -g 1555 student[root@localhost ~]# cat /etc/group /etc/group组信息文件 组信息存放在/etc/group文件中 123[root@localhost ~]# vim /etc/grouproot:x:0:#每个字段含义解释：组名:组密码占位符:GID:组中附加用户 /etc/gshadow组密码文件 组密码信息存放在/etc/gshadow文件中 123[root@localhost ~]# vim /etc/gshadowroot:::#每个字段含义解释：组名:组密码:组内管理员:组中附加用户 groupmod修改组属性 groupmod 用于修改指定工作组属性 命令格式：groupmod [-选项] 组名 常用选项： -g GID #修改组的GID -n 新组名 #修改组名 12345#修改组名[root@localhost ~]# groupmod -n stugrp student#修改组GIDroot@localhost ~]# groupmod -g 1666 stugrp gpasswd组管理命令 gpasswd 是Linux工作组文件/etc/group和/etc/gshadow管理工具，用于将用户添加到组或从组中删除 命令格式：gpasswd [-选项] 用户名 组名 常用选项： -a #将用户添加到工作组 -d #将用户从工作组中删除 123456789101112131415161718192021222324252627282930313233#创建用户[root@localhost ~]# useradd hary[root@localhost ~]# useradd tom[root@localhost ~]# useradd natasha[root@localhost ~]# useradd kenji[root@localhost ~]# useradd jack#讲用户加入到组[root@localhost ~]# gpasswd -a hary stugrp正在将用户“hary”加入到“stugrp”组中[root@localhost ~]# gpasswd -a tom stugrp正在将用户“tom”加入到“stugrp”组中[root@localhost ~]# gpasswd -a kenji stugrp正在将用户“kenji”加入到“stugrp”组中[root@localhost ~]# gpasswd -a natasha stugrp正在将用户“natasha”加入到“stugrp”组中[root@localhost ~]# gpasswd -a jack stugrp正在将用户“jack”加入到“stugrp”组中[root@localhost ~]# #查看组文件信息[root@localhost ~]# cat /etc/groupstugrp:x:1666:hary,tom,kenji,natasha,jack#将用户从组中删除root@localhost ~]# gpasswd -d tom stugrp[root@localhost ~]# gpasswd -d hary stugrp正在将用户“hary”从“stugrp”组中删除[root@localhost ~]# gpasswd -d jack stugrp正在将用户“jack”从“stugrp”组中删除[root@localhost ~]# gpasswd -d kenji stugrp正在将用户“kenji”从“stugrp”组中删除[root@localhost ~]# cat /etc/group groupdel删除组 groupdel 用于删除指定工作组 命令格式：groupdel 组名 1[root@localhost ~]# groupdel stugrp chmod权限管理 chmod（英文全拼：change mode）设置用户对文件的权限 命令格式：chmod [-选项] 归属关系+-=权限类别 文件… root用户可以修改任何文件和目录的权限 文件所有者 常用选项： -R 递归修改，包含目录下所有的子文件与子目录 归属关系：u 所有者 g 所属组 o 其他人 权限类别： r 读取 w 写入 x 执行 - 没有权限 操作：+ 添加权限 - 去除权限 = 重新定义权限 权限数字表示：r —- 4 w —- 2 x —- 1 0 没有权限 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167#查看文件详细属性[root@localhost ~]# ll hello-rw-r--r--. 1 root root 426 3月 28 15:00 hello#为文件所有者添加执行权限[root@localhost ~]# chmod u+x hello[root@localhost ~]# ll hello-rwxr--r--. 1 root root 426 3月 28 15:00 hello#为文件所属组添加写权限[root@localhost ~]# chmod g+w hello[root@localhost ~]# ll hello-rwxrw-r--. 1 root root 426 3月 28 15:00 hello#为文件其他人添加写权限[root@localhost ~]# chmod o+w hello[root@localhost ~]# ll hello-rwxrw-rw-. 1 root root 426 3月 28 15:00 hello#使用（逗号）可以同时为多个用户授权[root@localhost ~]# chmod g+x,o+x hello[root@localhost ~]# ll hello-rwxrwxrwx. 1 root root 426 3月 28 15:00 hello#去除所有者执行权限[root@localhost ~]# chmod u-x hello[root@localhost ~]# ll hello-rw-rwxrwx. 1 root root 426 3月 28 15:00 hello#去除所属组执行权限[root@localhost ~]# chmod g-x hello[root@localhost ~]# ll hello-rw-rw-rwx. 1 root root 426 3月 28 15:00 hello#去除其他人执行权限[root@localhost ~]# chmod o-x hello[root@localhost ~]# ll hello-rw-rw-rw-. 1 root root 426 3月 28 15:00 hello#同时去除ugo写权限[root@localhost ~]# chmod u-w,g-w,o-w hello[root@localhost ~]# ll hello-r--r--r--. 1 root root 426 3月 28 15:00 hello#重新定义所有者权限[root@localhost ~]# chmod u=rwx hello[root@localhost ~]# ll hello-rwxr--r--. 1 root root 426 3月 28 15:00 hello#重新定义所属组权限[root@localhost ~]# chmod g=rwx hello[root@localhost ~]# ll hello-rwxrwxr--. 1 root root 426 3月 28 15:00 hello#重新定义其他人权限[root@localhost ~]# chmod o=rwx hello[root@localhost ~]# ll hello-rwxrwxrwx. 1 root root 426 3月 28 15:00 hello#创建目录并设置目录权限[root@localhost ~]# mkdir /test[root@localhost ~]# ll -d /testdrwxr-xr-x. 2 root root 6 4月 11 14:30 /test#为目录所属组添加写权限[root@localhost ~]# chmod g+w /test[root@localhost ~]# ll -d /testdrwxrwxr-x. 2 root root 6 4月 11 14:30 /test#为目录其他人添加写权限[root@localhost ~]# chmod o+w /test[root@localhost ~]# ll -d /testdrwxrwxrwx. 2 root root 6 4月 11 14:30 /test[root@localhost ~]# #重新定义所有用户权限[root@localhost ~]# chmod u=rwx,g=rx,o=rx /test[root@localhost ~]# ll -d /testdrwxr-xr-x. 2 root root 6 4月 11 14:30 /test#同时为所有用户定义相同权限[root@localhost ~]# chmod ugo=rwx /test[root@localhost ~]# ll -d /testdrwxrwxrwx. 2 root root 21 4月 11 14:37 /test#权限数字定义方式[root@localhost ~]# ll hello-rwxrwxrwx. 1 root root 426 3月 28 15:00 hello所有者：rwx 4+2+1=7所属组：r 4其他人：r 4[root@localhost ~]# chmod 744 hello[root@localhost ~]# ll hello-rwxr--r--. 1 root root 426 3月 28 15:00 hello所有者：rw 4+2=6所属组：rw 4+2=6其他人：--- 0[root@localhost ~]# chmod 660 hello[root@localhost ~]# ll hello-rw-rw----. 1 root root 426 3月 28 15:00 hello所有者：rwx 4+2+1=7所属组：wx 2+1=3其他人：--- 0[root@localhost ~]# touch /hello.txt[root@localhost ~]# ll /hello.txt -rw-r--r--. 1 root root 0 4月 11 14:45 /hello.txt[root@localhost ~]# chmod 730 /hello.txt [root@localhost ~]# ll /hello.txt -rwx-wx---. 1 root root 0 4月 11 14:45 /hello.txt#去除所有用户权限[root@localhost ~]# chmod 000 /hello.txt [root@localhost ~]# ll /hello.txt ----------. 1 root student 0 4月 11 14:45 /hello.txt#递归修改目录下所有子文件与子目录权限[root@localhost ~]# ll -d /testdrwxrwxrwx. 2 root root 21 4月 11 14:37 /test[root@localhost ~]# mkdir /test/xxoo[root@localhost ~]# ll -d /test/xxoo/drwxr-xr-x. 2 root root 6 4月 11 14:54 /test/xxoo/[root@localhost ~]# ll /test/abc.txt -rw-r--r--. 1 root root 0 4月 11 14:37 /test/abc.txt#默认用户在该目录下创建文件权限与父目录不一致#递归修改目录下所有子文件与子目录权限[root@localhost ~]# chmod -R 777 /test[root@localhost ~]# ll /test/abc.txt -rwxrwxrwx. 1 root root 0 4月 11 14:37 /test/abc.txt[root@localhost ~]# ll -d /test/xxoodrwxrwxrwx. 2 root root 6 4月 11 14:54 /test/xxoo#深入理解权限，[root@localhost ~]# mkdir /test1[root@localhost ~]# chmod 777 /test1[root@localhost ~]# ll -d /test1drwxrwxrwx. 2 root root 6 4月 11 14:57 /test1#在该目录下创建文件与目录[root@localhost ~]# touch /test1/root.txt[root@localhost ~]# mkdir /test1/rootbak[root@localhost ~]# chmod o=rx /test1[root@localhost ~]# ll -d /test1drwxrwxr-x. 2 root root 6 4月 11 14:59 /test1[root@localhost ~]# touch /test1/root.txt#普通用户对该目录如果拥有rwx权限是可以删除该目录下任何用户创建的文件（包括root）[user1@localhost ~]$ cd /test1[user1@localhost test1]$ lsroot.txt[user1@localhost test1]$ ll root.txt -rw-r--r--. 1 root root 0 4月 11 14:57 root.txt[user1@localhost test1]$ rm -rf root.txt [user1@localhost test1]$ lsrootbak[user1@localhost test1]$ rm -rf rootbak/[user1@localhost test1]$ ls[user1@localhost test1]$ ll -d /test1drwxrwxrwx. 2 root root 6 4月 11 14:59 /test1总结：1.用户对文件拥有写权限可以增加/修改/删除文件里内容，并不能删除文件，删除文件取决于对文件的父目录有没有rwx权限2.用户对目录拥有rwx权限可以查看/创建/修改/删除目录下的文件 umask预设权限 umask用于显示或设置创建文件的权限掩码 命令格式：umask [-p] [-S] [mode] 12345678910111213141516171819202122232425root@localhost ~]# mkdir /test2[root@localhost ~]# ll -d /test2drwxr-xr-x. 2 root root 6 4月 11 15:05 /test2[root@localhost ~]# umask --helpumask: 用法:umask [-p] [-S] [模式]#查看目录默认权限掩码，以数字形式显示[root@localhost ~]# umask -pumask 0022#查看目录默认权限掩码，以字母形式显示[root@localhost ~]# umask -Su=rwx,g=rx,o=rx#设置目录默认权限掩码，为所属组添加写权限[root@localhost ~]# umask g+w [root@localhost ~]# mkdir /test3[root@localhost ~]# ll -d /test3drwxrwxr-x. 2 root root 6 4月 11 15:09 /test3#去除目录默认权限掩码[root@localhost ~]# umask g-w [root@localhost ~]# mkdir /test4[root@localhost ~]# ll -d /test4drwxr-xr-x. 2 root root 6 4月 11 15:10 /test4 chown归属关系管理 chown（英文全拼：change owner）用于设置文件的所有者和所属组关系 命令格式： chown [-选项] 所有者:所属组 文档 #同时修改所有者和所属组身份 chown [-选项] 所有者 文档 #只修改所有者身份 chown [-选项] :所属组 文档 #只修改所属组身份 常用选项： -R 递归修改 123456789101112131415161718192021222324252627282930313233#创建文件[root@localhost ~]# chmod 744 /hello.txt [root@localhost ~]# ll /hello.txt -rwxr--r--. 1 root student 0 4月 11 14:45 /hello.txt#修改文件所有者为user1用户[root@localhost ~]# chown user1 /hello.txt [root@localhost ~]# ll /hello.txt -rwxr--r--. 1 user1 student 0 4月 11 14:45 /hello.txt#修改文件所有者与所属组为lisi[root@localhost ~]# chown lisi:lisi /hello.txt [root@localhost ~]# ll /hello.txt -rwxr--r--. 1 lisi lisi 4 4月 11 15:26 /hello.txt#创建目录[root@localhost ~]# mkdir /test5[root@localhost ~]# ll -d /test5drwxr-xr-x. 2 root root 6 4月 11 15:30 /test5#修改目录所有者与所属组为lisi[root@localhost ~]# chown lisi:lisi /test5[root@localhost ~]# ll -d /test5drwxr-xr-x. 2 lisi lisi 6 4月 11 15:30 /test5[root@localhost ~]# touch /test5/root.txt[root@localhost ~]# ll /test5/root.txt -rw-r--r--. 1 root root 0 4月 11 15:31 /test5/root.txt#递归修目录下所有子文件与子目录归属关系[root@localhost ~]# chown -R lisi:lisi /test5[root@localhost ~]# ll /test5/root.txt -rw-r--r--. 1 lisi lisi 0 4月 11 15:31 /test5/root.txt SetUID特殊权限 SetUID（SUID）：对于一个可执行的文件用了SUID权限后，普通用户在执行该文件后，临时拥有文件所有者的身份，该权限只在程序执行过程中有效，程序执行完毕后用户恢复原有身份 SetUID权限会附加在所有者的 x 权限位上，所有者的 x 权限标识会变成 s 设置SetUID命令格式：chmod u+s 文件名 1234567891011121314151617181920212223242526272829303132333435363738394041424344#搜索命令绝对路径[root@localhost ~]# which passwd/usr/bin/passwd[root@localhost ~]# ll /usr/bin/passwd -rwsr-xr-x. 1 root root 27832 6月 10 2014 /usr/bin/passwd[root@localhost ~]# which cat/usr/bin/cat[root@localhost ~]# ll /usr/bin/cat-rwxr-xr-x. 1 root root 54160 10月 31 2018 /usr/bin/cat#普通用户使用cat命令是默认无法查看/etc/shadow文件内容[lisi@localhost ~]$ cat /etc/shadowcat: /etc/shadow: 权限不够#设置SUID权限[root@localhost ~]# chmod u+s /usr/bin/cat[root@localhost ~]# ll /usr/bin/cat-rwsr-xr-x. 1 root root 54160 10月 31 2018 /usr/bin/cat#普通用户再次使用cat命令时临时获取文件所有者身份[lisi@localhost ~]$ cat /etc/shadow#去除SUID权限[root@localhost ~]# chmod u-s /usr/bin/cat[root@localhost ~]# ll /usr/bin/cat-rwxr-xr-x. 1 root root 54160 10月 31 2018 /usr/bin/cat[root@localhost ~]# which vim/usr/bin/vim[root@localhost ~]# ll /usr/bin/vim-rwxr-xr-x. 1 root root 2294208 10月 31 2018 /usr/bin/vim#为vim设置SUID权限[root@localhost ~]# chmod u+s /usr/bin/vim[root@localhost ~]# ll /usr/bin/vim-rwsr-xr-x. 1 root root 2294208 10月 31 2018 /usr/bin/vim[root@localhost ~]# ll /etc/passwd-rw-r--r--. 1 root root 2737 4月 10 17:26 /etc/passwd[root@localhost ~]# chmod u-s /usr/bin/vim[root@localhost ~]# vim /etc/passwd SetGID特殊权限 SetGID（SGID）：当对一个可执行的二进制文件设置了SGID后，普通用户在执行该文件时临时拥有其所属组的权限，该权限只在程序执行过程中有效，程序执行完毕后用户恢复原有组身份 当对一个目录作设置了SGID权限后，普通用户在该目录下创建的文件的所属组，均与该目录的所属组相同 SetGID权限会附加在所属组的 x 权限位上，所属组的 x 权限标识会变成 s 设置SetGID命令格式：chmod g+s 文件名 123456789101112131415161718192021222324[root@localhost ~]# mkdir /test6[root@localhost ~]# chmod 777 /test6[root@localhost ~]# ll -d /test6drwxrwxrwx. 2 root root 6 4月 11 15:59 /test6#为目录设置SGID权限[root@localhost ~]# chmod g+s /test6[root@localhost ~]# ll -d /test6drwxrwsrwx. 2 root root 6 4月 11 15:59 /test6#SGID权限会附加在所属组执行权限位，所属组执行权限变为s[root@localhost ~]# touch /test6/1.txt[root@localhost ~]# ll /test6/1.txt -rw-r--r--. 1 root root 0 4月 11 16:00 /test6/1.txt#修改目录所属组为lisi组[root@localhost ~]# chown :lisi /test6[root@localhost ~]# ll -d /test6drwxrwsrwx. 2 root lisi 19 4月 11 16:00 /test6#SGID对目录设置后，在该目录下创建的任何文件都会继承父目录的所属组[root@localhost ~]# touch /test6/2.txt[root@localhost ~]# ll /test6/2.txt -rw-r--r--. 1 root lisi 0 4月 11 16:01 /test6/2.txt Sticky BIT特殊权限 Sticky BIT（SBIT）：该权限只针对于目录有效，当普通用户对一个目录拥有w和x权限时，普通用户可以在此目录下拥有增删改的权限，应为普通用户对目录拥有w权限时，是可以删除此目录下的所有文件 如果对一个目录设置了SBIT权限，除了root可以删除所有文件以外，普通用户就算对该目录拥有w权限，也只能删除自己建立的文件，不能删除其他用户建立的文件 SBIT权限会附加在其他人的 x 权限位上，其他人的 x 权限标识会变成 t 设置SBIT命令格式：chmod o+t 目录名 1234567891011#为目录设置SBIT[root@localhost ~]# chmod o+t /test[root@localhost ~]# ll -d /testdrwxrwxrwt. 2 root root 6 4月 11 16:07 /test[lisi@localhost test]$ lskenji.txt laowang.txt lisi.txt[lisi@localhost test]$ rm -rf *rm: 无法删除&quot;kenji.txt&quot;: 不允许的操作rm: 无法删除&quot;laowang.txt&quot;: 不允许的操作 FACL访问控制列表 FACL（Filesystemctl Access Control List）文件系统访问控制列表：利用文件扩展属性保存额外的访问控制权限，单独为每一个用户量身定制一个权限 命令格式：setfacl 选项 归属关系:权限 文档 常用选项： -m 设置权限 -x 删除指定用户权限 -b 删除所有用户权限 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#为natasha用户设置ACL权限[root@localhost ~]# setfacl -m u:natasha:rx /yunwei/[root@localhost ~]# ll -d /yunwei/drwxrwx---+ 2 root yunwei 54 4月 11 16:43 /yunwei/[root@localhost ~]# ll -d /testdrwxrwxrwt. 2 root root 42 4月 11 16:11 /test#查看目录ACL权限[root@localhost ~]# getfacl /yunweigetfacl: Removing leading '/' from absolute path names# file: yunwei# owner: root# group: yunweiuser::rwxuser:natasha:r-xgroup::rwxmask::rwxother::---#用户测试权限[natasha@localhost ~]$ ls /yunwei/hell.sh kenji.txt lisi.txt[natasha@localhost yunwei]$ rm -rf kenji.txt rm: 无法删除&quot;kenji.txt&quot;: 权限不够[natasha@localhost yunwei]$ touch natasha.txttouch: 无法创建&quot;natasha.txt&quot;: 权限不够[natasha@localhost yunwei]$ vim kenji.txt [root@localhost ~]# setfacl -m u:tom:rx /yunwei[root@localhost ~]# setfacl -m u:jack:rx /yunwei[root@localhost ~]# setfacl -m u:hary:rx /yunwei[root@localhost ~]# getfacl /yunweigetfacl: Removing leading '/' from absolute path names# file: yunwei# owner: root# group: yunweiuser::rwxuser:hary:r-xuser:tom:r-xuser:natasha:r-xuser:jack:r-xgroup::rwxmask::rwxother::---#删除指定用户ACL权限[root@localhost ~]# setfacl -x u:tom /yunwei[root@localhost ~]# getfacl /yunweigetfacl: Removing leading '/' from absolute path names# file: yunwei# owner: root# group: yunweiuser::rwxuser:hary:r-xuser:natasha:r-xuser:jack:r-xgroup::rwxmask::rwxother::---#删除所有用户ACL权限[root@localhost ~]# setfacl -b /yunwei[root@localhost ~]# getfacl /yunweigetfacl: Removing leading '/' from absolute path names# file: yunwei# owner: root# group: yunweiuser::rwxgroup::rwxother::--- 课后作业1.创建test1用户，并指定用户UID为6666，指定用户描述信息为test1@163.com，指定用户解释器为/sbin/nologin test1:x:6666:6666:test1@163.com:/home/test1:/sbin/nologin 2.创建名为stugrp组，将test1用户加入到stugrp组 [[root@localhost]# groupadd stugrp [[root@localhost]# gpasswd -a test1 stugrp 3.请写出/etc/passwd文件中每个字段含义 用户名 密码占位符 UID GID 描述信息 家目录 解释器 4.创建test2用户，并设置密码为123456 [[root@localhost]# useradd test2[[root@localhost]# passwd test2 5.修改root用户密码为123456 [[root@localhost]# passwd 6.请写出Linux系统下存放用户密码信息文件 /etc/shadow 7.设置test2用户首次登录系统需要修改密码 [[root@localhost]# chage -d 0 test2 8.使用root切换为test1用户身份 su - 用户名 9.将test2用户添加至stugrp组，并锁定用户密码 [[root@localhost]# gpasswd -a test2 stugrp [[root@localhost]# passwd -l test2 10.删除test1用户，连同用户家目录一并删除 [root@localhost]# userdel -r test1 11.请写出Linux系统存放组信息文件，与组密码信息文件 [[root@localhost]# ls /etc/group [[root@localhost]# ls /etc/gshadow 12.将test2用户从stugrp组中删除 [[root@localhost]# gpasswd -d test2 stugrp 13.在根下创建upload目录，并修改目录所有者为test2用户，所属组为stugrp组，并将lisi用户加入到stugrp组，修改所有者权限rwx，修改所属组权限为rwx，设置其他人没有任何权限 [[root@localhost]# mkdir /upload [[root@localhost]# chown test2:stugrp /upload/ [[root@localhost]# gpasswd -a lisi stugrp [[root@localhost]# chmod 770 /upload/ 14.创建test3用户，非交互式设置用户密码为123456，并设置test3用户可以对upload目录拥有rx权限 [[root@localhost]# useradd test3[[root@localhost]# echo 123456 | passwd –stdin test3 [[root@localhost]# setfacl -m u:test3:rx /upload/[[root@localhost]# getfacl /upload/ 15.在根下创建shared目录，并同时设置所有人都有完全权限（至少两种方法设置），要求所有普通用户在该目录下只能修改自己创建的文件 [[root@localhost]# mkdir /shared[[root@localhost]# chmod ugo=rwx /shared/[[root@localhost]# chmod 777 /shared/[[root@localhost]# ll -d /shared/ [[root@localhost]# chmod o+t /shared/ 常用特殊符号的使用Linux系统下通配符起到了很大的作用，对于不确定的文档名称可以使用以下特殊字符表示 *常用的特殊符号，在文件名上，用来代表任意多个任意字符 ? 常用的特殊符号，在文件名上，用来代表任意单个任意字符 [0-9] #在文件名上，用来代表多个字符或连续范围中的一个，若无则忽略 {a,b,cd,abcd} #在文件名上，用来代表多组不同的字符串，全匹配 范例 12345678910111213141516171819202122#查找以tab结尾的文件[root@localhost ~]# ls /etc/*tab[root@localhost ~]# ls /etc/*wd[root@localhost ~]# ls /etc/*.conf[root@localhost ~]# ls /etc/redhat*[root@localhost ~]# ls /etc/*ss*#查找以tty开头的文件，结尾以一个任意字符结尾[root@localhost ~]# ls /dev/tty?[root@localhost ~]# ls /etc/host?[root@localhost ~]# ls /etc/pass??#查找tty开头结尾以1-5连续字符结尾[root@localhost ~]# ls /dev/tty[1-5][root@localhost ~]# ls /dev/tty[4-9][root@localhost ~]# ls /dev/tty[1,3,5,7,9,15,20,30]#查找tty开头结尾为不连续字符结尾[root@localhost ~]# ls /dev/tty{1,3,5,7,9,15,20,30}[root@localhost ~]# ls /dev/tty{1..9}[root@localhost ~]# ls /dev/tty{1..10}[root@localhost ~]# ls /dev/tty[1-10] grep文件内容过滤 grep用于查找文件中符合条件的字符串，它能利用正则表达式搜索文件中的字符串，并把匹配到的字符串的行打印出来 命令格式：grep [-选项] “查找条件” 目标文件 常用选项： -n #以行号形式输出 -i #忽略字符串大小写 -v #显示不包含匹配的行（排除） 常用正则表达式符号 ^字符串 #显示以该字符串开头的行 $字符串 #显示以该字符串结尾的行 ^$ #显示空行 grep命令示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#过滤包含root关键字的行[root@localhost ~]# grep root /etc/passwdroot:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologin#以行号形式过滤包含root关键字的行[root@localhost ~]# grep -n root /etc/passwd1:root:x:0:0:root:/root:/bin/bash10:operator:x:11:0:operator:/root:/sbin/nologin[root@localhost ~]# grep -n bash /etc/passwd[root@localhost ~]# grep -n : /etc/passwd#忽略大小写过滤[root@localhost ~]# grep -i -n ssh /etc/passwd38:sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin#排除包含#号的行[root@localhost ~]# grep -n -v '^#' /etc/fstab#过滤以root开头的行[root@localhost ~]# grep ^root /etc/passwd#过滤以root结尾的行[root@localhost ~]# grep -n 'root$' /etc/passwd[root@localhost ~]# grep -n 'bash$' /etc/passwd#语法错误示范[root@localhost ~]# grep -n -v '^#' ^$ /etc/fstabgrep: ^$: 没有那个文件或目录/etc/fstab:1:/etc/fstab:9:/dev/mapper/centos-root / xfs defaults 0 0/etc/fstab:10:UUID=ae55ec6b-973b-498e-a366-f35e14b3d153 /boot xfs defaults 0 0/etc/fstab:11:/dev/mapper/centos-swap swap #语法错误示范[root@localhost ~]# grep -n -v '^#' /etc/fstab | grep -v ^$1:9:/dev/mapper/centos-root / xfs defaults 0 010:UUID=ae55ec6b-973b-498e-a366-f35e14b3d153 /boot xfs defaults 0 011:/dev/mapper/centos-swap swap swap defaults 0 0#正确语法[root@localhost ~]# grep -v '^#' /etc/fstab | grep -v ^$ -n2:/dev/mapper/centos-root / xfs defaults 0 03:UUID=ae55ec6b-973b-498e-a366-f35e14b3d153 /boot xfs defaults 0 04:/dev/mapper/centos-swap swap swap defaults 0 0#显示该文件内有效配置的行[root@localhost ~]# grep -v '^#' /etc/login.defs | grep -v ^$ -n | wc -l find文件/目录查找命令 find 命令根据预设的条件递归查找文件或目录所在位置 命令格式：find 查找路径 查找条件1 查找条件2 .. [-exec 处理命令 {} ; ] –exec 可接额外的命令来处理查找到结果 {} 代表find查找到的内容被放置{}中 ; 代表额外处理命令结束 常用查找条件 -type 类型（f文件 d目录 l链接文件） -name “文件名” -iname 按文件名查找忽略大小写 -size 文件大小（k、M、G + 大于 - 小于） -a （并且）两个条件同时满足 -o （或者）两个条件满足任意一个即可 -user 用户名 -mtime 按日期查找（+ 代表多少天之前 - 代表多少天之内，0代表24小时之内） find命令范例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677[root@localhost ~]# ls /var/log#按照类型查找，类型为文件[root@localhost ~]# find /var/log -type f[root@localhost ~]# ll boot.log-20210417[root@localhost ~]# ll /var/log/boot.log-20210417[root@localhost ~]# ll /var/log/vmware-network.2.log#按照类型查找，类型为目录[root@localhost ~]# find /var/log -type d[root@localhost ~]# ll -d /var/log/tuned[root@localhost ~]# ll -d /var/log/qemu-ga#按照类型查找，类型为链接文件[root@localhost ~]# find /var/log -type l[root@localhost ~]# fin /etc/ -type l[root@localhost ~]# find /etc/ -type l[root@localhost ~]# ll /etc/scl/conf#按照名字查找[root@localhost ~]# find /etc/ -name passwd/etc/passwd/etc/pam.d/passwd#按照名字查找，类型为文件[root@localhost ~]# find /etc/ -name passwd -type f#按照名字查找，以tab结尾，类型为文件[root@localhost ~]# find /etc/ -name '*tab' -type f#按照名字查找，以pass开头，类型为文件[root@localhost ~]# find /etc/ -name 'pass*' -type f[root@localhost etc]# find . -name '*.conf' -type f[root@localhost ~]# find /etc/ -name '*tab*' -type f#按照名字忽略大小写查找，类型为文件[root@localhost ~]# find /etc/ -iname FSTAB -type f/etc/fstab[root@localhost ~]# find /etc/ -name FSTAB -type f#查找大于10k的文件[root@localhost ~]# find /var/log -size +10k -type f[root@localhost ~]# du -h /var/log/boot.log-2021041716K /var/log/boot.log-20210417#查找大于1M的文件[root@localhost ~]# find /var/log -size +1M -type f[root@localhost ~]# du -h /var/log/audit/audit.log2.4M /var/log/audit/audit.log[root@localhost ~]# find /home -size +1M -type f#查找小于1M的文件[root@localhost ~]# find /var/log -size -1M -type f[root@localhost ~]# du -h /var/log/spooler0 /var/log/spooler#查找大于10k并且下于20k，类型为文件[root@localhost ~]# find /var/log -size +10k -a -size -20k -type f#查找大于10k或者小于100k，类型为文件[root@localhost ~]# find /var/log -size +10k -o -size -100k -type f#查找属于lisi用户的文件/目录[root@localhost ~]# find /home -user lisi#查找30天之前被修改过，类型为文件[root@localhost ~]# find /var/log -mtime +30 -type f[root@localhost ~]# find /var/log -mtime +10 -type f#查找10天之内被修改过，类型为文件[root@localhost ~]# find /var/log -mtime -10 -type froot@localhost ~]# find /var/log -mtime -30 -type f#查找30之前被修改过，类型为文件，拷贝到/opt目录下[root@localhost ~]# find /var/log -mtime -30 -type f -exec cp {} /opt \\; 题型： 查找/etc/目录下以.conf结尾的文件（只能在/etc这一层目录去查找） [[root@localhost]# ls /etc/*.conf 查找/etc/目录下以.conf结尾的文件（包含所有的子目录） [[root@localhost]# find /etc/ -name ‘*.conf’ -type f 压缩与解压缩 Linux独有压缩格式及命令工具: gzip—&gt; .gz bzip2—&gt; .bz2 xz—&gt; .xz 压缩命令格式 gzip [选项…] 文件名 常用选项：-d 解压缩 bzip2 [选项…] 文件名 常用选项：-d 解压缩 xz [选项…] 文件名 常用选项：-d 解压缩 查看压缩文件内容 zcat [选项…] 文件名 bzcat [选项…] 文件名 xzcat [选项…] 文件名 123456789101112131415161718192021222324252627282930313233343536373839404142[root@localhost ~]# cp /etc/services /opt[root@localhost ~]# cd /opt[root@localhost opt]# ll services -rw-r--r--. 1 root root 670293 4月 17 17:06 services[root@localhost opt]# ll -h services -rw-r--r--. 1 root root 655K 4月 17 17:06 services#使用gzip格式对文件进行压缩[root@localhost opt]# gzip services [root@localhost opt]# lsservices.gz[root@localhost opt]# ll -h services.gz -rw-r--r--. 1 root root 133K 4月 17 17:06 services.gz#不解压查看压缩文件内容[root@localhost opt]# zcat services.gz #解压文件[root@localhost opt]# gzip -d services.gz #使用bzip2格式对文件进行压缩[root@localhost opt]# bzip2 services [root@localhost opt]# lsservices.bz2[root@localhost opt]# ll -h services.bz2 -rw-r--r--. 1 root root 122K 4月 17 17:06 services.bz2#不解压查看文件内容[root@localhost opt]# bzcat services.bz2 #解压文件[root@localhost opt]# bzip2 -d services.bz2 #使用xz格式对文件进行压缩[root@localhost opt]# xz services [root@localhost opt]# lsservices.xz[root@localhost opt]# ll -h services.xz -rw-r--r--. 1 root root 98K 4月 17 17:06 services.xz#解压文件[root@localhost opt]# xz -d services.xz tar打包工具 tar命令用在linux下用于对文件/目录打包，使用 tar 程序打出来的包常称为 tar 包，tar 包文件通常都是以 .tar 结尾 tar 命令格式：tar 选项 压缩包名字 被压缩文件 常用选项： -c 创建打包文件 -f 指定打包后的文件名称 -z 调用gzip压缩工具 -J 调用xz压缩工具 -j 调用bzip2压缩工具 -t 列出打包文档内容 -x 释放打包文件 -C 指定解压路径 -v 显示详细信息 tar命令范例 1234567891011121314151617181920212223242526272829#同时打包多个文件/目录并使用gzip格式压缩[root@localhost opt]# tar -czf xxx.tar.gz /etc/passwd /etc/fstab /home#将压缩包数据解压到/media目录[root@localhost opt]# tar -xf xxx.tar.gz -C /media/[root@localhost opt]# ls /media/etc[root@localhost opt]# rm -rf xxx.tar.gz #同时打包多个文件/目录并使用xz格式压缩[root@localhost opt]# tar -cJf xx.tar.xz /etc/hostname /etc/services /home#错误语法，f选项要放到所有选项右边[root@localhost opt]# tar -ft xx.tar.xz tar: 您必须从&quot;-Acdtrux&quot;或是&quot;--test-label&quot;选项中指定一个请用“tar --help”或“tar --usage”获得更多信息。#不解压查看压缩包数据[root@localhost opt]# tar -tf xx.tar.xz etc/hostname#将压缩包数据解压到/tmp目录[root@localhost opt]# tar -vxf xx.tar.xz -C /tmp[root@localhost opt]# ls /tmp#同时打包多个文件/目录并使用bzip2格式压缩[root@localhost opt]# tar -cjf abc.tar.bz2 /etc/hostname /etc/group /home#解压缩[root@localhost opt]# tar -xf abc.tar.bz2 -C /media/ 磁盘介绍分区过程添加新硬盘–分区–格式化文件系统–挂载使用 扇区是磁盘存储数据的最小单元，默认一个扇区可以存储512字节的数据 磁盘类型介绍 IDE接口类型：主要用于个人家用计算机领域，优点价格便宜，缺点数据传输速度慢 SCSI接口类型：主要用于服务器理领域，数据传输速度快，支持热插拔 SATA接口类型：串口磁盘，主要用于个人家用计算机领域 NVMe接口类型：固态硬盘接口 Linux常用分区格式 MBR分区格式：比较古老的分区格式，分为主分区，只能划分4个主分区，扩展分区（容器）逻辑分区，最大支持2.2T磁盘容量 IDE接口硬盘逻辑分区最多可以划分59个 SCSI接口硬盘逻辑分区最多可以划分11个 最大支持2.2T以内磁盘容量 GPT分区格式：可划分128个主分区，最大支持18EB磁盘容量（1EB=1024PB，1PB=1024TB，1TB=1024GB） 文件系统类型详解 文件管理系统，赋予分区文件系统分区才可以正常的使用，根文件系统，多少个多少个文件系统 CentOS5：分区默认使用文件系统类型ext3 CentOS6：分区默认使用文件系统类型ext4 ext4日志记录功能，意外宕机，通过日志记录把没有保存的数据，在系统再次重启时快速恢复回来 单个文件系统最大支持1EB的分区容量，单个文件最大可以存储16TB数据 CentOS7：分区默认使用文件系统类型xfs xfs开启了日志记录的功能，数据恢复的时候比ext4文件系统块 单个文件系统最大支持8EB分区容量，单个文件最大可以存储500TB的数据 单个文件每秒读写数据的速度可以达到4G swap文件系统：交换分区，硬盘空间去充当内存去使用 挂载 在Linux系统中用户无法直接使用硬件设备的，硬件设备在系统中都是以只读的方式存在的，必须挂载 挂载就是给我们用户提供一个可以使用设备的一个接口 挂载注意事项： 挂载点必须是一个目录，理论上还得是一个空目录 一个文件系统不允许重复挂载到多个目录下 一个目录不允许重复挂载多个文件系统 lsblk查看系统所有磁盘信息 lsblk（英文全拼：list block）用于列出当前系统所有磁盘与磁盘内的分区信息 命令格式：lsblk [选项…] [设备名] 常用选项： -d #仅显示磁盘本身，不会列出磁盘的分区数据 -f #列出磁盘分区使用的文件系统类型 lsblk命令示例 12345678910111213141516171819202122232425262728293031323334353637383940#列出当前系统所有磁盘与磁盘内的分区信息[root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot└─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP]sr0 11:0 1 4.3G 0 rom /mnt/centos#sda1：sd代表SCSI磁盘，a代表第一块磁盘，1代表第一个分区#sdb：sd代表SCSI磁盘，b代表第二块磁盘，1代表第一个分区#解释：NAME #设备名称MAJ:MIN #主设备号:次设备号，内核通过主次设备号识别磁盘RM #是否为可卸载设备，1可卸载，0不可卸载SIZE #设备的容量大小RO #表示设备是否为只读，0非只读设备，1只读设备TYPE #表示设备类型（disk为磁盘，part为分区，lvm逻辑卷，rom只读）MOUNTPOINT #设备挂载点（SWAP没有挂载点）#列出指定的磁盘信息[root@localhost ~]# lsblk -d /dev/sdaNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk #列出所有磁盘分区内使用的文件系统类型[root@localhost ~]# lsblk -f NAME FSTYPE LABEL UUID MOUNTPOINTsda ├─sda1 xfs 4cb9bb38-c34a-4415-9614-ba38642bb86d /boot└─sda2 LVM2_member cKn0jP-z8Bq-SNvl-BsNa-7vTg-GBU2-OiHCro ├─centos-root xfs 55dad88d-a600-42d1-b387-236db62ce396 / └─centos-swap swap 2e91599a-6d72-483d-add8-6dfb84296170 [SWAP]sr0 iso9660 CentOS 7 x86_64 2018-11-25-23-54-16-00 /mnt/centos#列出指定分区的文件系统类型[root@localhost ~]# lsblk -df /dev/sda1NAME FSTYPE LABEL UUID MOUNTPOINTsda1 xfs 4cb9bb38-c34a-4415-9614-ba38642bb86d /boot df查看分区使用情况 df命令用于查看文件系统使用情况 命令格式：df [选项…] [参数…] 常用选项： -h 以人类易读方式显示文件系统容量 T 显示文件系统类型 df 命令示例 123456789101112131415[root@localhost ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/mapper/centos-root 17811456 3746320 14065136 22% /devtmpfs 480884 0 480884 0% /devtmpfs 497948 0 497948 0% /dev/shmtmpfs 497948 8340 489608 2% /runtmpfs 497948 0 497948 0% /sys/fs/cgroup/dev/sr0 4480476 4480476 0 100% /mnt/dev/sda1 1038336 169448 868888 17% /boottmpfs 99592 12 99580 1% /run/user/42tmpfs 99592 0 99592 0% /run/user/0[root@localhost ~]# df -h /Filesystem Size Used Avail Use% Mounted on/dev/mapper/centos-root 17G 3.6G 14G 22% / du统计文件/目录大小 du命令用于统计磁盘下目录或文件大小 命令格式：du [选项…] [参数…] 常用选项： -h #以人类易读方式（Kb，MB，GB）显示文件大小 -s #只统计每个参数的总数 du 命令示例 1 /dev/目录下文件详解 123456789101112131415[root@localhost ~]# ls /devhd[a-t]:IDE设备sd[a-z]:SCSI设备fd[0-7]：软盘驱动设备md[0-32]：软RAID设备loop[0-7]：本地回环设设备lp[0-3]:打印机设备mem：内存设备null：空设备，也称为黑洞，任何写入的数据都将被丢弃zero：零资源设备，任何写入的数据都将被丢弃full：满设备，任何写入的数据都将失败tty[0-63]：虚拟终端设备random：随机数设备urandom：随机数设备port：存取I/O端口 blkid查看设备属性 blkid命令显示块设备属性信息（设备名称，设备UUID，文件系统类型） 命令格式：blkid [选项…] [参数…] blkid命令示例 1234567891011#显示系统所有块设备属性信息[root@localhost ~]# blkid/dev/sda1: UUID=&quot;4cb9bb38-c34a-4415-9614-ba38642bb86d&quot; TYPE=&quot;xfs&quot; /dev/sda2: UUID=&quot;cKn0jP-z8Bq-SNvl-BsNa-7vTg-GBU2-OiHCro&quot; TYPE=&quot;LVM2_member&quot; /dev/sr0: UUID=&quot;2018-11-25-23-54-16-00&quot; LABEL=&quot;CentOS 7 x86_64&quot; TYPE=&quot;iso9660&quot; PTTYPE=&quot;dos&quot; /dev/mapper/centos-root: UUID=&quot;55dad88d-a600-42d1-b387-236db62ce396&quot; TYPE=&quot;xfs&quot; /dev/mapper/centos-swap: UUID=&quot;2e91599a-6d72-483d-add8-6dfb84296170&quot; TYPE=&quot;swap&quot; #查看执行分区属性信息root@localhost ~]# blkid /dev/sda1/dev/sda1: UUID=&quot;4cb9bb38-c34a-4415-9614-ba38642bb86d&quot; TYPE=&quot;xfs&quot; MBR分区格式 fdisk命令用于查看磁盘使用情况和磁盘分区（MBR分区格式） 命令格式：fdisk [选项…] [设备路径] 常用选项：-l 列出磁盘分区表类型与分区信息 分区 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124[root@localhost ~]# fdisk /dev/sdbm #获取命令帮助 ※p #显示磁盘分区表 ※n #新增加一个分区 ※q #不保存分区退出 ※d #删除一个分区 ※w #保存分区退出 ※a #设置可引导标记b #编辑bsd磁盘标签c #设置DOS操作系统兼容标记l #显示已知的文件系统类型，82为swap交换分区，83为Linux分区o #建立空白DOS分区表s #新建空白SUN磁盘标签t #改变分区的系统IDu #改变显示记录单位v #验证分区表x #附加功能命令(输入 m 获取帮助)：m命令(输入 m 获取帮助)：p#划分第一个主分区命令(输入 m 获取帮助)：nSelect (default p): 回车分区号 (1-4，默认 1)：回车起始 扇区 (2048-209715199，默认为 2048)：回车Last 扇区, +扇区 or +size{K,M,G} (2048-209715199，默认为 209715199)：+10G #指定大小（K,M,G）分区 1 已设置为 Linux 类型，大小设为 10 GiB命令(输入 m 获取帮助)：p磁盘标签类型：dos磁盘标识符：0xefc65503 设备 Boot Start End Blocks Id System/dev/sdb1 2048 20973567 10485760 83 Linux#划分第二个主分区命令(输入 m 获取帮助)：nSelect (default p): 分区号 (2-4，默认 2)：起始 扇区 (20973568-209715199，默认为 20973568)：Last 扇区, +扇区 or +size{K,M,G} (20973568-209715199，默认为 209715199)：+10G #指定分区大小#划分第三个主分区命令(输入 m 获取帮助)：nSelect (default p): 分区号 (3,4，默认 3)：起始 扇区 (41945088-209715199，默认为 41945088)：Last 扇区, +扇区 or +size{K,M,G} (41945088-209715199，默认为 209715199)：+10G#查看分区信息命令(输入 m 获取帮助)：p磁盘标签类型：dos磁盘标识符：0xefc65503 设备 Boot Start End Blocks Id System/dev/sdb1 2048 20973567 10485760 83 Linux/dev/sdb2 20973568 41945087 10485760 83 Linux/dev/sdb3 41945088 62916607 10485760 83 Linux#划分第四个分区命令(输入 m 获取帮助)：nSelect (default e): p起始 扇区 (62916608-209715199，默认为 62916608)：Last 扇区, +扇区 or +size{K,M,G} (62916608-209715199，默认为 209715199)：+10G#继续划分分区命令(输入 m 获取帮助)：nIf you want to create more than four partitions, you must replace aprimary partition with an extended partition first.#提示如果想要创建更多的分区，先将一个主分区替换为扩展分区#删除分区命令(输入 m 获取帮助)：d4分区号 (1-4，默认 4)：分区 4 已删除命令(输入 m 获取帮助)：d分区号 (1-3，默认 3)：3分区 3 已删除命令(输入 m 获取帮助)：p磁盘标签类型：dos磁盘标识符：0xefc65503 设备 Boot Start End Blocks Id System/dev/sdb1 2048 20973567 10485760 83 Linux/dev/sdb2 20973568 41945087 10485760 83 Linux#创建主分区命令(输入 m 获取帮助)：nSelect (default p): 分区号 (3,4，默认 3)：起始 扇区 (41945088-209715199，默认为 41945088)：Last 扇区, +扇区 or +size{K,M,G} (41945088-209715199，默认为 209715199)：+10G#创建按扩展分区命令(输入 m 获取帮助)：nSelect (default e): Using default response e已选择分区 4起始 扇区 (62916608-209715199，默认为 62916608)：Last 扇区, +扇区 or +size{K,M,G} (62916608-209715199，默认为 209715199)：分区 4 已设置为 Extended 类型，大小设为 70 GiB#创建逻辑分区命令(输入 m 获取帮助)：n添加逻辑分区 5起始 扇区 (62918656-209715199，默认为 62918656)：Last 扇区, +扇区 or +size{K,M,G} (62918656-209715199，默认为 209715199)：+10G分区 5 已设置为 Linux 类型，大小设为 10 GiB命令(输入 m 获取帮助)：p磁盘 /dev/sdb：107.4 GB, 107374182400 字节，209715200 个扇区磁盘标签类型：dos磁盘标识符：0xefc65503 设备 Boot Start End Blocks Id System/dev/sdb1 2048 20973567 10485760 83 Linux/dev/sdb2 20973568 41945087 10485760 83 Linux/dev/sdb3 41945088 62916607 10485760 83 Linux/dev/sdb4 62916608 209715199 73399296 5 Extended/dev/sdb5 62918656 83890175 10485760 83 Linux命令(输入 m 获取帮助)：w 格式化文件系统 mkfs命令用于在分区上建立文件系统 常用文件系统类型 ext4，xfs 命令格式： mkfs.xfs 分区设备路径 #格式化为xfs类型文件系统 mkfs.ext4 分区设备路径 #格式化为ext4类型文件系统 123456#格式化文件系统[root@localhost ~]# mkfs.xfs /dev/sdb1#查看文件系统类型[root@localhost ~]# blkid /dev/sdb1/dev/sdb1: UUID=&quot;3bb79b0b-3f17-4ad9-ad47-f00dcb6a5afa&quot; TYPE=&quot;xfs&quot; mount挂载 mount文件系统挂载命令 命令格式：mount 设备路径 挂载点目录 123456789101112#创建挂载点目录[root@localhost ~]# mkdir /mybak#挂载文件系统[root@localhost ~]# mount /dev/sdb1 /mybak#查看正在使用中的分区信息[root@localhost ~]# df -Th [root@localhost ~]# df -Th /mybak文件系统 类型 容量 已用 可用 已用% 挂载点/dev/sdb1 xfs 10G 33M 10G 1% /mybak 总结： 添加硬盘—查看系统是否识别新硬盘 lsblk 划分分区—fdisk 设备路径 格式化文件系统—mkfs.xfs 挂载—创建挂载点目录–挂载 mount 设备路径 挂载点目录 查看分区使用情况 df -hT umount卸载 umount命令用于卸载文件系统 命令格式：umount 挂载点目录 123#卸载文件系统[root@localhost ~]# umount /mybak[root@localhost ~]# df -h 开机自动挂载 /etc/fstab用于存放文件系统信息，当系统启动时，系统会自动读取文件内容将指定的文件系统挂载到指定的目录 文件内容详解 12345678910111213141516171819202122232425[root@localhost ~]# vim /etc/fstab/dev/mapper/centos-root / xfs defaults 0 0UUID=5d36a8b5-5a58-450f-acf9-81fcddaa62de /boot xfs defaults 0 0/dev/mapper/centos-swap swap swap defaults 0 0#解释：该文件内容为6个字段，每个字段详解如下第一个字段：要挂载的设备路径第二个字段：挂载点目录第三个字段：设备文件系统类型第四个字段：挂载参数，参数如下↓sync，async： 此文件系统是否使用同步写入 (sync) 或异步 (async) 的内存机制，默认为异步（async） atime，noatime：更新访问时间/不更新访问时间，访问分区时，是否更新文件的访问时间，默认为更新ro，rw：挂载文件为只读（ro）或读写（rw），默认为rwauto，noauto：自动挂载/手动挂载，执行mount -a时，是否自动挂载/etc/fstab文件内容，默认为自动（auto）dev，nodev：是否允许此文件系统上，可建立装置文件，默认为允许（dev）suid，nosuid：是否允许文件系统上含有SUID与SGID特殊权限，默认为允许（SUID）exec，noexec：是否允许文件系统上拥有可执行文件，默认为允许（exec）user，nouser：是否允许普通用户执行挂载操作，默认为不允许（nouser），只有root用户可以挂载分区defaults默认值：代表async，rw，auto，dev，suid，exec，nouser七个选项第五个字段：是否对文件系统进行备份，0不备份，1为备份第六个字段：是否检查文件系统顺序，允许的数字是0，1，2，0表示不检查，1的优先权最高/dev/mapper/centos-root / xfs defaults 0 0UUID=ae55ec6b-973b-498e-a366-f35e14b3d153 /boot xfs defaults 0 0/dev/mapper/centos-swap swap swap defaults 0 0/dev/sdb1 /mybak xfs defaults 0 0 #手动添加 mount常用选项： -a：依照配置文件/etc/fstab的数据将所有未挂载的磁盘都挂载上来 -o：该选项后边可跟挂载时额外参数 remount命令：重新挂载文件系统，在文件系统出错时或重新挂载文件系统时非常重要， 1[root@localhost ~]# mount -a GPT分区格式 gdisk命令用于查看磁盘使用情况和磁盘分区（GPT分区格式） 命令格式：gdisk [选项…] [设备路径] 常用选项：-l 列出磁盘分区表类型与分区信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[root@localhost ~]# gdisk /dev/sdcGPT fdisk (gdisk) version 0.8.10 #GPT版本Partition table scan: #分区表扫描 MBR: not present #MBR分区不存在 BSD: not present #BSD分区不存在 APM: not present #APM分区不存在 GPT: not present #GPT分区不存在Creating new GPT entries. #创建新的GPT分区Command (? for help): ? #输入？号获取命令帮助p #显示磁盘分区表 ※n #新增加一个分区 ※q #不保存分区退出 ※d #删除一个分区 ※w #保存分区退出 ※#创建新的分区Command (? for help): nPartition number (1-128, default 1): 回车First sector (34-209715166, default = 2048) or {+-}size{KMGTP}: 回车 #输入起始扇区，默认2048开始Last sector (2048-209715166, default = 209715166) or {+-}size{KMGTP}: +20G #输入新增分区的大小，可以通过扇区数来增加，也可以通过+size{KMGTP}方式来增加Hex code or GUID (L to show codes, Enter = 8300): #这里要求输入分区的类型，直接回车就行#查看分区类型Command (? for help): p #输入p查看创建的分区Disk /dev/sdc: 209715200 sectors, 100.0 GiB #磁盘总容量...Total free space is 167772093 sectors (80.0 GiB) #磁盘剩余容量Number Start (sector) End (sector) Size Code Name 1 2048 41945087 20.0 GiB 8300 Linux filesystem#以创建的分区Command (? for help): w #输入w保存配置，如果不想保存可以输入q退出Do you want to proceed? (Y/N): y #问你是否相想继续，输入y继续 OK; writing new GUID partition table (GPT) to /dev/sdc.The operation has completed successfully. #写入成功#格式化文件系统[root@localhost ~]# mkfs.xfs /dev/sdc1#查看文件系统类型[root@localhost ~]# blkid /dev/sdc1/dev/sdc1: UUID=&quot;c57746eb-8170-4c86-82ad-6aae95de19f3&quot; TYPE=&quot;xfs&quot; #创建挂载点[root@localhost ~]# mkdir /webbak[root@localhost ~]# mount /dev/sdc1 /webbak[root@localhost ~]# df -hT/dev/sdc1 xfs 20G 33M 20G 1% /webbak#开机自动挂载[root@localhost ~]# vim /etc/fstab/dev/mapper/centos-root / xfs defaults 0 0UUID=ae55ec6b-973b-498e-a366-f35e14b3d153 /boot xfs defaults 0 0/dev/mapper/centos-swap swap swap defaults 0 0/dev/sdb1 /mybak xfs defaults 0 0 /dev/sdc1 /webbak xfs defaults 0 0 #手动添加[root@localhost ~]# mount -a LVM逻辑卷 逻辑卷：LVM（Logical Volume Manager）逻辑卷管理系统 逻辑卷可以实现将底层的物理分区整合成一个大的虚拟硬盘 逻辑卷技术是通过Linux系统内核dm（device mapper）设备映射组件 创建卷组 创建卷组思路：将创建好的物理卷组成卷组（或者直接创建卷组） 命令格式：vgcreate 卷组名 设备路径1 设备路径2… 123456789101112131415161718192021222324252627282930#创建卷组[root@localhost ~]# vgcreate systemvg /dev/sdb2 /dev/sdb3#详细显示卷组信息[root@localhost ~]# vgdisplay systemvg --- Volume group --- VG Name systemvg #卷组名字 System ID Format lvm2 #卷组格式 Metadata Areas 2 Metadata Sequence No 1 VG Access read/write VG Status resizable MAX LV 0 Cur LV 0 Open LV 0 Max PV 0 Cur PV 2 Act PV 2 VG Size 19.99 GiB #卷组大小 PE Size 4.00 MiB Total PE 5118 Alloc PE / Size 0 / 0 Free PE / Size 5118 / 19.99 GiB VG UUID KEP7XS-wrkI-rTUY-RqBa-UJA6-YRkK-iKDabR #卷组UUID#简要显示卷组信息[root@localhost ~]# vgs systemvg VG #PV #LV #SN Attr VSize VFree systemvg 2 0 0 wz--n- 19.99g 19.99g 创建逻辑卷 创建逻辑卷思路：从创建好的卷组中创建逻辑卷 命令格式：lvcreate -L 大小 -n 逻辑卷名 卷组名 12345678910111213141516171819#创建逻辑卷[root@localhost ~]# lvcreate -L 10G -n mylv systemvg Logical volume &quot;mylv&quot; created.#简要查看逻辑卷信息[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root centos -wi-ao---- &lt;17.00g swap centos -wi-ao---- 2.00g mylv systemvg -wi-a----- 10.00g [root@localhost ~]# lvs /dev/systemvg/mylv LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert mylv systemvg -wi-a----- 10.00g #查看卷组信息，卷组信息以变小 [root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree centos 1 2 0 wz--n- &lt;19.00g 0 systemvg 2 1 0 wz--n- 19.99g 9.99g 格式化文件系统123456789101112#格式化文件系统[root@localhost ~]# mkfs.xfs /dev/systemvg/mylv#查看文件系统类型[root@localhost ~]# blkid /dev/systemvg/mylv/dev/systemvg/mylv: UUID=&quot;7f08daf8-ae3c-40b2-a282-4514a6f37111&quot; TYPE=&quot;xfs&quot; #挂载使用[root@localhost ~]# mkdir /dbbak[root@localhost ~]# mount /dev/systemvg/mylv /dbbak[root@localhost ~]# df -hT/dev/mapper/systemvg-mylv xfs 10G 33M 10G 1% /dbbak 扩展逻辑卷 逻辑卷支线上扩容，逻辑卷的空间来源于卷组，当卷组有足够的空间是，才可以扩展逻辑卷 扩展命令：lvextend 123456789#扩容逻辑卷[root@localhost ~]# lvextend -L +9G /dev/systemvg/mylv #查看逻辑卷信息[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root centos -wi-ao---- &lt;17.00g swap centos -wi-ao---- 2.00g mylv systemvg -wi-ao---- 19.00g #扩容成功 扩展文件系统 当逻辑卷扩大以后，也需要多逻辑卷的文件系统进行扩展 刷新文件系统容量： xfs_growfs #用于扩容XFS设备 resize2fs #用于扩容EXT3/EXT4设备（了解） 12345678910111213#扩展文件系统[root@localhost ~]# xfs_growfs /dbbak#[root@localhost ~]# df -hT/dev/mapper/systemvg-mylv xfs 19G 33M 19G 1% /dbbak#查看卷组信息[root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree centos 1 2 0 wz--n- &lt;19.00g 0 systemvg 2 1 0 wz--n- 19.99g 1016.00m#扩容卷组 扩展卷组 卷组的空间来源于物理分区，当卷组没有足够空间提供给逻辑卷时，须扩容卷组 扩展卷组命令：vgextend 1234567891011121314151617181920[root@localhost ~]# vgextend systemvg /dev/sdb5 /dev/sdb6 /dev/sdb7 /dev/sdb8[root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree centos 1 2 0 wz--n- &lt;19.00g 0 systemvg 6 1 0 wz--n- &lt;59.98g &lt;40.98g#扩容逻辑卷[root@localhost ~]# lvextend -L +40G /dev/systemvg/mylv [root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root centos -wi-ao---- &lt;17.00g swap centos -wi-ao---- 2.00g mylv systemvg -wi-ao---- 59.00g #扩展文件系统[root@localhost ~]# xfs_growfs /dbbak/dev/mapper/systemvg-mylv 59G 34M 59G 1% /dbbak 课后作业1.查看/var/log目录下以包含log的文件 [[root@localhost]# ls /var/log/log 2.查看/var/log目录下以数字结尾的文件 [[root@localhost]# ls /var/log/*[0-9] 3.查看/var/log目录下以字母结尾的文件（包括大写） [[root@localhost]# ls /var/log/*[a-Z] 4.过滤/etc/sudoers文件以root开头的行 [root@localhost]# grep ^root /etc/sudoersroot ALL=(ALL) ALL 5.看/etc/sudoers文件有效的配置 [[root@localhost]# grep -v ‘^#’ /etc/sudoers | grep -v ‘^$’ -n 6.查找/etc/目录下crontab文件存放位置，并查看文件内容 [[root@localhost]# find /etc/ -name crontab -type f [[root@localhost]# cat /etc/crontab [[root@localhost]# find /etc/ -name crontab -type f -exec cat {} ; 7.查找10分钟内被修改的文件 [[root@localhost]# find / -cmin -10 -type f 8.查找/var/log目录下30天之前被修改且大于1M的文件，清空文件内容 [[root@localhost]# find /var/log -mtime +30 -type f -size +10k -exec cp /dev/null {} ; 9.Linux下你常熟悉的压缩格式有哪些？ gzip bzip2 xz 10.对/home目录打包并压缩，打包后名为home.tar.gz [[root@localhost]# tar -czf home.tar.gz /home 11.将home.tar.gz压缩包内容解压至/homebak目录下 [[root@localhost]# tar -xvf home.tar.gz -C /homebak/ 12.MBR分区格式可以划分多少个主分区？支持多大容量磁盘？ 4个主分区，2.2T 13.GPT分区格式可以划分多少个主分区？支持多大容量磁盘？ 128主分区，18EB 14.CentOS7分区默认使用的文件系统类型是什么？ xfs 15.如何查看一块磁盘的分区格式？及扩展分区大小？ [[root@localhost]# fdisk -l /dev/sdc 磁盘标签类型：gpt 16如何查看一块磁盘剩余容量？ [[root@localhost]# lsblk /dev/sdc 17.linux下开机自动挂载文件是哪个？ /etc/fstab 18.如何查看一个分区文件系统类型？及使用情况？ [[root@localhost]# df -hT 19.为根分区扩容40G空间 1234567891011121314151617181920212223242526272829303132#查看根分区卷组[root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree centos 1 2 0 wz--n- &lt;19.00g 0 #扩容根分区卷组[root@localhost ~]# vgextend centos /dev/sdc2 /dev/sdc3#查看根分区逻辑卷信息[root@localhost ~]# lvs LV VG Attr LSize root centos -wi-ao---- &lt;17.00g #扩容逻辑卷[root@localhost ~]# lvextend -L +39G /dev/centos/root #查看逻辑卷信息[root@localhost ~]# lvs root centos -wi-ao---- &lt;56.00g #查看正在使用的分区信息[root@localhost ~]# df -hT文件系统 类型 容量 已用 可用 已用% 挂载点/dev/mapper/centos-root xfs 17G 4.4G 13G 26% /#扩容文件系统[root@localhost ~]# xfs_growfs /#查看使用情况[root@localhost ~]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/centos-root 56G 4.4G 52G 8% / 删除逻辑卷 逻辑卷的删除不允许联机操作，需要先卸载，在执行删除 在执行删除操作时，首先删除LV逻辑卷，在删除VG卷组，最后删除PV物理卷 删除命令：lvremove 123456789101112131415#删除逻辑卷错误示范[root@localhost ~]# lvremove /dev/systemvg/mylv Logical volume systemvg/mylv contains a filesystem in use. #提示文件正在使用中#需要先卸载[root@localhost ~]# umount /dblod/#删除逻辑卷[root@localhost ~]# lvremove /dev/systemvg/mylv Do you really want to remove active logical volume systemvg/mylv? [y/n]: y Logical volume &quot;mylv&quot; successfully removed#删除卷组[root@localhost ~]# vgremove systemvg Volume group &quot;systemvg&quot; successfully removed 逻辑卷的缩减 命令lvreduce 不允许连接缩减 先缩减文件系统的空间，在缩减逻辑卷的空间 RAID磁盘阵列 RAID中文全称：独立磁盘冗余阵列 ，简称磁盘阵列 RAID可通过技术（软件/硬件）将多个独立的磁盘整合成一个巨大容量大逻辑磁盘使用 RAID可以提高数据I/O（读写）速度，和冗余数据的功能 RAID级别RAID0：等量存储，至少由2块磁盘组成，同一个文档等量存放在不同的磁盘并行写入数据来提高效率，但只是单纯的提高效率，并没有冗余功能，如果其中一块盘故障，数据会丢失，不适合存放重要数据 RAID1：完整备份，至少由两块磁组成，同一个文档复制成多份存储到不同磁盘提高可靠性，读写速度没有提升，适合存储重要的数据 RAID2：至少由3块磁盘组成，数据分散存储在不同磁盘，在读写数据时需要对数据时时校验，由于采用的校验算法复杂，数据量比原有数据增大，而且导致硬件开销较大 RAID3：至少由三块磁盘组成，同一份文档分散写入不同的磁盘，校验数据单独存放在另外一块磁盘，由于每次读写操作都会访问校验盘，容易导致校验盘长时间高负荷工作而挂掉，如果校验盘损坏数据将无法恢复 RAID4：与RAID3类似，至少由3块磁盘组成，同一份文档分散存写入不同磁盘，校验数据单独存放在另外一块磁盘，由于每次读写操作都会访问校验盘，容易导致校验盘长时间高负荷工作而挂掉，如果校验盘损坏数据将无法恢复，与RAID3的区别是数据分割方式不一样 RAID5：至少由3块磁盘组成，同一份文档分散写入不同磁盘，每个硬盘都有校验数据，其中校验数据会占用磁盘三分之一的空间，三分之二的空间存放原始数据，允许同时坏一块磁盘，当一块磁盘损坏，其他磁盘里的数据配合校验信息可将数据恢复回来 RAID6：至少由4块磁盘组成，同一份文档分散写入不同磁盘，每个磁盘都有校验数据，由于采用双校验算法，所以校验数据量是RAID5的两倍，需要占用2块磁盘空间存放校验数据，两块盘存放原始数据，由于数据校验的算法计算量偏大，所以在速写速度上没有RAID5快，允许同时坏2块磁盘 RAID7：美国SCC公司专利，花钱 RAID10：RAID10=RAID1+RAID0合二为一，最少需要4块磁盘，先将4块硬盘组成两组RAID1，在将两组RAID1组成一个RAID0，既提高数据读写速度，又能保障数据安全性，缺点是可用容量是总容量的一半 实现RAID方式 实现RAID通常有三种方式，通过软件技术实现RAID功能（软RAID） 外接式磁盘阵列柜，被常用在大型服务器上，不过这类产品价格昂贵 RAID磁盘阵列卡，分为服务器自带和额外安装，硬RAID比软RAID更安全稳定，RAID卡带有缓存功能可实现数据自动恢复，RAID卡有电池 配置硬RAID方式 进程管理 什么是程序：用计算机语言编写的命令序列集合，用来实现特定的目标或解决特定的问题，程序占用磁盘空间，程序是静态并且是永久的 什么是进程：正在运行中的程序叫进程，占用内存空间，进程是动态的，进程是有生命周期的，进程有自己的独立内存空间，每启动一个进程，系统就会为它分配内存空间并分配一个PID号，每个进程都会对应一个父进程，而父进程可以复制多个子进程，每种进程都有两种方式存在，前台与后台，一般进程都是以后台方式运 什么是线程：线程也被称为轻量级进程，被包含在进程中，是进程的一个子集，是进程中的实际运作单位，一个进程中可以并发多个线程，每条线程并行执行不同的任务，每个线程都是独立的，线程之间共享进程的内存空间，在多线程的程序中，由于线程很“轻”，故线程的切换非常迅速且开销小（在同一进程中） 查看进程树 pstree以树状结构显示进程信息，包括进程之间的关系 命令格式：pstree [选项…] [参数…] 常用选项： -p #显示进程PID -a #显示完整的命令行 -u #列出每个进程所属账号名称 12345678910111213141516171819202122232425#查看进程树[root@localhost ~]# pstreesystemd─┬─ModemManager───2*[{ModemManager}]CentOS7版本：天父进程systemdCentOS6版本：天父进程init，ApstartCentOS5版本：天赋进程init#以PID形式显示进程信息[root@localhost ~]# pstree -psystemd(1)─┬─ModemManager(6714)─┬─{ModemManager}(6739)#查看系统用户的进程信息[root@localhost ~]# pstree -p lisisshd(15086)───bash(15089)───vim(15244)[root@localhost ~]# pstree -pa lisisshd,15086 └─bash,15089 └─vim,15244 1.txt#查看系统所有用户的进程root@localhost ~]# pstree -up... ├─smartd(6726) ├─sshd(7337)─┬─sshd(8880)───bash(8887)───pstree(15395) │ └─sshd(15066)───sshd(15086,lisi)───bash(15089)───vim(15244) ps aux：unix格式静态查看系统进程，查看系统所有进程信息 a #显示当前终端所有进程 u #以用户格式输出 x #当前用户在所有终端下的进程 ps -ef：Linux格式静态查看系统进程，查看系统所有进程信息 -e #显示系统所有进程 -l #以长格式输出信息 -f #显示最完整的进程信息 12345678910111213141516171819202122#查看系统所有进程信息[root@localhost ~]# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 2.2 0.3 127992 6576 ? Ss 09:08 0:01 /usr/lib/systemd/systemd --switched-root#个字段含义如下：user：进程属于那个用户PID ：进程PID号%CPU：进程占用CPU资源百分比%MEM：进程占用物理内存百分比VSZ ：进程使用掉的虚拟内存量（单位：Kb）RSS ：进程占用固定内存量（单位：Kb）TTY ：进程在那个终端运行，如果内核直接调用则显示“？”，tty1-tty6表示本机终端登录的用户进程，pts/0-255则表示远程终端登录用户的进程STAT：进程状态：R（Running）运行，S（Sleep）休眠，s包含子进程，T（stop）停止，Z（Zombie）僵尸，+后台进程START：进程启动时间TIME ：占用CPU运算时间COMMAND：产生进程的命令#查看系统所有进程信息[root@localhost ~]# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 09:08 ? 00:00:01 /usr/lib/systemd/systemd --switched-root --system --dese#PPID ：该进程的父进程ID号 top查看系统健康状态 top命令动态来查看系统运行性能及状态信息 命令格式：top [选项…] 常用选项：-d #指定刷新秒数，默认为3秒刷新一次 交互界面显示指令： 键盘上下键翻行 h #获取交互模式帮助 P(大写) #按照CPU使用资源排序 M #按照内存使用资源排序 q #退出 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364[root@localhost ~]# toptop - 21:22:04 up 12:13, 2 users, load average: 0.00, 0.01, 0.05Tasks: 115 total, 1 running, 114 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.3 us, 0.3 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 1863224 total, 1502920 free, 107872 used, 252432 buff/cacheKiB Swap: 2097148 total, 2097148 free, 0 used. 1565576 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 8317 root 20 0 161984 2220 1568 R 0.7 0.1 0:01.62 top #第一行top每个字段含义如下：第二列：21:22:04：当前系统时间第三列：up 12:13：系统运行时间，该系统以运行12小时13分钟（up 10 day，12:13 代表运行10天12小时13分钟）第四列：2 users：当前系统登录终端数量第五列：load average: 0.00, 0.01, 0.05：CPU1分钟，5分钟，15分钟之前平均负载量，根据CPU核数判断系统CPU负载量，1核CPU若高于1代表负载过高，2核CPU若高于2代表负载过高，依次类推。。。#第二行Tasks每个字段含义如下：第二列：115 total：当前系统中进程的总数量第三列：1 running：正在运行的进程数量第四列：114 sleeping：正在睡眠的进程数量第五列：0 stopped：正在停止的进程数量第六列：0 zombie：僵尸进程数量，僵尸进程是当子进程比父进程先结束，而父进程又没有回收子进程，释放子进程占用的资源，此时子进程将成为一个僵尸进程。#查找僵尸进程与其父进程ps -A -o stat,ppid,pid,cmd | grep &quot;^Zz&quot;命令解释：-A 参数列出所有进程-o 自定义输出字段，我们设定显示字段为 stat（状态）, ppid（父进程id）, pid(进程id)，cmd（命令）这四个参数，因为状态为 z或者Z的进程为僵尸进程，所以我们使用grep抓取stat状态为zZ进程#杀死进程kill -9 + 父进程号#第三行%Cpu(s)每个字段含义如下第二列：0.0 us：用户进程占用的CPU百分比第三列：0.0 sy：系统进程占用的CPU百分比第四列：0.0 ni：改变过优先级的用户进程占用的CPU百分比第五列：100.0 id：空闲的CPU百分比（重点关注）第六列：0.0 wa：等待输入/输出的进程的占用CPU百分比第七列：0.0 hi：硬中断请求服务占用的CPU百分比第八列：0.0 si：软中断请求服务占用的CPU百分比第九列：0.0 st：虚拟时间百分比，当有虚拟机时，虚拟CPU等待实际CPU的时间百分比#第四行KiB Mem每个字段含义如下：第二列：1863224 total：物理内存总量，单位KB第三列：1502516 free： 空闲内存总量，单位KB第四列：108240 used： 以使用的内存总量，单位KB第五列：252468 buff/cache：块设备与普通文件占用的缓存数量#第五行KiB Swap每个字段含义如下：第二列：2097148 total：交换空间总量，单位KB第三列：2097148 free：可用空闲交换空间总量，单位KB第四列：0 used：：以使用的交换空间总量，单位KB第五列：1565180 avail Mem：可用于进程下一次分配的物理内存数量#第六行每个字段含义如下：PID：进程PID号USER：进程所有者的用户名PR：进程优先级执行顺序，越小越优先被执行NI：负值表示高优先级，正值表示低优先级，越小越优先被执行VIRT：进程使用的虚拟内存总量，单位kb RES：进程使用的、未被换出的物理内存大小，单位kbSHR：共享内存大小，单位kbS：进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程%CPU：进程使用的CPU百分比（重点关注）%MEM：进程使用的物理内存百分比（重点关注）TIME+：进程使用的CPU时间总计，单位1/100秒COMMAND：命令名/命令行 检索进程 pgrep 通过匹配其程序名，找到匹配的进程 命令格式：pgrep [选项…] [参数…] 常用选项： -l #输出进程名与PID -U #检索指定用户进程 -t #检索指定终端进程 -x #精确匹配完整进程名 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#过滤sshd进程[root@localhost ~]# pgrep sshd73378880150661508617027过滤sshd进程，并显示进程名称[root@localhost ~]# pgrep -l sshd7337 sshd8880 sshd15066 sshd15086 sshd17027 sshd#过滤指定用户的进程[root@localhost ~]# pgrep -lU lisi15086 sshd15089 bash15244 vim#按照用户名过滤进程时，选项不要颠倒[root@localhost ~]# pgrep -Ul lisipgrep: invalid user name: l#查看系统所有终端用户[root@localhost ~]# whoroot pts/0 2021-04-24 14:06 (192.168.0.1)lisi pts/1 2021-04-24 15:57 (192.168.0.1)root pts/2 2021-04-24 16:29 (192.168.0.1)#过滤用户在指定终端开启的进程信息[root@localhost ~]# pgrep -lU lisi -t pts/115089 bash15244 vim#过滤用户在指定终端开启的进程信息[root@localhost ~]# pgrep -lU lisi -t pts/319704 bash19754 top#精确匹配进程名（没有则不显示）[root@localhost ~]# pgrep -x ssh#精确匹配进程名[root@localhost ~]# pgrep -xl crond7362 crond 进程的前后台调度 &amp; #将进程放入后台运行 jobs -l #查看后台进程列表 fg 进程编号 #将后台进程恢复至前台运行 ctrl + z 组合键 #挂起当前进程并放入后台 bg 进程编号 #激活后台被挂起进程 1234567891011121314151617181920[root@localhost ~]# sleep 5m &amp;[1] 20130#查看后台进程信息[root@localhost ~]# jobs -l[1]+ 20130 运行中 sleep 5m &amp;#将后台进程放入前台运行[root@localhost ~]# fg 1sleep 5m#挂起前台进程放入后台[root@localhost ~]# jobs[1]+ 已停止 sleep 5m#激活后台的进程[root@localhost ~]# bg 1[1]+ sleep 5m &amp;[root@localhost ~]# jobs -l[1]+ 20130 运行中 sleep 5m &amp; 杀死进程 杀死进程的方式 ctrl + c 组合键结束当前命令程序 kill [选项…] PID 常用选项：-l #列出可用进程信号 常用信号：-1重启进程，-9强制杀死进程，-15正常杀死进程（默认信号无需指定） killall -9 进程名 #强制杀死进程 killall -9 -u 用户名 #强制杀死该用户所有进程 pkill -9 进程名 #强制杀死进程 常用选项：-t 终端号 #提出终端用户 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122#结束前台正在运行的进程[root@localhost ~]# sleep 5m^C#启用进程放入后台[root@localhost ~]# sleep 5m &amp;[1] 21150[root@localhost ~]# sleep 6m &amp;[2] 21155[root@localhost ~]# sleep 7m &amp;[3] 21159[root@localhost ~]# sleep 8m &amp;[4] 21162#查看后台进程[root@localhost ~]# jobs -l[1] 21150 运行中 sleep 5m &amp;[2] 21155 运行中 sleep 6m &amp;[3]- 21159 运行中 sleep 7m &amp;[4]+ 21162 运行中 sleep 8m &amp;#杀死后台指定的进程（按照PID）[root@localhost ~]# kill 21150#查看后台进程[root@localhost ~]# jobs -l[1] 21150 已终止 sleep 5m[2] 21155 运行中 sleep 6m &amp;[3]- 21159 运行中 sleep 7m &amp;[4]+ 21162 运行中 sleep 8m &amp;[root@localhost ~]# kill 21155[root@localhost ~]# jobs -l[2] 21155 已终止 sleep 6m[3]- 21159 运行中 sleep 7m &amp;[4]+ 21162 运行中 sleep 8m &amp;#强制杀死进程[root@localhost ~]# kill -9 21159[root@localhost ~]# jobs -l[3]- 21159 已杀死 sleep 7m[4]+ 21162 运行中 sleep 8m &amp;#启动进程[root@localhost ~]# sleep 4m &amp;[5] 21402[root@localhost ~]# sleep 5m &amp;[6] 21406[root@localhost ~]# sleep 6m &amp;[7] 21409[root@localhost ~]# sleep 7m &amp;[8] 21412[root@localhost ~]# jobs -l[4] 21162 运行中 sleep 8m &amp;[5] 21402 运行中 sleep 4m &amp;[6] 21406 运行中 sleep 5m &amp;[7]- 21409 运行中 sleep 6m &amp;[8]+ 21412 运行中 sleep 7m &amp;#按照进程名去杀[root@localhost ~]# killall sleep[4] 已终止 sleep 8m[5] 已终止 sleep 4m[6] 已终止 sleep 5m[7]- 已终止 sleep 6m[8]+ 已终止 sleep 7m#启动进程[root@localhost ~]# sleep 5m &amp;[1] 21491[root@localhost ~]# sleep 6m &amp;[2] 21495[root@localhost ~]# sleep 7m &amp;[3] 21498[root@localhost ~]# jobs -l[1] 21491 运行中 sleep 5m &amp;[2]- 21495 运行中 sleep 6m &amp;[3]+ 21498 运行中 sleep 7m &amp;#按照进程名强制杀死进程[root@localhost ~]# killall -9 sleep[1] 已杀死 sleep 5m[2]- 已杀死 sleep 6m[3]+ 已杀死 sleep 7m[root@localhost ~]# whoroot pts/0 2021-04-24 14:06 (192.168.0.1)lisi pts/1 2021-04-24 15:57 (192.168.0.1)root pts/2 2021-04-24 16:29 (192.168.0.1)lisi pts/3 2021-04-24 17:14 (192.168.0.1)#杀死指定用户的所有进程（讲用户提出系统）[root@localhost ~]# killall -9 -u lisi[root@localhost ~]# whoroot pts/0 2021-04-24 14:06 (192.168.0.1)root pts/2 2021-04-24 16:29 (192.168.0.1)#pkill命令演示[root@localhost ~]# sleep 4m &amp;[1] 21870[root@localhost ~]# sleep 5m &amp;[2] 21873[root@localhost ~]# sleep 6m &amp;[3] 21876[root@localhost ~]# jobs [1] 运行中 sleep 4m &amp;[2]- 运行中 sleep 5m &amp;[3]+ 运行中 sleep 6m &amp;[root@localhost ~]# pkill sleep[1] 已终止 sleep 4m[2]- 已终止 sleep 5m[3]+ 已终止 sleep 6m[root@localhost ~]# whoroot pts/0 2021-04-24 14:06 (192.168.0.1)lisi pts/1 2021-04-24 17:47 (192.168.0.1)root pts/2 2021-04-24 16:29 (192.168.0.1)lisi pts/3 2021-04-24 17:48 (192.168.0.1)[root@localhost ~]# pkill -9 -t pts/3 用户登录分析 users who w #查看以登录的用户信息（详细度不同） last #显示登录成功的用户信息 lastb #显示登录失败的用户信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@localhost ~]# users[root@localhost ~]# userslisi root root#root：以登录系统的用户名[root@localhost ~]# whoroot pts/0 2021-04-24 14:06 (192.168.0.1)lisi pts/1 2021-04-24 17:47 (192.168.0.1)root pts/2 2021-04-24 16:29 (192.168.0.1)#第一列：以登录系统的用户名#第二列：用户登录的终端编号#第三列：登陆时间#第四列：远程登录地址[root@localhost ~]# w 08:16:10 up 55 min, 1 user, load average: 0.00, 0.01, 0.05USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 192.168.0.1 07:21 2.00s 0.10s 0.00s w#第一行为top命令显示的第一行数据#第二行每列含义如下：USER：以登录的用户名TTY：用户登录终端编号FROM：登录地址LOGIN@：登录时间IDLE：用户空闲时间，这是个计时器，一旦用户执行任何操作，该计时器便会被重置JCPU：该终端所有进程占用CPU处理时间，包括正在运行和后台作业占用时间。PCPU：进程执行以后消耗的CPU时间WHAT：当前正在执行的任务#显示登录成功用户[root@localhost ~]# lastlisi pts/1 192.168.0.1 Sat Apr 24 07:56 - 08:03 (00:07) #第一列：用户名#第二列：用户登录终端编号#第三列：登录地址#第四列：登录起使时间#第五列：登录结束时间#第六列：登录持续时间#查看最近2次登录系统成功的用户[root@localhost ~]# last -2lisi pts/3 192.168.0.1 Sat Apr 24 17:48 - 17:50 (00:01) lisi pts/3 192.168.0.1 Sat Apr 24 17:47 - 17:48 (00:00) #查看登录失败用户[root@localhost ~]# lastblisi ssh:notty 192.168.0.1 Sat Apr 24 08:52 - 08:52 (00:00) Linux软件包的分类 源码包 二进制包（RPM包） 源码包特点 源码包缺点：安装过程麻烦，需要用户手动编译，需要手动解决软件包的依赖关系 源码包优点：软件源代码开放，允许用户二次开发，安装灵活，可以自定义安装路径与安装功能，卸载方便 RPM包特点 RPM包缺点：所有功能用户无法自定义，安装没有源码包灵活，不可以看到软件源代码 RPM包优点：由于已经提前被编译过，所以安装简单，安装速度快 RPM包命名规则，如：vsftpd-3.0.2-25.el7.x86_64.rpm vsftpd #软件包名称 3.0.2 #软件包版本，主版本.次版本.修改版本 25 #补丁次数 el7 #适合的系统（el7表示RHEL7） x86_64 #适合的CPU架构 rpm #rpm包扩展名 RPM管理软件包 RPM命令管理软件包需要手动解决软件包之间依赖关系 树形依赖：a–&gt;b–&gt;c–d 环形依赖：a–&gt;b–&gt;c–a 模块依赖：需要模块文件支持，模块查询地址：www.rpmfind.net 命令格式：rpm 选项… 软件包全名 常用选项： -q #仅查询软件是否安装 -qa #列出所有已经安装在系统中的所有软件，可配合grep过滤指定的软件包 -qi #列出软件包详细信息，包含版本与官网地址 -qf #后边接文件名，查询配置文件由哪个软件包产生 -ql #列出与该软件包相关所有文件与目录的存放位置 -ivh #i安装，v显示详细信息，h显示软件安装进度 -Uvh #升级安装软件包 -e #卸载软件包 –import #导入红帽签名 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176#挂载iso镜像文件[root@localhost ~]# mkdir /mnt/centos[root@localhost ~]# mount /dev/cdrom /mnt/centos/#实现永久挂载，查看iso镜像文件系统类型[root@localhost ~]# df -hT[root@localhost ~]# vim /etc/fstab.../dev/cdrom /mnt/centos iso9660 defaults 0 0#重新加载[root@localhost ~]# mount -a#查询软件包是否安装[root@localhost centos]# rpm -q vsftpd未安装软件包 vsftpd #安装vsftpd软件包[root@localhost centos]# rpm -i Packages/vsftpd-3.0.2-25.el7.x86_64.rpm #查询系统中以安装的所有软件[root@localhost centos]# rpm -qa[root@localhost centos]# rpm -qa | grep vsftpdvsftpd-3.0.2-25.el7.x86_64#查询软件包详细的信息[root@localhost centos]# rpm -qi vsftpdName : vsftpd #软件包名Version : 3.0.2 #版本Release : 25.el7 #最终稳定版Architecture: x86_64 #适合安装的CPU架构Install Date: 2021年05月04日 星期二 14时47分06秒 #安装时间Group : System Environment/Daemons #软件包属于哪个群组Size : 361335 #软件包大小License : GPLv2 with exceptionsSignature : RSA/SHA256, 2018年11月12日 星期一 22时48分54秒, Key ID 24c6a8a7f4a80eb5Source RPM : vsftpd-3.0.2-25.el7.src.rpmBuild Date : 2018年10月31日 星期三 03时45分10秒Build Host : x86-01.bsys.centos.orgRelocations : (not relocatable)Packager : CentOS BuildSystem &lt;http://bugs.centos.org&gt;Vendor : CentOSURL : https://security.appspot.com/vsftpd.html #软件包官网地址Summary : Very Secure Ftp DaemonDescription : #描述信息vsftpd is a Very Secure FTP daemon. It was written completely fromscratch.[root@localhost centos]# which lsalias ls='ls --color=auto' /usr/sbin/ls #查询文件由哪个软件包产生 [root@localhost centos]# rpm -qf /usr/bin/lscoreutils-8.22-23.el7.x86_64[root@localhost centos]# which vim/usr/bin/vim[root@localhost centos]# rpm -qf /usr/bin/vimvim-enhanced-7.4.160-5.el7.x86_64[root@localhost centos]# rpm -qi vim-enhanced#查询软件包自带的文件与目录安装路径[root@localhost centos]# rpm -ql vsftpd[root@localhost centos]# rpm -qf /usr/bin/vimvim-enhanced-7.4.160-5.el7.x86_64[root@localhost centos]# rpm -ql vim-enhanced/etc/profile.d/vim.csh/etc/profile.d/vim.sh/usr/bin/rvim/usr/bin/vim/usr/bin/vimdiff/usr/bin/vimtutor[root@localhost centos]# rpm -q vsftpdvsftpd-3.0.2-25.el7.x86_64#卸载软件包[root@localhost centos]# rpm -e vsftpd[root@localhost centos]# rpm -q vsftpd未安装软件包 vsftpd #安装vsftpd软件包[root@localhost centos]# rpm -ivh Packages/vsftpd-3.0.2-25.el7.x86_64.rpm 警告：Packages/vsftpd-3.0.2-25.el7.x86_64.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID f4a80eb5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:vsftpd-3.0.2-25.el7 ################################# [100%][root@localhost centos]# rpm -q vsftpdvsftpd-3.0.2-25.el7.x86_64#升级安装软件包[root@localhost centos]# rpm -Uvh Packages/vsftpd-3.0.2-25.el7.x86_64.rpm 警告：Packages/vsftpd-3.0.2-25.el7.x86_64.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID f4a80eb5: NOKEY准备中... ################################# [100%] 软件包 vsftpd-3.0.2-25.el7.x86_64 已经安装#导入红帽签名文件[root@localhost centos]# rpm --import RPM-GPG-KEY-CentOS-7#安装软件包，查看是否还有警告信息[root@localhost centos]# rpm -q vsftpdvsftpd-3.0.2-25.el7.x86_64[root@localhost centos]# rpm -e vsftpd[root@localhost centos]# rpm -ivh Packages/vsftpd-3.0.2-25.el7.x86_64.rpm 准备中... ################################# [100%]正在升级/安装... 1:vsftpd-3.0.2-25.el7 ################################# [100%]#安装httpd软件包[root@localhost centos]# rpm -ivh Packages/httpd-(tab键)httpd-2.4.6-88.el7.centos.x86_64.rpm httpd-manual-2.4.6-88.el7.centos.noarch.rpmhttpd-devel-2.4.6-88.el7.centos.x86_64.rpm httpd-tools-2.4.6-88.el7.centos.x86_64.rpm[root@localhost centos]# rpm -ivh Packages/httpd-2.4.6-88.el7.centos.x86_64.rpm 错误：依赖检测失败： /etc/mime.types 被 httpd-2.4.6-88.el7.centos.x86_64 需要 httpd-tools = 2.4.6-88.el7.centos 被 httpd-2.4.6-88.el7.centos.x86_64 需要 libapr-1.so.0()(64bit) 被 httpd-2.4.6-88.el7.centos.x86_64 需要 libaprutil-1.so.0()(64bit) 被 httpd-2.4.6-88.el7.centos.x86_64 需要[root@localhost centos]# ls /etc/mime.typesls: 无法访问/etc/mime.types: 没有那个文件或目录#解决依赖关系[root@localhost centos]# rpm -ivh Packages/mailcap-2.1.41-2.el7.noarch.rpm 准备中... ################################# [100%]正在升级/安装... 1:mailcap-2.1.41-2.el7 ################################# [100%][root@localhost centos]# ls /etc/mime.types/etc/mime.types#解决依赖关系[root@localhost centos]# rpm -ivh Packages/httpd-tools-2.4.6-88.el7.centos.x86_64.rpm 错误：依赖检测失败： libapr-1.so.0()(64bit) 被 httpd-tools-2.4.6-88.el7.centos.x86_64 需要 libaprutil-1.so.0()(64bit) 被 httpd-tools-2.4.6-88.el7.centos.x86_64 需要#解决依赖关系（www.rpmfind.net官网查询提供libapr-1.so.0模块文件的软件包）[root@localhost centos]# rpm -ivh Packages/apr-(tab键)apr-1.4.8-3.el7_4.1.x86_64.rpm apr-util-1.5.2-6.el7.x86_64.rpm apr-devel-1.4.8-3.el7_4.1.x86_64.rpm apr-util-devel-1.5.2-6.el7.x86_64.rpm [root@localhost centos]# rpm -ivh Packages/apr-1.4.8-3.el7_4.1.x86_64.rpm 准备中... ################################# [100%]正在升级/安装... 1:apr-1.4.8-3.el7_4.1 ################################# [100%]#解决依赖关系（www.rpmfind.net官网查询提供libaprutil-1.so.0模块文件的软件包）[root@localhost centos]# rpm -ivh Packages/apr-util-(tab键)apr-util-1.5.2-6.el7.x86_64.rpm apr-util-devel-1.5.2-6.el7.x86_64.rpm [root@localhost centos]# rpm -ivh Packages/apr-util-apr-util-1.5.2-6.el7.x86_64.rpm apr-util-devel-1.5.2-6.el7.x86_64.rpm [root@localhost centos]# rpm -ivh Packages/apr-util-1.5.2-6.el7.x86_64.rpm 准备中... ################################# [100%]正在升级/安装... 1:apr-util-1.5.2-6.el7 ################################# [100%]#安装依赖关系[root@localhost centos]# rpm -ivh Packages/httpd-tools-2.4.6-88.el7.centos.x86_64.rpm 准备中... ################################# [100%]正在升级/安装... 1:httpd-tools-2.4.6-88.el7.centos ################################# [100%]#安装httpd主包[root@localhost centos]# rpm -ivh Packages/httpd-(tab键)httpd-2.4.6-88.el7.centos.x86_64.rpm httpd-manual-2.4.6-88.el7.centos.noarch.rpmhttpd-devel-2.4.6-88.el7.centos.x86_64.rpm httpd-tools-2.4.6-88.el7.centos.x86_64.rpm[root@localhost centos]# rpm -ivh Packages/httpd-2.4.6-88.el7.centos.x86_64.rpm 准备中... ################################# [100%]正在升级/安装... 1:httpd-2.4.6-88.el7.centos ################################# [100%] yum软件包管理 yum（软件仓库）：提供众多软件包的仓库，并自动解决软件包之间复杂依赖关系 yum常用命令： yum repolist #列出仓库可用软件包 yum list 软件包名 #查看系统中提供的软件包（包含未安装的软件包） yum list updates #查看系统中可供本机升级的软件包 yum install 软件包名 #安装软件包，-y自动回答yes yum update 软件包名 #升级软件包版本 yum remove 软件包名 #卸载软件包 yum clean all #清除仓库缓存 yum provides 文件名 #查看文件由哪个软件包产生（主要用于查找程序文件） 本地yum源配置（本地软件仓库） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768[root@localhost ~]# vim /etc/yum.repos.d/local.repo [local] #仓库名称，名称自定义，但具有唯一性name=local_centos #仓库描述，（类似于仓库解释），描述信息自定义，不具备唯一性baseurl=file:///mnt/centos #指定软件仓库地址，file://用于指定本地软件包存放位置enabled=1 #软件仓库是否启动，1启动，0不启动gpgcheck=0 #是否检测软件包签名，0不检测，1检测#检测仓库可用性[root@localhost centos]# yum repolist已加载插件：fastestmirror, langpacks 源标识 源名称 状态local local_centos 4,021repolist: 4,021#查找指定的软件包[root@localhost centos]# yum list gcc#安装软件包[root@localhost centos]# yum install gcc...Is this ok [y/d/N]: y (y安装/d下载到本地不安装/N不安装)[root@localhost centos]# rpm -q gccgcc-4.8.5-36.el7.x86_64[root@localhost centos]# rpm -qi gcc[root@localhost centos]# rpm -ql gcc#安装软件包并自动回答yes[root@localhost centos]# yum -y install gcc-c++ [root@localhost centos]# rpm -q gcc[root@localhost centos]# rpm -qi gcc[root@localhost centos]# rpm -ql gcc[root@localhost centos]# rpm -qf /usr/bin/ls[root@localhost centos]# yum provides /usr/bin/ls#下载挂载点[root@localhost ~]# umount /mnt/centos/[root@localhost ~]# ls /mnt/centos/#查看仓库可用性[root@localhost ~]# yum repolist源标识 源名称 状态local local_centos 4,021repolist: 4,021[root@localhost ~]# rpm -e vsftpdroot@localhost ~]# yum -y install vsftpdError downloading packages: vsftpd-3.0.2-25.el7.x86_64: [Errno 256] No more mirrors to try.[root@localhost ~]# yum clean all[root@localhost ~]# yum repolist源标识 源名称 状态local local_centos 0repolist: 0#挂载[root@localhost ~]# mount -amount: /dev/sr0 写保护，将以只读方式挂载 网络yum源配置（网络软件仓库，配置阿里开源软件仓库） https://developer.aliyun.com/special/mirrors/notice 阿里云官方镜象站（软件仓库） https://mirrors.tuna.tsinghua.edu.cn/centos/7/os/x86_64/ 清华大学官方镜象站 12345678910111213141516171819202122232425262728293031323334353637#下载wget工具[root@localhost ~]# yum -y install wget#下载阿里Base源（基本软件仓库，解决rpm软件的依赖关系）[root@localhost ~]# wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo#下载阿里epel源（额外软件仓库，包含许多基本软件仓库没有的软件包）[root@localhost ~]# wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo[root@localhost ~]# vim /etc/yum.repos.d/CentOS-Base.repo[base]name=CentOS-$releasever - Base - mirrors.aliyun.comfailovermethod=priority #故障转移方法，默认优先baseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/ http://mirrors.cloud.aliyuncs.com/centos/$releasever/os/$basearch/gpgcheck=1gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7#配置清华大学开源镜象站[root@localhost ~]# vim /etc/yum.repos.d/local.repo [local]name=local_centosbaseurl=file:///mnt/centos/enabled=1gpgcheck=0[tuna.tsinghua.edu.cn]name=tuna.tsinghua.edu.cnbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/7/os/x86_64/enabled=1gpgcheck=0#生成yum仓库缓存提高软件包下载速度[root@localhost ~]# yum makecache...元数据缓存已建立 设置yum源优先级12345678#设置本地yum为最高优先级[root@localhost ~]# vim /etc/yum.repos.d/local.repo[local]name=local_centosbaseurl=file:///mnt/centosenabled=1gpgcheck=0priority=1 #优先级为1-99之间，数字越小越优先 源码包安装方式123456789101112131415161718192021222324252627282930313233343536373839#从官网下载源码包http://nginx.org/#安装源码包依赖包[root@localhost ~]# yum -y install gcc pcre-devel openssl-devel zlib#解压源码包并进入源码包路径[root@localhost ~]# tar -xf nginx-1.20.0.tar.gz [root@localhost ~]# cd nginx-1.20.0/[root@localhost nginx-1.20.0]# lsauto CHANGES CHANGES.ru conf configure contrib html LICENSE man README src#使用configure程序检查系统环境并指定安装参数[root@localhost nginx-1.20.0]# ./configure --with-http_ssl_module --with-file-aio --with-http_realip_module nginx path prefix: &quot;/usr/local/nginx&quot; nginx binary file: &quot;/usr/local/nginx/sbin/nginx&quot; nginx modules path: &quot;/usr/local/nginx/modules&quot; nginx configuration prefix: &quot;/usr/local/nginx/conf&quot; nginx configuration file: &quot;/usr/local/nginx/conf/nginx.conf&quot; nginx pid file: &quot;/usr/local/nginx/logs/nginx.pid&quot; nginx error log file: &quot;/usr/local/nginx/logs/error.log&quot; nginx http access log file: &quot;/usr/local/nginx/logs/access.log&quot; nginx http client request body temporary files: &quot;client_body_temp&quot; nginx http proxy temporary files: &quot;proxy_temp&quot; nginx http fastcgi temporary files: &quot;fastcgi_temp&quot; nginx http uwsgi temporary files: &quot;uwsgi_temp&quot; nginx http scgi temporary files: &quot;scgi_temp&quot;#make将源码包转换成二进制[root@localhost nginx-1.20.0]# make#make install安装源码包[root@localhost nginx-1.20.0]# make install[root@localhost nginx-1.20.0]# cd /usr/local/nginx/[root@localhost nginx]# lsconf html logs sbin 源码包管理方式123456789101112131415161718192021#启动nginx服务[root@localhost nginx]# sbin/nginx#netstat|ss命令用于查看系统中启动的端口信息-a 显示所有端口信息-n 以数字格式显示端口号-t 显示TCP连接的端口-u 显示UDP连接的端口-l 显示服务正在监听的端口信息-p 显示监听端口的服务名称是什么（也就是程序名）#查看nginx服务端口信息[root@localhost ~]# ss -anptul | grep nginxtcp LISTEN 0 128 *:80 #Nginx服务默认通过TCP 80 端口监听客户端请求#查看系统所有服务占用的端口虚拟系[root@localhost nginx]# ss -ntlp [root@localhost nginx]# ss -anptul | grep sshd[root@localhost nginx]# ss -anptul | grep vsftpd systemd管理服务 systemd是内核加载的第一个进程（PID=1），systemd负责整个Linux系统的运行与服务控制，systemd为用户提供systemctl命令来管理RPM包安装的服务，如：启动服务、重启服务、关闭服务、查看服务状态，服务随机自启 服务的启动有两个阶段，一是系统开机时随着系统的启动而启动（随机自启），二是系统启动以后用户手动将服务启动 常用命令： systemctl start 程序名 #启动服务 systemctl restart 程序名 #重启服务 systemctl stop 程序名 #停止服务 systemctl enable 程序名 #设置服务随机自启 systemctl disable 程序名 #设置服务不随机自启 systemctl status 程序名 #查看服务状态 systemctl is-enabled 程序名 #查看服务是否被设置随机自启 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@localhost nginx]# yum -y install vsftpd[root@localhost nginx]# rpm -ql vsftpd.../usr/sbin/vsftpd#启动vsftpd服务[root@localhost nginx]# systemctl start vsftpd#查看服务运行状态[root@localhost nginx]# systemctl status vsftpd● vsftpd.service - Vsftpd ftp daemon Loaded: loaded (/usr/lib/systemd/system/vsftpd.service; disabled; vendor preset: disabled) Active: active (running) since 二 2021-05-04 17:58:38 CST; 1min 7s ago Process: 14028 ExecStart=/usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf (code=exited, status=0/SUCCESS) Main PID: 14030 (vsftpd)#查看端口信息[root@localhost nginx]# ss -anptul | grep vsftpdtcp LISTEN 0 32 :::21 :::* users:((&quot;vsftpd&quot;,pid=14030,fd=4))#重启服务（用于对配置发生修改且立即生效时使用）[root@localhost nginx]# systemctl restart vsftpd#停止服务[root@localhost nginx]# systemctl stop vsftpd#启动服务并设置服务随机自启[root@localhost nginx]# systemctl start vsftpd[root@localhost nginx]# systemctl enable vsftpdCreated symlink from /etc/systemd/system/multi-user.target.wants/vsftpd.service to /usr/lib/systemd/system/vsftpd.service.#查看服务是否被设置随机自启[root@localhost nginx]# systemctl is-enabled vsftpdenabled #随机自启#设置服务不随机自启[root@localhost nginx]# systemctl disable vsftpdRemoved symlink /etc/systemd/system/multi-user.target.wants/vsftpd.service.[root@localhost nginx]# systemctl is-enabled vsftpddisabled #不随机自启[root@localhost nginx]# systemctl is-enabled sshdenabled 课后作业1.请说出RAID0、RAID1、RAID5、RAID10的特点 RAID0：等量存储，至少由两块磁盘组成，同一个文档分散并行存储，提高数据的读写速度，没有冗余功能 RAID1：完整备份，至少由两块磁盘组成，同一个文档复制成多份分散存储，提高数据的安全性，没有提高读写速度 RAID5：至少由三块磁盘组成，同一份文档分散写入不同磁盘，每个磁盘中都有校验数据，允许坏一块磁盘的数据，校验数据会占用磁盘的三分之一存储空间 RAID10：至少需要4快磁盘组成，先将4快磁盘组成两组RAID1，在将两组RAID1组成一个RAID0，既能够提高数据读写速度，还有冗余功能，可用容量是总容量一半 2.如何查看系统中的进程树，并显示每个进程的PID pstree -p 3.如何查找到系统中lisi用户开启了哪些进程？ pstree -p lisi 4.如何将进程放入后台运行？ &amp; 5.如何将后台运行进程调度到前台运行？ fg 进程编号 6.如何查看后台进程？ jobs 7.kill与killall命令的区别是什么？ kill 结束进程时，按照进程的PID结束 killall 结束进程时候，按照进程名字结束 8.如何将lisi用户提出系统？ killall -9 -u lisi 9.如何查看系统中登录失败的用户？ lastb 10.如何查看系统中登录成功的用户？ last 11.如何查询一个软件包在系统中安装了哪些文件与目录？ rpm -ql 软件包名 12.如何查询ifconfig命令是由哪个软件包产生？ [[root@localhost]# which ifconfig/usr/sbin/ifconfig[[root@localhost]# rpm -qf /usr/sbin/ifconfignet-tools-2.0-0.24.20131004git.el7.x86_64 13.如何查看一个软件包是否被安装在系统中？ rpm -q 软件包名 14.如何卸载一个软件包？ 卸载RPM包：rpm -e 软件包名 卸载源码包：直接删除源码包安装路径 15.说明本地yum仓库每一行的配置含义 [仓库名字] name=仓库描述 baseurl=仓库地址 enabled=仓库状态（1/0，启用/不起用） 16.源码包的安装过程大体步骤 下载源码包 安装源码包依赖关系 解压源码包，进入源码包路径 ./configure 安装参数 make 编译 make install 安装 17.如何查看一个服务占用的端口信息？ ss/netstat -anptul | grep 程序名称 18.如何启动vsftpd服务？ systemctl start vsftpd 19.如何查看vsftpd运行状态？ systemctl status vsftpd 20.如何设置vsftpd服务随机自启？ systemctl enable vsftpd 21.如何停止vsftpd服务？ systemctl stop vsftpd shell概述 shell是一个程序，它连接了用户和Linux内核，它可以解释用户输入的命令传递给内核，让用户可以更加方便的使用Linux系统 shell 本身并不是内核的一部分，它只是站在内核的基础上编写的一个应用程序 shell具备编程的能力，shell也是一种语言，C,C++,java,Python,Go等 语言分为编译型语言，C,C++,Go，需要提前编译，编译语言都有编译器 解释型语言,shell，Python,php，不需要提前编译，一边执行，一边编译，每种解释型语言都有解释器 shell语言支持大部分编程语言都具备的功能：if判断，for循环，变量，数组，函数，加减乘除，逻辑运算 规范shell脚本组成1234[root@test ~]# vim user.sh#!/bin/bash（环境声明）#注释信息可执行代码… 如何写好一个shell脚本 明确任务需求 按需求整理好每一个步骤，先做什么，后做什么 运行脚本，并根据运行结果排除错误 优化脚本并达到最终效果 编写脚本 编写第一个脚本 1234567891011[root@localhost ~]# vim hello.sh#!/bin/bash#hello wordecho hello word#赋予执行权限[root@localhost ~]# chmod u+x hello.sh#执行脚本[root@localhost ~]# /root/hello.sh hello word 编写创建用户脚本 12345678910111213141516[root@localhost ~]# vim user.sh#!/bin/bashuseradd abc passwd abc[root@localhost ~]# chmod u+x user.sh #非交互[root@localhost ~]# vim user.sh#!/bin/bashuseradd yyyyecho 1 | passwd --stdin yyyy[root@localhost ~]# ./user.sh 更改用户 yyyy 的密码 。passwd：所有的身份验证令牌已经成功更新。 编写批量查看脚本 12345678910111213141516171819202122232425262728#查看系统版本信息，查看系统内核信息，查看系统内存信息，查看系统网卡信息，查看当前主机名[root@localhost ~]# vim info.shcat /etc/redhat-releaseuname -rfree -hifconfig ens32hostname#赋予执行权限[root@localhost ~]# chmod u+x info.sh #执行脚本[root@localhost ~]# ./info.sh CentOS Linux release 7.6.1810 (Core) 3.10.0-957.el7.x86_64 total used free shared buff/cache availableMem: 972M 480M 147M 16M 344M 260MSwap: 2.0G 239M 1.8Gens32: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.0.100 netmask 255.255.255.0 broadcast 192.168.0.255 inet6 fe80::8903:cb8:127b:dbc8 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:a0:e8:12 txqueuelen 1000 (Ethernet) RX packets 230110 bytes 325471733 (310.3 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 20635 bytes 1385581 (1.3 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0localhost.localdomain 编写配置本地yum源脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#编写搭建本地yum仓库脚本【版1，丢人版】[root@localhost ~]# vim yum.sh #!/bin/bashmkdir /mnt/centosmount /dev/cdrom /mnt/centosecho '/dev/cdrom /mnt/centos iso9660 defaults 0 0' &gt;&gt; /etc/fstabrm -rf /etc/yum.repos.d/*touch /etc/yum.repos.d/local.repoecho &quot;[local]&quot; &gt; /etc/yum.repos.d/local.repoecho &quot;name=local_centos&quot; &gt;&gt; /etc/yum.repos.d/local.repoecho &quot;baseurl=file:///mnt/centos&quot; &gt;&gt; /etc/yum.repos.d/local.repoecho &quot;enabled=1&quot; &gt;&gt; /etc/yum.repos.d/local.repoecho &quot;gpgcheck=0&quot; &gt;&gt; /etc/yum.repos.d/local.repo#编写搭建本地yum仓库脚本【版2，正常版】[root@localhost ~]# vim yum.sh #!/bin/bashmkdir /mnt/centosmount /dev/cdrom /mnt/centosecho '/dev/cdrom /mnt/centos iso9660 defaults 0 0' &gt;&gt; /etc/fstabmount -arm -rf /etc/yum.repos.d/*echo &quot;[local] name=local_centos baseurl=file:///mnt/centos enabled=1 gpgcheck=0&quot; &gt; /etc/yum.repos.d/local.repo#编写搭建本地yum仓库脚本【升级版】[root@localhost ~]# vim yum.sh #!/bin/bashecho &quot;正在配置本地yum仓库...&quot;mkdir /mnt/centosmount /dev/cdrom /mnt/centos &amp;&gt; /dev/nullecho '/dev/cdrom /mnt/centos iso9660 defaults 0 0' &gt;&gt; /etc/fstabmount -arm -rf /etc/yum.repos.d/*echo &quot;[local] name=local_centos baseurl=file:///mnt/centos enabled=1 gpgcheck=0&quot; &gt; /etc/yum.repos.d/local.repoecho &quot;本地yum仓库配置以完成...&quot;yum clean all &amp;&gt; /dev/nullyum repolist | tail -1echo &quot;仓库软件包数量&quot;#执行脚本[root@localhost ~]# ./yum.sh正在配置本地yum仓库...本地yum仓库配置以完成...repolist: 4,021仓库软件包数量 脚本的执行方式 执行一个脚本的方法有很多种 方法一：赋予脚本执行权限后，可用绝对路径或者当前路径执行 方法二：调用解释器执行脚本文件 123456789101112131415161718192021222324252627282930313233#绝对路径执行脚本[root@localhost ~]# /root/hello.sh #相对路径执行脚本[root@localhost ~]# ./hello.sh #去除执行权限[root@localhost ~]# chmod u-x hello.sh #执行脚本[root@localhost ~]# /root/hello.sh-bash: /root/hello.sh: 权限不够[root@localhost ~]# ./hello.sh-bash: ./hello.sh: 权限不够#调用解释器执行脚本[root@localhost ~]# bash hello.shhello word[root@localhost ~]# cat /etc/shells /bin/sh/bin/bash/usr/bin/sh/usr/bin/bash/bin/tcsh/bin/csh[root@localhost ~]# sh hello.shhello word[root@localhost ~]# tcsh hello.shhello word[root@localhost ~]# csh hello.shhello word 常用特殊符号补充 “ “ #双引号，引用整体 ‘ ’ #单引号，引用整体并取消所有特殊字符含义 $[] #四则运算（+ - * / % 取余数） $() #将命令的输出结果作为参数 反撇 `` 将命令的输出结果作为参数 123456789101112131415161718192021222324252627282930313233343536373839#引用整体，不屏蔽特殊符号的功能[root@localhost ~]# echo &quot;$PATH&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin#引用整体，屏蔽特殊符号的功能[root@localhost ~]# echo '$PATH'$PATH#没有特殊符号单引双引都可以[root@localhost ~]# echo &quot;xxoo&quot;xxoo[root@localhost ~]# echo 'xxoo'xxoo#四则运算[root@localhost ~]# echo $[1+1]2[root@localhost ~]# echo $[1+5]6[root@localhost ~]# echo $[10-5]5[root@localhost ~]# echo $[10*5]50[root@localhost ~]# echo $[10/5]2[root@localhost ~]# echo $[1+3+4+5+7]20[root@localhost ~]# echo $[10/3]3[root@localhost ~]# echo $[10%3]1#$()取命令结果作为参数root@localhost ~]# touch $(date +%F)-abc.txt2021-05-09-abc.txt #``取命令结果作为参数[root@localhost ~]# touch `date +%F`-xxoo.txt2021-05-09-xxoo.txt 变量 以固定的名称存放可能变化的值，提高脚本的灵活度来适应多变的环境 定义变量：变量名=变量值，如：a1=abc（等号两边不要有空格） 取消变量：unset 变量名 定义变量注意事项： 变量名由字母/数字/下划线组成，区分大小写，不能以数字开头，不要使用命令和特殊符号 若指定的变量名已经存在，相当于为此变量重新赋值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647root@localhost ~]# xx=haha[root@localhost ~]# echo $xxhaha[root@localhost ~]# xx=abcd[root@localhost ~]# echo $xxabcd[root@localhost ~]# xx=5[root@localhost ~]# echo $xx5[root@localhost ~]# echo $[xx+5]10#通过变量定义用户名[root@localhost ~]# vim user.sh #!/bin/bashuser=wangxinuseradd $user echo 1 | passwd --stdin $user[root@localhost ~]# ./user.sh 更改用户 wangxin 的密码 。passwd：所有的身份验证令牌已经成功更新。[root@localhost ~]# vim user.sh #!/bin/bashuser=sdduseradd $userecho 1 | passwd --stdin $user[root@localhost ~]# ./user.sh 更改用户 sdd 的密码 。passwd：所有的身份验证令牌已经成功更新。[root@localhost ~]# vim user.sh #!/bin/bashuser=panghuuseradd $userecho &quot;用户$user创建成功&quot;echo 1 | passwd --stdin $user &amp;&gt; /dev/nullecho &quot;用户$user密码设置成功&quot;[root@localhost ~]# ./user.sh 用户panghu创建成功用户panghu密码设置成功 read标准输入取值 read 读取用户在键盘上输入的内容，并把内容存放在变量里，可以降低脚本的使用难度 命令格式：read -p “提示信息” 变量名 1234567891011121314151617181920[root@localhost ~]# vim user.sh #!/bin/bashread -p '请输入用户名：' useruseradd $user echo &quot;用户$user创建成功&quot;read -p '请设置用户密码：' passecho $pass | passwd --stdin $user &amp;&gt; /dev/nullecho &quot;用户$user密码设置成功&quot;[root@localhost ~]# ./user.sh 请输入用户名：wuhan用户wuhan创建成功请设置用户密码：1用户wuhan密码设置成功[root@localhost ~]# ./user.sh 请输入用户名：liangjing用户liangjing创建成功请设置用户密码：xxoo用户liangjing密码设置成功 变量种类 环境变量：变量名一般都大写，用来设置用户/系统环境 位置变量：bash内置，存储执行脚本时提供的命令参数 预定义变量：bash内置，可直接调用的特殊值，不能直接修改 自定义变量：用户自定义 env 命令查看系统所有环境变量 set 命令查看系统所有变量，包括用户自定义变量 环境变量 12345678910111213141516171819202122232425262728[root@localhost etc]# envMAIL=/var/spool/mail/rootPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/binPWD=/rootLANG=zh_CN.UTF-8SELINUX_LEVEL_REQUESTED=HISTCONTROL=ignoredupsSHLVL=1HOME=/rootLOGNAME=rootXDG_DATA_DIRS=/root/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/shareSSH_CONNECTION=192.168.0.1 51791 192.168.0.100 22LESSOPEN=||/usr/bin/lesspipe.sh %sXDG_RUNTIME_DIR=/run/user/0DISPLAY=localhost:10.0_=/usr/bin/envOLDPWD=/root#获取变量值[root@localhost etc]# echo $SHELL/bin/bash[root@localhost ~]# echo $PWD/root#查看系统所有变量[root@localhost ~]# set[root@localhost ~]# set | grep $a 位置变量 $0 #脚本名称 $1 #第一个参数 $2 #第二个参数 $3 #第三个参数 $4 #第四个参数 $n… #第n个参数 预定义变量 $0 #代表脚本本身 $* #显示所有参数内容 $# #显示有多少个参数 $? #显示上一条命令的执行结果（0代表正确，非0代表错误） $$ #显示脚本进程号（PID） 123456789101112131415161718192021[root@localhost ~]# vim test.sh #!/bin/bashecho $0echo $1echo $2echo $3echo $*echo $#echo $$echo $?#赋予执行权限，执行脚本[root@localhost ~]# ./test.sh xx oo dd./test.sh $0xx $1oo $2dd $3xx oo dd $*3 $#15594 $$0 $? 判断文件状态 -e #判断文档（文件/目录）是否存在，存在为真 -d #判断目录是否存在，存在为真 -f #判断文件是否存在，存在为真 -r #可读为真 -w #可写为真 -x #可执行为真 12345678910111213141516171819202122232425262728293031323334#判断文档是否存在[root@localhost ~]# [ -e /etc/ ][root@localhost ~]# echo $?0 #为真#判断目录是否存在[root@localhost ~]# [ -d /opt ][root@localhost ~]# echo $?0[root@localhost ~]# [ -d /etc/passwd ][root@localhost ~]# echo $?1[root@localhost ~]# [ -f /etc/passwd ][root@localhost ~]# echo $?0#判断是否可读（以当前用户身份判断）[root@localhost ~]# [ -r /etc/passwd ][root@localhost ~]# echo $?0#判断是否可写[root@localhost ~]# [ -w /etc/passwd ][root@localhost ~]# echo $?0#判断是否可执行[root@localhost ~]# [ -x /etc/passwd ][root@localhost ~]# echo $?1[root@localhost ~]# ll /etc/passwd-rw-r--r--. 1 root root 3294 5月 9 16:43 /etc/passwd 整数比较 -gt 大于 -ge 大于等于 -eq 等于 -lt 小于 -le 小于等于 -ne 不等于 1234567891011121314151617181920212223242526272829303132333435363738[root@localhost ~]# [ 1 -gt 1 ][root@localhost ~]# echo $?1[root@localhost ~]# [ 1 -eq 1 ][root@localhost ~]# echo $?0[root@localhost ~]# [ 1 -ge 1 ][root@localhost ~]# echo $?0[root@localhost ~]# [ 1 -ge 2 ][root@localhost ~]# echo $?1[root@localhost ~]# [ 1 -lt 2 ][root@localhost ~]# echo $?0[root@localhost ~]# [ 1 -le 2 ][root@localhost ~]# echo $?0[root@localhost ~]# [ 1 -le 10 ][root@localhost ~]# echo $?0[root@localhost ~]# [ 10 -le 10 ][root@localhost ~]# echo $?0[root@localhost ~]# [ 1 -ne 2 ][root@localhost ~]# echo $?0[root@localhost ~]# [ 2 -ne 2 ][root@localhost ~]# echo $?1 字符串对比 == 相等 != 不相等 1234567891011121314151617181920212223[root@localhost ~]# [ root == xxoo ][root@localhost ~]# echo $?1[root@localhost ~]# [ root == $USER ][root@localhost ~]# echo $?0[root@localhost ~]# [ $USER == root ][root@localhost ~]# echo $?0[root@localhost ~]# [ abc == bcd ][root@localhost ~]# echo $?1[root@localhost ~]# [ abc != bcd ][root@localhost ~]# echo $?0[root@localhost ~]# [ $USER != root ][root@localhost ~]# echo $?1","link":"/2022/07/12/Centos%20Linux%20%E8%BF%90%E7%BB%B4%E7%BA%A7%E5%9F%BA%E7%A1%80%E6%95%99%E5%AD%A6/"},{"title":"Golang Mutex互斥锁","text":"互斥锁其中Mutex为互斥锁，Lock()加锁，Unlock()解锁，使用Lock()加锁后，便不能再次对其进行加锁，直到利用Unlock()解锁对其解锁后，才能再次加锁．适用于读写不确定场景，即读写次数没有明显的区别，并且只允许只有一个读或者写的场景，所以该锁叶叫做全局锁． 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;errors&quot;)type MyMap struct { mp map[string]int mutex *sync.Mutex}func (this *MyMap) Get(key string) (int, error) { this.mutex.Lock() i, ok := this.mp[key] this.mutex.Unlock() if !ok { return i, errors.New(&quot;不存在&quot;) } return i, nil}func (this *MyMap) Set(key string, v int) { this.mutex.Lock() defer this.mutex.Unlock() this.mp[key] = v}func (this *MyMap) Display() { this.mutex.Lock() defer this.mutex.Unlock() for k, v := range this.mp { fmt.Println(k, &quot;=&quot;, v) }}func SetValue(m *MyMap) { var a rune a = 'a' for i := 0; i &lt; 10; i++ { m.Set(string(a+rune(i)), i) }}func main() { m := &amp;MyMap{mp: make(map[string]int), mutex: new(sync.Mutex)} go SetValue(m) /*启动一个线程向 map 写入值*/ go m.Display() /*启动一个线程读取 map 的值*/ var str string /*这里主要是等待线程结束*/ fmt.Scan(&amp;str)} 读写锁读写锁即是针对于读写操作的互斥锁。它与普通的互斥锁最大的不同就是，它可以分别针对读操作和写操作进行锁定和解锁操作。读写锁遵循的访问控制规则与互斥锁有所不同。 在读写锁管辖的范围内，它允许任意个读操作的同时进行。但是，在同一时刻，它只允许有一个写操作在进行。并且，在某一个写操作被进行的过程中，读操作的进行也是不被允许的。 也就是说，读写锁控制下的多个写操作之间都是互斥的，并且写操作与读操作之间也都是互斥的。但是，多个读操作之间却不存在互斥关系。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;errors&quot; &quot;time&quot;)type MyMap struct { mp map[string]int mutex *sync.RWMutex}func (this *MyMap) Get(key string) (int, error) { this.mutex.RLock() i, ok := this.mp[key] this.mutex.RUnlock() if !ok { return i, errors.New(&quot;不存在&quot;) } return i, nil}func (this *MyMap) Set(key string, v int) { this.mutex.RLock() defer this.mutex.RUnlock() this.mp[key] = v}func (this *MyMap) Display() { this.mutex.RLock() defer this.mutex.RUnlock() for k, v := range this.mp { fmt.Println(k, &quot;=&quot;, v) }}func SetValue(m *MyMap) { var a rune a = 'a' for i := 0; i &lt; 10; i++ { m.Set(string(a+rune(i)), i) }}func main() { m := &amp;MyMap{mp: make(map[string]int), mutex: new(sync.RWMutex)} go SetValue(m) /*启动一个线程向 map 写入值*/ go m.Display() /*启动一个线程读取 map 的值*/ var str string /*这里主要是等待线程结束*/ fmt.Scan(&amp;str)} 读写锁小例子 12345678910111213141516171819202122232425262728293031323334package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot;)func main() { var lock sync.RWMutex go read(&amp;lock) go read(&amp;lock) go write(&amp;lock) time.Sleep(25000000) fmt.Println(&quot;end&quot;)}func read(lock *sync.RWMutex) { lock.RLock() fmt.Println(&quot;reading&quot;) time.Sleep(5000) fmt.Println(&quot;read end&quot;) lock.RUnlock()}func write(lock *sync.RWMutex) { time.Sleep(1000) //保证先让读拿到锁, 如果没有就会随机，不过应该先过read一般会先read. lock.Lock() fmt.Println(&quot;writing&quot;) time.Sleep(5000) fmt.Println(&quot;write end&quot;) lock.Unlock()} //结果 reading reading read end read end writing write end end map并发读写报错相似的报错：fatal error: concurrent map writes 原因1：加解锁异常代码写的不严谨，加锁后未解锁，未形成单次闭环解决：形成闭环，有加得必须有解 原因2：加解锁代码看起来貌似正常实际上是加锁内部的代码加了个寂寞，map操作不在锁的范围内，和外部的代码在使用的(共同读写的)还是相同的map（同地址），锁未起实际作用 解决：对map数据进行转移不使用旧map，在加锁与解锁之间生成新的map，将数据转移至新map(或其它数据结构)再返回新map 或 调整代码位置即可 原因3：锁未加完全 只给写map的goroutine实施了加解锁，而读goroutine方面没有；或只给读map的goroutine实施了加解锁，而写goroutine方面没有；或未加锁 原因4：对该map加的不是同一把锁 举例：对于某map，读map有2个goroutine，写map有2个goroutine，这四个依次编号为1,2,3,4，前3个使用mu1，最后一个使用mu2，就会造成该报错。 温馨提示：同一把锁可以作用多个map，但同一个map不能有两把锁操作。","link":"/2022/04/24/Golang%20Mutex%E4%BA%92%E6%96%A5%E9%94%81/"},{"title":"Golang判断字符串是否是纯数字","text":"提供了两个方法，一个逐字符判断，一个使用正则 1234567891011121314151617func IsNumeric(str string) bool { for _, v := range str { if !unicode.IsNumber(v) { // IsNumber判断是否为一个数字字符 (类别 N) // if !unicode.IsDigit(v) { // IsDigit 判断 r 是否为一个十进制的数字字符 return false } } return true}# https://www.coder.work/article/193576func IsNumericP(str string) bool { // 使用正则判断是不是数字字符串 return regexp.MustCompile(`^[0-9]+$`).MatchString(str)} 示例 123456func main() { str := &quot;12345&quot; str1 := &quot;123rr&quot; // fmt.Println(IsNumeric(str), IsNumeric(str1)) // true, false fmt.Println(IsNumericP(str), IsNumericP(str)) // true, false}","link":"/2022/06/11/Golang%E5%88%A4%E6%96%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%98%AF%E5%90%A6%E6%98%AF%E7%BA%AF%E6%95%B0%E5%AD%97/"},{"title":"Golang标准库之strings","text":"package strings 1import &quot;strings&quot; strings包实现了用于操作字符的简单函数。 func EqualFold 1func EqualFold(s, t string) bool 判断两个utf-8编码字符串（将unicode大写、小写、标题三种格式字符视为相同）是否相同。 Example func HasPrefix1func HasPrefix(s, prefix string) bool 判断s是否有前缀字符串prefix。 func HasSuffix1func HasSuffix(s, suffix string) bool 判断s是否有后缀字符串suffix。 func Contains1func Contains(s, substr string) bool 判断字符串s是否包含子串substr。 Example func ContainsRune1func ContainsRune(s string, r rune) bool 判断字符串s是否包含utf-8码值r。 func ContainsAny1func ContainsAny(s, chars string) bool 判断字符串s是否包含字符串chars中的任一字符。 Example func Count1func Count(s, sep string) int 返回字符串s中有几个不重复的sep子串。 Example func Index1func Index(s, sep string) int 子串sep在字符串s中第一次出现的位置，不存在则返回-1。 Example func IndexByte1func IndexByte(s string, c byte) int 字符c在s中第一次出现的位置，不存在则返回-1。 func IndexRune1func IndexRune(s string, r rune) int unicode码值r在s中第一次出现的位置，不存在则返回-1。 Example func IndexAny1func IndexAny(s, chars string) int 字符串chars中的任一utf-8码值在s中第一次出现的位置，如果不存在或者chars为空字符串则返回-1。 Example func IndexFunc1func IndexFunc(s string, f func(rune) bool) int s中第一个满足函数f的位置i（该处的utf-8码值r满足f(r)==true），不存在则返回-1。 Example func LastIndex1func LastIndex(s, sep string) int 子串sep在字符串s中最后一次出现的位置，不存在则返回-1。 Example func LastIndexAny1func LastIndexAny(s, chars string) int 字符串chars中的任一utf-8码值在s中最后一次出现的位置，如不存在或者chars为空字符串则返回-1。 func LastIndexFunc1func LastIndexFunc(s string, f func(rune) bool) int s中最后一个满足函数f的unicode码值的位置i，不存在则返回-1。 func Title1func Title(s string) string 返回s中每个单词的首字母都改为标题格式的字符串拷贝。 BUG: Title用于划分单词的规则不能很好的处理Unicode标点符号。 Example func ToLower1func ToLower(s string) string 返回将所有字母都转为对应的小写版本的拷贝。 Example func ToLowerSpecial1func ToLowerSpecial(_case unicode.SpecialCase, s string) string 使用_case规定的字符映射，返回将所有字母都转为对应的小写版本的拷贝。 func ToUpper1func ToUpper(s string) string 返回将所有字母都转为对应的大写版本的拷贝。 Example func ToUpperSpecial1func ToUpperSpecial(_case unicode.SpecialCase, s string) string 使用_case规定的字符映射，返回将所有字母都转为对应的大写版本的拷贝。 func ToTitle1func ToTitle(s string) string 返回将所有字母都转为对应的标题版本的拷贝。 Example func ToTitleSpecial1func ToTitleSpecial(_case unicode.SpecialCase, s string) string 使用_case规定的字符映射，返回将所有字母都转为对应的标题版本的拷贝。 func Repeat1func Repeat(s string, count int) string 返回count个s串联的字符串。 Example func Replace1func Replace(s, old, new string, n int) string 返回将s中前n个不重叠old子串都替换为new的新字符串，如果n&lt;0会替换所有old子串。 Example func Map1func Map(mapping func(rune) rune, s string) string 将s的每一个unicode码值r都替换为mapping(r)，返回这些新码值组成的字符串拷贝。如果mapping返回一个负值，将会丢弃该码值而不会被替换。（返回值中对应位置将没有码值） Example func Trim1func Trim(s string, cutset string) string 返回将s前后端所有cutset包含的utf-8码值都去掉的字符串。 Example func TrimSpace1func TrimSpace(s string) string 返回将s前后端所有空白（unicode.IsSpace指定）都去掉的字符串。 Example func TrimFunc1func TrimFunc(s string, f func(rune) bool) string 返回将s前后端所有满足f的unicode码值都去掉的字符串。 func TrimLeft1func TrimLeft(s string, cutset string) string 返回将s前端所有cutset包含的utf-8码值都去掉的字符串。 func TrimLeftFunc1func TrimLeftFunc(s string, f func(rune) bool) string 返回将s前端所有满足f的unicode码值都去掉的字符串。 func TrimPrefix1func TrimPrefix(s, prefix string) string 返回去除s可能的前缀prefix的字符串。 Example func TrimRight1func TrimRight(s string, cutset string) string 返回将s后端所有cutset包含的utf-8码值都去掉的字符串。 func TrimRightFunc1func TrimRightFunc(s string, f func(rune) bool) string 返回将s后端所有满足f的unicode码值都去掉的字符串。 func TrimSuffix1func TrimSuffix(s, suffix string) string 返回去除s可能的后缀suffix的字符串。 Example func Fields1func Fields(s string) []string 返回将字符串按照空白（unicode.IsSpace确定，可以是一到多个连续的空白字符）分割的多个字符串。如果字符串全部是空白或者是空字符串的话，会返回空切片。 Example func FieldsFunc1func FieldsFunc(s string, f func(rune) bool) []string 类似Fields，但使用函数f来确定分割符（满足f的unicode码值）。如果字符串全部是分隔符或者是空字符串的话，会返回空切片。 Example func Split1func Split(s, sep string) []string 用去掉s中出现的sep的方式进行分割，会分割到结尾，并返回生成的所有片段组成的切片（每一个sep都会进行一次切割，即使两个sep相邻，也会进行两次切割）。如果sep为空字符，Split会将s切分成每一个unicode码值一个字符串。 Example func SplitN1func SplitN(s, sep string, n int) []string 用去掉s中出现的sep的方式进行分割，会分割到结尾，并返回生成的所有片段组成的切片（每一个sep都会进行一次切割，即使两个sep相邻，也会进行两次切割）。如果sep为空字符，Split会将s切分成每一个unicode码值一个字符串。参数n决定返回的切片的数目： 123n &gt; 0 : 返回的切片最多n个子字符串；最后一个子字符串包含未进行切割的部分。n == 0: 返回niln &lt; 0 : 返回所有的子字符串组成的切片 Example func SplitAfter1func SplitAfter(s, sep string) []string 用从s中出现的sep后面切断的方式进行分割，会分割到结尾，并返回生成的所有片段组成的切片（每一个sep都会进行一次切割，即使两个sep相邻，也会进行两次切割）。如果sep为空字符，Split会将s切分成每一个unicode码值一个字符串。 Example func SplitAfterN1func SplitAfterN(s, sep string, n int) []string 用从s中出现的sep后面切断的方式进行分割，会分割到结尾，并返回生成的所有片段组成的切片（每一个sep都会进行一次切割，即使两个sep相邻，也会进行两次切割）。如果sep为空字符，Split会将s切分成每一个unicode码值一个字符串。参数n决定返回的切片的数目： 123n &gt; 0 : 返回的切片最多n个子字符串；最后一个子字符串包含未进行切割的部分。n == 0: 返回niln &lt; 0 : 返回所有的子字符串组成的切 Example func Join1func Join(a []string, sep string) string 将一系列字符串连接为一个字符串，之间用sep来分隔。 Example type Reader123type Reader struct { // 内含隐藏或非导出字段} Reader类型通过从一个字符串读取数据，实现了io.Reader、io.Seeker、io.ReaderAt、io.WriterTo、io.ByteScanner、io.RuneScanner接口。 func NewReader1func NewReader(s string) *Reader NewReader创建一个从s读取数据的Reader。本函数类似bytes.NewBufferString，但是更有效率，且为只读的。 func (*Reader) Len1func (r *Reader) Len() int Len返回r包含的字符串还没有被读取的部分。 func (*Reader) Read1func (r *Reader) Read(b []byte) (n int, err error) func (*Reader) ReadByte1func (r *Reader) ReadByte() (b byte, err error) func (*Reader) UnreadByte1func (r *Reader) UnreadByte() error func (*Reader) ReadRune1func (r *Reader) ReadRune() (ch rune, size int, err error) func (*Reader) UnreadRune1func (r *Reader) UnreadRune() error func (*Reader) Seek1func (r *Reader) Seek(offset int64, whence int) (int64, error) Seek实现了io.Seeker接口。 func (*Reader) ReadAt1func (r *Reader) ReadAt(b []byte, off int64) (n int, err error) func (*Reader) WriteTo1func (r *Reader) WriteTo(w io.Writer) (n int64, err error) WriteTo实现了io.WriterTo接口。 type Replacer123type Replacer struct { // 内含隐藏或非导出字段} Replacer类型进行一系列字符串的替换。 func NewReplacer1func NewReplacer(oldnew ...string) *Replacer 使用提供的多组old、new字符串对创建并返回一个*Replacer。替换是依次进行的，匹配时不会重叠。 Example func (*Replacer) Replace1func (r *Replacer) Replace(s string) string Replace返回s的所有替换进行完后的拷贝。 func (*Replacer) WriteString1func (r *Replacer) WriteString(w io.Writer, s string) (n int, err error) WriteString向w中写入s的所有替换进行完后的拷贝。 来源： Go语言标准库文档中文版 | Go语言中文网 | Golang中文社区 | Golang中国 (studygolang.com)","link":"/2021/11/19/Golang%E6%A0%87%E5%87%86%E5%BA%93%E4%B9%8Bstrings/"},{"title":"Go各时间字符串的解析","text":"Go 中时间格式化的模板123456789101112131415161718const ( ANSIC = &quot;Mon Jan _2 15:04:05 2006&quot; UnixDate = &quot;Mon Jan _2 15:04:05 MST 2006&quot; RubyDate = &quot;Mon Jan 02 15:04:05 -0700 2006&quot; RFC822 = &quot;02 Jan 06 15:04 MST&quot; RFC822Z = &quot;02 Jan 06 15:04 -0700&quot; // RFC822 with numeric zone RFC850 = &quot;Monday, 02-Jan-06 15:04:05 MST&quot; RFC1123 = &quot;Mon, 02 Jan 2006 15:04:05 MST&quot; RFC1123Z = &quot;Mon, 02 Jan 2006 15:04:05 -0700&quot; // RFC1123 with numeric zone RFC3339 = &quot;2006-01-02T15:04:05Z07:00&quot; RFC3339Nano = &quot;2006-01-02T15:04:05.999999999Z07:00&quot; Kitchen = &quot;3:04PM&quot; // Handy time stamps. Stamp = &quot;Jan _2 15:04:05&quot; StampMilli = &quot;Jan _2 15:04:05.000&quot; StampMicro = &quot;Jan _2 15:04:05.000000&quot; StampNano = &quot;Jan _2 15:04:05.000000000&quot;) 上面这些是官方定义的layout常量，我们自己也可以定义，如： 12345&quot;2006-01-02 15:04:05&quot; &quot;2006-01-02&quot;&quot;2006-01-02 15:04&quot;&quot;2006-01-02T15:04&quot; //js和html中多用这种形式&quot;2006-01-02 15:03:04 -0700 MST&quot; Format 格式化为字符串format 的使用对象是一个 time.Time 对象，可以使用官方或者自己定义的布局进行格式化的输出，如： 12now := time.Now()now.Format(&quot;2006-01-02 15:04:05&quot;) //输出 2020-07-21 10:12:13 Parse 字符串解析为时间戳或int64Parse 方法需要两个参数，第一个是布局，第二个是字符串 12345678910111213141516171819202122//Parse解析格式化的字符串并返回它表示的时间值。//布局通过显示参考时间（定义为2006年1月2日星期一1:04:05 -0700//如果它是值，则将被解释；它作为一个例子//输入格式。然后将对输入字符串。预定义的布局ANSIC，UnixDate，RFC3339等描述了参考时间的标准和便捷表示形式。有关格式和参考时间的定义的更多信息，请参见ANSIC文档以及此程序包定义的其他常量。//解析时间偏移为-0700的时间时，如果偏移量对应于当前位置（本地）使用的时区，则Parse在返回的时间中使用该位置和时区。否则，它将时间记录为处于伪造位置，时间固定在给定的区域偏移量。////另外，Time.Format的可执行示例详细说明了布局字符串的工作原理，是一个很好的参考。////值中省略的元素假定为零，或者//零不可能为1，因此解析“ 3:04 pm”将返回时间//对应于1月1日，0，15:04:00 UTC（请注意，因为年份是//0，此时间早于零时间）。//年份必须在0000..9999的范围内。将检查星期几的语法，否则将忽略该语法。////解析带有MST等区域缩写的时间时，如果该区域缩写在当前位置具有已定义的偏移量，则使用该偏移量。//区域缩写“ UTC”被识别为UTC，与位置无关。//如果未知区域缩写，则Parse将时间记录为位于指定位置的伪造位置，并具有零偏移量。//此选择意味着可以使用相同的布局无损地解析和重新格式化这样的时间，但是表示中使用的确切瞬间将因实际区域偏移而有所不同。为避免此类问题，请首选使用数字区域偏移量的时间布局或使用ParseInLocation。func Parse(layout, value string) (Time, error) { return parse(layout, value, UTC, Local)} 使用例子： 12eg, err := time.Parse(&quot;2006-01-02 15:04:05 -0700 MST&quot;, &quot;2019-08-29 16:48:21 +0800 CST&quot;)//输出结果为time.Time格式 使用 format格式化后为 2019-08-29 16:48:21 ParseInLocation12345678//ParseInLocation类似于Parse，但在两个重要方面有所不同。//首先，在没有时区信息的情况下，Parse将时间解释为UTC；//ParseInLocation将时间解释为给定位置。//第二，当给定区域偏移量或缩写时，Parse尝试将其与本地位置进行匹配； ParseInLocation使用给定的位置func ParseInLocation(layout, value string, loc *Location) (Time, error) { return parse(layout, value, loc, loc)} 参数： 1. 布局 2. 字符串 3. 时区 获取本地时区可以使用 time.Local 使用例子： 1onlineAt, err := time.ParseInLocation(&quot;2006-01-02T15:04&quot;, &quot;2020-01-02T15:04&quot;), time.Local) 解析为int64对于 time.Time 对象，可以使用.Unix() 方法转为 int64，如： 12eg.Unix() //默认使用 UTC时区 eg.Local().Unix() //返回本地时区的时间戳 int64 参考文章： golang的时区和神奇的time.Parse","link":"/2022/09/04/Go%E5%90%84%E6%97%B6%E9%97%B4%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E8%A7%A3%E6%9E%90/"},{"title":"Go算法","text":"排序冒泡12345678910111213141516171819package mainimport &quot;fmt&quot;func BubbleSort(list []int) []int { for i := 0; i &lt; len(list); i++ { for j := i + 1; j &lt; len(list); j++ { if list[j] &gt; list[i] { list[i], list[j] = list[j], list[i] } } } return list}func main() { list := []int{2, 4, 2, 6, 1, 3, 9} fmt.Println(BubbleSort(list))}","link":"/2022/06/11/Go%E7%AE%97%E6%B3%95/"},{"title":"Go语言学习相关文档","text":"官方文档https://golang.google.cn/doc/ TopGoerhttps://topgoer.com/ GoLang 标准库https://studygolang.com/pkgdoc [中文]https://pkg.go.dev/ [官方] Go编程时光https://golang.iswbm.com/index.html 跟煎鱼学Gohttps://eddycjy.gitbook.io/golang/ C语言中文网http://c.biancheng.net/golang/ 其他：Go 普通指针类型、unsafe.Pointer、uintptr之间的关系https://www.cnblogs.com/-wenli/p/12682477.html","link":"/2021/11/28/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/"},{"title":"Js获取图片宽高","text":"1234567&lt;img id=&quot;do&quot; src=&quot;./Web/img/20211207_20145862_avatar.png.jpg&quot; alt=&quot;&quot; /&gt;&lt;script&gt; setTimeout(() =&gt; { let i = document.getElementById(&quot;do&quot;); console.log(i.clientWidth); }, 1000);&lt;/script&gt;","link":"/2022/05/15/Js%E8%8E%B7%E5%8F%96%E5%9B%BE%E7%89%87%E5%AE%BD%E9%AB%98/"},{"title":"JavaScript使用 Fetch","text":"Fetch API 提供了一个 JavaScript接口，用于访问和操纵HTTP管道的部分，例如请求和响应。它还提供了一个全局 fetch()方法，该方法提供了一种简单，合理的方式来跨网络异步获取资源。 这种功能以前是使用 XMLHttpRequest实现的。Fetch提供了一个更好的替代方法，可以很容易地被其他技术使用，例如 Service Workers。Fetch还提供了单个逻辑位置来定义其他HTTP相关概念，例如CORS和HTTP的扩展。 请注意，fetch规范与jQuery.ajax()主要有两种方式的不同，牢记： 当接收到一个代表错误的 HTTP 状态码时，从 fetch()返回的 Promise 不会被标记为 reject， 即使该 HTTP 响应的状态码是 404 或 500。相反，它会将 Promise 状态标记为 resolve （但是会将 resolve 的返回值的 ok 属性设置为 false ），仅当网络故障时或请求被阻止时，才会标记为 reject。 默认情况下，fetch 不会从服务端发送或接收任何 cookies, 如果站点依赖于用户 session，则会导致未经认证的请求（要发送 cookies，必须设置 credentials 选项）。自从2017年8月25日后，默认的credentials政策变更为same-originFirefox也在61.0b13中改变默认值 进行 fetch 请求 参考一个基本的 fetch请求设置起来很简单。看看下面的代码： 1234567fetch('http://example.com/movies.json') .then(function(response) { return response.json(); }) .then(function(myJson) { console.log(myJson); }); 这里我们通过网络获取一个JSON文件并将其打印到控制台。最简单的用法是只提供一个参数用来指明想fetch()到的资源路径，然后返回一个包含响应结果的promise(一个 Response 对象)。 当然它只是一个 HTTP 响应，而不是真的JSON。为了获取JSON的内容，我们需要使用 json()方法（在Bodymixin 中定义，被 Request 和 Response 对象实现）。 注意：Body mixin 还有其他相似的方法，用于获取其他类型的内容。参考 Body。 最好使用符合内容安全策略 (CSP)的链接而不是使用直接指向资源地址的方式来进行Fetch的请求。 支持的请求参数参考fetch() 接受第二个可选参数，一个可以控制不同配置的 init 对象： 参考 fetch()，查看所有可选的配置和更多描述。 1234567891011121314151617181920212223// Example POST method implementation:postData('http://example.com/answer', {answer: 42}) .then(data =&gt; console.log(data)) // JSON from `response.json()` call .catch(error =&gt; console.error(error))function postData(url, data) { // Default options are marked with * return fetch(url, { body: JSON.stringify(data), // must match 'Content-Type' header cache: 'no-cache', // *default, no-cache, reload, force-cache, only-if-cached credentials: 'same-origin', // include, same-origin, *omit headers: { 'user-agent': 'Mozilla/4.0 MDN Example', 'content-type': 'application/json' }, method: 'POST', // *GET, POST, PUT, DELETE, etc. mode: 'cors', // no-cors, cors, *same-origin redirect: 'follow', // manual, *follow, error referrer: 'no-referrer', // *client, no-referrer }) .then(response =&gt; response.json()) // parses response to JSON} 发送带凭据的请求参考为了让浏览器发送包含凭据的请求（即使是跨域源），要将credentials: 'include'添加到传递给 fetch()方法的init对象。 123fetch('https://example.com', { credentials: 'include' }) 如果你只想在请求URL与调用脚本位于同一起源处时发送凭据，请添加credentials: 'same-origin'。 12345// The calling script is on the origin 'https://example.com'fetch('https://example.com', { credentials: 'same-origin' }) 要改为确保浏览器不在请求中包含凭据，请使用credentials: 'omit'。 123fetch('https://example.com', { credentials: 'omit' }) 上传 JSON 数据参考使用 fetch() POST JSON数据 123456789101112var url = 'https://example.com/profile';var data = {username: 'example'};fetch(url, { method: 'POST', // or 'PUT' body: JSON.stringify(data), // data can be `string` or {object}! headers: new Headers({ 'Content-Type': 'application/json' })}).then(res =&gt; res.json()).catch(error =&gt; console.error('Error:', error)).then(response =&gt; console.log('Success:', response)); 上传文件参考可以通过HTML&lt;input type=&quot;file&quot; /&gt;元素，FormData() 和fetch()上传文件。 12345678910111213var formData = new FormData();var fileField = document.querySelector(&quot;input[type='file']&quot;);formData.append('username', 'abc123');formData.append('avatar', fileField.files[0]);fetch('https://example.com/profile/avatar', { method: 'PUT', body: formData}).then(response =&gt; response.json()).catch(error =&gt; console.error('Error:', error)).then(response =&gt; console.log('Success:', response)); 上传多个文件参考可以通过HTML&lt;input type=&quot;file&quot; mutiple/&gt;元素，FormData() 和fetch()上传文件。 12345678910111213var formData = new FormData();var photos = document.querySelector(&quot;input[type='file'][multiple]&quot;);formData.append('title', 'My Vegas Vacation');formData.append('photos', photos.files);fetch('https://example.com/posts', { method: 'POST', body: formData}).then(response =&gt; response.json()).then(response =&gt; console.log('Success:', JSON.stringify(response))).catch(error =&gt; console.error('Error:', error)); 检测请求是否成功参考如果遇到网络故障，fetch() promise 将会 reject，带上一个 TypeError 对象。虽然这个情况经常是遇到了权限问题或类似问题——比如 404 不是一个网络故障。想要精确的判断 fetch() 是否成功，需要包含 promise resolved 的情况，此时再判断 Response.ok 是不是为 true。类似以下代码： 1234567891011fetch('flowers.jpg').then(function(response) { if(response.ok) { return response.blob(); } throw new Error('Network response was not ok.');}).then(function(myBlob) { var objectURL = URL.createObjectURL(myBlob); myImage.src = objectURL; }).catch(function(error) { console.log('There has been a problem with your fetch operation: ', error.message);}); 自定义请求对象参考除了传给 fetch() 一个资源的地址，你还可以通过使用 Request() 构造函数来创建一个 request 对象，然后再作为参数传给 fetch()： 123456789101112131415var myHeaders = new Headers();var myInit = { method: 'GET', headers: myHeaders, mode: 'cors', cache: 'default' };var myRequest = new Request('flowers.jpg', myInit);fetch(myRequest).then(function(response) { return response.blob();}).then(function(myBlob) { var objectURL = URL.createObjectURL(myBlob); myImage.src = objectURL;}); Request() 和 fetch() 接受同样的参数。你甚至可以传入一个已存在的 request 对象来创造一个拷贝： 1var anotherRequest = new Request(myRequest,myInit); 这个很有用，因为 request 和 response bodies 只能被使用一次（译者注：这里的意思是因为设计成了 stream 的方式，所以它们只能被读取一次）。创建一个拷贝就可以再次使用 request/response 了，当然也可以使用不同的 init 参数。 注意：clone() 方法也可以用于创建一个拷贝。它在语义上有一点不同于其他拷贝的方法。其他方法（比如拷贝一个 response）中，如果 request 的 body 已经被读取过，那么将执行失败，然而 clone() 则不会失败。 Headers参考使用 Headers 的接口，你可以通过 Headers() 构造函数来创建一个你自己的 headers 对象。一个 headers 对象是一个简单的多名值对： 12345var content = &quot;Hello World&quot;;var myHeaders = new Headers();myHeaders.append(&quot;Content-Type&quot;, &quot;text/plain&quot;);myHeaders.append(&quot;Content-Length&quot;, content.length.toString());myHeaders.append(&quot;X-Custom-Header&quot;, &quot;ProcessThisImmediately&quot;); 也可以传一个多维数组或者对象字面量： 12345myHeaders = new Headers({ &quot;Content-Type&quot;: &quot;text/plain&quot;, &quot;Content-Length&quot;: content.length.toString(), &quot;X-Custom-Header&quot;: &quot;ProcessThisImmediately&quot;,}); 它的内容可以被获取： 12345678910console.log(myHeaders.has(&quot;Content-Type&quot;)); // trueconsole.log(myHeaders.has(&quot;Set-Cookie&quot;)); // falsemyHeaders.set(&quot;Content-Type&quot;, &quot;text/html&quot;);myHeaders.append(&quot;X-Custom-Header&quot;, &quot;AnotherValue&quot;);console.log(myHeaders.get(&quot;Content-Length&quot;)); // 11console.log(myHeaders.getAll(&quot;X-Custom-Header&quot;)); // [&quot;ProcessThisImmediately&quot;, &quot;AnotherValue&quot;]myHeaders.delete(&quot;X-Custom-Header&quot;);console.log(myHeaders.getAll(&quot;X-Custom-Header&quot;)); // [ ] 虽然一些操作只能在 ServiceWorkers 中使用，但是它提供了更方便的操作 Headers 的 API。 如果使用了一个不合法的HTTP Header属性名，那么Headers的方法通常都抛出 TypeError 异常。如果不小心写入了一个不可写的属性，也会抛出一个 TypeError 异常。除此以外的情况，失败了并不抛出异常。例如： 123456var myResponse = Response.error();try { myResponse.headers.set(&quot;Origin&quot;, &quot;http://mybank.com&quot;);} catch(e) { console.log(&quot;Cannot pretend to be a bank!&quot;);} 最佳实践是在使用之前检查 content type 是否正确，比如： 123456789fetch(myRequest).then(function(response) { if(response.headers.get(&quot;content-type&quot;) === &quot;application/json&quot;) { return response.json().then(function(json) { // process your JSON further }); } else { console.log(&quot;Oops, we haven't got JSON!&quot;); }}); Guard参考由于 Headers 可以在 request 请求中被发送或者在 response 请求中被接收，并且规定了哪些参数是可写的，Headers 对象有一个特殊的 guard 属性。这个属性没有暴露给 Web，但是它影响到哪些内容可以在 Headers 对象中被操作。 可能的值如下： none：默认的 request：从 request 中获得的 headers（Request.headers）只读 request-no-cors：从不同域（Request.mode no-cors）的 request 中获得的 headers 只读 response：从 response 中获得的 headers（Response.headers）只读 immutable：在 ServiceWorkers 中最常用的，所有的 headers 都只读。 注意：你不可以添加或者修改一个 guard 属性是 request 的 Request Headers 的 Content-Length 属性。同样地，插入 Set-Cookie 属性到一个 response headers 是不允许的，因此 ServiceWorkers 是不能给合成的 Response 的 headers 添加一些 cookies。 Response 对象参考如上述, Response 实例是在 fetch() 处理完promises之后返回的。 你会用到的最常见的response属性有: Response.status — 整数(默认值为200) 为response的状态码. Response.statusText — 字符串(默认值为”OK”),该值与HTTP状态码消息对应. Response.ok — 如上所示, 该属性是来检查response的状态是否在200-299(包括200,299)这个范围内.该属性返回一个Boolean值. 它的实例也可用通过 JavaScript 来创建, 但只有在ServiceWorkers中才真正有用,当使用respondWith()方法并提供了一个自定义的response来接受request时: 1234567var myBody = new Blob();addEventListener('fetch', function(event) { event.respondWith(new Response(myBody, { headers: { &quot;Content-Type&quot; : &quot;text/plain&quot; } });}); Response() 构造方法接受两个可选参数—response的数据体和一个初始化对象(与Request()所接受的init参数类似.) 注意: 静态方法error()只是返回了一个错误的response. 与此类似地, redirect() 只是返回了一个可以重定向至某URL的response. 这些也只与Service Workers才有关。 Body参考不管是请求还是响应都能够包含body对象. body也可以是以下任意类型的实例. ArrayBuffer ArrayBufferView (Uint8Array等) Blob/File string URLSearchParams FormData “FormData 接口提供了一种表示表单数据的键值对的构造方式，经过它的数据可以使用 XMLHttpRequest.send() 方法送出，本接口和此方法都相当简单直接。如果送出时的编码类型被设为 “multipart/form-data”，它会使用和表单一样的格式。”) Body 类定义了以下方法 (这些方法都被 Request 和Response所实现)以获取body内容. 这些方法都会返回一个被解析后的Promise对象和数据. arrayBuffer() blob() json() text() “Body混入的 text() 方法提供了一个可供读取的”返回流”, ——它返回一个包含USVString对象 (text)的Promise对象，返回结果的编码为UTF-8。”) formData() 比起XHR来，这些方法让非文本化的数据使用起来更加简单。 请求体可以由传入body参数来进行设置: 12345var form = new FormData(document.getElementById('login-form'));fetch(&quot;/login&quot;, { method: &quot;POST&quot;, body: form}) request和response（包括fetch() 方法）都会试着自动设置Content-Type。如果没有设置Content-Type值，发送的请求也会自动设值。 特性检测参考Fetch API 的支持情况，可以通过检测Headers, Request, Response 或 fetch()是否在Window 或 Worker 域中。例如： 12345if(self.fetch) { // run my fetch request here} else { // do something with XMLHttpRequest?} 链接：https://www.jianshu.com/p/e18ced22cfaa","link":"/2022/05/22/JavaScript%E4%BD%BF%E7%94%A8%20Fetch/"},{"title":"Go语言学习笔记","text":"内置Go 语言拥有一些不需要进行导入操作就可以使用的内置函数。它们有时可以针对不同的类型进行操作，例如：len、cap 和 append，或必须用于系统级的操作，例如：panic。因此，它们需要直接获得编译器的支持。 12345678910111213append -- 用来追加元素到数组、slice中,返回修改后的数组、sliceclose -- 主要用来关闭channeldelete -- 从map中删除key对应的valuepanic -- 停止常规的goroutine （panic和recover：用来做错误处理）recover -- 允许程序定义goroutine的panic动作real -- 返回complex的实部 （complex、real imag：用于创建和操作复数）imag -- 返回complex的虚部make -- 用来分配内存，返回Type本身(只能应用于slice, map, channel)new -- 用来分配内存，主要用来分配值类型，比如int、struct。返回指向Type的指针cap -- capacity是容量的意思，用于返回某个类型的最大容量（只能用于切片和 map）copy -- 用于复制和连接slice，返回复制的数目len -- 来求长度，比如string、array、slice、map、channel ，返回长度print、println -- 底层打印函数，在部署环境中建议使用 fmt 包 go mod go mod help 查看帮助 go mod init&lt;项目模块名称&gt;初始化模块，会在项目根目录下生成 go.mod 文件。 go mod tidy 根据 go.mod 文件来处理依赖关系。 go mod vendor 将依赖包复制到项目下的 vendor 目录。建议一些使用了被墙包的话可以这么处理，方便用户快速使用命令 go build -mod=vendor 编译 go list -m all 显示依赖关系。go list -m -json all 显示详细依赖关系。 go mod download 下载依赖。参数是非必写的，path 是包的路径，version 是包的版本。 数组切片初始化数组的初始化有多种形式, 12345[5] int {1,2,3,4,5} //长度为5的数组，其元素值依次为：1，2，3，4，5[5] int {1,2} //长度为5的数组，其元素值依次为：1，2，0，0，0 。在初始化时没有指定初值的元素将会赋值为其元素类型int的默认值0,string的默认值是&quot;&quot; [...] int {1,2,3,4,5} //长度为5的数组，其长度是根据初始化时指定的元素个数决定的 [5] int { 2:1,3:2,4:3} //长度为5的数组，key:value,其元素值依次为：0，0，1，2，3。在初始化时指定了2，3，4索引中对应的值：1，2，3 [...] int {2:1,4:3} //长度为5的数组，起元素值依次为：0，0，1，0，3。由于指定了最大索引4对应的值3，根据初始化的元素个数确定其长度为5赋值与使用 数组的长度不可改变，在特定场景中这样的集合就不太适用，Go中提供了一种灵活，功能强悍的内置类型Slices切片(“动态数组”),与数组相比切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大。切片中有两个概念：一是len长度，二是cap容量，长度是指已经被赋过值的最大下标+1，可通过内置函数len()获得。容量是指切片目前可容纳的最多元素个数，可通过内置函数cap()获得。切片是引用类型，因此在当传递切片时将引用同一指针，修改值将会影响其他的对象。 切片可以通过数组来初始化，也可以通过内置函数make()初始化 .初始化时len=cap,在追加元素时如果容量cap不足时将按len的2倍扩容 1234567s :=[] int {1,2,3 } //直接初始化切片，[]表示是切片类型，{1,2,3}初始化值依次是1,2,3.其cap=len=3s := arr[:] //初始化切片s,是数组arr的引用s := arr[startIndex:endIndex] //将arr中从下标startIndex到endIndex-1 下的元素创建为一个新的切片s := arr[startIndex:] //缺省endIndex时将表示一直到arr的最后一个元素s := arr[:endIndex] //缺省startIndex时将表示从arr的第一个元素开始s1 := s[startIndex:endIndex] //通过切片s初始化切片s1s :=make([]int,len,cap) //通过内置函数make()初始化切片s,[]int 标识为其元素类型为int的切片 slice可以从一个数组或一个已经存在的slice中再次声明。slice通过array[i:j]来获取，其中i是数组的开始位置，j是结束位置，但不包含array[j]，它的长度是j-i。 注意slice和数组在声明时的区别：声明数组时，方括号内写明了数组的长度或使用...自动计算长度，而声明slice时，方括号内没有任何字符 切片是引用类型，在使用时需要注意其操作： 切片可以通过内置函数append(slice []Type,elems …Type)追加元素，elems可以是一排type类型的数据，也可以是slice,因为追加的一个一个的元素，因此如果将一个slice追加到另一个slice中需要带上”…”，这样才能表示是将slice中的元素依次追加到另一个slice中。另外在通过下标访问元素时下标不能超过len大小，如同数组的下标不能超出len范围一样。 12s :=append(s,1,2,3,4)s :=append(s,s1...) slice的默认开始位置是0，ar[:n]等价于ar[0:n] slice的第二个序列默认是数组的长度，ar[n:]等价于ar[n:len(ar)] 如果从一个数组里面直接获取slice，可以这样ar[:]，因为默认第一个序列是0，第二个是数组的长度，即等价于ar[0:len(ar)] slice是引用类型，所以当引用改变其中元素的值时，其它的所有引用都会改变该值，例如上面的aSlice和bSlice，如果修改了aSlice中元素的值，那么bSlice相对应的值也会改变。 go get 和 go get -u 的区别如题，区别如下：加上它可以利用网络来更新已有的代码包及其依赖包。如果已经下载过一个代码包，但是这个代码包又有更新了，那么这时候可以直接用 -u 标记来更新本地的对应的代码包。如果不加这个 -u 标记，执行 go get 一个已有的代码包，会发现命令什么都不执行。只有加了 -u 标记，命令会去执行 git pull 命令拉取最新的代码包的最新版本，下载并安装。 其他12345678func main() { x := 0x12345678 p := unsafe.Pointer(&amp;x) // *int -&gt; Pointer n := (*[4]byte)(p) // Pointer -&gt; *[4]byte for i := 0; i &lt; len(n); i++ { fmt.Printf(&quot;%X &quot;, n[i]) }} 输出 178 56 34 12 IEEE754 NAN f!=f 单引号字符常量表⽰ Unicode Code Point，⽀持 \\uFFFF、\\U7FFFFFFF、\\xFF 格式。对应 rune 类型，用for遍历是逐字节的for range遍历是字符 返回局部变量指针是安全的，编译器会根据需要将其分配在 GC Heap 上。 1234func test() *int { x := 100 return &amp;x // 在堆上分配 x 内存。但在内联时，也可能直接分配在⺫标栈。} 将 Pointer 转换成 uintptr，可变相实现指针运算。 123456789101112func main() { d := struct { s string x int }{&quot;abc&quot;, 100}p := uintptr(unsafe.Pointer(&amp;d)) // *struct -&gt; Pointer -&gt; uintptr p += unsafe.Offsetof(d.x) // uintptr + offset p2 := unsafe.Pointer(p) // uintptr -&gt; Pointer px := (*int)(p2) // Pointer -&gt; *int *px = 200 // d.x = 200 fmt.Printf(&quot;%#v\\n&quot;, d)} 输出： 1struct { s string; x int }{s:&quot;abc&quot;, x:200} 注意：GC 把 uintptr 当成普通整数对象，它⽆法阻⽌ “关联” 对象被回收。 自定义类型 命名类型：bool、int、string未命名类型： array、slice、map目标类型是未命名类型会发生隐式转换否则必须显式转换，例如 1234567type bigInt int64var a bigInt = 12var b int64 = a //报错 var b int64 = int64(a) type FooSlice []uintvar a FooSlice = FooSlice{1, 2, 3}var b []uint = a // 正常运行 运算符 ^取反 转换123456789101112131415161718192021func main() { var v int64 = 12 //默认10进制 s2 := strconv.FormatInt(v, 2) //10 转2进制 fmt.Printf(&quot;%v\\n&quot;, s2) s8 := strconv.FormatInt(v, 8) fmt.Printf(&quot;%v\\n&quot;, s8) s10 := strconv.FormatInt(v, 10) fmt.Printf(&quot;%v\\n&quot;, s10) s16 := strconv.FormatInt(v, 16) //10 yo 16 fmt.Printf(&quot;%v\\n&quot;, s16) var sv = &quot;11&quot; fmt.Println(strconv.ParseInt(sv, 16, 32)) // 16 to 10 fmt.Println(strconv.ParseInt(sv, 10, 32)) // 10 to 10 fmt.Println(strconv.ParseInt(sv, 8, 32)) // 8 to 10 fmt.Println(strconv.ParseInt(sv, 2, 32)) // 2 to 10 } 编码url为什么需要编码和解码1.是因为当字符串数据以url的形式传递给web服务器时,字符串中是不允许出现空格和特殊字符的；2.因为 url 对字符有限制，比如把一个邮箱放入 url，就需要使用 urlencode 函数，因为 url 中不能包含 @ 字符；3.url转义其实也只是为了符合url的规范而已。因为在标准的url规范中中文和很多的字符是不允许出现在url中的。 哪些字符是需要转化的呢？1. ASCII 的控制字符这些字符都是不可打印的，自然需要进行转化。 2. 一些非ASCII字符这些字符自然是非法的字符范围。转化也是理所当然的了。 3. 一些保留字符很明显最常见的就是“&amp;”了，这个如果出现在url中了，那你认为是url中的一个字符呢，还是特殊的参数分割用的呢？ 4. 就是一些不安全的字符了。例如：空格。为了防止引起歧义，需要被转化为“+”。明白了这些，也就知道了为什么需要转化了，而转化的规则也是很简单的。 按照每个字符对应的字符编码，不是符合我们范围的，统统的转化为%的形式也就是了。自然也是16进制的形式。 5.和字符编码无关通过urlencode的转化规则和目的，我们也很容易的看出，urleocode是基于字符编码的。同样的一个汉字，不同的编码类型，肯定对应不同的urleocode的串。gbk编码的有gbk的encode结果。apache等服务器，接受到字符串后，可以进行decode，但是还是无法解决编码的问题。编码问题，还是需要靠约定或者字符编码的判断解决。因此，urleocode只是为了url中一些非ascii字符，可以正确无误的被传输，至于使用哪种编码，就不是encode所关心和解决的问题了。编码问题，不是urlencode所要解决的。 golang之UrlEncode编码/UrlDecode解码12345678910111213141516package mainimport( &quot;fmt&quot; &quot;net/url&quot;)func main() { var urlStr string = &quot;傻了吧:%:%@163&amp; .html.html&quot; escapeUrl := url.QueryEscape(urlStr) fmt.Println(&quot;编码:&quot;,escapeUrl) enEscapeUrl, _ := url.QueryUnescape(escapeUrl) fmt.Println(&quot;解码:&quot;,enEscapeUrl)} 输出编码: %E5%82%BB%E4%BA%86%E5%90%A7%3A%25%3A%25%40163%26+.html.html解码: 傻了吧:%:%@163&amp; .html.html 原文地址： golang之UrlEncode编码/UrlDecode解码 deferGolang中的defer语句用于延迟函数的调用，每次 defer 都会把一个函数压入栈中，函数返回前再把延迟的函数取出并执行。Golang 中的 defer 可以帮助我们处理容易忽略的问题，如资源释放、连接关闭等。 关键字 return 不是一个原子操作，实际上 return 只代理汇编指令 ret，即将跳转程序执行。比如语句 return i，实际上分两步进行，即将 i 值存入栈中作为返回值，然后执行跳转，而 defer 的执行时机正是跳转前，所以说 defer 执行时还是有机会操作返回值的。 defer函数在return前执行 匿名返回值，返回字面量，不会被影响 1234567891011121314func foo() int { i := 0 defer func() { i++ }() return i // 0 匿名返回值}func gee() int { i := 0 defer func() { i++ } return 0 // 0 字面量} 具名返回值，会被影响 123456func bar() (result int) { defer func() { result++ }() return result // 1 这里return 0或者result都会返回1} 判断文件是否存在1234func FileExist(path string) bool { _, err := os.Lstat(path) // Stat return !os.IsNotExist(err)} 正则 (re) numbered capturing group (?Pre) named &amp; numbered capturing group (?:re) non-capturing group (?flags) set flags within current group; non-capturing (?flags:re) set flags during re; non-capturing Flag syntax is xyz (set) or -xyz (clear) or xy-z (set xy, clear z). The flags are: i case-insensitive (default false) m multi-line mode: ^ and $ match begin/end line in addition to begin/end text (default false) s let . match \\ (default false) U ungreedy: swap meaning of x* and x*?, x+ and x+?, etc (default false) 例如不区分大小写 1r := regexp.MustCompile(`(?i)CaSe`) 交换顺序12345a := 1b := 2a ^= bb ^= aa ^= b 123a := 1b := 2a, b = b, a 获取正在运行的函数名1234func getFuncName() string { pc, _, _, _ := runtime.Caller(1) return runtime.FuncForPC(pc).Name()} 123456func getFuncName()string{ pc := make([]uintptr,1) runtime.Callers(2,pc) f := runtime.FuncForPC(pc[0]) return f.Name()} 泛型 go &gt;= 1.18 123456789101112type Number interface { uint | uint8 | uint16 | uint32 | uint64 # 联合类型}func sum[K comparable, V Number](s map[K]V) (sum uint64) { for _, value := range s { sum += uint64(value) } return}fmt.Println(sum[int, uint64](map[int]uint64{1: 1, 2: 3})) 为 K 类型参数指定类型约束 comparable。专门针对此类情况，comparable 在 Go 中预先声明了约束。它允许任何类型的值可以用作比较运算符 == 和的操作数 !=。Go 要求 map keys 具有可比性。所以声明 K as comparable 是必要的，这样你就可以 K 在 map 变量中用作键。它还确保调用代码对 map keys 使用允许的类型。","link":"/2021/11/28/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"Html学习笔记","text":"li标签居中把要居中的li设置成 display: inline-block;然后在li加上 text-align: center; 让li居中。 img标签属性alt属性是当图片无法正常加载时显示的提示文字，而在ie中会被作为鼠标指向的文字提示。更好兼容的的鼠标指向文字提示应该使用title属性。 块级元素或者行内元素在设置float属性之后是否改变元素的性质？块级元素使用float属性后，将其属性变成inline-block，不能改变其块级元素的性质，只是能有块级元素的特性，不独占一行，宽度不会占满父元素，和行内元素排列成一行行内元素使用float属性后，也是将其属性变成inline-block，可以设置宽高，padding，margin属性 行内元素可不可以包含块元素，即行内元素是父元素。？？块级元素会独占一行,默认情况下,其宽度自动填满其父元素宽度. 行内元素不会独占一行,相邻的行内元素会排列在同一行里,直到一行排不下,才会换行,其宽度随元素的内容而变化. 块级元素可以设置width,height属性. 行内元素设置width,height属性无效. 块级元素即使设置了宽度,仍然是独占一行. 块级元素可以设置margin和padding属性. 行内元素的margin和padding属性,水平方向的padding-left,padding-right,margin-left,margin-right都产生边距 效果,但竖直方向的padding-top,padding-bottom,margin-top,margin-bottom却不会产生边距效果. 块级元素对应于display:block. 行内元素对应于display:inline. display:none与visible:hidden的区别display:none和visible:hidden都能把网页上某个元素隐藏起来，但两者有区别: display:none —不为被隐藏的对象保留其物理空间，即该对象在页面上彻底消失，通俗来说就是看不见也摸不到。 visible:hidden— 使对象在网页上不可见，但该对象在网页上所占的空间没有改变，通俗来说就是看不见但摸得到。 设置一个div居中，使用padding:0 auto;width:1000px;但是结果是不能使得元素居中使用margin：0 auto；的话，居中的两边背景色会用空白。 解决办法： 把要居中的div 设置成 display: inline-block;，然后在父div加上 text-align: center; 让div居中。 关于行内元素和块元素1、html中行内元素bai(a)中能不能放块元素（div）回答du：不能。XHTML标准是这样zhi定义的：*inline*a*inline excluding an enclosed a element解释就是 a标签属于daoinline， a标签只能嵌套inline元素，并也不能再嵌套a标签。2、那span里面能不能放div呢？？回答：不能1、html中行内元素(a)中能不能放块元素（div）回答：不能。XHTML标准是这样定义的：*inline*span*inline解释就是 span是属于inline，并且span也只能嵌套inline另外，XHTML标准还有一些我们容易疏漏的，比如所有标签都要小写，例如等我个人理解就是标准毕竟只是标准，就好像大家都走路靠右边走，但是你如果非要靠左边走，也没人拦你。所以写的时候有可能会通过浏览器的认证，但是如果在某些严格符合xhtml规范的编译器或浏览器，他们就不认账了。所以按照xhtml规范可以培养自己良好的开发习惯。顺便提一下，html元素分3中，顶级元素、块级元素、内联元素。行内实际上就是内敛元素… 1html access-charset img 的alt属性alt属性是当图片无法正常加载时显示的提示文字，而在ie中会被作为鼠标指向的文字提示。更好兼容的的鼠标指向文字提示应该使用title属性。","link":"/2020/07/05/Html%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"LInux shell之(for in 用法总结)","text":"一、语法 1234for 变量名 in 列表 do 程序段(command) done 注意1：是变量名而不是$变量！ 注意2：列表可以做文章！ 二、应用 第一类：数字性循环–&gt;seq在in后面的应用 123456#!/bin/bash #也是产生等差数列--&gt;默认是1for i in $(seq 1 10) #产生的是一个字符串，默认IFS是以空格隔开！ do echo $(expr $i \\* 3 + 1); #主要是复习:expr乘法的特殊用法！--&gt;空格隔开 done 补充：产生[1,10]的自然数–&gt;{}在in后面的应用 123456789101112131415total=0 #全局变量for i in {1..100} #&quot;..&quot;表示连续，默认也是IFS为空格隔开 do ((total+=i)) doneecho -e &quot;total is:${total}&quot;#多行注释&lt;&lt;COMMENRfor i in mysql_{0,1,4,12}sql #多个文件 do echo $i samtools view -c $i doneCOMMENT 第二类：字符性循环 最原始的 123456#!/bin/bash#使用列表for循环显示周一到周日对应的英文--&gt;学习日期的英文for day in Monday Tuesday Wednesday Thursday Friday Saturday Sunday do echo &quot;$day&quot; done 变量的类型 123456#!/bin/bash list=&quot;Linux Java C++ Python&quot; for i in $list do echo -e &quot;Language is ${i}&quot; done cat在in后面的应用–&gt;逐行读取文件的内容(默认是IFS)，所以不是逐行打印！ 12345#!/bin/bashfor i in $(cat 日志颜色.sh) #注意:pwd当前目录下的文件 do echo $i done 思考：如果想逐行原样输出！ 1234567891011#!/bin/bash# reading content from a filefile=&quot;日志文件.sh&quot;#将这个语句加入到脚本中，告诉bash shell在数据值中忽略空格和制表,使其只能识别换行符!IFS=$'\\n'for std in $(cat $file) do echo &quot;$std&quot; done 说明：IFS的一些说明！ 1234bash shell会将下列字符当作字段分隔符：空格、制表符、换行符说明：如果在shell在数据中看到这些字符中的任意一个，它就会假定这表明了列表中一个新数据字段的开始！参考的最佳安全实践：在改变IFS之前保存原来的IFS值，之后再恢复它。 https://zhuanlan.zhihu.com/p/36513249 保证了：在脚本的后续操作中使用的是IFS的默认值 实现： 1234IFS.OLD=$IFS #默认的IFS的数值--&gt;也是环境变量！IFS=$'\\n' #自定义的IFS数值&lt;在代码中使用新的IFS值&gt; #待使用自定义IFS的部分！IFS=$IFS.OLD #恢复默认的IFS 第三类：路径查找 ls在in后面的命令是–&gt;读取当前pwd下的文件(广义上)！ 12345#!/bin/bash for i in `ls`; #ls可以结合统配符应用！ do echo $i is file name\\! ; #注意:\\的应用！ done 用通配符读取目录(无命令) 1234for file in ~/*; #一级目录下的内容--&gt;并不递归显示！ do echo $file is file path \\! ; #${file}代表的是文件的全路径 done 通过脚本传参 12345678910#!/bin/bash#回忆1：统计脚本参数的个数echo &quot;argument number are $#&quot;！#回忆2：参数的内容--&gt;此处可以换成$@来测试！echo &quot;the input is $*&quot;#循环执行for argument in &quot;$*&quot;; do echo &quot;$argument &quot; done IFS：内部字段分隔符 需求如下： 1234#遍历一个文件中用冒号分隔的值：--&gt;特殊文件--&gt;/etc/passwd文件等！IFS=：#如果要指定多个IFS字符，只要将它们在赋值行串起来就行。IFS=$'\\n':;&quot; 总结： 12345678910#（1）从变量读取列表# 将一系列的值都集中存储在一个变量中，然后需要遍历变量中的整个列表#（2）从命令读取值#有两种方式可以将命令输出赋值给变量：# （1）反引号字符（`）# （2）$()格式 补充：在列表构成上分多种情景，如数字列表、字符串列表、命令列表、脚本传参列表等！ 数组遍历 遍历数组时，使用哪种方式取决于数组中元素的分布情况。 定义如下两个数组： 12345678910#下标连续arr1=(a b c d e)#下标不连续arr2=([2]=&quot;a b&quot; [5]=&quot;c&quot; [8]=4 [10]=&quot;csdn&quot;)1.for，适用于数组下标连续的情况，如果数组下标不连续会得不到完整的结果。for ((i=0;i&lt;${#arr1[@]};i++))do echo ${arr1[$i]}done 2.for…in，无论下标是否连续都可以，有两种方式，一种是直接遍历数组中的元素，一种是通过遍历数组下标获取数组元素。 #直接遍历数组 123456789for value in &quot;${arr1[@]}&quot;do echo $valuedone#通过遍历下标获取数组元素for i in ${!arr1[@]}do echo ${arr1[$i]}done while，适用于数组下标连续的情况，如果数组下标不连续会得不到完整的结果。 123456i=0while [ $i -lt ${#arr1[@]} ]do echo ${arr1[$i]} let i++done 除了下标问题外，关于@与*在使用时也要注意，并不是完全等价，并且在被双引号包围时的解析有时也略有不同。 对于第一种遍历方式，$","link":"/2022/04/24/LInux%20shell%E4%B9%8B(for%20in%20%E7%94%A8%E6%B3%95%E6%80%BB%E7%BB%93)/"},{"title":"Linux find 命令","text":"Linux find 命令用来在指定目录下查找文件。任何位于参数之前的字符串都将被视为欲查找的目录名。如果使用该命令时，不设置任何参数，则 find 命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示。 语法1find path -option [ -print ] [ -exec -ok command ] {} \\; 参数说明 : find 根据下列规则判断 path 和 expression，在命令列上第一个 - ( ) , ! 之前的部份为 path，之后的是 expression。如果 path 是空字串则使用目前路径，如果 expression 是空字串则使用 -print 为预设 expression。 expression 中可使用的选项有二三十个之多，在此只介绍最常用的部份。 -mount, -xdev : 只检查和指定目录在同一个文件系统下的文件，避免列出其它文件系统中的文件 -amin n : 在过去 n 分钟内被读取过 -anewer file : 比文件 file 更晚被读取过的文件 -atime n : 在过去n天内被读取过的文件 -cmin n : 在过去 n 分钟内被修改过 -cnewer file :比文件 file 更新的文件 -ctime n : 在过去n天内被修改过的文件 -empty : 空的文件-gid n or -group name : gid 是 n 或是 group 名称是 name -ipath p, -path p : 路径名称符合 p 的文件，ipath 会忽略大小写 -name name, -iname name : 文件名称符合 name 的文件。iname 会忽略大小写 -size n : 文件大小 是 n 单位，b 代表 512 位元组的区块，c 表示字元数，k 表示 kilo bytes，w 是二个位元组。 -type c : 文件类型是 c 的文件。 d: 目录 c: 字型装置文件 b: 区块装置文件 p: 具名贮列 f: 一般文件 l: 符号连结 s: socket -pid n : process id 是 n 的文件 你可以使用 ( ) 将运算式分隔，并使用下列运算。 exp1 -and exp2 ! expr -not expr exp1 -or exp2 exp1, exp2 实例将当前目录及其子目录下所有文件后缀为 .c 的文件列出来: 1# find . -name &quot;*.c&quot; 将目前目录其其下子目录中所有一般文件列出 1# find . -type f 将当前目录及其子目录下所有最近 20 天内更新过的文件列出: 1# find . -ctime -20 查找 /var/log 目录中更改时间在 7 日以前的普通文件，并在删除之前询问它们： 1# find /var/log -type f -mtime +7 -ok rm {} \\; 查找当前目录中文件属主具有读、写权限，并且文件所属组的用户和其他用户具有读权限的文件： 1# find . -type f -perm 644 -exec ls -l {} \\; 查找系统中所有文件长度为 0 的普通文件，并列出它们的完整路径： 1# find / -type f -size 0 -exec ls -l {} \\; 来源：https://www.runoob.com/linux/linux-comm-find.html","link":"/2021/05/01/Linux%20find%20%E5%91%BD%E4%BB%A4/"},{"title":"Linux sed 命令","text":"Linux sed 命令是利用脚本来处理文本文件。 sed 可依照脚本的指令来处理、编辑文本文件。 Sed 主要用来自动编辑一个或多个文件、简化对文件的反复操作、编写转换程序等。 语法1sed [-hnV][-e&lt;script&gt;][-f&lt;script文件&gt;][文本文件] 参数说明： 12345-e&lt;script&gt;或--expression=&lt;script&gt; 以选项中指定的script来处理输入的文本文件。-f&lt;script文件&gt;或--file=&lt;script文件&gt; 以选项中指定的script文件来处理输入的文本文件。-h或--help 显示帮助。-n或--quiet或--silent 仅显示script处理后的结果。-V或--version 显示版本信息。 动作说明： 123456a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！d ：删除，因为是删除啊，所以 d 后面通常不接任何东西；i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ 实例在testfile文件的第四行后添加一行，并将结果输出到标准输出，在命令行提示符下输入如下命令： 1sed -e 4a\\newLine testfile 首先查看testfile中的内容如下： 12345$ cat testfile #查看testfile 中的内容 HELLO LINUX! Linux is a free unix-type opterating system. This is a linux testfile! Linux test 使用sed命令后，输出结果如下： 123456$ sed -e 4a\\newline testfile #使用sed 在第四行后添加新字符串 HELLO LINUX! #testfile文件原有的内容 Linux is a free unix-type opterating system. This is a linux testfile! Linux test newline 以行为单位的新增/删除将 /etc/passwd 的内容列出并且列印行号，同时，请将第 2~5 行删除！ 12345[root@www ~]# nl /etc/passwd | sed '2,5d'1 root:x:0:0:root:/root:/bin/bash6 sync:x:5:0:sync:/sbin:/bin/sync7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown.....(后面省略)..... sed 的动作为 ‘2,5d’ ，那个 d 就是删除！因为 2-5 行给他删除了，所以显示的数据就没有 2-5 行罗～ 另外，注意一下，原本应该是要下达 sed -e 才对，没有 -e 也行啦！同时也要注意的是， sed 后面接的动作，请务必以 ‘’ 两个单引号括住喔！ 只要删除第 2 行 1nl /etc/passwd | sed '2d' 要删除第 3 到最后一行 1nl /etc/passwd | sed '3,$d' 在第二行后(亦即是加在第三行)加上『drink tea?』字样！ 123456[root@www ~]# nl /etc/passwd | sed '2a drink tea'1 root:x:0:0:root:/root:/bin/bash2 bin:x:1:1:bin:/bin:/sbin/nologindrink tea3 daemon:x:2:2:daemon:/sbin:/sbin/nologin.....(后面省略)..... 那如果是要在第二行前 1nl /etc/passwd | sed '2i drink tea' 如果是要增加两行以上，在第二行后面加入两行字，例如 Drink tea or ….. 与 drink beer? 12345678[root@www ~]# nl /etc/passwd | sed '2a Drink tea or ......\\&gt; drink beer ?'1 root:x:0:0:root:/root:/bin/bash2 bin:x:1:1:bin:/bin:/sbin/nologinDrink tea or ......drink beer ?3 daemon:x:2:2:daemon:/sbin:/sbin/nologin.....(后面省略)..... 每一行之间都必须要以反斜杠\\来进行新行的添加喔！所以，上面的例子中，我们可以发现在第一行的最后面就有 \\存在。 以行为单位的替换与显示将第2-5行的内容取代成为『No 2-5 number』呢？ 12345[root@www ~]# nl /etc/passwd | sed '2,5c No 2-5 number'1 root:x:0:0:root:/root:/bin/bashNo 2-5 number6 sync:x:5:0:sync:/sbin:/bin/sync.....(后面省略)..... 透过这个方法我们就能够将数据整行取代了！ 仅列出 /etc/passwd 文件内的第 5-7 行 1234[root@www ~]# nl /etc/passwd | sed -n '5,7p'5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin6 sync:x:5:0:sync:/sbin:/bin/sync7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 可以透过这个 sed 的以行为单位的显示功能， 就能够将某一个文件内的某些行号选择出来显示。 数据的搜寻并显示搜索 /etc/passwd有root关键字的行 12345678nl /etc/passwd | sed '/root/p'1 root:x:0:0:root:/root:/bin/bash1 root:x:0:0:root:/root:/bin/bash2 daemon:x:1:1:daemon:/usr/sbin:/bin/sh3 bin:x:2:2:bin:/bin:/bin/sh4 sys:x:3:3:sys:/dev:/bin/sh5 sync:x:4:65534:sync:/bin:/bin/sync....下面忽略 如果root找到，除了输出所有行，还会输出匹配行。 使用-n的时候将只打印包含模板的行。 12nl /etc/passwd | sed -n '/root/p'1 root:x:0:0:root:/root:/bin/bash 数据的搜寻并删除删除/etc/passwd所有包含root的行，其他行输出 12345nl /etc/passwd | sed '/root/d'2 daemon:x:1:1:daemon:/usr/sbin:/bin/sh3 bin:x:2:2:bin:/bin:/bin/sh....下面忽略#第一行的匹配root已经删除了 数据的搜寻并执行命令搜索/etc/passwd,找到root对应的行，执行后面花括号中的一组命令，每个命令之间用分号分隔，这里把bash替换为blueshell，再输出这行： 12nl /etc/passwd | sed -n '/root/{s/bash/blueshell/;p;q}' 1 root:x:0:0:root:/root:/bin/blueshell 最后的q是退出。 数据的搜寻并替换除了整行的处理模式之外， sed 还可以用行为单位进行部分数据的搜寻并取代。基本上 sed 的搜寻与替代的与 vi 相当的类似！他有点像这样： 1sed 's/要被取代的字串/新的字串/g' 先观察原始信息，利用 /sbin/ifconfig 查询 IP 123456[root@www ~]# /sbin/ifconfig eth0eth0 Link encap:Ethernet HWaddr 00:90:CC:A6:34:84inet addr:192.168.1.100 Bcast:192.168.1.255 Mask:255.255.255.0inet6 addr: fe80::290:ccff:fea6:3484/64 Scope:LinkUP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1.....(以下省略)..... 本机的ip是192.168.1.100。 将 IP 前面的部分予以删除 12[root@www ~]# /sbin/ifconfig eth0 | grep 'inet addr' | sed 's/^.*addr://g'192.168.1.100 Bcast:192.168.1.255 Mask:255.255.255.0 接下来则是删除后续的部分，亦即： 192.168.1.100 Bcast:192.168.1.255 Mask:255.255.255.0 将 IP 后面的部分予以删除 12[root@www ~]# /sbin/ifconfig eth0 | grep 'inet addr' | sed 's/^.*addr://g' | sed 's/Bcast.*$//g'192.168.1.100 多点编辑一条sed命令，删除/etc/passwd第三行到末尾的数据，并把bash替换为blueshell 123nl /etc/passwd | sed -e '3,$d' -e 's/bash/blueshell/'1 root:x:0:0:root:/root:/bin/blueshell2 daemon:x:1:1:daemon:/usr/sbin:/bin/sh -e表示多点编辑，第一个编辑命令删除/etc/passwd第三行到末尾的数据，第二条命令搜索bash替换为blueshell。 直接修改文件内容(危险动作)sed 可以直接修改文件的内容，不必使用管道命令或数据流重导向！ 不过，由於这个动作会直接修改到原始的文件，所以请你千万不要随便拿系统配置来测试！ 我们还是使用文件 regular_express.txt 文件来测试看看吧！ regular_express.txt 文件内容如下： 1234567[root@www ~]# cat regular_express.txt runoob.google.taobao.facebook.zhihu-weibo- 利用 sed 将 regular_express.txt 内每一行结尾若为 . 则换成 ! 12345678[root@www ~]# sed -i 's/\\.$/\\!/g' regular_express.txt[root@www ~]# cat regular_express.txt runoob!google!taobao!facebook!zhihu-weibo- :q:q 利用 sed 直接在 regular_express.txt 最后一行加入 # This is a test: 123456789[root@www ~]# sed -i '$a # This is a test' regular_express.txt[root@www ~]# cat regular_express.txt runoob!google!taobao!facebook!zhihu-weibo-# This is a test 由于$ 代表的是最后一行，而 a 的动作是新增，因此该文件最后新增 # This is a test！ sed 的 -i 选项可以直接修改文件内容，这功能非常有帮助！举例来说，如果你有一个 100 万行的文件，你要在第 100 行加某些文字，此时使用 vim 可能会疯掉！因为文件太大了！那怎办？就利用 sed 啊！透过 sed 直接修改/取代的功能，你甚至不需要使用 vim 去修订！ 笔记 追加行的说明： 1sed -e 4a\\newline testfile a 动作是在匹配的行之后追加字符串，追加的字符串中可以包含换行符（实现追加多行的情况）。 追加一行的话前后都不需要添加换行符 \\n，只有追加多行时在行与行之间才需要添加换行符(最后一行最后也无需添加，添加的话会多出一个空行)。 man sed 信息： 1Append text, which has each embedded newline preceded by a backslash. 例如： 4 行之后添加一行： 1sed -e '4 a newline' testfile 4 行之后追加 2 行： 1sed -e '4 a newline\\nnewline2' testfile 4 行之后追加 3 行(2 行文字和 1 行空行) 1sed -e '4 a newline\\nnewline2\\n' testfile 4 行之后追加 1 行空行： 12#错误：sed -e '4 a \\n' testfilesed -e '4 a \\ ' testfile 实际上 实际上是插入了一个含有一个空格的行，插入一个完全为空的空行没有找到方法（不过应该没有这个需求吧，都要插入行了插入空行干嘛呢？） 添加空行： 12345# 可以添加一个完全为空的空行sed '4 a \\\\'# 可以添加两个完全为空的空行sed '4 a \\\\n' 统计log中某一时间段的数量[没有测试]sed -n '/2017-01-04 11:00:00/,/2017-01-04 11:20:55/p' ejabberd.log 来源：https://www.runoob.com/linux/linux-comm-sed.html","link":"/2021/05/01/Linux%20sed%20%E5%91%BD%E4%BB%A4/"},{"title":"Linux 信号列表","text":"linux 信号列表 信号 取值 默认动作 含义（发出信号的原因） SIGHUP 1 Term 终端的挂断或进程死亡 SIGINT 2 Term 来自键盘的中断信号 SIGQUIT 3 Core 来自键盘的离开信号 SIGILL 4 Core 非法指令 SIGABRT 6 Core 来自 abort 的异常信号 SIGFPE 8 Core 浮点例外 SIGKILL 9 Term 杀死 SIGSEGV 11 Core 段非法错误 (内存引用无效) SIGPIPE 13 Term 管道损坏：向一个没有读进程的管道写数据 SIGALRM 14 Term 来自 alarm 的计时器到时信号 SIGTERM 15 Term 终止 SIGUSR1 30,10,16 Term 用户自定义信号 1 SIGUSR2 31,12,17 Term 用户自定义信号 2 SIGCHLD 20,17,18 Ign 子进程停止或终止 SIGCONT 19,18,25 Cont 如果停止，继续执行 SIGSTOP 17,19,23 Stop 非来自终端的停止信号 SIGTSTP 18,20,24 Stop 来自终端的停止信号 SIGTTIN 21,21,26 Stop 后台进程读终端 SIGTTOU 22,22,27 Stop 后台进程写终端 SIGBUS 10,7,10 Core 总线错误（内存访问错误） SIGPOLL Term Pollable 事件发生 (Sys V)，与 SIGIO 同义 SIGPROF 27,27,29 Term 统计分布图用计时器到时 SIGSYS 12,-,12 Core 非法系统调用 (SVr4) SIGTRAP 5 Core 跟踪 / 断点自陷 SIGURG 16,23,21 Ign socket 紧急信号 (4.2BSD) SIGVTALRM 26,26,28 Term 虚拟计时器到时 (4.2BSD) SIGXCPU 24,24,30 Core 超过 CPU 时限 (4.2BSD) SIGXFSZ 25,25,31 Core 超过文件长度限制 (4.2BSD) SIGIOT 6 Core IOT 自陷，与 SIGABRT 同义 SIGEMT 7,-,7 Term SIGSTKFLT -,16,- Term 协处理器堆栈错误 (不使用) SIGIO 23,29,22 Term 描述符上可以进行 I/O 操作 SIGCLD -,-,18 Ign 与 SIGCHLD 同义 SIGPWR 29,30,19 Term 电力故障 (System V) SIGINFO 29,-,- 与 SIGPWR 同义 SIGLOST -,-,- Term 文件锁丢失 SIGWINCH 28,28,20 Ign 窗口大小改变 (4.3BSD, Sun) SIGUNUSED -,31,- Term 未使用信号 (will be SIGSYS) 非可靠信号 名称 说明 SIGHUP 连接断开 SIGINT 终端中断符 SIGQUIT 终端退出符 SIGILL 非法硬件指令 SIGTRAP 硬件故障 SIGABRT 异常终止 (abort) SIGBUS 硬件故障 SIGFPE 算术异常 SIGKILL 终止 SIGUSR1 用户定义信号 SIGUSR2 用户定义信号 SIGSEGV 无效内存引用 SIGPIPE 写至无读进程的管道 SIGALRM 定时器超时 (alarm) SIGTERM 终止 SIGCHLD 子进程状态改变 SIGCONT 使暂停进程继续 SIGSTOP 停止 SIGTSTP 终端停止符 SIGTTIN 后台读控制 tty SIGTTOU 后台写向控制 tty SIGURG 紧急情况 (套接字) SIGXCPU 超过 CPU 限制 (setrlimit) SIGXFSZ 超过文件长度限制 (setrlimit) SIGVTALRM 虚拟时间闹钟 (setitimer) SIGPROF 梗概时间超时 (setitimer) SIGWINCH 终端窗口大小改变 SIGIO 异步 I/O SIGPWR 电源失效 / 重启动 SIGSYS 无效系统调用 可靠信号 名称 用户自定义 SIGRTMIN SIGRTMIN+1 SIGRTMIN+2 SIGRTMIN+3 SIGRTMIN+4 SIGRTMIN+5 SIGRTMIN+6 SIGRTMIN+7 SIGRTMIN+8 SIGRTMIN+9 SIGRTMIN+10 SIGRTMIN+11 SIGRTMIN+12 SIGRTMIN+13 SIGRTMIN+14 SIGRTMIN+15 SIGRTMAX-14 SIGRTMAX-13 SIGRTMAX-12 SIGRTMAX-11 SIGRTMAX-10 SIGRTMAX-9 SIGRTMAX-8 SIGRTMAX-7 SIGRTMAX-6 SIGRTMAX-5 SIGRTMAX-4 SIGRTMAX-3 SIGRTMAX-2 SIGRTMAX-1 SIGRTMAX 来源： https://wiki.swoole.com/#/other/signal","link":"/2022/06/11/Linux%20%E4%BF%A1%E5%8F%B7%E5%88%97%E8%A1%A8/"},{"title":"Linux 里的 2&gt;&amp;1 究竟是什么","text":"我们在Linux下经常会碰到nohup command&gt;/dev/null 2&gt;&amp;1 &amp;这样形式的命令。首先我们把这条命令大概分解下： 首先就是一个nohup：表示当前用户和系统的会话下的进程忽略响应HUP消息。 &amp;是把该命令以后台的job的形式运行。 command&gt;/dev/null较好理解，/dev/null表示一个空设备，就是说把 command 的执行结果重定向到空设备中，说白了就是不显示任何信息。 可以把/dev/null 可以看作”黑洞”。它等价于一个只写文件。所有写入它的内容都会永远丢失，而尝试从它那儿读取内容则什么也读不到。 那么2&gt;&amp;1又是什么含义? 几个基本符号及其含义： /dev/null 表示空设备文件； 0 表示stdin标准输入； 1 表示stdout标准输出； 2 表示stderr标准错误。 从command&gt;/dev/null说起 其实这条命令是一个缩写版，对于一个重定向命令，肯定是a &gt; b这种形式，那么command &gt; /dev/null难道是command 充当 a 的角色，/dev/null 充当 b 的角色。这样看起来比较合理，其实一条命令肯定是充当不了 a，肯定是 command 执行产生的输出来充当 a，其实就是标准输出 stdout。所以command &gt; /dev/null相当于执行了command 1 &gt; /dev/null。执行 command 产生了标准输出 stdout（用1表示），重定向到/dev/null的设备文件中。 说说 2&gt;&amp;1 通过上面command &gt; /dev/null等价于command 1 &gt; /dev/null，那么对于2&gt;&amp;1也就好理解了，2就是标准错误，1是标准输出，那么这条命令不就是相当于把标准错误重定向到标准输出么。 2&gt;1和2&gt;&amp;1的写法有什么区别： 2&gt;1的作用是把标准错误的输出重定向到1，但这个1不是标准输出，而是一个文件!!!,文件名就是1； 2&gt;&amp;1的作用是把标准错误的输出重定向到标准输出1，&amp;指示不要把1当作普通文件，而是fd=1即标准输出来处理。 command&gt;a 2&gt;a 与 command&gt;a 2&gt;&amp;1的区别 通过上面的分析，对于command&gt;a 2&gt;&amp;1这条命令，等价于command 1&gt;a 2&gt;&amp;1可以理解为执行 command 产生的标准输入重定向到文件 a 中，标准错误也重定向到文件 a 中。那么是否就说command 1&gt;a 2&gt;&amp;1等价于command 1&gt;a 2&gt;a呢。其实不是，command 1&gt;a 2&gt;&amp;1与command 1&gt;a 2&gt;a还是有区别的，区别就在于前者只打开一次文件a，后者会打开文件两次，并导致 stdout 被 stderr 覆盖。&amp;1的含义就可以理解为用标准输出的引用，引用的就是重定向标准输出产生打开的 a。从IO效率上来讲，command 1&gt;a 2&gt;&amp;1比command 1&gt;a 2&gt;a的效率更高。 为何2&gt;&amp;1要写在后面？ index.php task testOne &gt;/dev/null 2&gt;&amp;1 我们可以理解为，左边是标准输出，好，现在标准输出直接输入到/dev/null中，而2&gt;&amp;1是将标准错误重定向到标准输出，所以当程序产生错误的时候，相当于错误流向左边，而左边依旧是输入到/dev/null中。 可以理解为，如果写在中间，那会把隔断标准输出指定输出的文件 你可以用： ls 2&gt;1测试一下，不会报没有2文件的错误，但会输出一个空的文件1； ls xxx 2&gt;1测试，没有xxx这个文件的错误输出到了1中； ls xxx 2&gt;&amp;1测试，不会生成1这个文件了，不过错误跑到标准输出了； ls xxx &gt;out.txt 2&gt;&amp;1，实际上可换成 ls xxx 1&gt;out.txt 2&gt;&amp;1；重定向符号&gt;默认是1，错误和输出都传到out.txt了。 举个栗子 来个shell 1234//test.sh#!/bin/shtdate1234 chmod +x test.sh为test.sh增加执行权限。这里我们弄了两条命令，其中t指令并不存在，执行会报错，会输出到stderr。date能正常执行，执行会输出当前时间，会输出到stdout。 执行./test.sh &gt; res1.log结果为： 我们发现stderr并没有被重定向到res1.log中，stderr被打印到了屏幕上。这也进一步证明了上面说的./test.sh &gt; res1.log等价于./test.sh 1&gt;res1.log 执行./test.sh&gt;res2.log 2&gt;&amp;1结果为： 这次我们发现stdout和stderr都被重定向到了res2.log中了。上面我们未对stderr也就是2说明如何输出，stderr就输出到了屏 幕上，这里我们不仅对stdout进行说明，重定向到res2.log中，对标准错误也进行了说明，让其重定向到res2.log的引用即 res2.log的文件描述符中。 再思考一下 为何2&gt;&amp;1要写在 command&gt;1 的后面，直接用2可以么。比如ls 2&gt;a。其实这种用法也是可以的，ls 命令列出当前的目录，用stdout（1）表示，由于这个时候没有stderr（2），这个时候执行ls 2&gt;a也会正常产生一个 a 的文件，但是 a 的文件中是空的，因为这时候执行ls并没有产生stderr（2）。","link":"/2020/11/19/Linux%20%E9%87%8C%E7%9A%84%202&gt;&amp;1%20%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88/"},{"title":"Linux下tar, tar.gz, xz，unzip，bzip2文件解压方法","text":"tar1tar -zxvf filename z 一般处理.gz文件 x 解压 c压缩 v 显示执行过程 f 指定备份文件 压缩tar.gz 1tar -zcvf dest.tar.gz ./ori/* # 压缩一个目录 压缩包含隐藏文件 1tar -zcvf back.tar.gz .[!.]* * tar czvf test.tar.gz * 压缩当前文件夹下非[隐藏文件]的文件; tar czvf test.tar.gz .[!.]* 压缩当前文件夹下[隐藏文件]排除两个[隐藏文件]夹”.”和“..” 先创建tar包最后删除 1tar -cvzf a.tar.gz a --remove-files 解压tar.gz 12tar -zxvf origin.tar.gztar -zxvf origin.tar.gz -C /home 设置解压目录 xz解压.xz文件 123xz -dk node-v14.15.1-linux-x64.tar.xz #将.xz解压为.tartar -xvf node-v14.15.1-linux-x64.tar # 将.tar解压为普通文件tar -xvf node-v14.15.1-linux-x64.tar.xz d 解压.xz文件 k 保留原文件（如果不想保留，可以去掉k） 12345678910111213141516171819xz -help用法:xz[选项]…[文件]…压缩或解压.xz格式的文件。-z，——compress 压缩-d，——decompress, --uncompress 解压-t，——test 测试压缩文件的完整性-l，——list 列出关于.xz文件的列表信息-k，——keep 保留(不要删除)输入文件-f，——force 强制重写输出文件和(de)压缩链接-c，——stdout，——to-stdout 写入标准输出，不要删除输入文件-0 …-9 压缩预设;默认是6;在使用7-9之前，请考虑压缩机和减压器的内存使用情况!-e，——extreme 极端尝试提高压缩比使用更多的CPU时间; 不影响解压内存要求-T，——threads=NUM使用最多的NUM线程;默认值为1;设置为0 使用任意多的处理器内核-q，——quiet 安静压制警告;指定两次也可以抑制错误-v，——verbose 啰嗦;如果要更详细，请指定两次-h，——help 帮助显示此简短的帮助和退出-H，——long-help 显示long help(同时列出高级选项)-V，——version 版本显示版本号并退出 没有文件时，或文件为-时，读取标准输入。 unzip1、把文件解压到当前目录下 1unzip test.zip 2、如果要把文件解压到指定的目录下，需要用到-d参数。 1unzip -d /temp test.zip 3、解压的时候，有时候不想覆盖已经存在的文件，那么可以加上-n参数 12unzip -n test.zipunzip -n -d /temp test.zip 4、只看一下zip压缩包中包含哪些文件，不进行解压缩 1unzip -l test.zip 5、查看显示的文件列表还包含压缩比率 1unzip -v test.zip 6、检查zip文件是否损坏 1unzip -t test.zip 7、将压缩文件test.zip在指定目录tmp下解压缩，如果已有相同的文件存在，要求unzip命令覆盖原先的文件 1unzip -o test.zip -d /tmp/ bzip2安装 1sudo apt install bzip2 压缩 123bzip2 filenamebzip2 -z filenamebzip2 -z backup.tar 重要：bzip2 默认会在压缩及解压缩文件时删除输入文件（原文件），要保留输入文件，使用-k或者–keep选项。此外，-f或者–force标志会强制让 bzip2 覆盖已有的输出文件 12bzip2 -zk filenamebzip2 -zk backup.tar 你也可以设置块的大小，从 100k 到 900k，分别使用-1或者–fast到-9或者–best： 12345bzip2 -k1 Etcher-linux-x64.AppImagels -lh Etcher-linux-x64.AppImage.bz2 bzip2 -k9 Etcher-linux-x64.AppImage bzip2 -kf9 Etcher-linux-x64.AppImage ls -lh Etcher-linux-x64.AppImage.bz2 解压 要解压缩.bz2文件，确保使用-d或者–decompress选项： 1bzip2 -d filename.bz2 注意：这个文件必须是.bz2的扩展名，上面的命令才能使用。 123bzip2 -vd Etcher-linux-x64.AppImage.bz2 bzip2 -vfd Etcher-linux-x64.AppImage.bz2 ls -l Etcher-linux-x64.AppImage","link":"/2022/04/24/Linux%E4%B8%8Btar,%20tar.gz,%20xz%EF%BC%8Cunzip%EF%BC%8Cbzip2%E6%96%87%E4%BB%B6%E8%A7%A3%E5%8E%8B%E6%96%B9%E6%B3%95/"},{"title":"Linux一些文件及用途","text":"常用文件/etc/sysconfig/network-scripts/ifcfg-eth0 各参数的意思1234567891011121314151617DEVICE=eth0 #网卡设备名称ONBOOT=yes #启动时是否激活 yes | noBOOTPROTO=static #协议类型IPADDR=192.168.1.90 #网络IP地址NETMASK=255.255.255.0 #网络子网地址GATEWAY=192.168.1.1 #网关地址BROADCAST=192.168.1.255 #广播地址HWADDR=00:0C:29:FE:1A:09 #网卡MAC地址TYPE=Ethernet #网卡类型为以太网 /etc/sysconfig/i18ni18n是internationalization的缩写，意思指i和n之间有18个字母。/etc/sysconfig/i18n里面存放着系统的区域语言设置，可以使linux系统支持国际化信息显示。就是支持多种字符集的转换，避免出现乱码。同一时间i18n只能是英文和一种选定的语言，例如英文+中文、英文+德文、英文+韩文等等。使用locale [-a]查看系统当前locale环境变量 1234/etc/sysconfig/i18n 这里存放的是系统的区域语言设置第一行 表明你当前系统的语言环境变量设置 ，这里是 zh_CN.GB18030第二行 表明系统预置了那些语言支持 ，不在项目中的语言不能正常显示第三行 定义控制台终端字体，你文本登录的时候显示的字体就是这个 latarcyrheb-sun16 123456789101112131415[root@localhost chengyao]# locale LANG=zh_CN.GB18030 LC_CTYPE=&quot;zh_CN.GB18030&quot; LC_NUMERIC=&quot;zh_CN.GB18030&quot; LC_TIME=&quot;zh_CN.GB18030&quot; LC_COLLATE=&quot;zh_CN.GB18030&quot; LC_MONETARY=&quot;zh_CN.GB18030&quot; LC_MESSAGES=&quot;zh_CN.GB18030&quot; LC_PAPER=&quot;zh_CN.GB18030&quot; LC_NAME=&quot;zh_CN.GB18030&quot; LC_ADDRESS=&quot;zh_CN.GB18030&quot; LC_TELEPHONE=&quot;zh_CN.GB18030&quot; LC_MEASUREMENT=&quot;zh_CN.GB18030&quot; LC_IDENTIFICATION=&quot;zh_CN.GB18030&quot; LC_ALL= /etc/inittabhttps://blog.csdn.net/localhostcom/article/details/78057132 netplanhttps://www.jianshu.com/p/174656635e74 发行版本1cat /etc/os-release # systemd 比uname -a更全的信息","link":"/2021/12/07/Linux%E4%B8%80%E4%BA%9B%E6%96%87%E4%BB%B6%E5%8F%8A%E7%94%A8%E9%80%94/"},{"title":"Linux下登录Oracle命令行时删除键^H解决方法","text":"在linux服务器下登录oracle的控制台，如果输入错误，想用删除键删除时却不能删除，打出的是^H的字符。 方法1：用如下的命令可以使删除键生效： 1$ stty erase ^H1 恢复以前的设置的命令是： 1$ stty erase ^？1 方法2：利用rlwrap工具解决： 1、安装rlwrap和readline库 CentOS下可以用EPEL的yum源直接安装，步骤如下： （1）RHEL/CentOS/SL Linux 6.x 下安装 EPEL6 yum源： 32位系统选择： 1# rpm -ivh http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm1 64位系统选择： 1# rpm -ivh http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm1 导入key： 1# rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-61 默认会在/etc/yum.repos.d/下创建epel.repo和epel-testing.repo两个配置文件。 （2）安装rlwrap和readline： 1# yum install rlwrap readline readline-devel1 其他Linux发行版如果源里没有rlwrap和readline的（如SUSE企业版默认没有这两个包），要分别下载这两个源码包编译安装一下。 1234567891011121314# wget ftp://ftp.gnu.org/gnu/readline/readline-6.2.tar.gz# tar zxvf readline-6.2.tar.gz# cd readline-6.2/# ./configure# make# make install# wget http://utopia.knoware.nl/~hlub/rlwrap/rlwrap-0.37.tar.gz# tar zxvf rlwrap-0.37.tar.gz# cd rlwrap-0.37/# ./configure# make# make install1234567891011121314 （3）设置sqlplus的系统别名： 1# vim /home/oracle/.bash_profile1 在头部或尾部添加： 12alias sqlplus='rlwrap sqlplus'alias rman='rlwrap rman'12 退出oracle用户再重新登录就ok了。","link":"/2021/04/04/Linux%E4%B8%8B%E7%99%BB%E5%BD%95Oracle%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%97%B6%E5%88%A0%E9%99%A4%E9%94%AE%5EH%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"},{"title":"Linux下使用Vim常用的一些命令","text":"方法一 ：块选择模式批量注释： Ctrl + v 进入块选择模式，然后移动光标选中你要注释的行，再按大写的I进入行首插入模式输入注释符号如 // 或 #，输入完毕之后，按两下ESC，Vim会自动将你选中的所有行首都加上注释，保存退出完成注释。 取消注释： Ctrl + v 进入块选择模式，选中你要删除的行首的注释符号，注意// 要选中两个，选好之后按d即可删除注释，ESC保存退出。 方法二 替换命令批量注释： 使用下面命令在指定的行首添加注释： :起始行号,结束行号s/^/注释符/g 取消注释： :起始行号,结束行号s/^注释符//g 例子： 在10 - 20行添加 // 注释 :10,20s#^#//#g 在10 - 20行删除 // 注释 :10,20s#^//##g 在10 - 20行添加 # 注释 :10,20s/^/#/g 在10 - 20行删除 # 注释 :10,20s/^/#/g 注意：替换方法的例子中正则的分割符使用的是相反的符号，如果匹配// 那么使用 #作分隔符这样不需要对/作转义处理，节省输入次数。 12:s/return/ret/g:%s/return/ret/g 快速清空文件12gg # 跳到行首dG # 删除直到末尾 缩进行首 1ctrl + v 按向下箭头选中行，按 &gt; 或者 &lt; 调整缩进 括号寻找123public function index() {} 光标移动到第一个括号位置，按下%将跳到相应的闭合括号位置 批量删除删除后原位置留空123ctrl + v 上下左右箭头选中按下D 删除后内容上移123ctrl + v 上下左右箭头选中按下:d 或者:%d 格式化1234ggctrl + v G = 或者 1gg=G 缩进 1:10,100&lt; //将10到100行向左缩进 可以使用:set shiftwidth = 2设置缩进，也可以放在.vimrc中 删除一个单词通常要先将光标移动到单词头部，在末行模式按下b即可，再按下dw即可删除。或者直接输入daw删除单词。另外还有一个删除字符x可以在末行模式使用 删除光标后的内容直接D 剪切内容，下面的内容上移v / ctrl + v 选中:d 回车p 粘贴 单词间移动w/e 后， b前 vim 折行折叠方式可用选项 ‘foldmethod’ 来设定折叠方式：set fdm=*****。有 6 种方法来选定折叠： 123456manual 手工定义折叠indent 更多的缩进表示更高级别的折叠expr 用表达式来定义折叠syntax 用语法高亮来定义折叠diff 对没有更改的文本进行折叠marker 对文中的标志折叠 注意，每一种折叠方式不兼容，如不能即用expr又用marker方式，我主要轮流使用indent和marker方式进行折叠。 使用时，用：set fdm=marker 命令来设置成marker折叠方式（fdm是foldmethod的缩写）。要使每次打开vim时折叠都生效，则在.vimrc文件中添加设置，如添加：set fdm=syntax，就像添加其它的初始化设置一样。 折叠命令选取了折叠方式后，我们就可以对某些代码实施我们需要的折叠了，由于我使用indent和marker稍微多一些，故以它们的使用为例：如果使用了indent方式，vim会自动的对大括号的中间部分进行折叠，我们可以直接使用这些现成的折叠成果。在可折叠处（大括号中间）： 12345678zc 折叠zC 对所在范围内所有嵌套的折叠点进行折叠zo 展开折叠zO 对所在范围内所有嵌套的折叠点展开[z 到当前打开的折叠的开始处。]z 到当前打开的折叠的末尾处。zj 向下移动。到达下一个折叠的开始处。关闭的折叠也被计入。zk 向上移动到前一折叠的结束处。关闭的折叠也被计入。 当使用marker方式时，需要用标计来标识代码的折叠，系统默认是{{{`和`}}}，最好不要改动之：）我们可以使用下面的命令来创建和删除折叠： 1234zf 创建折叠，比如在marker方式下： zf56G，创建从当前行起到56行的代码折叠； 10zf或10zf+或zf10↓，创建从当前行起到后10行的代码折叠。 10zf-或zf10↑，创建从当前行起到之前10行的代码折叠。 在括号处zf%，创建从当前行起到对应的匹配的括号上去（（），{}，[]，&lt;&gt;等）。zd 删除 (delete) 在光标下的折叠。仅当 'foldmethod' 设为 &quot;manual&quot; 或 &quot;marker&quot; 时有效。zD 循环删除 (Delete) 光标下的折叠，即嵌套删除折叠。 仅当 'foldmethod' 设为 &quot;manual&quot; 或 &quot;marker&quot; 时有效。zE 除去 (Eliminate) 窗口里“所有”的折叠。 仅当 'foldmethod' 设为 &quot;manual&quot; 或 &quot;marker&quot; 时有效。 查看/修改十六进制或者二进制文件等1hexdump a.txt 1xxd a.txt 1vim -b a.txt xxd是linux的一个命令，vim可以通过”!”来调用外部命令，其功能就是进行十六进制的dump或者反之。 123:%!od :%!xxd:%!xxd -r 16进制转为2进制 参考：http://blog.chinaunix.net/uid-29767867-id-4413135.html推荐：https://blog.csdn.net/xxxxxx91116/article/details/8042312 执行shell脚本报错/usr/bin/env: ‘bash\\r’: No such file or directory主要原因是*.sh是在windows下编辑然后上传到linux系统里执行的。.sh文件的格式为dos格式。而linux只能执行格式为unix格式的脚本。 1234vim release.sh:set ff # 查看fileformat 应该是dos:set ff=unix # 设置为unix:wq 统计关键词出现的次数1:%s/keyword/gn 参数说明： % - 指明操作区间，%表示全文本；可以使用1,$或者行区间代替 s – substitute，表示替换 pattern - 要查找的字符串 // - 替代文本应该放在这里，两个斜杠中间没有任何字符表示无替代文本 g – Replace all occurences in the line. Without this argument, replacement occurs only for the first occurence - in each line. n – Report the number of matches, and do not actually substitute. 这是核心功能，同时也说明为什么//之间可以添加任意字符。 一些引申出的应用： (1) :k,ls/pattern//gn统计k行到l行出现pattern的次数(2) :%s/pattern//gn统计在当前编辑文本出现的次数(3) cat file|greg –i pattern |wc –l统计在文件中出现的行数","link":"/2021/03/30/Linux%E4%B8%8B%E4%BD%BF%E7%94%A8Vim%E5%B8%B8%E7%94%A8%E7%9A%84%E4%B8%80%E4%BA%9B%E5%91%BD%E4%BB%A4/"},{"title":"Linux命令","text":"常用Linux命令ps1ps -ef | grep redis 根据进程id查找文件，找到pid，例如123 1ls -lp /proc/123/cwd cat命令 连接文件并打印到标准输出设备上，cat经常用来显示文件的内容。 注意：当文件较大时，文本在屏幕上迅速闪过（滚屏），用户往往看不清所显示的内容。因此，一般用more等命令分屏显示。 为了控制滚屏，可以按Ctrl+S键，停止滚屏；按Ctrl+Q键可以恢复滚屏。按Ctrl+C（中断）键可以终止该命令的执行，并且返回Shell提示符状态。 -n或-number：有1开始对所有输出的行数编号； -b或–number-nonblank：和-n相似，只不过对于空白行不编号； -s或–squeeze-blank：当遇到有连续两行以上的空白行，就代换为一行的空白行； -A：显示不可打印字符，行尾显示“$”； -e：等价于”-vE”选项； -t：等价于”-vT”选项； ##从键盘创建一个文件 $ cat &gt; d.txt ##将几个文件合并为一个文件 $ cat c.txt d.txt &gt; e.txt ##显示一个文件的内容 $ cat e.txt 显示多个文件的内容 $ cat e.txt a.txt 对所有输出行编号 $ cat -n e.txt 对非空输出行编号 $ cat -b e.txt 如果有连续两行以上的空白行，输出时只显示一行 $ cat -s e.txt 显示不可打印字符，输出时每行结尾会加上一个$ $ cat -A e.txt 将一个文件的内容加上行号后输入到另一个文件里（直接覆盖掉这个文件原来的内容） $ cat -n e.txt &gt; a.txt 将一个文件的内容加上行号后输入到另一个文件里（在尾部追加） $ cat -n e.txt &gt;&gt; a.txt 复制这个文件 $ cat e.txt &gt; a.txt 合并几个文件，并且test4是已经排好序的 $ cat test test1 test2 test3 | sort &gt; test4 如果有大量的文件包含不适合在输出端子和屏幕滚动起来非常快，我们可以多和少用参数与cat命令如上表演。 $ cat e.txt | more $ cat e.txt | less tac命令反序输出文件的内容，文件的最后一行显示在第一行 它可以对调试日志文件提供了很大的帮助，扭转日志内容的时间顺序。 $ tac e.txt lsattr, chattr查看和修改文件属性 jobs1jobs -rp // 暂时不知到什么用 查看挂起的进程，kill %1 可以停止jobs中标号为1的进程 也可以使用fg %1 来切到前台，部分可能不需要% statawkzcatzgreptee12345678# 将sql输入到文件back.sqltee back.sql &lt;&lt;-'EOT'insert intousers(id)values1;EOT sed1sed -e &quot;1ititle:test&quot; back.txt // 给back.txt文件第一行前添加title:text jq 解析json 1echo '{&quot;name&quot;: &quot;max&quot;}' | jq ls123ls -SX 按照文件类型排序，文件夹在前ll -ht 按照时间排序ll -hS 按照大小排序 https://www.cnblogs.com/ginvip/p/6351696.html nohuphttps://www.cnblogs.com/baby123/p/6477429.html pidofhttps://www.cnblogs.com/fengzhilaoling/p/12269923.html killhttps://blog.csdn.net/u010486679/article/details/78415666 hostnamehttps://blog.csdn.net/qhairen/article/details/45913465 expr12expr 1 + 2expr lentdh &quot;test&quot; Linux expr命令 | 菜鸟教程 (runoob.com) lscpu查看CPU信息 lsmem查看内存信息 cutcut命令用于显示每行从开头算起 num1 到 num2 的文字 Linux cut命令 | 菜鸟教程 (runoob.com) netcat(38条消息) Linux系统终端命令：netcat的基本使用_麒麒川的博客-CSDN博客_linux netcat systemctl1systemctl status -l ssh1ssh -n -x ssh-keygen12ssh-keygen -t rsassh-keygen -A htoplocate1updatedb 更新locatedb findfreetreealias调试objdumpgdbPHP相关12php --ri grpc // 查看swoole扩展php -l index.php // 检查语法错误 安装build-essential1apt-get install build-essential lrzsz，可以在ssh终端中上传和下载文件安装ubuntu下 1sudo apt install lrzsz 或者编译安装 12345tar zxvf lrzsz-0.12.20.tar.gzcd lrzsz-0.12.20./configuremakemake install 上面安装过程默认把lsz和lrz安装到了/usr/local/bin/目录下,可以建立一个软连接 123cd /usr/binln -s /usr/local/bin/lrz rzln -s /usr/local/bin/lsz sz 上传 1rz 下载 1sz &lt;filename&gt; killall命令找不到，可以用下面的命令安装 1apt-get install psmisc put上传ftp文件put 使用lftp登录ftp服务器之后，可以使用put指令将文件上传到服务器。 ##语法 put [-E] [-a] [-c] [-O base] lfile [-o rfile] ##选项列表 选项 说明 -o 指定输出文件的名字，不指定则使用原来的名字 -c 如果失败，持续获取 -E 获取之后，删除源文件 -a 使用ascii模式 -O 指定输出文件存放的目录 ##实例 上传文件 123456789101112131415161718192021[root@localhost weijie]# lftp 192.168.1.8 //登录服务器lftp 192.168.1.8:~&gt; cd pub/ //切换目录lftp 192.168.1.8:/pub&gt; put 3.c //上传文件65 bytes transferredlftp 192.168.1.8:/pub&gt; ls //查看内容，已经上传成功-rwxrwxrwx 1 0 0 2375494044 Aug 14 06:38 1.zip-rw-r--r-- 1 0 0 0 Oct 02 01:19 11c-rw-r--r-- 1 0 0 0 Oct 02 01:19 22c-rw------- 1 14 50 65 Oct 02 01:48 3.cdrwxr-xr-x 2 0 0 4096 Oct 02 01:12 testftplftp 192.168.1.8:/pub&gt; 测试端口 linux测试某个端口的bai连通性可以du使用zhi如下命令测试daoTCP协议 1telnet ip port TCP/UDP协议测试zhuan端口 12nc -vuz ip port #测试udp协议nc -vtz ip port #测试tcp协议 端口扫描 nc -z -v -n 192.168.21.135 1-100 z参数告诉nc使用0 输入/输出模式，一般在扫描通信端口的时候使用 12Nc -z -v -n 192.168.21.135 1-100 # 检测1-100端口Nc -z -v -n 192.168.21.135 8989 #检测8989端口 lsof 你可以使用 lsof 命令来查看某一端口是否开放。查看端口可以这样来使用，我就以80端口为例： lsof -i:80或者lsof -i:22如果有显示说明已经开放了，如果没有显示说明没有开放##netstat -aptn是否监听在0.0.0.0:3306 其他方式netstat -nupl (UDP类型的端口)netstat -ntpl (TCP类型的端口) telnet ip端口号 方式 测试远程主机端口是否打开 telnet 127.0.0.1 3306 #其他命令 删除输入的错误有时候在linux终端中执行某个命令时，往往会输错命令，想删除掉重敲可以按backspace键，但这样较慢，一种简便技巧是，按住esc键同时按backspace键会较快删除【esc+backspace】组合键。或者【ctrl+u】组合键 当然，直接回车更直接，但可能会产生一堆的错误提示。##vimv / ctrl + v 可视模式，&lt; &gt; 缩进，d,D,y dw d$ vim :行号，行号&lt; 回车 可以缩进 vim中统计文字出现次数 :%s/name//gn ##其他lhalinux 的 ls -1 和 -lshell 的[ -s file] 文件大小不为0为真 eliflcd put lftppsql -c -fhttps://www.cnblogs.com/ftl1012/p/ssh.htmlhttps://www.cnblogs.com/hmwh/p/11015439.html telnet 1telnet 127.0.0.1 9501 退出 ctrl + ] 再按ctrl + d 或者输入 quit 笔记linuxvim ctrl + g 显示当前编辑的文件名 sudo nautilus ubuntu以管理员方式打开文件可视化文件管理器 apt install build-essential ubuntu安装需要的文件 du -sh df -h 查看硬盘占用情况 wc -l -w -c / -lwc 统计行数，字数字节数 排除grep -v 包含 egrep/grep -e 'a|b|c' 路径 可以使用正则 cat /tac tail head ps -ef/af/x/aux 不与终端有关的进程也显示出来 pstree -Aup kill -9 强制结束 kill -2 相当于ctrl+c 数字+G 跳行，数字+D删除数字+Y复制，:setnu显示行号，G/gg ，dd`剪切 su + username 切换用户 ctrl + d 注销 sudo -l 查看自己的权限 visudo 修改用户权限 admin[用户] ALL[允许登录的主机]=(ALL[以root运行]) ALL[所有命令] [%]s/搜索内容/替换内容/[g] %表示替换所有，没有g表示一行，有g表示所有 netstat -tunpl | grep 80 查看80口占用 -ano -lntp列出系统里监听网络链接的端口号和相应进程pid lsof [-i :80] 列出当前系统打开的文件(listen opened files) ubuntu-drivers devices 查看可以安装的闭源显卡驱动 apt editor-sources 修改源 select-editor 更换默认编辑器 chown/chgrp -R 用户名/组名 文档 chown -R username:group /etc/文件…同时修改 rsync {d}{rwx}{rwx}{rwx} -&gt; d表示文件夹，rwx-1 表示拥有者，rwx-2表示用户所在组，rwx-3表示其他人，使用chmod修改权限 chmod ug+w,o-w file1.txt file2.txt 给file1.txt 和file2.txt 加上对用户和用户组的写权限，去掉其他人的写权限 清空文件 gg跳到行首dG清空 ctrl-c 发送 SIGINT 信号给前台进程bai组中的所有进du程。常用于终止正在运zhi行的程序。ctrl-z 发送 SIGTSTP 信号给前台进程dao组中的所有进程，常用于挂起一个进程。用户可以使用fg/bg操作继续前台或后台的任务，fg命令重新启动前台被中断的任务,bg命令把被中断的任务放在后台执行.ctrl-d 不是发送信号，而是表示一个特殊的二进制值，表示 EOF。ctrl-\\ 发送 SIGQUIT 信号给前台进程组中的所有进程，终止前台进程并生成 core 文件。 linux添加计划任务 crond 是linux用来定期执行程序的命令。当安装完成操作系统之后，默认便会启动此任务调度命令。crond命令每分锺会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作。可以用以下的方法启动、关闭这个服务: /sbin/service crond start //启动服务 /sbin/service crond stop //关闭服务 /sbin/service crond restart //重启服务 /sbin/service crond reload //重新载入配置 1.linux任务调度的工作主要分为以下两类： *系统执行的工作：系统周期性所要执行的工作，如备份系统数据、清理缓存 *个人执行的工作：某个用户定期要做的工作，例如每隔10分钟检查邮件服务器是否有新信，这些工作可由每个用户自行设置。 2.crontab命令选项: cron服务提供crontab命令来设定cron服务的，以下是这个命令的一些参数与说明: crontab -u //设定某个用户的cron服务，一般root用户在执行这个命令的时候需要此参数 crontab -l //列出某个用户cron服务的详细内容 crontab -r //删除没个用户的cron服务 crontab -e //编辑某个用户的cron服务 比如说root查看自己的cron设置:crontab -u root -l 再例如，root想删除fred的cron设置:crontab -u fred -r 在编辑cron服务时，编辑的内容有一些格式和约定，输入:crontab -u root -e 进入vi编辑模式，编辑的内容一定要符合下面的格式:*/1 * * * * ls &gt;&gt; /tmp/ls.txt 3.cron文件语法 分 小时 日 月 星期 命令 0-59 0-23 1-31 1-12 0-6 command (取值范围,0表示周日一般一行对应一个任务) 4.记住几个特殊符号的含义: “*”代表取值范围内的数字, “/“代表”每”, “-“代表从某个数字到某个数字, “,”分开几个离散的数字 5.举几个例子 5 * * * * ls //指定每小时的第5分钟执行一次ls命令 30 5 * * * ls //指定每天的 5:30 执行ls命令 30 7 8 * * ls //指定每月8号的7：30分执行ls命令 30 5 8 6 * ls //指定每年的6月8日5：30执行ls命令 30 6 * * 0 ls //指定每星期日的6:30执行ls命令[注：0表示星期天，1表示星期1，以此类推，也可以用英文来表示，sun表示星期天，mon表示星期一等。] 30 3 10,20 * * ls //每月10号及20号的3：30执行ls命令[注：”,”用来连接多个不连续的时段] 25 8-11 * * * ls //每天8-11点的第25分钟执行ls命令[注：”-”用来连接连续的时段] */15 * * * * ls //每15分钟执行一次ls命令 [即每个小时的第0 15 30 45 60分钟执行ls命令 ] 30 6 */10 * * ls //每个月中，每隔10天6:30执行一次ls命令[即每月的1、11、21、31日是的6：30执行一次ls命令。 ] 50 7 * * * root run-parts /etc/cron.daily //每天7：50以root 身份执行/etc/cron.daily目录中的所有可执行文件[ 注：run-parts参数表示，执行后面目录中的所有可执行文件。 ] 6.新增调度任务可用两种方法： a.在命令行输入: crontab -e 然后添加相应的任务，wq存盘退出。 b.直接编辑/etc/crontab 文件，即vi /etc/crontab，添加相应的任务。 lsb_release -a ubuntu 查看版本信息 uname [参数] 12345678910111213141516171819202122232425$ uname -a //显示所有信息Linux BigManing 4.4.0-83-generic #106-Ubuntu SMP Mon Jun 26 17:54:43 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux$ uname -s //显示内核名称Linux$ uname -n //显示网络节点上的主机名BigManing$ uname -r //显示内核发行号4.4.0-83-generic$ uname -v //显示内核版本号#106-Ubuntu SMP Mon Jun 26 17:54:43 UTC 2017 $ uname -m //显示机器硬件名称 显示i686说明你安装了32位操作系统 显示 x86_64说明你安装了64位操作系统x86_64$ uname -p //显示处理器类型x86_64$ uname -i //显示硬件平台x86_64$ uname -o //操作系统GNU/Linux wget在下载的时候就重命名: wget -c &quot;www.baidu.com&quot; -O baidu.index.html保存输出日至，可以使用: wget -c &quot;www.baidu.com&quot; -O baidu.index.html -o wget.log 递归下载 12345678910111213$ wget -r -p -np -k http://archives.fedoraproject.org/pub/archive/epel/5Server/x86_64/$ wget -r -p -np -k http://archives.fedoraproject.org/pub/epel/6Server/x86_64/-c, --continue resume getting a partially-downloaded file. 断点续传-nd, --no-directories don't create directories. 不创建层级目录，所有文件下载到当前目录-r, --recursive specify recursive download. 递归下载-p, --page-requisites get all images, etc. needed to display HTML page. 下载页面所有文件，使页面能在本地打开-k, --convert-links make links in downloaded HTML or CSS point to local files. 转换链接指向本地文件-np, --no-parent don't ascend to the parent directory. 不下载父级目录的文件-o, --output-file=FILE log messages to FILE. 指定日志输出文件-O, --output-document=FILE write documents to FILE. 指定文件下载位置-L, --relative follow relative links only. 只下载相对链接，如果页面嵌入其他站点不会被下载wget -m&lt;镜像/整站抓取&gt; -e rebots=off&lt;忽略robots协议&gt; -k&lt;将绝对url转换为本地相对url&gt; -E&lt;将所有text/html以html扩展名保存&gt; 'http://baidu,com' fdisk -llsblk -f 创建两个文件touch app.{js,css} linux下如何输入EOF1ctrl + d 不同系统有不同组合键 12345678int main(int argc, char *argv[]){ int c; while ((c = getc(stdin)) != EOF) { putc(c, stdout); }} umask1umask 022 查看进程占用网速和流量使用情况 有三个命令vnstat、iftop、nethogs（推荐） vnstat1vnstat -i eth0 -l #实时流量情况 iftopiftop可以用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等 命令用法： -i设定监测的网卡，如：# iftop -i eth1 -B 以bytes为单位显示流量(默认是bits)，如：# iftop -B -n使host信息默认直接都显示IP，如：# iftop -n -N使端口信息默认直接都显示端口号，如: # iftop -N 交互命令： 按n切换显示本机的IP或主机名; 按s切换是否显示本机的host信息; 按d切换是否显示远端目标主机的host信息; 按t切换显示格式为2行/1行/只显示发送流量/只显示接收流- 量; 按N切换显示端口号或端口服务名称; 按S切换是否显示本机的端口信息; 按D切换是否显示远端目标主机的端口信息; 按p切换是否显示端口信息; nethogs 按进程实时统计网络带宽利用率(推荐) 命令用法： 设置5秒钟刷新一次，通过-d来指定刷新频率：nethogs -d 5 监视eth0网络带宽 :nethogs eth0 同时监视eth0和eth1接口 : nethogs eth0 eth1 交互命令：以下是NetHogs的一些交互命令(键盘快捷键) m : 修改单位 r : 按流量排序 s : 按发送流量排序 q : 退出命令提示符 匹配进程名结束进程ps -ef | grep 进程名 | awk ‘{ print $2 }’ | xargs kill -9 expect12345678910111213#!/usr/bin/expectset user &quot;git账号&quot;set pass &quot;密码&quot;set timeout 10spawn git pull # spawn启动新的进程expect &quot;Username*&quot; # 匹配username*send &quot;$user\\n&quot; #发送账号到进程内expect &quot;Password*&quot; # 匹配passwordsend &quot;$pass\\n&quot; #发送密码到进程内expect eofexpect -f pull.sh #运行脚本 查看公网ip1curl ifconfig.me","link":"/2021/11/07/Linux%E5%91%BD%E4%BB%A4/"},{"title":"MongoDB学习笔记","text":"优劣：高性能、易部署、易使用，存储数据非常方便。 不支持连表查询，不支持sql语句，不支持事务存储过程等，所以不适合存储数据间关系比较复杂的数据，一般主要是当做一个数据仓库来使用。 适用于：日志系统，股票数据等。 不适用于：电子商务系统等需要连多表查询的功能。 概念文档文档是mongoDB中数据的基本单元，类似关系数据库的行， 多个键值对有序地放置在一起便是文档。 MongoDB 中以文档的方式存取记录，如一条记录格式如下： 1234567{ “username”:”Tom”, “age”:10 ,email:’abc@qq.com’,’sex’:男，键,值}{ &quot;username&quot;:&quot;Tom&quot; , &quot;age&quot; : &quot;10&quot; } {“Username”:”Tom”,”age”:10} {“Username”:”Tom” } 注意： （1）以上是几个不同的文档，MongoDB****区分大小写的数据类型，第一个age字段是数字类型，第二个age是字符串类型。 （2）每一个文档尺寸不能超过16M 集合集合就是一组文档，多个文档组成一个集合，集合类似于 mysql里面的表 。 无模式是指，在同一个集合中可以包含不同格式的文档，如： 123{ &quot;Name&quot; : &quot;Mongodb&quot; , &quot;Type&quot; : &quot;Nosql&quot; }{ &quot;UserName&quot; : &quot;Tom&quot; , &quot;age&quot; : 20 , &quot;Gender&quot; : &quot;male&quot; } 以上两个文档可以放在同一个集合中。 在Mysql需要先建表再插入数据， 模式自由（schema-free）：意思是集合里面没有行和列的概念， 注意：MongoDB中的集合不用创建、没有结构，所以可以放不同格式的文档。 数据库多个集合可以组成数据库。一个mongoDB实例可以承载多个数据库，他们之间完全独立。 Mongodb中的数据库和Mysql中的数据库概念类似，只是无需创建。 一个数据库中可以有多个集合。一个集合中可以有多个文档。 其他 单个文档最大16M, 32位系统上单个数据库最大2G 简单使用连接linux下启动mongo后使用mongo命令连接 1mongodb://127.0.0.1:27017 可以使用mongo –help查看帮助 语法1use 数据库 如果不存在，则创建，否则切换。如果创建了没有做任何操作会自动删除。 1show dbs 查看数据库列表 添加文档1db.集合名.insert({}) 集合隐式创建，所以可以直接使用， db表示当前数据库，也就是前面use的数据库，可以使用db命令查看当前数据库，添加命令如下 1db.test.insert({&quot;name&quot;: &quot;max&quot;}) 数据类型是BSON, 支持的值更丰富 在添加的数据中都有一个”_id”的键，值为对象类型 1{ &quot;_id&quot; : ObjectId(&quot;61a365b5e2e6abe7dea43ac8&quot;), &quot;name&quot; : &quot;tet&quot; } ObjectId类型： 每个文档都有一个_id字段，并且同一集合中的_id值唯一，该字段可以是任意类型的数据，默认是一个ObjectId对象。 ObjectId对象对象数据组成：时间戳|机器码|PID|计数器， _id的键值我们可以自己输入，但是不能重复，重复会报错 使用js批量插入 123for(var i = 0; i &lt; 10; i++) { db.test.insert({&quot;name&quot;: &quot;maxphp&quot;, &quot;age&quot;: i})} 查看集合1show tables 查询12345db.集合名.find() // 查询所有db.集合名.find(条件) // 查询某条件下所有db.集合名.findOne() // 查询一个文档db.集合名.findOne(条件) // 查询某条件下一个文档db.集合名.find().pretty() 可以使用操作符 $lt , $lte , $gt , $gte ( &lt; , &lt;= , &gt; , &gt;= ), $ne ( &lt;&gt; ) ,$in , $nin , $or , $not, $mod (取模), $exists, $where 例如 123db.users.find({&quot;age&quot;: {&quot;$gt&quot;: 12}}, {&quot;name&quot;: 1}) // 只显示年龄大于12的用户名字db.users.find({&quot;age&quot;: {&quot;$gt&quot;: 12}}, {&quot;name&quot;: 0}) // 年龄大于12的用户，除了名字其他都显示db.users.find({}, {&quot;$lt&quot;: 1}) 排序 1db.test.find().sort({&quot;age&quot;: 1}) //根据年龄升序， -1为降序 限制 12db.test.find().limit(3) // 查询前3条db.test.find().skip(3).limit(2) // 查询偏移量为3的2个文档 count 1db.test.count() // 查询集合文档总数 删除文档1db.集合名.remove({条件}) // 如果没有条件会删除所有 例如 1db.users.remove({”age“: 5}) // 删除用户中年龄等于5的文档 1db.users.remove({&quot;age&quot;: {&quot;$gt&quot;: 8}}) 删除集合1db.集合名.drop() 删除数据库12use 数据库db.dropDatabase() 更新文档直接修改1db.集合名.update(条件，新文档, 是否新增, 是否修改多条) 是否新增：如果值是1（true）则没有满足条件的则添加。 是否修改多条：若值是1（true），如果满足条件的有多个文档则都要修改 1db.users.update({&quot;age&quot;: 3}, {&quot;age&quot;: 4}, true, true) 上面的修改会导致其他数据键值丢失，所以不推荐 使用修改器$inc : 加一个数字 $set : 修改某一个字段,如果该字段不存在就增这个字段 1db.集合名.update({条件}, {修改器名称: {修改的键: 修改后的值}}) 例如 12db.test.update({&quot;name&quot;: &quot;maxphp&quot;}, {&quot;$set&quot;: {&quot;age&quot;: 14}}, true, true) // 将所有名字为maxphp的修改年龄为14db.test.update({&quot;age&quot;: 14}, {&quot;$inc&quot;: {&quot;age&quot;: 100}}) // 将年龄为14的一个年龄增加100 帮助123help // 全局db.help() // 数据库相关帮助db.集合名.help() // 集合相关帮助 用户管理（权限控制）在mongodb里面的用户是属于数据库的,每个数据库有自己的管理员，管理员登录后，只能操作所属的数据库。 注意：一般在admin数据库中创建的用户授予超级管理员权限，登录后可以操作任何的数据库。 创建用户注意：在开启权限管理控制时，一定先要创建一个超级管理员授予超级管理权限。 1234567use admindb.createUser({user: &quot;root&quot;, pwd: &quot;123456&quot;, roles: [{role: &quot;root&quot;, db: &quot;admin&quot;}]}) // 创建超级管理员use phpdb.createUser({user: &quot;phpadmin&quot;, pwd: &quot;123456&quot;, roles: [{role: &quot;dbOwner&quot;, db: &quot;php&quot;}]}) // 创建普通用户 用户相关 1234show users // 查看当前库的所有用户db.dropUser(&quot;username&quot;) // 删除用户db.updateUser(&quot;admin&quot;, {pwd: &quot;password&quot;}) // 修改admin密码ab.auth(&quot;user&quot;, &quot;pass&quot;) // 使用密码认证 登录 12mongo 数据库 -u 用户名 -p 密码 // 本地mongo IP地址:端口/数据库名称 -u 用户名 -p 密码 // 远程 角色（1）数据库用户角色：read、readWrite; （2）数据库管理角色：dbAdmin、dbOwner、userAdmin； （3）集群管理角色：clusterAdmin、clusterManager、clusterMonitor、hostManager； （4）备份恢复角色：backup、restore； （5）所有数据库角色：readAnyDatabase、readWriteAnyDatabase、userAdminAnyDatabase、 dbAdminAnyDatabase （6）超级用户角色：root","link":"/2021/11/28/MongoDB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"MySQL面试题","text":"唯一索引比普通索引快吗, 为什么 唯一索引不一定比普通索引快, 还可能慢。 查询时, 在未使用 limit 1 的情况下, 在匹配到一条数据后, 唯一索引即返回, 普通索引会继续匹配下一条数据, 发现不匹配后返回. 如此看来唯一索引少了一次匹配, 但实际上这个消耗微乎其微. 更新时, 这个情况就比较复杂了. 普通索引将记录放到 change buffer 中语句就执行完毕了. 而对唯一索引而言, 它必须要校验唯一性, 因此, 必须将数据页读入内存确定没有冲突, 然后才能继续操作. 对于写多读少的情况, 普通索引利用 change buffer 有效减少了对磁盘的访问次数, 因此普通索引性能要高于唯一索引。 MySQL由哪些部分组成, 分别用来做什么 一. Server 连接器: 管理连接, 权限验证. 分析器: 词法分析, 语法分析. 优化器: 执行计划生成, 索引的选择. 执行器: 操作存储引擎, 返回执行结果. 二. 存储引擎: 存储数据, 提供读写接口。 MySQL查询缓存有什么弊端, 应该什么情况下使用, 8.0版本对查询缓存有什么变更 查询缓存可能会失效非常频繁, 对于一个表, 只要有更新, 该表的全部查询缓存都会被清空. 因此对于频繁更新的表来说, 查询缓存不一定能起到正面效果.对于读远多于写的表可以考虑使用查询缓存.8.0版本的查询缓存功能被删了 (￣.￣)。4.MyISAM和InnoDB的区别有哪些 InnoDB支持事务, MyISAM不支持； InnoDB支持行级锁, MyISAM支持表级锁； InnoDB支持多版本并发控制(MVVC), MyISAM不支持； InnoDB支持外键, MyISAM不支持； MyISAM支持全文索引, InnoDB部分版本不支持(但可以使用Sphinx插件)； 5.MySQL怎么恢复半个月前的数据 通过整库备份+binlog进行恢复. 前提是要有定期整库备份且保存了binlog日志6.MySQL事务的隔离级别, 分别有什么特点 读未提交(RU): 一个事务还没提交时, 它做的变更就能被别的事务看到. 读提交(RC): 一个事务提交之后, 它做的变更才会被其他事务看到. 可重复读(RR): 一个事务执行过程中看到的数据, 总是跟这个事务在启动时看到的数据是一致的. 当 然在可重复读隔离级别下, 未提交变更对其他事务也是不可见的. 串行化(S): 对于同一行记录, 读写都会加锁. 当出现读写锁冲突的时候, 后访问的事务必须等前一个事务执行完成才能继续执行 做过哪些MySQL索引相关优化 尽量使用主键查询: 聚簇索引上存储了全部数据, 相比普通索引查询, 减少了回表的消耗.MySQL5.6之后引入了索引下推优化, 通过适当的使用联合索引, 减少回表判断的消耗.若频繁查询某一列数据, 可以考虑利用覆盖索引避免回表.联合索引将高频字段放在最左边。 简要说一下数据库范式 第一范式: 属性不可再分。第二范式: 在一范式的基础上, 要求数据库表中的每个实例或行必须可以被惟一地区分. 通常需要为表加上一个列, 以存储各个实例的惟一标识. 这个惟一属性列被称为主关键字或主键。第三范式: 在二范式的基础上, 要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。 所以第三范式具有如下特征：1). 每一列只有一个值. 2). 每一行都能区分. 3). 每一个表都不包含其他表已经包含的非主关键字信息。 一千万条数据的表, 如何分页查询 数据量过大的情况下, limit offset 分页会由于扫描数据太多而越往后查询越慢. 可以配合当前页最后一条ID进行查询, SELECT * FROM T WHERE id &gt; #{ID} LIMIT #{LIMIT} . 当然, 这种情况下ID必须是有序的, 这也是有序ID的好处之一。 订单表数据量越来越大导致查询缓慢, 如何处理 分库分表. 由于历史订单使用率并不高, 高频的可能只是近期订单, 因此, 将订单表按照时间进行拆分, 根据数据量的大小考虑按月分表或按年分表. 订单ID最好包含时间(如根据雪花算法生成), 此时既能根据订单ID直接获取到订单记录, 也能按照时间进行查询。MySQL基础 在这里插入图片描述 一张表里面有 ID 自增主键当 当insert 了17 条记录之后 ，删除了第 15,16,17 条记录 ， 再把Mysql 重启 ，再insert 一条记录，这条记录的 ID 是18还是15 ？ 如果表的类型是MyISAM，那么是18。因为MyISAM表会把自增主键的最大ID记录到内存中，所以重启数据库或者是对表进行OPTIMIZE操作，都会导致最大ID丢失。 2 .Mysql 的技术特点是什么？ Mysql 数据库软件是一个客户端或服务器系统，其中包括：支持各种客户端程序和库的多线程 SQL 服务器、不同的后端、广泛的应用程序编程接口和管理工具。 3.Heap 表是什么？ HEAP 表存在于内存中，用于临时高速存储。 BLOB 或 TEXT 字段是不允许的 只能使用比较运算符=，&lt;，&gt;，=&gt;，= &lt; HEAP 表不支持 AUTO_INCREMENT 索引不可为 NULL 4.Mysql 服务器默认端口是什么？ Mysql 服务器的默认端口是 3306。5.与 Oracle 相比，Mysql 有什么优势？ Mysql 是开源软件，随时可用，无需付费。 Mysql 是便携式的 带有命令提示符的 GUI。 使用 Mysql 查询浏览器支持管理 6.如何区分FLOAT和DOUBLE ？ 以下是 FLOAT 和 DOUBLE 的区别： 浮点数以 8 位精度存储在 FLOAT 中，并且有四个字节。 浮点数存储在 DOUBLE 中，精度为 18 位，有八个字节。 7.区分 CHAR_LENGTH 和 和 LENGTH CHAR_LENGTH 是字符数，而 LENGTH 是字节数。Latin 字符的这两个数据是相同的，但是对于 Unicode 和其他编码，它们是不同的。8.在 Mysql 中 ENUM 的用法是什么？ ENUM 是一个字符串对象，用于指定一组预定义的值，并可在创建表时使用。Create table size(name ENUM(‘Smail,’Medium’,’Large’);9.如何定义 REGEXP ？ REGEXP 是模式匹配，其中匹配模式在搜索值的任何位置。10 .CHAR 和 和 VARCHAR 的区别？ 以下是 CHAR 和 VARCHAR 的区别： CHAR 和 VARCHAR 类型在存储和检索方面有所不同 CHAR 列长度固定为创建表时声明的长度，长度值范围是 1 到 255当 CHAR 值被存储时，它们被用空格填充到特定长度，检索 CHAR 值时需删除尾随空格。 11.列的字符串类型可以是什么？ 字符串类型是： SET BLOB ENUM CHAR TEXT VARCHAR 12.如何获取当前的 l Mysql 版本？ SELECT VERSION();用于获取当前 Mysql 的版本。 Mysql 中使用什么存储引擎？ 存储引擎称为表类型，数据使用各种技术存储在文件中。技术涉及： Storage mechanism Locking levels Indexing Capabilities and functions. 14.Mysql 驱动程序是什么？ 以下是 Mysql 中可用的驱动程序： PHP 驱动程序 JDBC 驱动程序 ODBC 驱动程序 CWRAPPER PYTHON 驱动程序 PERL 驱动程序 RUBY 驱动程序 CAP11PHP 驱动程序 Ado.net5.mxj 15.TIMESTAMP 在 在 UPDATE P CURRENT_TIMESTAMP 数据类型上做什么？ 创建表时 TIMESTAMP 列用 Zero 更新。只要表中的其他字段发生更改，UPDATECURRENT_TIMESTAMP 修饰符就将时间戳字段更新为当前时间。16.主键和候选键有什么区别？ 表格的每一行都由主键唯一标识,一个表只有一个主键。主键也是候选键。按照惯例，候选键可以被指定为主键，并且可以用于任何外键引用。17.如何使用 Unix l shell 登录 Mysql ？ 我们可以通过以下命令登录：18.myisamchk 是用来做什么的？ 它用来压缩 MyISAM 表，这减少了磁盘或内存使用。19.如何控制 HEAP 表的最大尺寸？ Heal 表的大小可通过称为 max_heap_table_size 的 Mysql 配置变量来控制。 MyISAM Static 和 和 MyISAM Dynamic 有什么区别？ 在 MyISAM Static 上的所有字段有固定宽度。动态 MyISAM 表将具有像 TEXT，BLOB等字段，以适应不同长度的数据类型。MyISAM Static 在受损情况下更容易恢复。21.federated 表是什么？ federated 表，允许访问位于其他服务器数据库上的表。22.如果一个表有一列定义为 TIMESTAMP ，将发生什么？ 每当行被更改时，时间戳字段将获取当前时间戳。 列设置为 AUTO INCREMENT 时，如果在表中达到最大值，会发生什么情况？ 它会停止递增，任何进一步的插入都将产生错误，因为密钥已被使用。24.怎样才能找出最后一次插入时分配了哪个自动增量？ LAST_INSERT_ID 将返回由 Auto_increment分配的最后一个值，并且不需要指定表名称。25.你怎么看到为表格定义的所有索引？ 索引是通过以下方式为表格定义的：sqlqSHOW INDEX FROM ; LIKE 声明中的％和_ 是什么意思？ ％对应于 0 个或更多字符，_只是 LIKE 语句中的一个字符。27.如何在 x Unix 和 和 l Mysql 时间戳之间进行转换？ UNIX_TIMESTAMP 是从 Mysql 时间戳转换为 Unix 时间戳的命令FROM_UNIXTIME 是从 Unix 时间戳转换为 Mysql 时间戳的命令28.列对比运算符是什么？ 在 SELECT 语句的列比较中使用=，&lt;&gt;，&lt;=，&lt;，&gt; =，&gt;，&lt;&lt;，&gt;&gt;，&lt;=&gt;，AND，OR 或LIKE 运算符。29.我们如何得到受查询影响的行数？ 行数可以通过以下代码获得：SELECT COUNT(user_id)FROM users;30.Mysql 查询是否区分大小写？ 不区分 所有这些例子都是一样的，Mysql 不区分大小写。31.LIKE 和 REGEXP 操作有什么区别？ LIKE 和 REGEXP 运算符用于表示^和％。SELECT * FROM employee WHERE emp_name REGEXP “^b”;SELECT * FROM employee WHERE emp_name LIKE “%b”; BLOB 和 和 TEXT 有什么区别？ BLOB 是一个二进制对象，可以容纳可变数量的数据。有四种类型的 BLOB TINYBLOB BLOB MEDIUMBLOB LONGBLOB 它们只能在所能容纳价值的最大长度上有所不同。TEXT 是一个不区分大小写的 BLOB。四种 TEXT 类型 TINYTEXT TEXT MEDIUMTEXT LONGTEXT 它们对应于四种 BLOB 类型，并具有相同的最大长度和存储要求。BLOB 和 TEXT 类型之间的唯一区别在于对 BLOB 值进行排序和比较时区分大小写，对TEXT 值不区分大小写。33.mysql_fetch_array 和 和 mysql_fetch_object 的区别是什么？ 以下是 mysql_fetch_array 和 mysql_fetch_object 的区别： mysql_fetch_array（） - 将结果行作为关联数组或来自数据库的常规数组返回。 mysql_fetch_object - 从数据库返回结果行作为对象。 34.我们如何在 mysql 中运行批处理模式？ 以下命令用于在批处理模式下运行：35.MyISAM 表格将在哪里存储，并且还提供其存储格式？ 每个 MyISAM 表格以三种格式存储在磁盘上： “.frm”文件存储表定义 数据文件具有“.MYD”（MYData）扩展名 索引文件具有“.MYI”（MYIndex）扩展名 Mysql 中有哪些不同的表格？ 共有 5 种类型的表格： MyISAM Heap Merge INNODB ISAM MyISAM 是 Mysql 的默认存储引擎。 SAM 是什么？ ISAM 简称为索引顺序访问方法。它是由 IBM 开发的，用于在磁带等辅助存储系统上存储和检索数据。38.Mysql 如何优化 DISTINCT ？ DISTINCT 在所有列上转换为 GROUP BY，并与 ORDER BY 子句结合使用。SELECT DISTINCT t1.a FROM t1,t2 where t1.a=t2.a;39.如何输入字符为十六进制数字？ 如果想输入字符为十六进制数字，可以输入带有单引号的十六进制数字和前缀（X），或者只用（Ox）前缀输入十六进制数字。如果表达式上下文是字符串，则十六进制数字串将自动转换为字符串。40.如何显示前 0 50 行？ 在 Mysql 中，使用以下代码查询显示前 50 行：SELECT*FROM xx LIMIT 0,50;41.可以使用多少列创建索引？ 任何标准表最多可以创建 16 个索引列。42.NOW（）和 CURRENT_DATE （）有什么区别？ NOW（）命令用于显示当前年份，月份，日期，小时，分钟和秒。CURRENT_DATE（）仅显示当前年份，月份和日期。43.什么样的对象可以使用 CREATE 语句创建？ 以下对象是使用 CREATE 语句创建的： DATABASE EVENT FUNCTION INDEX PROCEDURE TABLE TRIGGER USER VIEW 44.解释访问控制列表 ACL（访问控制列表）是与对象关联的权限列表。这个列表是 Mysql 服务器安全模型的基础，它有助于排除用户无法连接的问题。 Mysql 将 ACL（也称为授权表）缓存在内存中。当用户尝试认证或运行命令时，Mysql 会按照预定的顺序检查 ACL 的认证信息和权限。 45.MYSQL 数据表在什么情况下容易损坏？ 服务器突然断电导致数据文件损坏。强制关机，没有先关闭 mysql 服务等。46.mysql 有关权限的表都有哪几个？ Mysql 服务器通过权限表来控制用户对数据库的访问，权限表存放在 mysql 数据库里，由mysql_install_db 脚本初始化。这些权限表分别 user，db，table_priv，columns_priv和 host。MySQL中级1.MySQL 中有哪几种锁？ 表级锁： 开销小， 加锁快； 不会出现死锁； 锁定粒度大， 发生锁冲突的概率最高， 并发度最低。 行级锁： 开销大， 加锁慢； 会出现死锁； 锁定粒度最小， 发生锁冲突的概率最低， 并发度也最高。 页面锁： 开销和加锁时间界于表锁和行锁之间； 会出现死锁； 锁定粒度界于表锁和行锁之间， 并发度一般。 2.MySQL 中有哪些不同的表格？ 共有 5 种类型的表格： 1、MyISAM2、Heap 3、Merge 4、INNODB 5、MISAM 3.简述在MySQL 数据库中 MyISAM 和InnoDB 的区别 MyISAM： 不支持事务， 但是每次查询都是原子的； 支持表级锁， 即每次操作是对整个表加锁； 存储表的总行数；一个 MYISAM 表有三个文件： 索引文件、表结构文件、数据文件；采用菲聚集索引， 索引文件的数据域存储指向数据文件的指针。辅索引与主索引基本一致， 但是辅索引不用保证唯一性。 InnoDb： 支持 ACID 的事务， 支持事务的四种隔离级别； 支持行级锁及外键约束： 因此可以支持写并发； 不存储总行数：一个 InnoDb 引擎存储在一个文件空间（ 共享表空间， 表大小不受操作系统控制，一个表可能分布在多个文件里）， 也有可能为多个（ 设置为独立表空， 表大小受操作系统文件大小限制， 一般为 2G）， 受操作系统文件大小的限制；主键索引采用聚集索引（ 索引的数据域存储数据文件本身）， 辅索引的数据域存储主键的值； 因此从辅索引查找数据， 需要先通过辅索引找到主键值， 再访问辅索引； 最好使用自增主键， 防止插入数据时， 为维持 B+树结构， 文件的大调整。 4.MySQL 中InnoDB 支持的四种事务隔离级别名称，以及逐级之间的区别？ SQL 标准定义的四个隔离级别为： read uncommited ： 读到未提交数据 read committed： 脏读， 不可重复读 repeatable read： 可重读 serializable ： 串行事物 5.CHAR 和VARCHAR 的区别？ CHAR 和 VARCHAR 类型在存储和检索方面有所不同 CHAR 列长度固定为创建表时声明的长度， 长度值范围是 1 到 255 当 CHAR 值被存储时， 它们被 用空格填充到特定长度， 检索 CHAR 值时需删除尾随空格。 6.主键和候选键有什么区别？ 表格的每一行都由主键唯一标识,一个表只有一个主键。主键也是候选键。按照惯例， 候选键可以被指定为主键， 并且可以用于任何外键引用。7.myisamchk 是用来做什么的？ 它用来压缩 MyISAM 表， 这减少了磁盘或内存使用。 MyISAM Static 和 MyISAM Dynamic 有什么区别？ 在 MyISAM Static 上的所有字段有固定宽度。动态 MyISAM 表将具有像 TEXT， BLOB 等字段， 以适应不同长度的数据类型。MyISAM Static 在受损情况下更容易恢复。 8.如果一个表有一列定义为TIMESTAMP，将发生什么？ 每当行被更改时， 时间戳字段将获取当前时间戳。列设置为 AUTO INCREMENT 时， 如果在表中达到最大值， 会发生什么情况？它会停止递增， 任何进一步的插入都将产生错误， 因为密钥已被使用。怎样才能找出最后一次插入时分配了哪个自动增量？LAST_INSERT_ID 将返回由 Auto_increment 分配的最后一个值， 并且不需要指定表名称。 9.你怎么看到为表格定义的所有索引？ 索引是通过以下方式为表格定义的：10.LIKE 声明中的％是什么意思？ ％ 对应于 0 个或更多字符，只是 LIKE 语句中的一个字符。11.列对比运算符是什么？ 在 SELECT 语句的列比较中使用=，&lt;&gt;，&lt;=，&lt;，&gt; =，&gt;，&lt;&lt;，&gt;&gt;，&lt;=&gt;，AND， OR 或 LIKE 运算符。12.BLOB 和TEXT 有什么区别？ BLOB 是一个二进制对象， 可以容纳可变数量的数据。TEXT 是一个不区分大小写的 BLOB。BLOB 和 TEXT 类型之间的唯一区别在于对 BLOB 值进行排序和比较时区分大小写， 对 TEXT 值不区分大小写。13.MySQL_fetch_array 和MySQL_fetch_object 的区别是什么？ 以下是 MySQL_fetch_array 和 MySQL_fetch_object 的区别： MySQL_fetch_array（ ） – 将结果行作为关联数组或来自数据库的常规数组返回。 MySQL_fetch_object – 从数据库返回结果行作为对象。 14.MyISAM 表格将在哪里存储，并且还提供其存储格式？ 每个 MyISAM 表格以三种格式存储在磁盘上： ·“.frm” 文件存储表定义 ·数据文件具有“.MYD”（ MYData） 扩展名索引文件具有“.MYI”（ MYIndex） 扩展名 15.如何显示前 50 行？ 在 MySQL 中， 使用以下代码查询显示前 50 行：SELECT*FROM TABLE LIMIT 0,50;16.可以使用多少列创建索引？ 任何标准表最多可以创建 16 个索引列。17.NOW（）和 CURRENT_DATE（）有什么区别？ NOW（）: 命令用于显示当前年份， 月份， 日期， 小时， 分钟和秒。 CURRENT_DATE（）: 仅显示当前年份， 月份和日期。18.什么是非标准字符串类型？ TINYTEXT TEXT MEDIUMTEXT LONGTEXT 19.什么是通用 SQL 函数？ CONCAT(A, B) – 连接两个字符串值以创建单个字符串输出。通常用于将两个或多个字段合并为一个字段。 FORMAT(X, D)- 格式化数字 X 到 D 有效数字。 CURRDATE(), CURRTIME()- 返回当前日期或时间。 NOW（） – 将当前日期和时间作为一个值返回。 MONTH（）， DAY（ ）， YEAR（）， WEEK（）， WEEKDAY（） – 从日期值中提取给定数据。 HOUR（）， MINUTE（）， SECOND（） – 从时间值中提取给定数据。 DATEDIFF（ A， B） – 确定两个日期之间的差异， 通常用于计算年龄 SUBTIMES（ A， B） – 确定两次之间的差异。 FROMDAYS（ INT） – 将整数天数转换为日期值。 20.MySQL 支持事务吗？ 在缺省模式下，MySQL 是 autocommit 模式的，所有的数据库更新操作都会即时提交， 所以在缺省情况下， MySQL 是不支持事务的。 但是如果你的 MySQL 表类型是使用 InnoDB Tables 或 BDB tables 的话， 你的MySQL 就可以使用事务处理,使用SETAUTOCOMMIT=0 就可以使 MySQL 允许在非 autocommit 模式， 在非autocommit 模式下，你必须使用 COMMIT 来提交你的更改，或者用 ROLLBACK 来回滚你的更改。 21.MySQL 里记录货币用什么字段类型好 NUMERIC 和 DECIMAL 类型被 MySQL 实现为同样的类型， 这在 SQL92 标准允许。他们被用于保存值， 该值的准确精度是极其重要的值， 例如与金钱有关的数据。当声明一个类是这些类型之一时， 精度和规模的能被(并且通常是)指定。 例如: salary DECIMAL(9,2) 在这个例子中， 9(precision)代表将被用于存储值的总的小数位数，而 2(scale)代表将被用于存储小数 点后的位数。因此， 在这种情况下， 能被存储在 salary 列中的值的范围是从-9999999.99 到 9999999.99。 22.MySQL 有关权限的表都有哪几个？ MySQL 服务器通过权限表来控制用户对数据库的访问， 权限表存放在 MySQL 数据库里，由MySQL_install_db 脚本初始化。 这些权限表分别 user，db，table_priv， columns_priv 和 host 。 23.列的字符串类型可以是什么？ 字符串类型是： SET BLOB ENUM CHAR TEXT 24.MySQL 数据库作发布系统的存储，一天五万条以上的增量， 预计运维三年,怎么优化？ 设计良好的数据库结构， 允许部分数据冗余， 尽量避免 join 查询， 提高效率。 选择合适的表字段数据类型和存储引擎， 适当的添加索引。 MySQL 库主从读写分离。 找规律分表， 减少单表中的数据量提高查询速度。 添加缓存机制， 比如 memcached， apc等。 不经常改动的页面， 生成静态页面。 书写高效率的 SQL。比如 SELECT * FROM TABEL 改为 SELECT field_1, field_2, field_3 FROM TABLE. 25.锁的优化策略 读写分离 分段加锁 减少锁持有的时间，多个线程尽量以相同的顺序去获取资源不能将锁的粒度过于细化， 不然可能会出现线程的加锁和释 放次数过多， 反而效率不如一次加一把大锁。 26.索引的底层实现原理和优化 B+树，经过优化的 B+树 主要是在所有的叶子结点中增加了指向下一个叶子节点的指针， 因此 InnoDB 建议为大部分表使用默认自增的主键作为主索引。27.什么情况下设置了索引但无法使用 以“%” 开头的 LIKE 语句， 模糊匹配 OR 语句前后没有同时使用索引 数据类型出现隐式转化（ 如 varchar 不加单引号的话可能会自动转换为 int 型） 28.实践中如何优化 MySQL 最好是按照以下顺序优化： SQL 语句及索引的优化 数据库表结构的优化 系统配置的优化 硬件的优化 29.优化数据库的方法 选取最适用的字段属性，尽可能减少定义字段宽度，尽量把字段设置 NOTNULL， 例如省份, 性别 最好适用 ENUM 使用连接(JOIN)来代替子查询 适用联合(UNION)来代替手动创建的临时表 事务处理 锁定表、优化事务处理 适用外键， 优化锁定表 建立索引 优化查询语句 30.简单描述 MySQL 中，索引，主键，唯一索引，联合索引的区别，对数据库的性能有什么影响（从读写两方面） 索引是一种特殊的文件(InnoDB 数据表上的索引是表空间的一个组成部分)， 它们包含着对数据表里所有记录的引用指针。 普通索引(由关键字KEY或 INDEX定义的索引)的唯一任务是加快对数据的访问速度。普通索引允许被索引的数据列包含重复的值。如果能确定某个数据列将只包含彼此各不相同的值， 在为这个数据列创建索引的时候就应该用关键字UNIQUE 把它定义为一个唯一索引。也就是说， 唯一索引可以保证数据记录的唯一性。 主键， 是一种特殊的唯一索引， 在一张表中只能定义一个主键索引， 主键用于唯一标识一条记录， 使用关键字 PRIMARY KEY 来创建。索引可以覆盖多个数据列，如像INDEX(columnA, columnB)索引，这就是联合索引。索引可以极大的提高数据的查询速度， 但是会降低插入、删除、更新表的速度， 因为在执行这些写操作时， 还要操作索引文件。 31.数据库中的事务是什么？ 事务（ transaction） 是作为一个单元的一组有序的数据库操作。如果组中的所有操作都成功， 则认为事务成功， 即使只有一个操作失败， 事务也不成功。如果所有操作完成， 事务则提交， 其修改将作用于所有其他数据库进程。如果一个操作失败， 则事务将回滚， 该事务所有操作的影响都将取消。 事务特性： 原子性： 即不可分割性， 事务要么全部被执行， 要么就全部不被执行。 一致性或可串性：事务的执行使得数据库从一种正确状态转换成另一种正确状态。 隔离性：在事务正确提交之前，不允许把该事务对数据的任何改变提供给任何其他事务。 持久性：事务正确提交后， 其结果将永久保存在数据库中， 即使在事务提交后有了其他故障， 事务的处理结果也会得到保存。 或者这样理解：事务就是被绑定在一起作为一个逻辑工作单元的 SQL 语句分组， 如果任何一个语句操作失败那么整个操作就被失败， 以后操作就会回滚到操作前状态， 或者是上有个节点。为了确保要么执行， 要么不执行， 就可以使用事务。要将有组语句作为事务考虑， 就需要通过 ACID 测试， 即原子性， 一致性， 隔离性和持久性。 32.SQL 注入漏洞产生的原因？如何防止？ SQL 注入产生的原因： 程序开发过程中不注意规范书写 sql 语句和对特殊字符进行过滤，导致客户端可以通过全局变量 POST 和 GET 提交一些 sql 语句正常执行。 防止 SQL 注入的方式： 开启配置文件中的 magic_quotes_gpc 和 magic_quotes_runtime 设置 执行 sql 语句时使用 addslashes 进行 sql 语句转换Sql 语句书写尽量不要省略双引号和单引号。 过滤掉 sql 语句中的一些关键词：update、insert、delete、select、 * 。 提高数据库表和字段的命名技巧， 对一些重要的字段根据程序的特点命名， 取不易被猜到的。 33.为表中得字段选择合适得数据类型 字段类型优先级: 整形&gt;date,time&gt;enum,char&gt;varchar&gt;blob,text 优先考虑数字类型， 其次是日期或者二进制类型， 最后是字符串类型， 同级别得数据类型， 应该优先选择占用空间小的数据类型。34.存储时期(日期) Datatime: 以 YYYY-MM-DD HH:MM:SS 格式存储时期时间， 精确到秒， 占用 8 个字节得存储空间，datatime 类型与时区无关。 Timestamp: 以时间戳格式存储，占用 4 个字节，范围小 1970-1-1 到 2038-1-19， 显示依赖于所指定得时区， 默认在第一个列行的数据修改时可以自动得修改timestamp 列得值 。 Date: 占用得字节数比使用字符串.datatime.int 储存要少， 使用 date 只需要 3 个字节， 存储日期月份， 还可以利用日期时间函数进行日期间的计算。 Time: 存储时间部分的数据 注意:不要使用字符串类型来存储日期时间数据（ 通常比字符串占用得储存空间小， 在进行查找过滤可以利用日期得函数）使用 int 存储日期时间不如使用 timestamp 类型35.对于关系型数据库而言，索引是相当重要的概念，请回答有关索引的几个问题 1、索引的目的是什么？ 快速访问数据表中的特定信息， 提高检索速度 创建唯一性索引， 保证数据库表中每一行数据的唯一性。加速表和表之间的连接 使用分组和排序子句进行数据检索时， 可以显著减少查询中分组和排序的时间 2、索引对数据库系统的负面影响是什么？ 负面影响： 创建索引和维护索引需要耗费时间， 这个时间随着数据量的增加而增加； 索引需要占用物理空间， 不光是表需要占用数据空间， 每个索引也需要占用物理空间；当对表进行增、删、改、的时候索引也要动态维护， 这样就降低了数据的维护速度。 3、为数据表建立索引的原则有哪些？ 在最频繁使用的、用以缩小查询范围的字段上建立索引。 在频繁使用的、需要排序的字段上建立索引。 4、什么情况下不宜建立索引？ 对于查询中很少涉及的列或者重复值比较多的列， 不宜建立索引。 对于一些特殊的数据类型， 不宜建立索引， 比如文本字段（ text） 等 36.解释 MySQL 外连接、内连接与自连接的区别 先说什么是交叉连接: 交叉连接又叫笛卡尔积，它是指不使用任何条件，直接将一个表的所有记录和另一个表中的所有记录一一匹配。 内连接： 则是只有条件的交叉连接，根据某个条件筛选出符合条件的记录，不符合条件的记录不会出现在结果集中， 即内连接只连接匹配的行。 外连接： 其结果集中不仅包含符合连接条件的行，而且还会包括左表、右表或两个表中的所有数据行， 这三种情况依次称之为左外连接， 右外连接， 和全外连接。 左外连接： 也称左连接，左表为主表， 左表中的所有记录都会出现在结果集中， 对于那些在右表中并没有匹配的记录， 仍然要显示， 右边对应的那些字段值以NULL 来填充。 右外连接： 也称右连接，右表为主表，右表中的所有记录都会出现在结果集中。左连接和右连接可以互换， MySQL 目前还不支持全外连接。37.Myql 中的事务回滚机制概述 事务是用户定义的一个数据库操作序列， 这些操作要么全做要么全不做， 是一个不可分割的工作单位， 事务回滚是指将该事务已经完成的对数据库的更新操作撤销。 要同时修改数据库中两个不同表时， 如果它们不是一个事务的话， 当第一个表修改完， 可能第二个表修改过程中出现了异常而没能修改， 此时就只有第二个表依旧是未修改之前的状态， 而第一个表已经被修改完毕。 而当你把它们设定为一个事务的时候， 当第一个表修改完， 第二表修改出现异常而没能修改， 第一个表和第二个表都要回到未修改的状态， 这就是所谓的事务回滚。 38.SQL 语言包括哪几部分？每部分都有哪些操作关键字？ SQL 语言包括数据定义(DDL)、数据操纵(DML),数据控制(DCL)和数据查询（ DQL） 四个部分。 数据定义： Create Table,Alter Table,Drop Table, Craete/Drop Index等数据操纵： Select,insert,update,delete,数据控制：grant,revoke数据查询：select39.完整性约束包括哪些？ 数据完整性(Data Integrity)是指数据的精确(Accuracy)和可靠性(Reliability)。 分为以下四类： 实体完整性： 规定表的每一行在表中是惟一的实体。 域完整性： 是指表中的列必须满足某种特定的数据类型约束，其中约束又包括 取值范围、精度等规定。 参照完整性： 是指两个表的主关键字和外关键字的数据应一致， 保证了表之间的数据的一致性，防止了数据丢失或无意义的数据在数据库中扩散。 用户定义的完整性： 不同的关系数据库系统根据其应用环境的不同，往往还需 要一些特殊的约束条件。用户定义的完整性即是针对某个特定关系数据库的约束条件， 它反映某一具体应用必须满足的语义要求。与表有关的约束：包括列约束(NOT NULL（ 非空约束）)和表约束(PRIMARY KEY、foreign key、check、UNIQUE)。 ————————————————版权声明：本文为CSDN博主「Cs 挽周」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/weixin_45692705/article/details/119343669","link":"/2021/10/06/MySQL%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"title":"Markdown基本语法","text":"Markdown是一种纯文本格式的标记语言。通过简单的标记语法，它可以使普通文本内容具有一定的格式。 相比WYSIWYG编辑器 优点：1、因为是纯文本，所以只要支持Markdown的地方都能获得一样的编辑效果，可以让作者摆脱排版的困扰，专心写作。2、操作简单。比如:WYSIWYG编辑时标记个标题，先选中内容，再点击导航栏的标题按钮，选择几级标题。要三个步骤。而Markdown只需要在标题内容前加#即可 缺点：1、需要记一些语法（当然，是很简单。五分钟学会）。2、有些平台不支持Markdown编辑模式。 1开启方式：设置-&gt;默认编辑器-&gt;Markdown编辑器 一、标题在想要设置为标题的文字前面加#来表示一个#是一级标题，二个#是二级标题，以此类推。支持六级标题。 注：标准语法一般在#后跟个空格再写文字，貌似简书不加空格也行。 示例： 123456# 这是一级标题## 这是二级标题### 这是三级标题#### 这是四级标题##### 这是五级标题###### 这是六级标题 效果如下： 这是一级标题这是二级标题这是三级标题这是四级标题这是五级标题这是六级标题 二、字体 加粗 要加粗的文字左右分别用两个*号包起来 斜体 要倾斜的文字左右分别用一个*号包起来 斜体加粗 要倾斜和加粗的文字左右分别用三个*号包起来 删除线 要加删除线的文字左右分别用两个~~号包起来 示例： 1234**这是加粗的文字***这是倾斜的文字*`***这是斜体加粗的文字***~~这是加删除线的文字~~ 效果如下： 这是加粗的文字这是倾斜的文字这是斜体加粗的文字这是加删除线的文字 三、引用在引用的文字前加&gt;即可。引用也可以嵌套，如加两个&gt;&gt;三个&gt;&gt;&gt;n个…貌似可以一直加下去，但没神马卵用 示例： 123&gt;这是引用的内容&gt;&gt;这是引用的内容&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;这是引用的内容 效果如下： 这是引用的内容 这是引用的内容 这是引用的内容 四、分割线三个或者三个以上的 - 或者 * 都可以。 示例： 1234-------******** 效果如下：可以看到，显示效果是一样的。 五、图片语法： 1234![图片alt](图片地址 ''图片title'')图片alt就是显示在图片下面的文字，相当于对图片内容的解释。图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加 示例： 12![blockchain](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=702257389,1274025419&amp;fm=27&amp;gp=0.jpg &quot;区块链&quot;) 效果如下： blockchain 上传本地图片直接点击导航栏的图片标志，选择图片即可 markdown格式追求的是简单、多平台统一。那么图片的存储就是一个问题，需要用图床，提供统一的外链，这样就不用在不同的平台去处理图片的问题了。才能做到书写一次，各处使用。关于图床的选择我写了一篇文章，对网上存在的各种方法做了总结，需要的朋友可以看看。markdown图床 六、超链接语法： 12[超链接名](超链接地址 &quot;超链接title&quot;)title可加可不加 示例： 12[简书](http://jianshu.com)[百度](http://baidu.com) 效果如下： 简书百度 注：Markdown本身语法不支持链接在新页面中打开，貌似简书做了处理，是可以的。别的平台可能就不行了，如果想要在新页面中打开的话可以用html语言的a标签代替。 1234&lt;a href=&quot;超链接地址&quot; target=&quot;_blank&quot;&gt;超链接名&lt;/a&gt;示例&lt;a href=&quot;https://www.jianshu.com/u/1f5ac0cf6a8b&quot; target=&quot;_blank&quot;&gt;简书&lt;/a&gt; 七、列表无序列表语法：无序列表用 - + * 任何一种都可以 12345- 列表内容+ 列表内容* 列表内容注意：- + * 跟内容之间都要有一个空格 效果如下： 列表内容 列表内容 列表内容 有序列表语法：数字加点 123451. 列表内容2. 列表内容3. 列表内容注意：序号跟内容之间要有空格 效果如下： 列表内容 列表内容 列表内容 列表嵌套上一级和下一级之间敲三个空格即可 一级无序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 一级无序列表内容 二级有序列表内容 二级有序列表内容 二级有序列表内容 一级有序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 一级有序列表内容 二级有序列表内容 二级有序列表内容 二级有序列表内容 八、表格语法： 1234567891011表头|表头|表头---|:--:|---:内容|内容|内容内容|内容|内容第二行分割表头和内容。- 有一个就行，为了对齐，多加了几个文字默认居左-两边加：表示文字居中-右边加：表示文字居右注：原生的语法两边都要用 | 包起来。此处省略 示例： 12345姓名|技能|排行--|:--:|--:刘备|哭|大哥关羽|打|二哥张飞|骂|三弟 效果如下： 姓名 技能 排行 刘备 哭 大哥 关羽 打 二哥 张飞 骂 三弟 九、代码语法：单行代码：代码之间分别用一个反引号包起来 1`代码内容` 代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行 1(```) 代码... 代码... 代码...(```) 注：为了防止转译，前后三个反引号处加了小括号，实际是没有的。这里只是用来演示，实际中去掉两边小括号即可。 示例： 单行代码 1`create database hero;` 代码块 123456(```) function fun(){ echo &quot;这是一句非常牛逼的代码&quot;; } fun();(```) 效果如下： 单行代码 create database hero; 代码块 1234function fun(){ echo &quot;这是一句非常牛逼的代码&quot;;}fun(); 十、流程图123456789```flowst=&gt;start: 开始op=&gt;operation: My Operationcond=&gt;condition: Yes or No?e=&gt;endst-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op&amp;``` 链接: https://www.jianshu.com/p/191d1e21f7ed/","link":"/2022/08/19/Markdown%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/"},{"title":"Mysql binlog相关使用笔记","text":"开启bin-log1vim /etc/mysql/mysql.conf.d/mysqld.cnf 1234[mysqld]区块添加log-bin=mysql-bin(也可指定二进制日志生成的路径，如：log-bin=/opt/Data/mysql-bin)server-id=1binlog_format=MIXED(加入此参数才能记录到insert语句) 重启Mysql123systemctl restart mysql//或者service mysql restart 查看binlog日志是否开启1mysql&gt; show variables like 'log_%'; 测试链接数据库向数据表中插入一行查看bin-log1mysqlbinlog -v /var/log/mysql/mysql-bin.000001 导出，可以指定时间段1mysqlbinlog --base64-output=decode-rows -v --start-date='2014-09-16 14:00:00' --stop-date='2014-09-16 14:20:00' /var/log/mysql/mysql-bin.000001 &gt;/tmp/log.sql 推荐：https://www.cnblogs.com/Presley-lpc/p/9619571.htmlhttps://blog.csdn.net/Allenzyg/article/details/106446992","link":"/2021/07/16/Mysql%20binlog%E7%9B%B8%E5%85%B3%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"},{"title":"Mysql5.* Mysql 8.0* 一条SQL实现树形递归查询","text":"用户表 user id username pid 1 张三 0 2 李四 1 3 王五 2 4 赵六 3 5 孙七 4 拿到id为5的用户，查他的所有上级，如何用一条SQL实现树形的递归查询呢 Mysql5.* @变量迭代递归查询老版本的Mysql（5.6）通过使用的@变量 123456789101112SELECT T2.id, T2.`username` FROM ( SELECT @r AS _id,( SELECT @r := pid FROM user WHERE id = _id ) AS parent_id,@l := @l + 1 AS lvl FROM ( SELECT @r := 5, @l := 0 ) vars,user h WHERE @r &lt;&gt; 0 ) T1 JOIN user T2 ON T1._id = T2.idORDER BY T1.lvl DESC Mysql8. 中不能这么用会报警告⚠*Warning: #1287 Setting user variables within expressions is deprecated and will be removed in a future release. Please set variables in separate statements instead. Mysql8.* CTE递归查询Mysql8版本的支持了CTE递归查询的语法 123456WITH RECURSIVE parent_cte AS ( SELECT * FROM user WHERE id=91 UNION ALL SELECT u.* FROM user u INNER JOIN parent_cte parent_cte2 ON u.id = parent_cte2.pid) SELECT id,username FROM parent_cte ORDER BY id ASC 本地Mysql8.* ，线上服务器Mysql5.6，在不改动数据库版本的情况下，使用用户自定义函数Function 实现树形递归 Mysql Function函数// 在Mysql中创建getParentList函数 123456789101112131415161718192021222324252627CREATE DEFINER=`root`@`%` FUNCTION `getParentList`(rootId varchar(100)) RETURNS varchar(1000) CHARSET utf8mb4 COLLATE utf8mb4_general_ciBEGIN DECLARE fid varchar(100) default ''; DECLARE str varchar(1000) default rootId; WHILE rootId is not null do SET fid =(SELECT PID FROM user WHERE ID = rootId); IF fid is not null THEN SET str = concat(str, ',', fid); SET rootId = fid; ELSE SET rootId = fid; END IF;END WHILE;return str;END// 业务中直接调用函数SELECT * from user where FIND_IN_SET(id,getParentList(5)); CTECTE，全名 Common Table Expressions WITH cte1 AS (SELECT a, b FROM table1), cte2 AS (SELECT c, d FROM table2)SELECT b, d FROM cte1 JOIN cte2WHERE cte1.a = cte2.c; cte1, cte2 为我们定义的CTE，可以在当前查询中引用 递归查询先来看下递归查询的语法 12345678WITH RECURSIVE cte_name AS( SELECT ... -- return initial row set UNION ALL / UNION DISTINCT SELECT ... -- return additional row sets)SELECT * FROM cte; 定义一个CTE，这个CTE 最终的结果集就是我们想要的 ”递归得到的树结构”，RECURSIVE 代表当前 CTE 是递归的第一个SELECT 为 “初始结果集”第二个SELECT 为递归部分，利用 “初始结果集/上一次递归返回的结果集” 进行查询得到 “新的结果集”直到递归部分结果集返回为null，查询结束最终UNION ALL 会将上述步骤中的所有结果集合并（UNION DISTINCT 会进行去重），再通过 SELECT * FROM cte; 拿到所有的结果集可以参考下MySQL开发文档：https://dev.mysql.com/doc/refman/8.0/en/with.htmlhttps://dev.mysql.com/doc/refman/8.0/en/with.html#common-table-expressions-recursive-examples文章来源于:https://blog.tius.cn/archives/260","link":"/2021/07/10/Mysql5.%EF%80%AA%20Mysql%208.0%EF%80%AA%20%E4%B8%80%E6%9D%A1SQL%E5%AE%9E%E7%8E%B0%E6%A0%91%E5%BD%A2%E9%80%92%E5%BD%92%E6%9F%A5%E8%AF%A2/"},{"title":"OpenAPI标准规范","text":"https://honeypps.com/architect/openapi-standard-specification/","link":"/2021/11/07/OpenAPI%E6%A0%87%E5%87%86%E8%A7%84%E8%8C%83/"},{"title":"Nginx-基础总结","text":"原文地址：https://www.mwbo.com/133.html 常规配置模板123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#user www www;worker_processes auto;error_log /home/wwwlogs/nginx_error.log crit;#pid /usr/local/nginx/nginx.pid;#Specifies the value for maximum file descriptors that can be opened by this process.worker_rlimit_nofile 655350;events { use epoll; worker_connections 655350; }http { include mime.types; default_type application/octet-stream; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 50m; # 如果报错413，可以尝试将这个参数改大 server_tokens off; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 60; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 256k; proxy_connect_timeout 600; proxy_read_timeout 600; proxy_send_timeout 600; proxy_buffer_size 64k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/plain application/x-javascript text/css application/xml text/xml application/json; gzip_vary on; log_format access '$remote_addr - $remote_user [$time_local] $host ' '&quot;$request&quot; $status $body_bytes_sent $request_time ' '&quot;$http_referer&quot; &quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;' '$upstream_addr $upstream_status $upstream_response_time' ; #设置Web缓存区名称为cache_one，内存缓存空间大小为256MB，1天没有被访问的内容自动清除，硬盘缓存空间大小为30GB。 proxy_temp_path /home/proxy_temp_dir; proxy_cache_path /home/proxy_cache_path levels=1:2 keys_zone=cache_one:256m inactive=1d max_size=30g; server { listen 80; server_name _; return 403; } include vhost/*.conf;} 以“exmaple.org”为例，如下为基于 upstream 负载均衡模式的配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061upstream example_backend { server 127.0.0.1:9080; server 192.168.1.198:9080; server 172.16.0.4:80 weight=5 max_fails=3 fail_timeout=10s; # 权重、健康监测 server 172.16.0.5:8080 backup; # 备份节点, ip_hash; #调度算法 }server { listen 80; server_name www.example.org example.com .example.org; location / {# 如果后端服务器出现502 或504错误代码的话nginx就不会请求某台服务器了,当后端服务器又工作正常了,nginx继续请求,这样一来达到了后端服务器健康状况检测的功能, proxy_next_upstream error timeout invalid_header http_500 http_502 http_503; proxy_pass http://example_backend; proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 设置后端连接超时时间 proxy_connect_timeout 600; proxy_read_timeout 600; proxy_send_timeout 600; proxy_buffer_size 8k; proxy_temp_file_write_size 64k; # nginx本地cache开启 proxy_cache cache_one; proxy_cache_valid 200 304 30d; proxy_cache_valid 301 302 404 1m; proxy_cache_valid any 1m; proxy_cache_key $host$request_uri; # 客户端缓存，在header中增加“Expires” expires 30d; add_header Cache-Control public; add_header X-Proxy-Cache $upstream_cache_status; proxy_set_header If-Modified-Since $http_if_modified_since; if_modified_since before; } location ~ .*\\.(gif|jpg|jpeg|png|bmp|ico|swf|xml|css|js)$ { proxy_pass http://example_backend; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; expires 15d; } location ~ .*\\.(jhtml)$ { proxy_pass http://example_backend; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; expires -1; } access_log logs/www.example.org.log;} 其他的 proxy 配置： 1.proxy_set_header :在将客户端请求发送给后端服务器之前，更改来自客户端的请求头信息。2.proxy_connect_timeout:配置Nginx与后端代理服务器尝试建立连接的超时时间。3.proxy_read_timeout : 配置Nginx向后端服务器组发出read请求后，等待相应的超时时间。4.proxy_send_timeout：配置Nginx向后端服务器组发出write请求后，等待相应的超时时间。5.proxy_redirect :用于修改后端服务器返回的响应头中的Location和Refresh。 用户认证12345678910111213# htpasswd -bc /usr/local/nginx/auth/passwd admin 123456vim /usr/local/nginx/conf/vhost/www.confserver { listen 80; server_name www.com; index index.html index.htm; root /www;location / { auth_basic &quot;test&quot;; auth_basic_user_file /usr/local/nginx/auth/passwd;}#service nginx restart 解决跨域12345678910111213141516171819202122232425262728293031# 提示： add_header 也可以添加到 server 中，这样当前 server 下都允许跨域server{ listen 3002; server_name localhost; location /ok { proxy_pass http://localhost:3000; # 指定允许跨域的方法，*代表所有 add_header Access-Control-Allow-Methods *; # 预检命令的缓存，如果不缓存每次会发送两次请求 add_header Access-Control-Max-Age 3600; # 带cookie请求需要加上这个字段，并设置为true add_header Access-Control-Allow-Credentials true; # 表示允许这个域跨域调用（客户端发送请求的域名和端口） # $http_origin动态获取请求客户端请求的域 不用*的原因是带cookie的请求不支持*号 add_header Access-Control-Allow-Origin $http_origin; # 表示请求头的字段 动态获取 add_header Access-Control-Allow-Headers $http_access_control_request_headers; # OPTIONS预检命令，预检命令通过时才发送请求 # 检查请求的类型是不是预检命令 if ($request_method = OPTIONS){ return 200; } }} URL 重写比如说访问某站点的路径为/forum/ , 此时想使用/bbs 来访问此站点需要做 url 重写如下 123location / { rewrite ^/forum/?$ /bbs/ permanent;} 比如说某站点有个图片服务器(10.0.0.1/p_w_picpaths/ ) 此时访问某站点上/p_w_picpaths/的资源时希望访问到图片服务器上的资源 123location / { rewrite ^/p_w_picpaths/(.*\\.jpg)$ /p_w_picpaths2/$1 break;} 域名跳转123456server { listen 80; server_name www.com; rewrite ^/ http://www.www.com/; # return 301 http://www.andy.com/;} 123if ($host != 'www.xyz.com') { ####注意，这里很严格，if后面要有空格，!=两边都是空格。 rewrite ^/(.*)$ http://www.xyz.com/$1 permanent;} 域名镜像12345server { listen 80; server_name www.com; rewrite ^/(.*)$ http://www.www.com/$1 last;} 判断表达式 -f 和 !-f 用来判断是否存在文件 -d 和 !-d 用来判断是否存在目录 -e 和 !-e 用来判断是否存在文件或目录 -x 和 !-x 用来判断文件是否可执行 防盗链12345location ~* \\.(gif|jpg|png|swf|flv)$ { valid_referers none blocked www.com; if ($invalid_referer) { rewrite ^/ http://www.com/403.html; } 会话保持12345678# ip_hash使用源地址哈希算法，将同一客户端的请求只发往同一个后端服务器（除非该服务器不可用）。# 问题： 当后端服务器宕机后，session会话丢失；同一客户端会被转发到同一个后端服务器，可能导致负载失衡；upstream backend { ip_hash; server backend1.example.com; server backend2.example.com; server backend3.example.com down;} sticky_cookie_insert 12345678910111213# 使用sticky_cookie_insert 启用会话亲缘关系，会导致来自同一客户端的请求被传递到一组服务器的同一台服务器。与ip_hash不同之处在于，它不是基于IP来判断客户端的，而是基于cookie来判断。因此可以避免上述ip_hash中来自同一客户端导致负载失衡的情况(需要引入第三方模块才能实现)。upstream backend { server backend1.example.com; server backend2.example.com; sticky_cookie_insert srv_id expires=1h domain=3evip.cn path=/;}server { listen 80; server_name 3evip.cn; location / { proxy_pass http://backend; }} expires：设置浏览器中保持 cookie 的时间domain：定义 cookie 的域path：为 cookie 定义路径 日志切割示列一 1234567#!/bin/bash# 适合单个网站日志文件LOGS_PATH=/home/wwwroot/yunwei/logsyesterday=`date +&quot;%F&quot; -d &quot;-1 days&quot;`mv ${LOGS_PATH}/yunwei.log ${LOGS_PATH}/yunwei-${yesterday}.logkill -USR1 $(cat /var/logs/nginx.pid) 示列二 1234567891011121314151617181920212223242526272829303132#nginx日志切割# Nginx pidNGINX_PID=$(cat /var/logs/nginx.pid)# 多个日志文件LOGS=(xxx.access.log xxx.access.log)# Nginx日志路径目录BASH_PATH=&quot;/www/wwwlogs&quot;# xxxx年xx月lOG_PATH=$(date -d yesterday +&quot;%Y%m&quot;)# 昨天日期DAY=$(date -d yesterday +&quot;%d&quot;)# 循环移动for log in ${LOGS[@]}do # 先判断日志目录是否存在 [[ ! -d &quot;${BASH_PATH}/${lOG_PATH}&quot; ]] &amp;&amp; mkdir -p ${BASH_PATH}/${lOG_PATH} # 进入日志目录 cd ${BASH_PATH} mv ${log} ${lOG_PATH}/${DAY}-${log} #kill -USR1 `ps axu | grep &quot;nginx: master process&quot; | grep -v grep | awk '{print $2}'` kill -USR1 ${NGINX_PID} # 删除30天的备份,最好是移动到其他位置，不建议 rm -fr #find ${BASH_PATH}/${lOG_PATH} -mtime +30 -name &quot;.&quot; -exec rm -fr {} \\;done 示列三 12345678910111213141516171819202122232425262728#!/bin/bash#set the path to nginx log fileslog_files_path=&quot;/usr/local/nginx/logs/&quot;log_files_dir=${log_files_path}$(date -d &quot;yesterday&quot; +&quot;%Y&quot;)/$(date -d &quot;yesterday&quot; +&quot;%m&quot;)#set nginx log files you want to cutlog_files_name=(gw20 gw20-json)#set the path to nginx.nginx_sbin=&quot;/usr/bin/nginx&quot;#Set how long you want to savesave_days=10#############################################Please do not modify the following script #############################################mkdir -p $log_files_dirlog_files_num=${#log_files_name[@]}#cut nginx log filesfor((i=0;i&lt;$log_files_num;i++));domv ${log_files_path}${log_files_name[i]}.log ${log_files_dir}/${log_files_name[i]}_$(date -d &quot;yesterday&quot; +&quot;%Y%m%d&quot;).logdone#delete 30 days ago nginx log filesfind $log_files_path -mtime +$save_days -exec rm -rf {} \\;$nginx_sbin -s reload 示列四 123456789server{ if ($time_iso8601 ~ '(\\d{4}-\\d{2}-\\d{2})') { set $day $1; } access_log /www/wwwlogs/xxx.com-$day.log main; error_log /www/wwwlogs/xxx.com.error.log;} 动静分离 为加快网站解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。 在动静分离的 tomcat 的时候比较明显，因为 tomcat 解析静态很慢，简单来说，是使用正则表达式匹配过滤，交给不同的服务器。 1、准备环境 123192.168.62.159 代理服务器192.168.62.157 动态资源192.168.62.155 静态资源 2、配置 nginx 反向代理 upstream 123456789101112131415161718192021222324252627282930[root@nginx-server conf.d]# cat upstream.confupstream static { server 192.168.62.155:80 weight=1 max_fails=1 fail_timeout=60s;}upstream phpserver { server 192.168.62.157:80 weight=1 max_fails=1 fail_timeout=60s;}server { listen 80; server_name localhost; #动态资源加载 location ~ \\.(php|jsp)$ { proxy_pass http://phpserver; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } #静态资源加载 location ~ .*\\.(html|gif|jpg|png|bmp|swf|css|js)$ { proxy_pass http://static; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; }} 3、192.168.62.155 静态资源 12345678910#静态资源配置server { listen 80; server_name localhost; location ~ \\.(html|jpg|png|js|css|gif|bmp|jpeg) { root /home/www/nginx; index index.html index.htm; }} 4、192.168.62.157 动态资源 123456789101112server { listen 80; server_name localhost; location ~ \\.php$ { root /home/nginx/html; #指定网站目录 fastcgi_pass 127.0.0.1:9000; #指定访问地址 fastcgi_index index.php; #指定默认文件 fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; #站点根目录，取决于root配置项 include fastcgi_params; #包含nginx常量定义 }} PHP的很多框架里面都是通过获取$_SERVER[‘PATH_INFO’]处理路由 , 这个变量是通过nginx传递过来的 , 我们在nginx中经常见到下面两句 fastcgi_split_path_info ^(.+.php)(/.*)$;fastcgi_param PATH_INFO $fastcgi_path_info; nginx默认获取不到PATH_INFO的值，得通过fastcgi_split_path_info指定定义的正则表达式来获取值。^(.+.php)(/.*)$; 这个正则表达是有两个小括号 , 也就是有两个捕获。第二个捕获到的值会自动重新赋值给$fastcgi_path_info变量。第一个捕获的值会重新赋值给$fastcgi_script_name变量。如果访问 /index.php/test ,第二个捕获的是/test $fastcgi_path_info就是/test,因此就会把/test传递给php的$_SERVER[‘PATH_INFO’] location 优先级12345678当有多条 location 规则时，nginx 有一套比较复杂的规则，优先级如下：`精确匹配=`前缀匹配^~（立刻停止后续的正则搜索）`按文件中顺序的正则匹配~或~*`匹配不带任何修饰的前缀匹配。这个规则大体的思路是`先精确匹配，没有则查找带有^~的前缀匹配，没有则进行正则匹配，最后才返回前缀匹配的结果（如果有的话） HTTPS 使用自颁发证书实现123456789101112131415161718192021222324252627# 建立存放https证书的目录mkdir -pv /usr/local/nginx/conf/.sslkey# 生成网站私钥文件cd /usr/local/nginx/conf/.sslkeyopenssl genrsa -out https.key 1024# 生存网站证书文件,需要注意的是在生成的过程中需要输入一些信息根据自己的需要输入,但Common Name 项输入的必须是访问网站的FQDNopenssl req -new -x509 -key https.key -out https.crt# 为了安全起见,将存放证书的目录权限设置为400chmod -R 400 /usr/local/nginx/conf/.sslkey#vim /usr/local/nginx/conf/vhost/www.confserver { listen 443; server_name www.com; index index.html index.htm; root /www; ssl on; ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5; ssl_certificate /usr/local/nginx/conf/.sslkey/https.crt; ssl_certificate_key /usr/local/nginx/conf/.sslkey/https.key; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m;}#重新启动nginx服务service nginx restar 基于 HTTPS 配置核心配置12345678910111213141516171819202122232425upstream example_backend { server 127.0.0.1:9080; server 192.168.1.198:9080; }server { listen 80; server_name www.example.org example.org; rewrite ^/(.*)$ https://$host/$1 last; }server { listen 443; server_name www.example.org example.org; ssl on; ssl_certificate /usr/local/nginx/conf/ssl/example.crt; ssl_certificate_key /usr/local/nginx/conf/ssl/example.key; ssl_session_timeout 5m; ssl_protocols SSLv3 TLSv1 TLSv1.2 TLSv1.1; ssl_ciphers HIGH:!aNULL:!MD5:!EXPORT56:!EXP; ssl_prefer_server_ciphers on; location / { ... }} 根据页面不存在则自定义跳转123if (!-f $request_filename) { rewrite ^(/.*)$ http://www.com permanent;} 直接输出消息直接返回文本：1234location / { default_type text/plain; return 502 &quot;服务正在升级，请稍后再试……&quot;;} 也可以使用html标签格式：1234location / { default_type text/html; return 502 &quot;服务正在升级，请稍后再试……&quot;;} 也可以直接返回json文本：1234location / { default_type application/json; return 502 '{&quot;status&quot;:502,&quot;msg&quot;:&quot;服务正在升级，请稍后再试……&quot;}';} 根据文件类型设置过期时间123456location ~* \\.(js|css|jpg|jpeg|gif|png|swf)$ { if (-f $request_filename) { expires 1h; break; }} 根据域名自定义跳转123if ( $host = 'www.baidu.com' ) { rewrite ^/(.*)$ http://baidu.com/$1 permanent;} 浏览器的类型,作出相应的跳转123456789# 根据浏览器头部 URL 重写到指定目录if ($http_user_agent ~* MSIE) { rewrite ^(.*)$ /msie/$1 break;}# 判断是否是手机端if ( $http_user_agent ~* &quot;(Android|iPhone|Windows Phone|UC|Kindle)&quot; ) { rewrite ^/(.*)$ http://m.qp.com$uri redirect;} 禁止访问目录|文件1234location ~* \\.(txt|doc)${ root /data/www/wwwroot/linuxtone/test; deny all;} 如果前端是反向代理的情况下： 1234567891011location /admin/ { allow 192.168.1.0/24; deny all;}# 后端# set $allow false;# if ($allow = false) { return 403;}if ($http_x_forwarded_for !~* ^192\\.168\\.1\\.*) { return 403;} 添加模块–支持 WebsockNginx 动态添加模块 版本平滑升级，和添加模块操作类似 准备模块这里以 nginx-push-stream-module 为例,模块我放在 /data/module 下，你也可以放在其他位置 12mkdir -p /data/module &amp;&amp; cd /data/module/git clone http://github.com/wandenberg/nginx-push-stream-module.git 查看 Nginx 已安装模块12/usr/local/nginx/sbin/nginx -V--prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-http_stub_status_module --with-http_gzip_static_module --with-http_flv_module --with-http_mp4_module --with-pcre 备份源执行文件备份原来的 nginx 可执行文件 12cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx_bak# 有必要的话，可以再备份下配置文件，以防万一 下载源码编译下载相同版本的 Nginx 源码包编译（以前安装时的源码包），如果已经删除了可重新下载，版本相同即可 12345678wget http://nginx.org/download/nginx-1.16.1.tar.gztar xf nginx-1.16.1.tar.gzcd nginx-1.16.1 ./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-http_stub_status_module --with-http_gzip_static_module --with-http_flv_module --with-http_mp4_module --with-pcre --add-module=/data/module/nginx-push-stream-module# 编译Nginx（千万不要make install，不然就真的覆盖了）makemv objs/nginx /usr/local/nginx/sbin/ 查看是否安装12/usr/local/nginx/sbin/nginx -V--prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-http_stub_status_module --with-http_gzip_static_module --with-http_flv_module --with-http_mp4_module --with-pcre --add-module=/data/module/nginx-push-stream-module 添加模块–支持健康检查模块缺陷？自带健康检查的缺陷： Nginx 只有当有访问时后，才发起对后端节点探测。如果本次请求中，节点正好出现故障，Nginx 依然将请求转交给故障的节点,然后再转交给健康的节点处理。所以不会影响到这次请求的正常进行。但是会影响效率,因为多了一次转发自带模块无法做到预警被动健康检查使用第三访模块 nginx_upstream_check_module： 区别于 nginx 自带的非主动式的心跳检测，淘宝开发的 tengine 自带了一个提供主动式后端服务器心跳检测模块若健康检查包类型为 http，在开启健康检查功能后，nginx 会根据设置的间隔向指定的后端服务器端口发送健康检查包，并根据期望的 HTTP 回复状态码来判断服务是否健康。后端真实节点不可用，则请求不会转发到故障节点故障节点恢复后，请求正常转发 准备模块123yum install patch git -ycd /usr/local/srcgit clone https://github.com/yaoweibin/nginx_upstream_check_module.git 打补丁12345# 需进入源码包打补丁# 个人习惯，源码放在 /usr/local/src# 例如我的 nginx 源码包存放： /usr/local/src/nginx-1.16.1 , 若源码已经删除，那么去官网上再下载同版本cd /usr/local/src/nginx-1.16.1patch -p1 &lt; ../nginx_upstream_check_module/check_1.16.1+.patch 重新编译1234567891011121314151617nginx -V# configure arguments: --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-http_stub_status_module --add-module=/root/nginx_upstream_check_module/# 在运行中的 nginx 添加模块； 首先一点: 修改东西之前要先备份mv /usr/loca/nginx/sbin/nginx{,_bak}./configure --prefix=/usr/local/nginx \\--user=www --group=www \\--with-http_ssl_module \\--with-http_stub_status_module \\--add-module=../nginx_upstream_check_modulemake# **别手贱， 千万不要 make install**cp objs/nginx /usr/local/nginx/sbin/ 查看模块12nginx -Vconfigure arguments: --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-http_stub_status_module --add-module=../nginx_upstream_check_module 如何使用？1234567891011121314151617181920212223242526272829303132333435http { upstream cluster { server 192.168.0.1:80; server 192.168.0.2:80; server 127.0.0.1:80; check interval=5000 rise=1 fall=3 timeout=4000; #check interval=3000 rise=2 fall=5 timeout=1000 type=ssl_hello; #check interval=3000 rise=2 fall=5 timeout=1000 type=http; #check_http_send &quot;HEAD / HTTP/1.0\\r\\n\\r\\n&quot;; #check_http_expect_alive http_2xx http_3xx; } server { listen 80; location / { proxy_pass http://cluster; } location /status { # 默认html，请求方式： check_status html|json|xml; # allow 允许的IP地址 check_status; access_log off; allow SOME.IP.ADD.RESS; deny all; } }}# kill -USER2 `cat /usr/local/nginx/logs/nginx.pid` #热升级nginx,如果当前nginx不是用绝对路径下的nginx命令启动的话，热升级无效。# 只能 `nginx -s stop` &amp;&amp; /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf` 验证1234567891011121314# curl http://127.0.0.1/status?format=http# curl http://127.0.0.1/status?format=xmlcurl http://127.0.0.1/status?format=json&quot;&quot;&quot;{&quot;servers&quot;: { &quot;total&quot;: 3, &quot;generation&quot;: 2, &quot;server&quot;: [ {&quot;index&quot;: 0, &quot;upstream&quot;: &quot;cluster&quot;, &quot;name&quot;: &quot;192.168.0.1:80&quot;, &quot;status&quot;: &quot;down&quot;, &quot;rise&quot;: 0, &quot;fall&quot;: 432, &quot;type&quot;: &quot;tcp&quot;, &quot;port&quot;: 0}, {&quot;index&quot;: 1, &quot;upstream&quot;: &quot;cluster&quot;, &quot;name&quot;: &quot;192.168.0.2:80&quot;, &quot;status&quot;: &quot;down&quot;, &quot;rise&quot;: 0, &quot;fall&quot;: 432, &quot;type&quot;: &quot;tcp&quot;, &quot;port&quot;: 0}, {&quot;index&quot;: 2, &quot;upstream&quot;: &quot;cluster&quot;, &quot;name&quot;: &quot;127.0.0.1:80&quot;, &quot;status&quot;: &quot;up&quot;, &quot;rise&quot;: 4, &quot;fall&quot;: 0, &quot;type&quot;: &quot;tcp&quot;, &quot;port&quot;: 0} ]}}&quot;&quot;&quot; 注意事项如果后端是基于域名访问，可使用 check_http_send “GET /xxx HTTP/1.0\\r\\n HOST www.xxx.com\\r\\n\\r\\n”;方式在请求时添加请求头信息 参数详解interval： 检测间隔 3 秒fall: 连续检测失败次数 5 次时，认定 relaserver is downrise: 连续检测成功 2 次时，认定 relaserver is uptimeout: 超时 1 秒default_down: 初始状态为 down,只有检测通过后才为 uptype: 检测类型方式 tcptcp :tcp 套接字,不建议使用，后端业务未 100%启动完成,前端已经放开访问的情况ssl_hello： 发送 hello 报文并接收 relaserver 返回的 hello 报文http: 自定义发送一个请求，判断上游 relaserver 接收并处理mysql: 连接到 mysql 服务器，判断上游 relaserver 是否还存在ajp: 发送 AJP Cping 数据包，接收并解析 AJP Cpong 响应以诊断上游 relaserver 是否还存活(AJP tomcat 内置的一种协议)fastcgi: php 程序是否存活 GIthub 地址https://github.com/yaoweibin/nginx_upstream_check_module 添加模块–支持国家城市模块安装依赖 libmaxmindd 因为需要读取在 GeoIP2 的 IP 数据库库，需要使用到 libmaxminddb 中的一个 C 库 pay源码 12345678910wget https://github.com/maxmind/libmaxminddb/releases/download/1.3.2/libmaxminddb-1.3.2.tar.gztar zxvf libmaxminddb-1.3.2.tar.gzcd libmaxminddb-1.3.2./configuremakemake install# 添加库路径并更新库sh -c &quot;echo /usr/local/lib &gt;&gt; /etc/ld.so.conf.d/local.conf&quot;ldconfig yum 1yum install libmaxminddb-devel -y 下载 GeoIP 源码12wget https://github.com/leev/ngx_http_geoip2_module/archive/3.2.tar.gztar zxvf 3.2.tar.gz Nginx 重新编译12 ./configure --prefix=/usr/local/nginx --add-module=../ngx_http_geoip2_module-3.2make &amp;&amp; make install 下载 GeoLite这个库是为了将 IP 地址翻译成具体的地址信息，下载需要注册…URL: https://www.maxmind.com/en/accounts/current/people/current 账号： xxxx@qq.com 密码： xxx.. 12345gunzip GeoLite2-City.mmdb.gzgunzip GeoLite2-Country.mmdb.gzmkdir /data/geoipmv GeoLite2-City.mmdb /data/geoip/city.mmdbmv GeoLite2-Country.mmdb /data/geoip/country.mmdb 启用 GeoIP123456789101112131415161718192021222324vim /usr/local/nginx/conf/nginx.confhttp { geoip2 /data/geoip/country.mmdb { $geoip2_data_country_code default=CN country iso_code; $geoip2_data_country_name country names en; } geoip2 /data/geoip/city.mmdb { $geoip2_data_city_name default=Shenzhen city names en; } server { listen 80; server_name localhost; location / { add_header geoip2_data_country_code $geoip2_data_country_code; add_header geoip2_data_city_name $geoip2_data_city_name; if ($geoip2_data_country_code = CN){ root /data/webroot/cn; } if ($geoip2_data_country_code = US){ root /data/webroot/us; } }｝ 检查 GeoIP12345mkdir /data/webroot/usmkdir /data/webroot/cnecho &quot;US Site&quot; &gt; /data/webroot/us/index.htmlecho &quot;CN Site&quot; &gt; /data/webroot/cn/index.htmlcurl 试一试 内置变量123456789101112131415161718192021222324252627282930313233http://wiki.nginx.org/HttpCoreModule#Variables 官方文档$arg_PARAMETER$args$binary_remote_addr$body_bytes_sent$content_length$content_type$cookie_COOKIE$document_root$document_uri$host$hostname$http_HEADER$sent_http_HEADER$is_args$limit_rate$nginx_version$query_string$remote_addr$remote_port$remote_user$request_filename$request_body$request_body_file$request_completion$request_method$request_uri$scheme$server_addr$server_name$server_port$server_protocol$uri nginx配置location基本语法：location [=||*|^~] /uri/ { … } 1234567= 严格匹配。如果这个查询匹配，那么将停止搜索并立即处理此请求。~ 为区分大小写匹配(可用正则表达式)!~为区分大小写不匹配~* 为不区分大小写匹配(可用正则表达式)!~*为不区分大小写不匹配^~ 如果把这个前缀用于一个常规字符串,那么告诉nginx 如果路径匹配那么不测试正则表达式。123456 例子 12345678910111213141516171819location = / { # 只匹配 / 查询。}location / { # 匹配任何查询，因为所有请求都以 / 开头。但是正则表达式规则和长的块规则将被优先和查询匹配。}location ^~ /images/ { # 匹配任何以 /images/ 开头的任何查询并且停止搜索。任何正则表达式将不会被测试。}location ~*.(gif|jpg|jpeg)$ { # 匹配任何以 gif、jpg 或 jpeg 结尾的请求。}location ~*.(gif|jpg|swf)$ { valid_referers none blocked start.igrow.cn sta.igrow.cn; if ($invalid_referer) { #防盗链 rewrite ^/ http://$host/logo.png; }} try_files123location / { try_files $uri $uri/ /index.php?$query_string;} 当用户请求 http://localhost/example 时，这里的 $uri 就是 /example。try_files 会到硬盘里尝试找这个文件。如果存在名为 /$root/example（其中 $root 是项目代码安装目录）的文件，就直接把这个文件的内容发送给用户。显然，目录中没有叫 example 的文件。然后就看 $uri/，增加了一个 /，也就是看有没有名为 /$root/example/ 的目录。又找不到，就会 fall back 到 try_files 的最后一个选项 /index.php，发起一个内部 “子请求”，也就是相当于 nginx 发起一个 HTTP 请求到 http://localhost/index.php。 12345678910111213loaction / {try_files $uri @apache}loaction @apache{proxy_pass http://127.0.0.1:88include aproxy.conf} try_files方法让Ngxin尝试访问后面得$uri链接，并进根据@apache配置进行内部重定向。 当然try_files也可以以错误代码赋值，如try_files /index.php = 404 @apache，则表示当尝试访问得文件返回404时，根据@apache配置项进行重定向。 Nginx配置中的if判断当rewrite的重写规则满足不了需求时，比如需要判断当文件不存在时、当路径包含xx时等条件，则需要用到if if语法123if (表达式) { ...} 表达式语法： 当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会当做false直接比较变量和内容时，使用=或!= 1234-f和!-f用来判断是否存在文件-d和!-d用来判断是否存在目录-e和!-e用来判断是否存在文件或目录-x和!-x用来判断文件是否可执行 为了配置if的条件判断，这里需要用到nginx中内置的全局变量 123456789101112131415161718192021$args 这个变量等于请求行中的参数，同$query_string$content_length 请求头中的Content-length字段。$content_type 请求头中的Content-Type字段。$document_root 当前请求在root指令中指定的值。$host 请求主机头字段，否则为服务器名称。$http_user_agent 客户端agent信息$http_cookie 客户端cookie信息$limit_rate 这个变量可以限制连接速率。$request_method 客户端请求的动作，通常为GET或POST。$remote_addr 客户端的IP地址。$remote_port 客户端的端口。$remote_user 已经经过Auth Basic Module验证的用户名。$request_filename 当前请求的文件路径，由root或alias指令与URI请求生成。$scheme HTTP方法（如http，https）。$server_protocol 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。$server_addr 服务器地址，在完成一次系统调用后可以确定这个值。$server_name 服务器名称。$server_port 请求到达服务器的端口号。$request_uri 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。$uri 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。$document_uri 与$uri相同。 举例说明1、如果文件不存在则返回400 123if (!-f $request_filename) { return 400;} 2、如果host不是jouypub.com，则301到jouypub.com中 123if ( $host != 'jouypub.com' ){ rewrite ^/(.*)$ https://jouypub.com/$1 permanent;} 3、如果请求类型不是POST则返回405 123if ($request_method = POST) { return 405;} 4、如果参数中有a=1则301到指定域名 123if ($args ~ a=1) { rewrite ^ http://example.com/ permanent;} 5、在某种场景下可结合location规则来使用，如： 1234567891011121314#访问 /test.html 时location = /test.html { #设置默认值为xiaowu set $name xiaowu; #如果参数中有 name=xx 则使用该值 if ($args ~* name=(\\w+?)(&amp;|$)) { set $name $1; } #301 rewrite ^ /$name.html permanent;}#上面表示：#/test.html =&gt; /xiaowu.html#/test.html?name=ok =&gt; /ok.html?name=ok 强制跳转www123if ($host != 'www.1kmb.com') { rewrite ^/(.*) https://www.1kmb.com/$1 permanent;} 代理中的几点区别在nginx中配置proxy_pass代理转发时，如果在proxy_pass后面的url加/，表示绝对根路径；如果没有/，表示相对路径，把匹配的路径部分也给代理走。假设下面四种情况分别用 http://127.0.0.1/proxy/test.html 进行访问。 第一种： 123location /proxy/ { proxy_pass http://127.0.0.1/;} 代理到URL：http://127.0.0.1/test.html 第二种（相对于第一种，最后少一个 / ） 123location /proxy/ { proxy_pass http://127.0.0.1;} 代理到URL：http://127.0.0.1/proxy/test.html 第三种： 123location /proxy/ { proxy_pass http://127.0.0.1/abc/;} 代理到URL：http://127.0.0.1/abc/test.html 第四种（相对于第三种，最后少一个 / ） 123location /proxy/ { proxy_pass http://127.0.0.1/abc;} 代理到URL：http://127.0.0.1/abctest.html Nginx限流高并发系统有三把利器：缓存、降级和限流；限流的目的是通过对并发访问/请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页）、排队等待（秒杀）、降级（返回兜底数据或默认数据）。 高并发系统常见的限流有：限制总并发数（数据库连接池）、限制瞬时并发数（如nginx的limit_conn模块，用来限制瞬时并发连接数）、限制时间窗口内的平均速率（nginx的limit_req模块，用来限制每秒的平均速率）。 另外还可以根据网络连接数、网络流量、CPU或内存负载等来限流 Module ngx_http_limit_conn_modulehttp://nginx.org/en/docs/http/ngx_http_limit_conn_module.html 限流算法计数器，令牌桶，漏桶 请求限制依赖于nginx的ngx_http_limit_req_module模块，需要在http段配置参照标准和状态缓存区大小 limit_req_zone 只能配置在 http 范围内； $binary_remote_addr 表示客户端请求的IP地址； mylimit 自己定义的变量名； rate 请求频率，每秒允许多少请求； limit_req 与 limit_req_zone 对应，burst 表示缓存的请求数，也就是任务队列。 例如如下配置 123456789101112# 定义了一个 mylimit 缓冲区（容器），请求频率为每秒 1 个请求（nr/s）limit_req_zone $binary_remote_addr zone=mylimit:10m rate=1r/s;server { listen 80; location / { # nodelay 不延迟处理 # burst 是配置超额处理,可简单理解为队列机制 # 上面配置同一个 IP 没秒只能发送一次请求（1r/s），这里配置了缓存3个请求，就意味着同一秒内只能允许 4 个任务响应成功，其它任务请求则失败（503错误） limit_req zone=mylimit burst=3 nodelay; proxy_pass http://localhost:7070; }} 并发限制Nginx 并发限制的功能来自于 ngx_http_limit_conn_module 模块，跟请求配置一样，使用它之前，需要先定义参照标准和状态缓存区。 limit_conn_zone 只能配置在 http 范围内； $binary_remote_addr 表示客户端请求的IP地址； myconn 自己定义的变量名（缓冲区）； limit_rate 限制传输速度 limit_conn 与 limit_conn_zone 对应，限制网络连接数 下面的配置就是定义了使用客户端的 IP 作为参照依据，并使用一个 10M 大小的状态缓存区。限定了每个IP只允许建立一个请求连接，同时传输的速度最大为 1024KB 123456789101112# 定义了一个 myconn 缓冲区（容器）limit_conn_zone $binary_remote_addr zone=myconn:10m;server { listen 70; location / { # 每个 IP 只允许一个连接 limit_conn myconn 1; # 限制传输速度（如果有N个并发连接，则是 N * limit_rate） limit_rate 1024k; proxy_pass http://localhost:7070; }} 原文地址：https://cloud.tencent.com/developer/article/1786015 Nginx代理后服务端使用remote_addr获取真实IP在代理服务器的Nginx配置（yourWebsite.conf）的location /中添加： 12345#获取客户端IPproxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header REMOTE-HOST $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 在业务服务器的Nginx配置（yourWebsite.conf）的location中添加： 1fastcgi_param HTTP_X_FORWARDED_FOR $http_x_forwarded_for; 配置到这，可以用HTTP_X_FORWARDED_FOR获取客户端真实IP，以PHP为例，$_SERVER[‘HTTP_X_FORWARDED_FOR’]，但是remote_addr还是代理服务器的IP，接着往下配置，把remote_addr也配置成真实IP。 在业务服务器的Nginx配置（yourWebsite.conf）的location中继续添加： 12set_real_ip_from 172.18.209.11/24;#这里的IP是代理服务器的IP，也可以是IP段。意思是把该IP请求过来的x_forwarded_for设为remote_addrreal_ip_header X-Forwarded-For; Tip：添加上面两行之前，需要查看Nginx是否安装了realip模块，Nginx默认是不安装的，查看命令 nginx -V ，结果如下所示，如果没有realip模块，需要先安装。 12345nginx version: nginx/1.14.0built by gcc 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017TLS SNI support enabledconfigure arguments: --prefix=/usr/local/nginx --with-select_module --with-poll_module --with-threads --with-file-aio --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_auth_request_module --with-http_random_index_module --with-http_degradation_module --with-http_slice_module --with-http_stub_status_module --with-stream --with-stream=dynamic --with-stream_ssl_module --with-pcre --add-module=/usr/local/nginx_upstream_check_module-master/ 关于nginx不支持PATHINFO问题的解决配置好的NGINX配置文件 server { listen 80; server_name www.newmvc.com; root /Users/likang/Desktop/mvc_new; #charset koi8-r; access_log logs/www.newmvc.com.access.log main; error_log logs/www.newmvc.com.error.log; location / { autoindex on; index index.php index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ \\.php { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi_params; set $real_script_name $fastcgi_script_name; if ($fastcgi_script_name ~ &quot;^(.+?\\.php)(/.+)$&quot;) { set $real_script_name $1; set $path_info $2; } fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_INFO $path_info; } # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #} } 需要注意的是 1location ~ \\.php 这个地方$ 要去掉 还有一种更简单的办法，还是不支持pathinfo使用另外的路由模式，也能解决问题，建议使用第一种办法 1234if (!-e $request_filename) { rewrite ^index.php/(.*)$ /index.php?$1 last; break;} 反向代理后视频需要全部缓冲后才能播放可以尝试添加下面的头部 12proxy_set_header Range $http_range;proxy_set_header If-Range $http_if_range;","link":"/2021/06/16/Nginx-%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/"},{"title":"PHP  fsockopen","text":"1234567fsockopen( string $hostname, int $port = -1, int &amp;$errno = ?, string &amp;$errstr = ?, float $timeout = ini_get(&quot;default_socket_timeout&quot;)): resource 初始化一个套接字连接到指定主机（hostname）。 PHP支持以下的套接字传输器类型列表 所支持的套接字传输器（Socket Transports）列表。也可以通过stream_get_transports()来获取套接字传输器支持类型。 默认情况下将以阻塞模式开启套接字连接。当然你可以通过stream_set_blocking()将它转换到非阻塞模式。 stream_socket_client()与之非常相似，而且提供了更加丰富的参数设置，包括非阻塞模式和提供上下文的的设置。 参数 ¶ hostname 如果安装了OpenSSL，那么你也许应该在你的主机名地址前面添加访问协议ssl://或者是tls://，从而可以使用基于TCP/IP协议的SSL或者TLS的客户端连接到远程主机。 port 端口号。如果对该参数传一个-1，则表示不使用端口，例如unix://。 errno 如果传入了该参数，holds the system level error number that occurred in the system-level connect() call。如果errno的返回值为0，而且这个函数的返回值为**false**，那么这表明该错误发生在套接字连接（connect()）调用之前，导致连接失败的原因最大的可能是初始化套接字的时候发生了错误。 errstr 错误信息将以字符串的信息返回。 timeout 设置连接的时限，单位为秒。注意:注意：如果你要对建立在套接字基础上的读写操作设置操作时间设置连接时限，请使用stream_set_timeout()，**fsockopen()**的连接时限（timeout）的参数仅仅在套接字连接的时候生效。 返回值 ¶**fsockopen()将返回一个文件句柄，之后可以被其他文件类函数调用（例如：fgets()，fgetss()，fwrite()，fclose()还有feof()）。如果调用失败，将返回false**。 错误／异常 ¶如果主机（hostname）不可访问，将会抛出一个警告级别（**E_WARNING**）的错误提示。 **示例 #1 *fsockopen()*的例子 123456789101112131415&lt;?php$fp = fsockopen(&quot;www.example.com&quot;, 80, $errno, $errstr, 30);if (!$fp) { echo &quot;$errstr ($errno)&lt;br /&gt;\\n&quot;;} else { $out = &quot;GET / HTTP/1.1\\r\\n&quot;; $out .= &quot;Host: www.example.com\\r\\n&quot;; $out .= &quot;Connection: Close\\r\\n\\r\\n&quot;; fwrite($fp, $out); while (!feof($fp)) { echo fgets($fp, 128); } fclose($fp);}?&gt; 示例 #2 使用UDP连接 下面这个例子展示了怎么样在自己的机器上通过UDP套接字连接（端口号13）来检索日期和时间。 123456789101112131415&lt;?php$fp = fsockopen(&quot;www.example.com&quot;, 80, $errno, $errstr, 30);if (!$fp) { echo &quot;$errstr ($errno)&lt;br /&gt;\\n&quot;;} else { $out = &quot;GET / HTTP/1.1\\r\\n&quot;; $out .= &quot;Host: www.example.com\\r\\n&quot;; $out .= &quot;Connection: Close\\r\\n\\r\\n&quot;; fwrite($fp, $out); while (!feof($fp)) { echo fgets($fp, 128); } fclose($fp);}?&gt; 原文地址： https://www.php.net/manual/zh/function.fsockopen.php","link":"/2021/11/21/PHP%20%20fsockopen/"},{"title":"PHP yield ，生成器，迭代器，聚合迭代器，协程","text":"yield语法1$data = (yield $express); yield 的左边是一个赋值语句，右边可以是值（也可是表达式） 。而yield 会先执行右边的表达式，并把值$value送到生成器外面。当生成器收到值后，会执行yield左边的语句，赋值给$data. 使用12345678910111213141516&lt;?php$generator = (function () { $a = yield 'first'; echo PHP_EOL;var_dump($a); $b = yield 'second'; echo PHP_EOL;var_dump($b); $c = yield; echo PHP_EOL;var_dump($c);})();echo $generator-&gt;current();$generator-&gt;next();echo $generator-&gt;current();$generator-&gt;next();$generator-&gt;send('third'); php7之前需要(yield 123) 执行$generator-&gt;current(); 会执行第一个yield, 然后暂停 当执行$generator-&gt;next()或者$generator-&gt;send(null); 会往下执行直到第二个yield 当执行$generator-&gt;send(‘third’); 时候，yield实际是send的值, 将yield的值赋值给$a，所以代码中的$c为third，并且会执行下面的语句, 执行下一个yield，此时再调用$generator-&gt;current() 就是下一个yield 当生成器全部迭代完毕可以调用$generator-&gt;getReturn() 获取返回值 调用$generator-&gt;next()会到达下一个yield 第一次直接send() 会导致yield弹出值丢失 yield from 左边不能有接收，因为没有意义，但是可以嵌套 $c[] = yield ‘name’ =&gt; ‘zhangsan’ 支持这样的写法 当$gen迭代器被创建的时候一个rewind()方法已经被隐式调用，rewind执行会导致第一个yield被执行且忽略返回值 12345678$g = function () { yield 1; yield 2;};$g = $g();var_dump($g-&gt;send('test')); // 2 yield from 是一个强大且不可缺少的语法，如果只有 yield 那么就只是有了生成器，有了 yield from 那就有了一根强大的“针”——穿过一个个 生成器，按照call stack 把一个个生成器串了起来。 调用方法用 call_user_func()，调用 生成器用 yield from . yield from: https://segmentfault.com/a/1190000022754223 协程1234567891011&lt;?php$logger = (function () { $fd = fopen('./log.log', 'a+'); while (true) { fwrite($fd, yield); } fclose($fd);})();$logger-&gt;send('test'. PHP_EOL); ZH-CN : https://www.laruence.com/2015/05/28/3038.htmlEN-US： https://www.npopov.com/2012/12/22/Cooperative-multitasking-using-coroutines-in-PHP.html","link":"/2021/12/26/PHP%20yield%20%EF%BC%8C%E7%94%9F%E6%88%90%E5%99%A8%EF%BC%8C%E8%BF%AD%E4%BB%A3%E5%99%A8%EF%BC%8C%E8%81%9A%E5%90%88%E8%BF%AD%E4%BB%A3%E5%99%A8%EF%BC%8C%E5%8D%8F%E7%A8%8B/"},{"title":"Mysql基础命令及语法笔记","text":"show 命令 help show 查看允许的show语句 12345678show databasesshow tablesshow [full] columns from &lt;table&gt;show create database &lt;name&gt;show statusshow grantsshow errorsshow warnings set names设置编码 1set names 'utf8'; select1select distinct &lt;column&gt; from &lt;table&gt; 对于order by , A 和 a 不一定相同（在mysql中默认相同【字典排序】），取决于数据库怎么设计，通常可以改变这种行为。 对于没有排序的语句，返回的结果集的顺序没有特殊意义，又可能按照插入表的顺序，也有可能不是，只要返回总数正确，就是正常的。 正则1SELECT * FROM users WHERE name REGEXP BINARY '^cheng.*g$' --使用BINARY来区分大小写 1SELECT * FROM information WHERE salary REGEXP '1000|2000' --OR匹配 1SELECT * FROM users WHERE name REGEXT '[cz]ong' -- 单一字符，会匹配cong / zong； 可以使用否定 例如：[^cz] 其他支持的正则 [0-9], \\\\-（特殊字符）-, 也可以用来引用元字符，例如\\\\f (换页)， \\\\n （换行），\\\\r （换行）, \\\\t （制表）, \\\\v （纵向制表），\\\\ （反斜线），多数正则表达式使用单个反斜线转义特殊字符，mysql要求使用两个，一个由mysql解析，另外一个由正则表达式库解析。 like 也支持binary来区分大小写 like binary, 大小写主要取决于表的校对规则collect 字符类（character class） 类 说明 [:alnum:] 任意字母和数字.(同[ a-zA-Z0-9]) [:alpha:] 任意字符（同[ a-zA-Z]) [:blank:] 空格和制表（同[ \\lt]) [:cntrl:] ASCII控制字符（ASCII 0到31和127) [:digit:] 任意数字（同[0-9]) [:graph:] 与[ :print : ]相同，但不包括空格 [:lower:] 任意小写字母(同[ a-z]) [:print:] 任意可打印字符 [:punct:] 既不在[ :alnum: ]又不在[ :cntrl: ]中的任意字符 [:space:] 包括空格在内的任意空白字符（同[ \\lf\\ln \\lrlltllv]) [:upper:] 任意大写字母(同[A-Z]) [:xdigit:] 任意十六进制数字（同[ a-fA-FO-9]) 12select * from contracts where amount regexp '[[:digit:]]{2,4}'-- 匹配2到四位数字 匹配多个实例支持*,+, ?, {n}, {n,}, {n,m} 其中m不能大于255 （mysql8测试可以输入大于255的数字，但是有没有效果没有测试） 元字符 元字符 说明 ^ 文本的开始 $ 文本的结尾 [[:&lt;:]] 词的开始 [[:&gt;:]] 词的结尾 匹配词的边界，兼容perl的正则表达式通常使用\\b单词边界 或者\\B 非单词边界 使REGEXP起类似LIKE的作用， LIKE和REGEXP的不同在于、LIKE匹配整个串而REGEXP匹配子串。利用定位符,通过用^开始每个表达式，用$结束每个表达式可以使REGEXP的作用与LIKE一样。 简单的正则表达式测试可以在不使用数据库表的情况下用SELECT来测试正则表达式。 REGEXP检查总是返回0(没有匹配）或1(匹配）。可以用带文字串的REGEXP来测试表达式，并试验它们。相应的语法如下: 1SELECT 'hello' REGEXP '[0-9]'; 计算字段拼接（concatenate）字段或者字符串 多数数据库采用||或者+ 来拼接，而Mysql使用concat() 函数拼接。 删除多余空格rtrim() ltrim() trim() AS 别名，可以用来创建一个计算字段，当列名不符合规定的字符例如包含空格的时候可以使用别名代替，在原名易混淆时候扩充它。别名也称作导出列（derivid column） 函数文本处理函数 函数 说明 LEFT(Str,length) 返回串左边的字符 Length() 返回串的长度 Locate() 找出一个串的子串 Lower() 将串转为小写 Ltrim() 去掉左边的空格 Right() 返回串右边的字符 Rtrim() 去掉右边空格 Soundex() 发音接近 SubString() 返回子串的字符 Upper() 将串转为大写 LOCATE(substr,str) 寻找子串位置，返回数字，0表示没有找到 LOCATE(substr,str,pos) POSITION(substr IN str) INSTR(str,substr) REVERSE(Str) 翻转 12345678SELECT * FROM party_course_studyWHERE LOCATE(findCode, '00001') &gt;0 // 注：Mybatis使用场景，需要加 &lt;![CDATA[ ]]&gt;SELECT * FROM party_course_studyWHERE &lt;![CDATA[ LOCATE(findCode, '00001') &gt; 0 ]]&gt; 表中的SOUNDEX需要做进一步的解释。SOUNDEX是一个将任何文本串转换为描述其语音表示的字母数字模式的算法。SOUNDEX考虑了类似的发音字符和音节，使得能对串进行发音比较而不是字母比较。虽然SOUNDEX不是SQL概念，但MySQL（就像多数DBMS一样）都提供对SOUNDEX的支持。 日期和时间处理函数 函数 说明 AddDate() 增加一个日期（天、周等） AddTime() 增加一个时间（时、分等） CurDate() 返回当前日期 CurTime () 返回当前时间 Date() 返回日期时间的日期部分 DateDiff () 计算两个日期之差 Date_Add() 高度灵活的日期运算函数 Date Format () 返回一个格式化的日期或时间串 Day() 返回一个日期的天数部分 DayOfWeek() 对千一个日期， 返回对应的星期几 Hour() 返回一个时间的小时部分 minute() 返回一个时间的分钟部分 Month () 返回一个日期的月份部分 Now() 返回当前日期和时间 Second() 返回一个时间的秒部分 Time () 返回一个日期时间的时间部分 Year() 返回一个日期的年份部分 DATE_FORMAT(CURDATE(),’%Y%m’) 结果为当前年和月 CURRENT_TIMESTAM 当前时间戳 CURRENT_TIME 当前时间 CURRENT_DATE 当前日期 mysql查询今天、昨天、本周、本月、上一月 、今年数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384--今天select * from 表名 where to_days(时间字段名) = to_days(now());--昨天SELECT * FROM 表名 WHERE TO_DAYS( NOW( ) ) - TO_DAYS( 时间字段名) &lt;= 1--本周SELECT * FROM 表名 WHERE YEARWEEK( date_format( 时间字段名,'%Y-%m-%d' ) ) = YEARWEEK( now() ) ;--本月SELECT * FROM 表名 WHERE DATE_FORMAT( 时间字段名, '%Y%m' ) = DATE_FORMAT( CURDATE( ) ,'%Y%m' ) --上一个月SELECT * FROM 表名 WHERE PERIOD_DIFF(date_format(now(),'%Y%m'),date_format(时间字段名,'%Y%m') =1--本年SELECT * FROM 表名 WHERE YEAR( 时间字段名 ) = YEAR( NOW( ) ) --上一月SELECT * FROM 表名 WHERE PERIOD_DIFF( date_format( now( ) , '%Y%m' ) , date_format( 时间字段名, '%Y%m' ) ) =1--查询本季度数据select * from `ht_invoice_information` where QUARTER(create_date)=QUARTER(now());--查询上季度数据select * from `ht_invoice_information` where QUARTER(create_date)=QUARTER(DATE_SUB(now(),interval 1 QUARTER));--查询本年数据select * from `ht_invoice_information` where YEAR(create_date)=YEAR(NOW());--查询上年数据select * from `ht_invoice_information` where year(create_date)=year(date_sub(now(),interval 1 year));--查询当前这周的数据 SELECT name,submittime FROM enterprise WHERE YEARWEEK(date_format(submittime,'%Y-%m-%d')) = YEARWEEK(now());--查询上周的数据SELECT name,submittime FROM enterprise WHERE YEARWEEK(date_format(submittime,'%Y-%m-%d')) = YEARWEEK(now())-1;--查询当前月份的数据select name,submittime from enterprise where date_format(submittime,'%Y-%m')=date_format(now(),'%Y-%m')--查询距离当前现在6个月的数据select name,submittime from enterprise where submittime between date_sub(now(),interval 6 month) and now();--查询上个月的数据select name,submittime from enterprise where date_format(submittime,'%Y-%m')=date_format(DATE_SUB(curdate(), INTERVAL 1 MONTH),'%Y-%m')select * from ` user ` where DATE_FORMAT(pudate, ' %Y%m ' ) = DATE_FORMAT(CURDATE(), ' %Y%m ' ) ;select * from user where WEEKOFYEAR(FROM_UNIXTIME(pudate,'%y-%m-%d')) = WEEKOFYEAR(now())select * from user where MONTH (FROM_UNIXTIME(pudate, ' %y-%m-%d ' )) = MONTH (now())select * from [ user ] where YEAR (FROM_UNIXTIME(pudate, ' %y-%m-%d ' )) = YEAR (now())and MONTH (FROM_UNIXTIME(pudate, ' %y-%m-%d ' )) = MONTH (now())select * from [ user ] where pudate between 上月最后一天and 下月第一天where date(regdate) = curdate();select * from test where year(regdate)=year(now()) and month(regdate)=month(now()) and day(regdate)=day(now())SELECT date( c_instime ) ,curdate( )FROM `t_score`WHERE 1LIMIT 0 , 30 数值处理函数 函数 说明 Abs () 返回一个数的绝对值 Cos () 返回一个角度的余弦 Exp () 返回一个数的指数值 Mod () 返回除操作的余数 Pi（） 返回圆周率 Rand () 返回一个随机数 Sin () 返回一个角度的正弦 Sqrt() 返回一个数的平方根 Tan () 返回一个角度的正切 聚集函数 AVG() 返回某列的平均值 COUNT() 返回某列的行数 MAX() 返回某列的最大值 MIN() 返回某列的最小值 SUM() 返回某列值之和 不可以使用distinct , count() 包含null，count(字段) 不包含null，；利用标准运算符，所有的聚集函数都可以执行多个列的运算 1select count(distinct cid) from notes; 聚合函数可以聚合多个列的计算值，例如 1select sum(price * stock) from products; concat系列函数concatmysql 1select concat(id, name) as id_and_name from users; 返回两个字段拼接的值，如果有一个字段的值为null，则返回null oracle, psql 可以使用||来分割，例如 1select id || name as id_and_name from users; 好像是上面这么写的，好久没用了。 concat_ws concat with separator, 使用分隔符分割 1select concat_ws(',', id, name) as id_and_name from users; 返回结果例如，分隔符如果为null则返回null 12id = 1, name = 2id_and_name 1,2 group_concat 功能：将group by产生的同一个分组中的值连接起来，返回一个字符串结果。 语法：group_concat( [distinct] 要连接的字段 [order by 排序字段 asc/desc ] [separator '分隔符']) 在有group by的查询语句中，select指定的字段要么就包含在group by语句的后面，作为分组的依据，要么就包含在聚合函数中 例如，查询相同姓名中年龄最小的用户 1select name, min(age) from users group by name; 如果要查出所有 1select name, age from users order by age; 则name可能重复，可以使用group_concat 1select name, group_concat(age) from users group by name; 分组group by 必须出现在where之后order by之前 使用with rollup 可以获取分组汇总级别 1select count(id), id from users group by id with rollup; 我们经常发现用GROUP BY分组的数据确实是以分组顺序输出的。但情况并不总是这样，它并不是SQL规范所要求的。此外，用户也可能会要求以不同于分组的顺序排序。仅因为你以某种方式分组数据（获得特定的分组聚集值)，并不表示你需要以相同的方式排序输出。应该提供明确的ORDER BY子句，即使其效果等同于GROUP BY子句也是如此。 不要忘记ORDER BY一般在使用GROUP BY子句时，应该也给出ORDER BY子句。这是保证数据正确排序的唯一方法。千万不要仅依赖GROUP BY排序数据。 排序随机排序1order by rand() 取消排序1order by null 自定义排序1order by field(id, 1,3,4) 根据id自定义排序，如果id是null或者不存在于后面的列表中则排序为0，否则按照后面给定的排序进行排序 SQL子句顺序 子句 说明 是否必须使用 SELECT 要返回的列或表达式 是 FROM 从中检索数据的表 仅在从表选择数据时使用 WHERE 行级过滤 否 GROUP BY 分组说明 仅在按组计算聚集时使用 HAVING 组级过滤 否 ORDER BY 输出排序顺序 否 LIMIT 要检索的行数 否 子查询1select * from maker where country_id in (select country_id from country); 联表自联结内联外联【左，右】full join 组合查询union 会去除重复行union all 不会去除重复行 索引禁用、启用索引 12alter table users disable keys; --禁用alter table users enable keys; --启用 在批量插入数据之前禁用索引，插入完成后启用索引 创建索引添加PRIMARY KEY（主键索引）1ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` ) 添加UNIQUE(唯一索引)1ALTER TABLE `table_name` ADD UNIQUE ( `column` ) 添加INDEX(普通索引)1ALTER TABLE `table_name` ADD INDEX index_name ( `column` ) 添加FULLTEXT(全文索引)建表时建立123456CREATE TABLE article ( id INT AUTO_INCREMENT NOT NULL PRIMARY KEY, title VARCHAR(200), body TEXT, FULLTEXT(title, body) ) TYPE=MYISAM; 修改1ALTER TABLE `table_name` ADD FULLTEXT INDEX index_name( `column`, `column2`); 直接添加1CREATE FULLTEXT INDEX index_name(`column`) on `table_name`; 添加多列索引1ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` ) 修改索引mysql中没有真正意义上的修改索引，只有先删除之后在创建新的索引才可以达到修改的目的，原因是mysql在创建索引时会对字段建立关系长度等，只有删除之后创建新的索引才能创建新的关系保证索引的正确性； 如：将login_name_index索引修改为单唯一索引； 12DROP INDEX login_name_index ON `user`; ALTER TABLE `user` ADD UNIQUE login_name_index ( `login_name` ); 删除索引格式：DROP INDEX 索引名称 ON 表名; 123DROP INDEX login_name_index ON 'user';ALTER TABLE `table_name` DROP INDEX 'index_name'; 查询索引格式：SHOW INDEX FROM 表名; 1SHOW INDEX FROM `user`; 全文索引全文本搜索时，MySQL不需要分别查看每个行，不需要分别分析和处理每个词。MySQL创建指定列中各词的-一个索引，搜索可以针对这些词进行。这样，MySQL可以快速有效地决定哪些词匹配(哪些行包含它们)，哪些词不匹配，它们匹配的频率，等等。 Mysql5.7之后innodb引擎也支持全文索引 通常在建表的时候添加fulltext索引，例如 1234create table notes ( title text, fulltext(title))engine=myisam; 也可以使用create index 或者alter table来添加索引 match() against() 还可以作为一个列， 1select match(title) against('rabbit') as sc from notes; sc 表示全文检索的计算出的等级值 使用参考：MySQL使用全文索引(fulltext index)_椰汁菠萝-CSDN博客_fulltext index 使用全文索引需要注意的是：(基本单位是词)， MySQL默认的分词是所有非字母和数字的特殊符号都是分词符 使用Match() 和 Against() 来使用全文索引进行检索 1select note_text from notes where match(note_text) against('book'); match() 可以包含多个列，例如match(title,content) , 应该和建立索引时候的顺序一致 当查询多列数据时，建议在此多列数据上创建一个联合的全文索引，否则使用不了索引的 检索的文本越靠前，等级值越大。如果包含多个搜索项，则包含多个匹配词的行的等级值更高 查询扩展扫描步骤如下： 全文检索，筛选结果行 检查匹配行，选择有用词 再次全文检索，包含上个步骤选择词 1select note_text from notes where match(note_text) against('book' with query expansion); 记录越多，文本越多，使用查询扩展返回的结果越好 布尔全文检索 即使没有fulltext索引也可以使用，但是比较慢且性能差 关键点： 要匹配的词 要排除的词（即使有匹配到的词也会排除掉） 排列提示（指定一些更重要的词，越重要的词等级越高） 表达式分组 其他 12--匹配heavy 排除rope*（rope开头的词）SELECT note_ text FROM productnotes WHERE Match(note_ text) Agai nst( 'heavy -rope*' IN BOOLEAN MODE); 布尔操作符 说明 + 包含，词必须存在 - 排除，词必须不出现 &gt; 包含且增加等级值 &lt; 包含且减少等级值 （） 把词组成子表达式，允许这些组表达式作为一个组被包含，排除，排列等 ~ 取消一个词的排序值 * 词尾的通配符 “” 定义一个短语，它匹配整个短语 12345678910SELECT note_text FROM productnotes WHERE Match(note_text) Against('+rabbit +bait'IN BOOLEAN MODE);--这个搜索匹配包含词rabbit和bait的行。SELECT note_text FROM productnotes WHERE Match(note_text) Against('rabbit bait'IN BOOLEAN MODE); --没有指定操作符，这个搜索匹配包含rabbit和bait中的至少一个词的行。SELECT note_text FROM productnotes WHERE Match(note_text) Against('&quot;rabbit bait&quot;'IN BOOLEAN MODE); --这个搜索匹配短语rabbitbait而不是匹配两个词rabbit和bait。SELECT note_text FROM productnotes WHERE Match(note_text) Against('&gt;rabbit &lt;carrot'IN BOOLEAN MODE); --匹配rabbit和carrot,增加前者的等级，降低后者的等级。SELECT note_text FROM productnotes WHERE Match (note_text) Against('+safe +(&lt;Combination)'IN BOOLEAN MODE); --这个搜索匹配词safe和combination,降低后者的等级。 扩展 在索引全文本数据时，短词被忽略且从索引中排除。短词定义为那些具有3个或3个以下字符的词(如果需要,这个数目可以更改)。 MySQL带有一个内建的非用词(stopword) 列表，这些词在索引全文本数据时总是被忽略。如果需要，可以覆盖这个列表(请参阅MySQL文档以了解如何完成此工作)。 许多词出现的频率很高，搜索它们没有用处(返回太多的结果)。因此，MySQL规定了一条50%规则，如果-一个词出现在50%以上的行中，则将它作为一个非用词忽略。50%规则不用于IN BOOLEAN MODE。 如果表中的行数少于3行，则全文本搜索不返回结果(因为每个词或者不出现，或者至少出现在50%的行中)。 忽略词中的单引号。例如，don’t索 引为dont。 不具有词分隔符(包括日语和汉语)的语言不能恰当地返回全文本搜索结果。 邻近操作符 视图使用视图的优势： 重用SQL语句 简化复杂的SQL 使用表的组成部分而不是整个表，因此可以作保保护数据即授予表特定部分的访问权限，而不是整个表 更改数据格式，视图可以返回与底层表示和格式不同的数据 视图本身不包含数据，使用视图实际上是使用视图的查询规则检索数据。如果修改源表的数据，视图中查询到的数据也会被修改。 可以通过视图修改数据 视图创建的规则和限制 视图名不可与其他视图或表名重复 创建视图数量没有限制 创建视图必须有相应访问权限 视图可以嵌套（使用视图再创建视图） ORDER BY可以在视图中使用，但是如果检索的SQL中有ORDER BY则视图中的被覆盖 视图不能索引，也不能有关联的触发器或者默认值 视图可以和表一起使用 使用视图创建视图1create view &lt;view_name&gt; as &lt;dql&gt; 查看创建视图语句1show create view &lt;view_name&gt; 删除视图1drop view &lt;view_name&gt; 修改视图可以先删除视图在创建，也可以 1create or repace view &lt;view_name&gt; 视图可以更新，但是如果Mysql认为基数据不能被正确更新，则不会更新，在以下情况下不会更新 分组 group by 和having 联结 子查询 并 聚集函数 Distinct 导出（计算）列 上面的情况可能随着版本不同而有差异，一般情况下视图用来检索 存储过程使用存储过程1call procedure_name(@in, @out) 创建存储过程1234create procedure procedure_name() comment 'procedure comment'beginselect * from notes;end; 注意要先使用\\d $ 或者delimiter $将分隔符;临时更改为$或者其他字符 其中()中可接受参数，begin, end 包含的为存储过程体 可以使用参数 12345create procedure get_username(in id int, out name varchar(10))beginselect `username` into name from users where `id` = id;end;--没有测试，正确性未知 所有变量都必须以@开始 调用 1call get_username(1, @ret); 查询执行返回值 1select @ret; 定义变量1declare total decimal(8,2) default 0; 判断123if &lt;variable&gt; thenselect * from users;end if; 查看存储过程 12show procedure status [like 'keywords'];show create procedure &lt;procudure_name&gt;; 游标 MySQL游标不同于其他多数DBMS， 只能用于存储过程和函数 【早期资料】 使用游标 使用游标前应该先声明（定义），这个过程实际没有检索数据，只是定义要使用的SELECT 语句 一旦声明后，应该打开游标来使用，这个过程用前面定义的SELECT 语句把数据检索出来 对于填有数据的游标，根据需要取出（检索）各行 结束后必须关闭游标 声明游标后，可以频繁地打开或者关闭游标，游标打开后，可以频繁地执行取操作 创建游标使用declare 定义游标 1declare products_f cursor for select * from products order by id; 定义游标之后可以打开游标 1open products_f; open 语句执行查询，存储检索到地数据以提供浏览和滚动。 游标处理完成，应该关闭游标 1close products_f; 关闭游标会释放游标所使用地内存等资源，所以当游标不再需要使用地时候就应该关闭游标，如果你不明确关闭游标，MySQL会在end语句时关闭游标。 使用游标数据 游标被打开后，可以使用fetch语句访问它的每一行。fetch指定检索所需的列，数据存放位置，还会向前移动游标内部指针，使下一条fetch语句检索下一行。 1fetch products_f into o; 检索游标中结果的第一行并将数据存放到局部变量o中，再次执行fetch将检索下一行，除了使用repeat ,还可以使用其他循环语句来重复执行，直到使用leave手动退出，通常repeat的语法更适合对游标进行循环。 例子 1234567891011121314151617create procedure products_p()begin declare done boolean default 0; declare o int; declare products_f cursor for select id from users; -- continue handler 条件出现时被执行的代码 即 SQLSTATE '02000'出现时执行set done = 1 -- SQLSTATE '02000'是一个未找到条件，即没有更多行时候不再循环 ，更多错误代码列可以查看MySQL手册https://dev.mysql.com/doc/refman/8.0/en/error-handling.html declare continue handler for SQLSTATE '02000' set done = 1; open products_f; -- 反复执行知道done为真 repeat fetch products_f into o; until done end repeat; close products_f;end DECLARE语句的次序： DECLARE语句的发布存在特定的次序。用DECLARE语句定义的局部变量必须在定义任意游标或句柄之前定义，而句柄必须在游标之后定义，不遵守此顺序将产生错误消息。 触发器MySQL响应delete, insert, update语句而执行触发的一条SQL或位于begin, end 之间的一组SQL。其他MySQL语句不支持触发器。 创建触发器创建触发器需要提供以下信息 唯一的触发器名 触发器关联的表 触发器应该响应的活动（delete, insert, update） 触发器何时执行（前或者后） 触发器名必须在每个表中唯一，而在每个数据库中不一定唯一。这在其它DBMS中是不允许的。最好是在同一个数据库中保持触发器名唯一 使用create trigger 创建触发器 1create trigger get_id after insert on users for each row select 'insert'; 其中for each row 表示代码对每个插入执行 只有表支持触发器，视图不支持，每个表每个事件只允许一个触发器，因此每个表支支持6个触发器（insert, update, delete 前后 ）。 如果before触发器执行失败，则MySQL不执行请求的操作，如果触发器或语句本身失败，如果有after触发器，则不执行。 删除触发器1drop trigger get_id; 触发器不能更新或者覆盖，因此必须先删除再创建 使用insert 触发器 在insert 触发器代码内，可引用一个NEW的虚拟表，访问被插入的行 在before insert 触发器内，NEW中的值也可以被更新（允许更改被插入的值） 对于auto_increment 列，NEW 在insert 之前包含0，在insert 执行之后包含新的自动生成的值 delete 触发器 在delete 触发器代码内，你可以引用一个名为OLD的虚拟表，访问被删除的行。 OLD中的值全部是只读的，不能更新 下面例子，使用OLD保存将要被删除的行到一个存档表中： 1234create trigger 触发器名 before delete on 表1 for each row begin insert into 表2(列,列,列)values(old.表1列名,old.表1列名,old.表1列名);end 删除表1的数据前会把数据存到结构相同的表2中使用begin end 块的好处是触发器能容纳多条sql语句 **UPDATE 触发器 ** 在update触发器代码中，可以引用一个名为old虚拟表访问以前的值，引用new虚拟表访问新更新的值 new中的值可能被更新，old中的值全部是只读的 1create trigger 触发器名 before update on 表1 for each row set new.id = upper(new.id); 显然，每次更新一个行时，new.id 中的值（将用来更新表行的值）都用upper(new.id)替换。 也就是，如果new.id = 110，那用update更新表1的id时，将用110这个值更新。 触发器的进一步介绍 触发器可以用来创建审计跟踪，使用触发器，把更改记录到另一个表非常容易 mysql触发器不支持call语句，这表示不能从触发器内调用存储过程，只能把存储过程代码复制到触发器内 事务术语事务（transaction）指一组SQL语句 回滚（rollback）撤销指定SQL执行过程 提交（commit）将为存储的SQL语句结果写入数据表 保留点（savepoint）事务处理中设置的临时占位符（place holder） ,可以发布或者回退（与回退整个事务不同） 事务用来管理insert, update, delete 语句，不能回退drop，select， create 操作，即使使用了也不会撤销。 隐含事务提交：commit 或者rollback 后事务会自动关闭。 保留点简单的commit或者rollback会撤销整个事务，但是实际上可能需要回滚或者提交一部分事务，就需要在事务处理块中放置合适的保留点，回滚时回滚到某个保留点，可以使用savepoint创建保留点。 1savepoint delete1; 当需要回滚时，可以指定保留点 1rollback to delete1 可以尽可能多地创建保留点，因为这样就可以更灵活地控制事务。当执行commit 或者rollback 后自动释放保留点，也可以使用release savepoint 释放保留点。 更改默认提交行为关闭自动提交 1set autocommit = 0 该标志是针对当前连接而不是服务器 字符集和编码字符集 字母和符号的集合 编码 某个字符集内成员的内部表示 校对 规定字符集如何比较的指令 查看可用的校对和字符集 123show collation;show variables like '%character%';show variables like '%collation%'; 可以给单个表，单个列设置字符集和校对 select 语句中可以指定使用不同的校对，例如可以使用区分大小写的校对 1select * from users order by username collate latin1_general_cs; 使用cast() 或者convert() 可以在字符集之间转换 数据备份数据备份mysqldump mysqlhotcopy 从一个数据库复制全部数据 back up table / select into outfile -&gt; restore table 为保证所有数据都被写到磁盘（包括索引数据），可能需要在备份前使用flush tables 语句 命令行下具体用法如下： 1mysqldump -u用戶名 -p密码 -d 数据库名 表名 &gt; 脚本名; 导出整个数据库结构和数据 1mysqldump -h localhost -uroot -p123456 database &gt; dump.sql 导出整个数据库结构和数据[包含建库语句] 1mysqldump -h localhost -uroot -p123456 -B database &gt; dump.sql 导出单个数据表结构和数据 1mysqldump -h localhost -uroot -p123456 database table &gt; dump.sql 导出整个数据库结构（不包含数据） 1mysqldump -h localhost -uroot -p123456 -d database &gt; dump.sql 导出单个数据表结构（不包含数据） 1mysqldump -h localhost -uroot -p123456 -d database table &gt; dump.sql 恢复未登录 1mysql -uroot -proot -h127.0.0.1 -P3306 test&lt;s1.sql 登录 1source ./a.sql 数据维护 analyze table 检查表键是否正确 check table 针对许多问题进行检查，在myisam引擎上还针对索引进行检查 , 如果在Myisam引擎上产生的结果不正确，可能需要使用repare table 修复响应的表。 changed 检查自最后一次检查以来改动过的表 extended 执行最彻底的检查 fast 检查未正常关闭的表 medium 检查所有被删除的链接并进行键检验 quick 只进行快速扫描 optimize table 优化表，如果有大量删除操作，应该使用 诊断启动问题 –safe-mode 装载减去某些最佳配置的服务器 –verbose 显示全文本消息，常与–help 联合使用 查看日志文件 错误日志，包含启停或任意关键位置的错误细节，日志名通常为hostname.err 位于data 目录， 可用–log-error 命令更改 查询日志，记录MySQL活动，在诊断问题时非常有用，日志可能会很快变得很大，所以不应该长期使用，位于data 目录，可用–log更改 二进制日志(bin-log)，记录更新或者可能更新过数据的所有语句，日志名通常为hostname-bin，位于data 目录，可用–log-bin 更改 慢查询日志， 可用–log-slow-queries 更改 性能优化MySQL 使用一系列默认配置预先配置的，但随着需求增加，往往需要重新调整分配内存，缓冲区等等。可以使用下面的命令查看变量以及状态 12show [global] variables;show status; 当你遇到MySQL性能显著不良的时候，可以使用 1show [full] processlist 查看活动以及他们的线程id和执行时间，可以使用kill 来终止 使用explain [analyze] 来解释如何执行一条SQL 一般来说，存储过程比一条一条执行SQL性能好 insert 支持一个可选的 delayed 关键字，如果使用，将把控制立即返回给调用程序，并且一旦有可能就实际执行该操作 在导入数据时，应该关闭自动提交，临时禁用索引，索引在导入完成后再开启 1alter table notes disable/enable keys; 如果SQL存在大量OR，可以尝试使用union关键字连接结果 索引可能会加快查询，也可能会降低插入，更新速度 一般来说，尽量使用fulltext 而不是用like 其他语法alter123456789alter table &lt;table_name&gt;( add column &lt;column_name&gt; datatype [null|not null] [constraint], change column &lt;column_name&gt; datatype [null|not null] [constraint], drop column &lt;column_name&gt; add index &lt;column_name&gt; )ALTER table Teacher change Tid Tnum int; //修改列名 create index1create index &lt;index_name&gt; on &lt;table_name&gt; (column [desc|asc], ...); create user1create user &lt;username&gt;[@host] identified [with mysql_native_password] by &lt;password&gt;; drop1drop database|index|procedure|table|trigger|user|view|itemname; insert select1insert into users select * from users_bak; select123456789select column from table_namewhereuniongroup by havingorder by 事务1start transaction; 排序字符串以字典顺序排序，从左向右一次比较每一个字符，这将导致‘10‘位于’2‘之前，数值才能正确排序。 删除1drop procedure &lt;procedure_name&gt; [if exists] 插入123insert 语句耗时，可能因为等待而降低select性能，所以使用下面的语句降低有限级INSERT LOW_PRIORITY INTO--降低insert的有限级，同样适用于update,delete。 更新更新可以使用子查询，即将查到的值更新到列。update ignore 可以忽略错误 更新表不能包含该表的子查询例如 1update user set sex = 1 where id in (select id from user where age &gt; 8) 上面的SQL会报错，应该更改为 1update user left inner join (select id from user where age &gt; 8) set sex = 1; 上面的SQL只是示例 删除12truncate [table] users;delete from 其他外键不能跨引擎，例如myisam不能添加innodb表的主键为外键 12rename table notes to note;alter table notes rename to note; Mysql添加自增列两句查完： 123set @rownum=0;select (@rownum:=@rownum+1),colname from [tablename or (subquery) a]; 一句查完： 1select @rownum:=@rownum+1,colnum from (select @rownum:=0) a,[tablename or (subquery) b]; 多条SQL要用;分割，单条SQL末尾的分号非必须，推荐加上分号，如果使用命令行，则必须要有结尾符。 SQL 语句不区分大小写。最佳的方式是按照大小写惯例，且使用时保持一致。 SQL可以分成多行，用更直观的格式表达 1desc / describe &lt;table&gt;; 函数COALLESCE1COALESCE(expression, value1, value2, valuen) 返回按顺序取第一个不为NULL的值，都为NULL则返回NULL, 因为不判断空字符串，所以如果有空字符串则需要先处理，例如： 1COALESCE(NULLIF(text1, ''), NULLIF(text2, '')) 其他替代 123456--MYSQL: IFNULL(expression,value) --MSSQLServer: ISNULL(expression,value) --Oracle: NVL(expression,value) 格式化时间日期https://www.cnblogs.com/shuilangyizu/p/8036620.html IFMysql的if既可以作为表达式用，也可在存储过程中作为流程控制语句使用IF表达式 1IF(expr1,expr2,expr3) 如果 expr1 是TRUE (expr1 &lt;&gt; 0 and expr1 &lt;&gt; NULL)，则 IF()的返回值为expr2; 否则返回值则为 expr3。IF() 的返回值为数字值或字符串值，具体情况视其所在语境而定。 1select *,if(sva=1,&quot;男&quot;,&quot;女&quot;) as ssva from taname where sva != &quot;&quot; 作为表达式的if也可以用CASE when来实现： 1select CASE sva WHEN 1 THEN '男' ELSE '女' END as ssva from taname where sva != '' 在第一个方案的返回结果中， value=compare-value。而第二个方案的返回结果是第一种情况的真实结果。如果没有匹配的结果值，则返回结果为ELSE后的结果，如果没有ELSE 部分，则返回值为 NULL。 例如： 1234SELECT CASE 1 WHEN 1 THEN 'one' WHEN 2 THEN 'two' ELSE 'more' END as testCol 将输出one 1IFNULL(expr1,expr2) 假如expr1 不为 NULL，则 IFNULL() 的返回值为 expr1; 否则其返回值为 expr2。IFNULL()的返回值是数字或是字符串，具体情况取决于其所使用的语境。 1234567891011mysql&gt; SELECT IFNULL(1,0); -&gt; 1mysql&gt; SELECT IFNULL(NULL,10); -&gt; 10mysql&gt; SELECT IFNULL(1/0,10); -&gt; 10mysql&gt; SELECT IFNULL(1/0,'yes'); -&gt; 'yes' IFNULL(expr1,expr2) 的默认结果值为两个表达式中更加“通用”的一个，顺序为STRING、 REAL或 INTEGER。 IF ELSE 做为流程控制语句使用if实现条件判断，满足不同条件执行不同的操作，这个我们只要学编程的都知道if的作用了，下面我们来看看mysql 存储过程中的if是如何使用的吧。 1234567IF search_condition THEN statement_list[ELSEIF search_condition THEN] statement_list ...[ELSE statement_list]END IF 当IF中条件search_condition成立时，执行THEN后的statement_list语句，否则判断ELSEIF中的条件，成立则执行其后的statement_list语句，否则继续判断其他分支。当所有分支的条件均不成立时，执行ELSE分支。search_condition是一个条件表达式，可以由“=、&lt;、&lt;=、&gt;、&gt;=、!=”等条件运算符组成，并且可以使用AND、OR、NOT对多个表达式进行组合。 例如，建立一个存储过程，该存储过程通过学生学号（student_no）和课程编号（course_no）查询其成绩（grade），返回成绩和成绩的等级，成绩大于90分的为A级，小于90分大于等于80分的为B级，小于80分大于等于70分的为C级，依次到E级。那么，创建存储过程的代码如下： 1234567891011121314151617create procedure dbname.proc_getGrade(stu_no varchar(20),cour_no varchar(10))BEGINdeclare stu_grade float;select grade into stu_grade from grade where student_no=stu_no and course_no=cour_no;if stu_grade&gt;=90 then select stu_grade,'A';elseif stu_grade&lt;90 and stu_grade&gt;=80 then select stu_grade,'B';elseif stu_grade&lt;80 and stu_grade&gt;=70 then select stu_grade,'C';elseif stu_grade70 and stu_grade&gt;=60 then select stu_grade,'D';else select stu_grade,'E';end if;END 注意：IF作为一条语句，在END IF后需要加上分号“;”以表示语句结束，其他语句如CASE、LOOP等也是相同的。 help show 查看允许的show语句 其他1tee /home/cheng/log.sql 将下面的操作都写入改日志 1grant all privileges on testdb.* to ‘test_user’@’localhost’ identified by “jack” with grant option; WITH GRANT OPTION 这个选项表示该用户可以将自己拥有的权限授权给别人。注意：经常有人在创建操作用户的时候不指定WITH GRANT OPTION选项导致后来该用户不能使用GRANT命令创建用户或者给其它用户授权。如果不想这个用户有这个grant的权限，可以不加这句 mysql的SQL长度限制1max_allowed_packet = 6M 把上面这个配置改大就行了 监听SQL登录mysql 12set global general_log_file='/tmp/general.log';set global general_log='on'; 之后执行命令都会记录进LOG 排序MySQL中的排序ORDER BY 除了可以用ASC和DESC，还可以自定义字符串/数字来实现排序。 格式如下： 1SELECT * FROM table ORDER BY FIELD(status,1,2,0); 这样子写的话，返回的结果集是按照字段status的1、2、0进行排序的，当然，也可以对字符串进行排序。 原理如下： FIELD()函数是将参数1的字段对后续参数进行比较，并返回1、2、3等等，如果遇到null或者没有在结果集上存在的数据，则返回0，然后根据升序进行排序。 json字段自MySQL5.7.8版本以来，MySQL支持原生JSON数据类型。允许使用原生JSON数据类型比以前MySQL版本中所使用JSON文本格式更能有效地存储JSON文档。 MySQL以内部格式存储JSON文档，允许对文档元素的快速读取访问。JSON二进制格式的结构是允许服务器通过键或数组索引直接搜索JSON文档中的值，这非常快。 JSON文档的存储大约与存储LONGBLOB或LONGTEXT数据量相同。 要定义数据类型为JSON的列，请使用以下语法： 12345CREATE TABLE `json_test` ( `id` int(11) unsigned NOT NULL, `j` json DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; json列不能有默认值，而且不能直接编入索引，可以在包含从json列中提取的生成列上创建索引，当从JSON列查询数据时，MySQL优化器将在匹配JSON表达式的虚拟列上查找兼容的索引。 如下json数据，存储为两条记录 12insert into json_test values(2, '{&quot;name&quot;:&quot;test&quot;,&quot;age&quot;: 14}');insert into json_test values(2, '{&quot;name&quot;:&quot;test1&quot;,&quot;age&quot;: 12}'); 查询，使用列路径运算符(-&gt;) 1select id, j-&gt;'$.name' as name from json_test; 查询结果如下 123456+----+------------+| id | name |+----+------------+| 1 | &quot;chengyao&quot; || 2 | &quot;test&quot; |+----+------------+ name列值中有引号，怎么去掉，可以使用内联路径运算符( -&gt;&gt;) 1select id, j-&gt;&gt;'$.name' as name from json_test; 查询结果 123456+----+----------+| id | name |+----+----------+| 1 | chengyao || 2 | test |+----+----------+ json函数： (53条消息) MySQL常用Json函数_dragonpeng2008的博客-CSDN博客 生成列MySQL 5.7引入了一个名为生成列的新功能。它之所以叫作生成列，因为此列中的数据是基于预定义的表达式或从其他列计算的。 例如，假设有以下结构的一个contacts表： 123456CREATE TABLE IF NOT EXISTS contacts ( id INT AUTO_INCREMENT PRIMARY KEY, first_name VARCHAR(50) NOT NULL, last_name VARCHAR(50) NOT NULL, email VARCHAR(100) NOT NULL); 要获取联系人的全名，请使用CONCAT()函数，如下所示： 1234SELECT id, CONCAT(first_name, ' ', last_name), emailFROM contacts; 这不是最优的查询。 通过使用MySQL生成的列，可以重新创建contacts表，如下所示： 123456789DROP TABLE IF EXISTS contacts;CREATE TABLE contacts ( id INT AUTO_INCREMENT PRIMARY KEY, first_name VARCHAR(50) NOT NULL, last_name VARCHAR(50) NOT NULL, fullname varchar(101) GENERATED ALWAYS AS (CONCAT(first_name,' ',last_name)), email VARCHAR(100) NOT NULL); GENERATED ALWAYS as(expression)是创建生成列的语法。要测试“全名”列，请在contacts表中插入一行。 12INSERT INTO contacts(first_name,last_name, email)VALUES('john','doe','john.doe@yiibai.com'); 现在，可以从contacts表中查询数据。 当从contacts表中查询数据时，fullname列中的值将立即计算。 MySQL提供了两种类型的生成列：存储和虚拟。每次读取数据时，虚拟列都将在运行中计算，而存储的列在数据更新时被物理计算和存储。 基于此定义，上述示例中的fullname列是虚拟列。 MySQL生成列的语法定义生成列的语法如下： 12column_name data_type [GENERATED ALWAYS] AS (expression) [VIRTUAL | STORED] [UNIQUE [KEY]] 首先，指定列名及其数据类型。 接下来，添加GENERATED ALWAYS子句以指示列是生成的列。 然后，通过使用相应的选项来指示生成列的类型：VIRTUAL或STORED。 默认情况下，如果未明确指定生成列的类型，MySQL将使用VIRTUAL。 之后，在AS关键字后面的大括号内指定表达式。 该表达式可以包含文字，内置函数，无参数，操作符或对同一表中任何列的引用。 如果你使用一个函数，它必须是标量和确定性的。 最后，如果生成的列被存储，可以为它定义一个唯一约束。 MySQL存储列示例我们来看一下products表。 123456789101112131415mysql&gt; desc products;+--------------------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------------------+---------------+------+-----+---------+-------+| productCode | varchar(15) | NO | PRI | | || productName | varchar(70) | NO | | NULL | || productLine | varchar(50) | NO | MUL | NULL | || productScale | varchar(10) | NO | | NULL | || productVendor | varchar(50) | NO | | NULL | || productDescription | text | NO | | NULL | || quantityInStock | smallint(6) | NO | | NULL | || buyPrice | decimal(10,2) | NO | | NULL | || MSRP | decimal(10,2) | NO | | NULL | |+--------------------+---------------+------+-----+---------+-------+9 rows in set 使用quantityInStock和buyPrice列的数据，通过以下表达式计算每个SKU的股票值： 1quantityInStock * buyPrice 但是，可以使用以下ALTER TABLE … ADD COLUMN语句将名为stock_value的存储的生成列添加到products表： 123ALTER TABLE productsADD COLUMN stockValue DOUBLE GENERATED ALWAYS AS (buyprice*quantityinstock) STORED; 通常，ALTER TABLE语句需要完整的表重建，因此，如果更改大表是耗时的。 但是，虚拟列并非如此。 现在，我们可以直接从products表中查询库存值。 1234SELECT productName, ROUND(stockValue, 2) AS stock_valueFROM products; 执行上面查询语句，得到以下结果 - 1234567891011121314151617+---------------------------------------------+-------------+| productName | stock_value |+---------------------------------------------+-------------+| 1969 Harley Davidson Ultimate Chopper | 387209.73 || 1952 Alpine Renault 1300 | 720126.90 || 1996 Moto Guzzi 1100i | 457058.75 || 2003 Harley-Davidson Eagle Drag Bike | 508073.64 || 1972 Alfa Romeo GTA | 278631.36 || 1962 LanciaA Delta 16V | 702325.22 || 1968 Ford Mustang | 6483.12 ||************** 省略了一大波数据 ****************************|| The Queen Mary | 272869.44 || American Airlines: MD-11S | 319901.40 || Boeing X-32A JSF | 159163.89 || Pont Yacht | 13786.20 |+---------------------------------------------+-------------+110 rows in set 参考： MySQL生成列 - MySQL教程 (yiibai.com) 常见错误处理Operation CREATE USER failed for XXX原因：可能是执行了如下操作 1delete from mysql.user where user ='user_1'; 需要再执行下面命令 1drop user user1; ERROR 1269 (HY000): Can’t revoke all privileges for one or more of the requested users需要加上host，例如 1REVOKE ALL PRIVILEGES ON *.* FROM 'testuser'@'localhost'; 字符校对规则问题查询视图时报错：java.sql.SQLException: Illegal mix of collations (utf8mb4_general_ci,IMPLICIT) and (utf8mb4_0900_ai_ci,IMPLICIT) for operation ‘=’； 本地环境:mysql8.0.13 异常提示排序规则编码混乱，mysql8.0.1之后的默认COLLATE为utf8mb4_0900_ai_ci； 检查视图中所包含的表发现其中一个建表时 没有设置编码，并且其他的表设置的是 CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci；因此导致混乱； 查看当前数据库的默认编码： 1mysql&gt; show variables where Variable_name like 'collation%'; 查看各表编码： 1mysql&gt; show create table ‘table_name’; 解决方案给没有设置编码的表重新设置一下： 1mysql&gt; alter table table_name default character set utf8mb4 collate=utf8mb4_general_ci; 这样设置只针对表的，但是表中字段未修改： 1mysql&gt; ALTER TABLE table_name convert to CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci; 修改完成以后，重新创建视图！！！！ 排序内存溢出问题报错：SQLSTATE[HY001]: Memory allocation error: 1038 Out of sort memory, consider increasing sort buffer size 找到mysql配置文件（我的是/etc/mysql/mysql.conf.d/mysqld.cnf）, 添加一行 1sort_buffer_size = 16M 重启数据库，报错继续加大 数据类型相关记录datetime到毫秒5.6 之后可以将字段类型设置为datetime(3), 其中的数字表示精度，三位精确到毫秒 Incorrect key file for notes解决方案（目前使用myisam引擎） 1optimize table notes; 如果不行就google一下 不用密码登录1vim /etc/my.cnf 在[mysqld]段后加一行 1skip-grant-tables 或者用这条命令运行 1/usr/bin/mysqld --skip-grant-tables 重启mysql 12/etc/init.d/mysql restartservice mysql restart 修改validate_password_policy参数的值123set global validate_password_policy=0;#validate_password_length(密码长度)参数默认为8，修改为需要长度set global validate_password_length=1; mysqld命令https://www.cnblogs.com/shymen/p/8850655.html utf8_unicode_ci与utf8_general_ci的区别当前，utf8_unicode_ci校对规则仅部分支持Unicode校对规则算法。一些字符还是不能支持。并且，不能完全支持组合的记号。这主要影响越南和俄罗斯的一些少数民族语言，如：Udmurt 、Tatar、Bashkir和Mari。 utf8_unicode_ci的最主要的特色是支持扩展，即当把一个字母看作与其它字母组合相等时。例如，在德语和一些其它语言中‘ß’等于‘ss’。 utf8_general_ci是一个遗留的 校对规则，不支持扩展。它仅能够在字符之间进行逐个比较。这意味着utf8_general_ci校对规则进行的比较速度很快，但是与使用utf8_unicode_ci的校对规则相比，比较正确性较差）。 例如，使用utf8_general_ci和utf8_unicode_ci两种 校对规则下面的比较相等： Ä = A Ö = O Ü = U 两种校对规则之间的区别是，对于utf8_general_ci下面的等式成立： ß = s 但是，对于utf8_unicode_ci下面等式成立： ß = ss 对于一种语言仅当使用utf8_unicode_ci排序做的不好时，才执行与具体语言相关的utf8字符集 校对规则。例如，对于德语和法语，utf8_unicode_ci工作的很好，因此不再需要为这两种语言创建特殊的utf8校对规则。 utf8_general_ci也适用与德语和法语，除了‘ß’等于‘s’，而不是‘ss’之外。如果你的应用能够接受这些，那么应该使用utf8_general_ci，因为它速度快。否则，使用utf8_unicode_ci，因为它比较准确。 常见报错 ERROR 1055 (42000): Expression #1 of SELECT list is not in GROUP BY clause and contains nonaggregated column ‘work_ad.api_community_pic.id’ which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by mysql5.7默认没有ONLY_FULL_GROUP_BY的设定，将不允许查询字段包括非聚集列，可以使用select @@GLOBAL.sql_mode; 或者 select @@SESSION.sql_mode;查询sql_mode，结果可能是ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION，only_full_group_by：使用这个就是使用和oracle一样的group 规则, select的列都要在group中,或者本身是聚合列(SUM,AVG,MAX,MIN) 才行，其实这个配置目前个人感觉和distinct差不多的，所以去掉就好","link":"/2021/07/05/Mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4%E5%8F%8A%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"title":"PHP7内核zval","text":"一、简介zval可以表示一切PHP中的数据类型, 所以它包含了一个type字段, 表示这个zval存储的是什么类型的值, 常见的可能选项是IS_NULL, IS_LONG, IS_STRING, IS_ARRAY, IS_OBJECT等等。根据type字段的值不同, 我们就要用不同的方式解读value的值, 这个value是个联合体, 比如对于type是IS_STRING, 那么我们应该用value.str来解读zval.value字段, 而如果type是IS_LONG, 那么我们就要用value.lval来解读。另外, PHP是用引用计数来做基本的垃圾回收的, 所以zval中有一个refcount__gc字段, 表示这个zval的引用数目, 但这里有一个要说明的, 在5.3以前, 这个字段的名字还叫做refcount, 5.3以后, 在引入新的垃圾回收算法来对付循环引用计数的时候, 作者加入了大量的宏来操作refcount, 为了能让错误更快的显现, 所以改名为refcount__gc, 迫使大家都使用宏来操作refcount。类似的, 还有is_ref, 这个值表示了PHP中的一个类型是否是引用, 这里我们可以看到是不是引用是一个标志位。这就是PHP5时代的zval。PHP7中的zval和PHP7中的zval从底层上做了很大调整，主要体现在类型和value字段。 二、PHP5中的zval1、zval结构Zend使用zval结构来存储PHP变量的值，该结构如下所示： Zend根据type值来决定访问value的哪个成员，可用值如下：IS_NULL N/AIS_LONG 对应value.lvalIS_DOUBLE 对应value.dvalIS_STRING 对应value.strIS_ARRAY 对应value.htIS_OBJECT 对应value.objIS_BOOL 对应value.lval.IS_RESOURCE 对应value.lval根据这个表格可以发现两个有意思的地方：首先是PHP的数组其实就是一个HashTable，这就解释了为什么PHP能够支持关联数组了；其次，Resource就是一个long值，它里面存放的通常是个指针、一个内部数组的index或者其它什么只有创建者自己才知道的东西，可以将其视作一个handle。 2、引用计数引用计数在垃圾收集、内存池以及字符串等地方应用广泛，Zend就实现了典型的引用计数。多个PHP变量可以通过引用计数机制来共享同一份zval，zval中剩余的两个成员is_ref和refcount就用来支持这种共享。很明显，refcount用于计数，当增减引用时，这个值也相应的递增和递减，一旦减到零，Zend就会回收该zval。那么is_ref呢？ 3、zval状态在PHP中，变量有两种——引用和非引用的，它们在Zend中都是采用引用计数的方式存储的。对于非引用型变量，要求变量间互不相干，修改一个变量时，不能影响到其他变量，采用Copy-On-Write机制即可解决这种冲突——当试图写入一个变量时，Zend若发现该变量指向的zval被多个变量共享，则为其复制一份refcount为1的zval，并递减原zval的refcount，这个过程称为“zval分离”。然而，对于引用型变量，其要求和非引用型相反，引用赋值的变量间必须是捆绑的，修改一个变量就修改了所有捆绑变量。可见，有必要指出当前zval的状态，以分别应对这两种情况，is_ref就是这个目的，它指出了当前所有指向该zval的变量是否是采用引用赋值的——要么全是引用，要么全不是。此时再修改一个变量，只有当发现其zval的is_ref为0，即非引用时，Zend才会执行Copy-On-Write。 4、zval状态切换当在一个zval上进行的所有赋值操作都是引用或者都是非引用时，一个is_ref就足够应付了。然而，世界总不会那么美好，PHP无法对用户进行这种限制，当我们混合使用引用和非引用赋值时，就必须要进行特别处理了。情况I、看如下PHP代码：代码如下: 这段代码首先进行了一次初始化，这将创建一个新的zval，is_ref=0, refcount=1，并将a指向这个zval；之后是两次非引用赋值，正如前面所说，只要把b和c都指向a的zval即可；最后一行是个引用赋值，需要is_ref为1，但是Zend发现c指向的zval并不是引用型的，于是为c创建单独的zval，并同时将d指向该zval。从本质上来说，这也可以看作是一种Copy-On-Write，不仅仅是value，is_ref也是受保护的对象。整个过程图示如下： 情况2，看如下PHP代码：代码如下: 这段代码的前三句将把a、b和c指向一个zval，其is_ref=1, refcount=3；第四句是个非引用赋值，通常情况下只需要增加引用计数即可，然而目标zval属于引用变量，单纯的增加引用计数显然是错误的， Zend的解决办法是为d单独生成一份zval副本。全过程如下所示： 5、 参数传递PHP函数参数的传递和变量赋值是一样的，非引用传递相当于非引用赋值，引用传递相当于引用赋值，并且也有可能会导致执行zval状态切换。三、PHP7中的zvalPHP7中的zval的类型做了比较大的调整, 总体来说有如下17种类型: 其中PHP5的时候的IS_BOOL类型, 现在拆分成了IS_FALSE和IS_TRUE俩种类型. 而原来的引用是一个标志位, 现在的引用是一种新的类型。对于IS_INDIRECT和IS_PTR来说, 这俩个类型是用在内部的保留类型, 用户不会感知到。从PHP7开始, 对于在zval的value字段中能保存下的值, 就不再对他们进行引用计数了, 而是在拷贝的时候直接赋值, 这样就省掉了大量的引用计数相关的操作, 这部分类型有:1. IS_LONG2. IS_DOUBLE当然对于那种根本没有值, 只有类型的类型, 也不需要引用计数了:1. IS_NULL2. IS_FALSE3. IS_TRUE而对于复杂类型, 一个size_t保存不下的, 那么我们就用value来保存一个指针, 这个指针指向这个具体的值, 引用计数也随之作用于这个值上, 而不在是作用于zval上了。 另外，关于PHP7中的zval还有标志位和zval预先分配的知识。可以看下下面的参考。","link":"/2020/07/05/PHP7%E5%86%85%E6%A0%B8zval/"},{"title":"Oracle","text":"查询建表语句 ：select dbms_metadata.get_ddl(‘TABLE’,’name’) from dual; 查看存储过程： select dbms_metadata.get_ddl(‘PROCEDURE’,’BSA_PROC_FTP_MGMT’,’CLARO’) from dual; trunc()下面日期操作有误，仅做参考 1.select trunc(sysdate) from dual –2013-01-06 今天的日期为2013-01-062.select trunc(sysdate, ‘mm’) from dual –2013-01-01 返回当月第一天.3.select trunc(sysdate,’yy’) from dual –2013-01-01 返回当年第一天4.select trunc(sysdate,’dd’) from dual –2013-01-06 返回当前年月日5.select trunc(sysdate,’yyyy’) from dual –2013-01-01 返回当年第一天6.select trunc(sysdate,’d’) from dual –2013-01-06 (星期天)返回当前星期的第一天7.select trunc(sysdate, ‘hh’) from dual –2013-01-06 17:00:00 当前时间为17:358.select trunc(sysdate, ‘mi’) from dual –2013-01-06 17:35:00 TRUNC()函数没有秒的精确 /*TRUNC（number,num_digits）Number 需要截尾取整的数字。Num_digits 用于指定取整精度的数字。Num_digits 的默认值为 0。TRUNC()函数截取时不进行四舍五入*/9.select trunc(123.458) from dual –12310.select trunc(123.458,0) from dual –12311.select trunc(123.458,1) from dual –123.412.select trunc(123.458,-1) from dual –12013.select trunc(123.458,-4) from dual –014.select trunc(123.458,4) from dual –123.45815.select trunc(123) from dual –12316.select trunc(123,1) from dual –12317.select trunc(123,-1) from dual –120 oracle数据库控制台的删除变成^H的解决办法 在linux服务器下登录oracle的控制台，如果输入错误，想用删除键删除时却不能删除，打出的是^H的字符。 用如下的命令可以使删除键生效： $ stty erase ^H 恢复以前的设置的命令是： $ stty erase ^？ select table_name from all_tables; 查看所有表 select table_name from user_tables; 查看用户表 desc table_name; 查看表结构 select * from table_name where rownum &lt; 10; 查看前rownum 小于10的数据 ROWNUM是一个序列，bai是oracle数据库du从数据文件或缓冲区中读取数据的顺序。它取得第一条记录则rownum值为1，第二条为2，依次类推。ROWNUM是一个序列，是oracle数据库从数据文件或缓冲区中读取数据的顺序。它取得第一条记录则rownum值为1，第二条为2，依次类推。","link":"/2021/04/02/Oracle/"},{"title":"PHP8配置opcache并开启jit","text":"配置php编译参数需要加上–enable-opcache 配置文件如下： 123456789101112131415161718zend_extension=opcache.so[opcache]opcache.enable=1opcache.enable_cli=1opcache.memory_consumption=528opcache.interned_strings_buffer=8opcache.max_accelerated_files=10000opcache.revalidate_freq=1opcache.fast_shutdown=1opcache.jit_buffer_size # 开启jit，设置buffer_size 请注意，如果您通过命令行运行PHP，则还可以通过-d标志传递这些选项，而不是将它们添加到php.ini： php -dopcache.enable=1 -dopcache.jit_buffer_size=100M如果不包含此伪指令，那么默认值将设置为0，并且JIT将不会运行。如果要在CLI脚本中测试JIT，则需要使用opcache.enable_cli来启用opcache： php -dopcache.enable_cli=1 -dopcache.jit_buffer_size=100Mopcache.enable和opcache.enable_cli之间的区别是，如果要运行，例如内置的PHP服务器则应该使用前者。如果您实际上正在运行CLI脚本，则需要opcache.enable_cli。 在继续之前，让我们确保JIT确实有效，创建一个可通过浏览器或CLI访问的PHP脚本（取决于您测试JIT的位置），并查看以下输出opcache_get_status()： var_dump(opcache_get_status()[‘jit’]); 清除opcache12opcache_reset ()opcache_invalidate ()","link":"/2022/06/15/PHP8%E9%85%8D%E7%BD%AEopcache%E5%B9%B6%E5%BC%80%E5%90%AFjit/"},{"title":"PHPstorm代码提示优化","text":"先看一段代码 1234&lt;?php$request = Max\\Di\\Context::getContainer()-&gt;get(ServerRequestInterface::class);$get = $request-&gt;get(); 此时会发现get方法是不能点击进去的，因为ide不知道$request是个什么。 解决这个问题有三种方法： 方法一： 1234&lt;?php/** @var ServerRequestInterface $request */$request = Max\\Di\\Context::getContainer()-&gt;get(ServerRequestInterface::class);$get = $request-&gt;get(); 给$request添加一个注释，说明类型是一个ServerRequestInterface，这时候ide就会有自动提示了 方法二： 在项目目录添加.phpstorm.meta.php 文件，内容如下： 12345&lt;?phpnamespace PHPSTORM_META { override(\\Max\\Di\\Container::make(0), map('@'));} 这时候，make方法的返回值类型就是make方法的第一个参数，这时候ide也会自动提示 方法三： 1234567891011/** * @template T * * @param class-string&lt;T&gt; $id * * @return T */ public function make(string $id) { } 使用phpstorm泛型注解，可以参考文章 https://www.evget.com/article/2021/7/19/42418.html 另外再提一点关于方法注释的问题 php 越来越向强类型转换了，因此在使用高版本php的代码中，有一些注释我认为是可以去掉的，如下： 12345678910if (function_exists('base_path') === false) { /** * @param string $path * @return string */ function base_path(string $path = ''): string { return BASE_PATH . ltrim($path, '/'); }} 其中的 1234/** * @param string $path * @return string */ 是完全可以删除的，因为函数的原型已经描述得很清楚了，参数path类型是string，返回值是string。对于方法中没有提示类型的可以加上参数类型的注释，对于抛出异常应该加注释，如果想要解释这个函数的作用 1234567/*** balabala*/function base_path(string $path = ''): string{ return BASE_PATH . ltrim($path, '/');} 就可以了。","link":"/2022/07/10/PHPstorm%E4%BB%A3%E7%A0%81%E6%8F%90%E7%A4%BA%E4%BC%98%E5%8C%96/"},{"title":"PHP中的Session","text":"一、session预定义常量个人感觉PHP 最大的特点就是功能的实现都靠提供的函数扩展，函数扩展都是根据功能分大类的，session只是其中的一个扩展。该扩展中定义了一些常量，可在PHP 编译或运行时动态载入时可用： 1、SID(string)包含着会话名及会话ID 的常量，格式为”name=ID”，如果会话ID 已经在恰当的会话cookie 中设定时则为空字符串。和session_id() 返回的是同一个ID。 2、PHP_SESSION_DISABLED(int)自PHP 5.4.0起可用。如果会话已禁用，则返回session_status（）的值。 3、PHP_SESSION_NONE(int)自PHP 5.4.0起可用。在会话已启用，但还没有会话时返回session_status（）的值。 4、PHP_SESSION_ACTIVE(int)自PHP 5.4.0起可用。在会话已启用，并存在会话时返回session_status（）的值。 注：会话在PHP中默认为激活（启用）。 session常量动态定义的，网友： 123var_dump(defined('SID')); // bool(false) - Not defined...session_start();var_dump(defined('SID')); // bool(true) - Defined now! 自己测试了下，结果两个都是bool(true)，应该是自己的问题。之后随后重新建一个php文档，执行： 12345&lt;?phpecho SID; //提示使用了未定义常量session_start();echo SID; //显示&quot;name=UID&quot;样式字符串。说明确实是动态定义，因为没有会话就没有会话的UID.?&gt; 二、基本用法通过为每个独立用户分配唯一的会话 ID，可以实现针对不同用户分别存储数据的功能。 会话通常被用来在多个页面请求之间保存及共享信息。 一般来说，会话 ID 通过 cookie 的方式发送到浏览器，并且在服务器端也是通过会话 ID 来取回会话中的数据。 如果请求中不包含会话 ID 信息，那么 PHP 就会创建一个新的会话，并为新创建的会话分配新的 ID。 会话的工作流程很简单。当开始一个会话时，PHP 会尝试从请求中查找会话 ID （通常通过会话 cookie）， 如果请求中不包含会话 ID 信息，PHP 就会创建一个新的会话。 会话开始之后，PHP 就会将会话中的数据设置到 $_SESSION 变量中。 当 PHP 停止的时候，它会自动读取 $_SESSION 中的内容，并将其进行序列化， 然后发送给会话保存管理器器来进行保存。 默认情况下，PHP 使用内置的文件会话保存管理器（files）来完成会话的保存。 也可以通过配置项session.save_handler 来修改所要采用的会话保存管理器。 对于文件会话保存管理器，会将会话数据保存到配置项session.save_path 所指定的位置。 可以通过调用函数 session_start() 来手动开始一个会话。 如果配置项 session.auto_start 设置为1， 那么请求开始的时候，会话会自动开始。 PHP 脚本执行完毕之后，会话会自动关闭。 同时，也可以通过调用函数 session_write_close() 来手动关闭会话。 Example #1 在 $_SESSION 中注册变量。 12345678&lt;?php session_start(); if (!isset($_SESSION['count'])) { $_SESSION['count'] = 0; } else { $_SESSION['count']++; }?&gt; Example #2 从 $_SESSION 中反注册变量。 1234&lt;?php session_start(); unset($_SESSION['count']);?&gt; Caution 千万不要使用 unset($_SESSION) 来复位超级变量 $_SESSION， 因为这样会导致无法继续在 $_SESSION中注册会话变量。 Warning 由于无法将一个引用恢复到另外一个变量， 所以不可以将引用保存到会话变量中。 Warning 如果会话中存在和全局变量同名的变量，那么 register_globals 会导致全局变量被会话变量覆盖。 更多信息请参考 注册全局变量。 Note: 无论是通过调用函数 session_start() 手动开启会话， 还是使用配置项 session.auto_start 自动开启会话， 对于基于文件的会话数据保存（PHP 的默认行为）而言， 在会话开始的时候都会给会话数据文件加锁， 直到 PHP 脚本执行完毕或者显式调用 session_write_close() 来保存会话数据。 在此期间，其他脚本不可以访问同一个会话数据文件。 对于大量使用 Ajax 或者并发请求的网站而言，这可能是一个严重的问题。 解决这个问题最简单的做法是如果修改了会话中的变量， 那么应该尽快调用 session_write_close() 来保存会话数据并释放文件锁。 还有一种选择就是使用支持并发操作的会话保存管理器来替代文件会话保存管理器。 理解：由于HTTP 的不可维持性（执行一段php脚本，实际上进行了一次http 通信），每段php脚本执行完时，会话会自动自动关闭。即同一时刻，只有一个php脚本访问到该session及其数据文件。为了保证每个php脚本访问到的session及其数据文件都是最新的，每次对该session的数据修改都应该及时保存进数据文件中，这在大量Ajax 应用中非常重要。 总结session： 1、session_destroy()：常用方法。 2、unset($_SESSION)：终结必杀，使用后无法继续使用$_SESSION 注册会话变量，所以一般不能用，算不上真正的方法。 网上的另一种方法，思路和删除cookie一样，没有具体实践，不知可行否： 3、setcookie(session_name(),session_id(),time() -8000000,..);","link":"/2021/04/03/PHP%E4%B8%AD%E7%9A%84Session/"},{"title":"PHP判断文件是不是图片","text":"php判断文件是不是图片的方法：1、利用getimagesize函数获取图片信息，然后进行判断；2、读取图片的前2个字节，然后进行判断；3、利用exif_imagetype函数实现判断。 方法一利用 getimagesize 函数获取图片信息，然后进行判断： 12345678910111213141516171819202122232425262728&lt;?php/* Author @ Huoty* Date @ 2015-11-24 16:59:26* Brief @*/function isImage($filename){ $types = '.gif|.jpeg|.png|.bmp'; //定义检查的图片类型 if (file_exists($filename)) { if ($info = @getimagesize($filename)) { return 0; } $ext = image_type_to_extension($info['2']); return stripos($types, $ext); } else { return false; }}if (isImage('isimg.txt') !== false) { echo isImage('1.jpg'); echo '是图片';} else { echo '不是图片';}?&gt; 方法二读取图片的前 2 个字节，然后判断是不是图片： 12345678910111213141516171819202122232425262728293031&lt;?php/* Author @ Huoty* Date @ 2015-11-25 16:42:38* Brief @*///判断上传的是不是图片function isImg($fileName){ $file = fopen($fileName, &quot;rb&quot;); $bin = fread($file, 2); // 只读2字节 fclose($file); $strInfo = @unpack(&quot;C2chars&quot;, $bin); $typeCode = intval($strInfo['chars1'] . $strInfo['chars2']); $fileType = ''; if ($typeCode == 255216 /*jpg*/ || $typeCode == 7173 /*gif*/ || $typeCode == 13780 /*png*/) { return $typeCode; } else {// echo '&quot;仅允许上传jpg/jpeg/gif/png格式的图片！'; return false; }}if (isImg(&quot;1.jpg&quot;)) { echo &quot;是图片&quot;;} else { echo &quot;不是图片&quot;;}?&gt; 方法三最后一种方法是利用 exif_imagetype 函数，该函数用于判断一个图像的类型，采用这种方法更加简单。读取一个图像的第一个字节并检查其签名。 如果发现了恰当的签名则返回一个对应的常量，否则返回 FALSE。返回值和 getimagesize() 返回的数组中的索引 2 的值是一样的，但该函数要快得多。 该函数的返回值常量定义如下： IMAGETYPE_GIF IMAGETYPE_JPEG IMAGETYPE_PNG IMAGETYPE_SWF IMAGETYPE_PSD IMAGETYPE_BMP IMAGETYPE_TIFF_II（Intel 字节顺序） IMAGETYPE_TIFF_MM（Motorola 字节顺序） IMAGETYPE_JPC IMAGETYPE_JP2 IMAGETYPE_JPX IMAGETYPE_JB2 IMAGETYPE_SWC IMAGETYPE_IFF IMAGETYPE_WBMP IMAGETYPE_XBM 示例： 12345678910111213&lt;?php/* Author @ Huoty* Date @ 2015-11-25 16:53:04* Brief @*/$mimetype = exif_imagetype(&quot;1.jpg&quot;);if ($mimetype == IMAGETYPE_GIF || $mimetype == IMAGETYPE_JPEG || $mimetype == IMAGETYPE_PNG || $mimetype == IMAGETYPE_BMP) { echo &quot;是图片&quot;;}?&gt; 原文地址","link":"/2021/03/07/PHP%E5%88%A4%E6%96%AD%E6%96%87%E4%BB%B6%E6%98%AF%E4%B8%8D%E6%98%AF%E5%9B%BE%E7%89%87/"},{"title":"PHP如何实现Aop","text":"前言至于什么是面向切面，面向切面的优势可以参考： https://zhuanlan.zhihu.com/p/421999882 目前看来比较好的实现方式是代理类，代理类就是对原始类文件进行修改，并且通过自动加载加载代理类而非原始类从而实现某些功能。对于常驻内存型的应用，可以使用子进程扫描的方式直接生成代理类，非常驻型则需要提前生成好后将代理类的map缓存起来下次直接使用。 下面讲下基于PHP8原生注解和上述的思路实现的切面 代理类先看下这个类 123456789101112131415161718192021222324252627282930313233343536&lt;?phpdeclare(strict_types=1);/** * This file is part of the Max package. * * (c) Cheng Yao &lt;987861463@qq.com&gt; * * For the full copyright and license information, please view the LICENSE * file that was distributed with this source code. */namespace App\\Http\\Controllers;use Max\\Di\\Annotations\\Inject;use Max\\Routing\\Annotations\\Controller;use Max\\Routing\\Annotations\\GetMapping;use Psr\\Http\\Message\\ResponseInterface;use Psr\\Http\\Message\\ServerRequestInterface;#[Controller(prefix: '/')]class IndexController{ #[Inject] protected ServerRequestInterface $request; #[Inject] protected ResponseInterface $response; #[GetMapping(path: '/')] #[Cacheable] public function index(): array { return $this-&gt;response-&gt;success(message: 'Hello, ' . $this-&gt;request-&gt;get('name', 'MaxPHP') . '!'); }} 使用了类注解，属性注解，方法注解。和代理类相关的主要有属性注解和方法注解，来看下生成的代理类 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?phpdeclare (strict_types=1);/** * This file is part of the Max package. * * (c) Cheng Yao &lt;987861463@qq.com&gt; * * For the full copyright and license information, please view the LICENSE * file that was distributed with this source code. */namespace App\\Http\\Controllers;use Max\\Cache\\Aspects\\Cacheable;use Max\\Di\\Annotations\\Inject;use Max\\Routing\\Annotations\\Controller;use Max\\Routing\\Annotations\\GetMapping;use Psr\\Http\\Message\\ResponseInterface;use Psr\\Http\\Message\\ServerRequestInterface;#[Controller(prefix: '/')]class IndexController{ use \\Max\\Aop\\ProxyHandler; use \\Max\\Aop\\PropertyHandler; public function __construct() { $this-&gt;__handleProperties(); } #[Inject] protected ServerRequestInterface $request; #[Inject] protected ResponseInterface $response; #[GetMapping(path: '/')] #[Cacheable] public function index() : array { return $this-&gt;__callViaProxy(__FUNCTION__, function () { return $this-&gt;response-&gt;success(message: 'Hello, ' . $this-&gt;request-&gt;get('name', 'MaxPHP') . '!'); }, func_get_args()); }} 对比上面的代码，可以发现由于使用了Inject和Cacheable注解，代理类多了构造方法，并且index方法的方法体被$this-&gt;__callViaProxy包裹了。在运行时实际加载的类文件是代理类，而不是原始类。那么如何实现这一过程呢，下面是hyperf的一段代码 12345678910111213141516171819202122$loaders = spl_autoload_functions();// Proxy the composer class loaderforeach ($loaders as &amp;$loader) { $unregisterLoader = $loader; if (is_array($loader) &amp;&amp; $loader[0] instanceof ComposerClassLoader) { /** @var ComposerClassLoader $composerClassLoader */ $composerClassLoader = $loader[0]; AnnotationRegistry::registerLoader(function ($class) use ($composerClassLoader) { return (bool) $composerClassLoader-&gt;findFile($class); }); $loader[0] = new static($composerClassLoader, $proxyFileDirPath, $configDir); } spl_autoload_unregister($unregisterLoader);}unset($loader);// Re-register the loadersforeach ($loaders as $loader) { spl_autoload_register($loader);} 注册新的类加载器，而加载被代理的文件时会加载对应的代理类。下面是MaxPHP的实现 12345678910/** @var Composer\\Autoload\\ClassLoader $loader */unlink($proxyMap);if (!file_exists($proxyMap)) { if (($pid = pcntl_fork()) == -1) { throw new ProcessException('Process fork failed.'); } pcntl_wait($pid);}$loader-&gt;addClassMap($this-&gt;getProxyMap());// 收集注解 思路：因为扫描注解过程会加载类文件，加载之后不能被重新加载（目前不知道咋实现，知道的可以讲下），所以采用子进程扫描生成代理类地图。如上代码，$proxyMap是代理类地图文件，内容例如下： 123456&lt;?php return array ( 'App\\\\Http\\\\Controllers\\\\IndexController' =&gt; '/home/cheng/max/max-http-project/bin/../runtime/aop/proxy/App_Http_Controllers_IndexController_Proxy.php', 'App\\\\Listeners\\\\DatabaseQueryListener' =&gt; '/home/cheng/max/max-http-project/bin/../runtime/aop/proxy/App_Listeners_DatabaseQueryListener_Proxy.php', 'App\\\\Http\\\\Middlewares\\\\ExceptionHandlerMiddleware' =&gt; '/home/cheng/max/max-http-project/bin/../runtime/aop/proxy/App_Http_Middlewares_ExceptionHandlerMiddleware_Proxy.php',); 当文件不存在的时候fork子进程，然后使用pcntl_wait等待子进程退出，接着走到$this-&gt;getProxyMap() 方法，方法内容如下： 1234567891011protected function getProxyMap(){ if(代理类地图不存在) { // 收集注解 // 生成代理类，并写入 // 生成代理类地图，并写入 exit; } // 返回代理类地图} 如上伪代码，代理类不存在会导致子进程退出，而在上面的代码中事先将代理类地图删掉了，所以重启服务肯定会启动两个进程，一个扫描注解，生成代理类后退出，一个等待退出后直接加载代理类地图 ，当然框架中实现还添加了缓存，可以参考max/aop包。重新回到fork子进程的代码，可以看到$loader-&gt;addClassMap()， 代码如下： 12345678public function addClassMap(array $classMap){ if ($this-&gt;classMap) { $this-&gt;classMap = array_merge($this-&gt;classMap, $classMap); } else { $this-&gt;classMap = $classMap; }} 将覆盖原始的类自动加载映射，至此代理类生成原理和代理方法介绍完毕，生成代理类需要使用”nikic/php-parser”包。 如何代理接下来看到代理类的代码，控制器方法里添加了以下代码 1234public function __construct(){ $this-&gt;__handleProperties();} $this-&gt;__handleProperties() 主要是用来处理属性的，在注解扫描过程中会将符合条件的注解收集起来，这个方法会根据收集的注解，在实例化对象后将对应的属性使用对应的注解来处理，例如Inject注解，将容器中的实例注入到该属性中，因此在编写代码的时候不必要在构造方法中初始化值，都有代理类完成。这样的好处是你不必依赖容器或这其他服务来注入或者操作属性，直接使用new关键字实例化依然可以自动注入 被切入的方法然后看到控制器方法index 123456public function index() : array{ return $this-&gt;__callViaProxy(__FUNCTION__, function () { return $this-&gt;response-&gt;success(message: 'Hello, ' . $this-&gt;request-&gt;get('name', 'MaxPHP') . '!'); }, func_get_args());} 可以看到$this-&gt;__callVieProxy传递了三个参数，依次是本方法名，闭包（包含原方法体），原方法参数列表，走到这，就意味着这个方法被切入了。 来看下__callVieProxy方法： 12345678910protected function __callViaProxy(string $method, Closure $callback, array $parameters): mixed{ /** @var AspectInterface $aspect */ $pipeline = array_reduce( array_reverse([...AspectCollector::getClassAspects(__CLASS__), ...AspectCollector::getMethodAspects(__CLASS__, $method)]), fn($stack, $aspect) =&gt; fn(JoinPoint $joinPoint) =&gt; $aspect-&gt;process($joinPoint, $stack), fn(JoinPoint $joinPoint) =&gt; $joinPoint-&gt;process() ); return $pipeline(new JoinPoint($this, $method, $parameters, $callback));} 方法很简单，将收集的该方法的切面，使用array_reduce处理。最终调用的方法在JoinPoint中，该对象包含所有元数据，例如对象，方法和方法参数，这些都是可以在切面类中拿到并且可以修改的，最终调用的方法如下 1234public function process(): mixed{ return call_user_func_array($this-&gt;callback, $this-&gt;parameters);} 可以看到调用闭包并传递处理后的参数。 切面类实现如下123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?phpdeclare(strict_types=1);/** * This file is part of the Max package. * * (c) Cheng Yao &lt;987861463@qq.com&gt; * * For the full copyright and license information, please view the LICENSE * file that was distributed with this source code. */namespace Max\\Cache\\Aspects;use Closure;use Max\\Aop\\Contracts\\AspectInterface;use Max\\Aop\\JoinPoint;use Psr\\Container\\ContainerExceptionInterface;use ReflectionException;#[\\Attribute(\\Attribute::TARGET_METHOD)]class TestRandom implements AspectInterface{ public function __construct( protected int $ramdom = 0, ) { } /** * @throws ContainerExceptionInterface * @throws ReflectionException */ public function process(JoinPoint $joinPoint, Closure $next): mixed { echo 'before'; $result = $next($joinPoint); echo 'after'; return $result; }} 可以看到调用方法和pipeline原理类似。构造方法的参数是可以通过使用注解的时候传递的。 总结php的aop的重点：代理类生成，如何调用 浅薄理解，相对于其他框架的思路可能略显幼稚。感兴趣可以参与开发 max/aop： https://github.com/topyao/max-aop","link":"/2022/05/22/PHP%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0Aop/"},{"title":"PHP实现Basic认证","text":"如何认证对于需要basic认证的页面，我们可以让服务端响应一个 1WWW-Authenticate: Basic 的header头，并且返回响应码401，浏览器会自动弹出认证的窗口。 客户端要做什么 当你输入用户名和密码后，后面的请求都会添加下面这样的头部 1Authorization: Basic dXNlcjpwYXNz 其中basic后面的是base64编码的字符串，解码之后的内容是 1user:pass 上面这样以用户名:密码组成的字符串 服务端怎么实现看下面伪代码 12345678910111213public function process(ServerRequestInterface $request, RequestHandlerInterface $handler): ResponseInterface{ if(有Authorization头部) { 解析头部 if (匹配到用户) { 继续响应 }else { 响应WWW-Authenticate: Basic和401 } } 响应WWW-Authenticate: Basic和401*/} 如果你使用的是Apache,那么需要在配置文件中加入 1SetEnvIf Authorization .+ HTTP_AUTHORIZATION=$0 还可以查看官方提供的方案：https://www.php.net/manual/zh/features.http-auth.php","link":"/2021/11/27/PHP%E5%AE%9E%E7%8E%B0Basic%E8%AE%A4%E8%AF%81/"},{"title":"PHP如何爬取页面数据","text":"前提PHP作为世界上最好的语言，爬页面当然不在话下，官方提供了解析DOM的类DOMDocument和XPATH相关的类DOMXPath，使用起来方便快速，但是对于一些不标准的页面可能会出现各种报错。所以推荐下面一款包，虽然依然是使用上面提到的两个类，但是却做了许多容错处理 1composer require voku/simple_html_dom packagist : https://packagist.org/packages/voku/simple_html_dom 使用说明可以参考文档，但是这里还是有必要记录一下 使用引入文件12345&lt;?phpuse voku\\helper\\HtmlDomParser;require_once &quot;./vendor/autoload.php&quot;; 解析html12$html = curl($url);$dom = HtmlDomParser::str_get_html($html); 查找元素12$elements = $dom-&gt;findMulti('.class');$element = $dom-&gt;findOne('#id') 这个返回值是一个可以迭代的对象，所以需要迭代它 迭代元素123foreach($elements as $element) { var_dump($element);} 示例12345678910111213141516171819$html = &lt;&lt;&lt;EOT&lt;ul id=&quot;example-list&quot;&gt; &lt;li class=&quot;list&quot;&gt; 第一行 &lt;/li&gt; &lt;li class=&quot;list&quot;&gt; 第二行 &lt;/li&gt; &lt;li id=&quot;end-li&quot;&gt; 第二行 &lt;/li&gt;&lt;/ul&gt;EOT;$dom = HtmlDomParser::str_get_html($html);foreach($dom-&gt;findMulti('.list')-&gt;getIterator() as $li) { var_dump($li-&gt;attr['class']);}$ul = $dom-&gt;findOne('#example-list #end-li'); // 例子var_dump($ul-&gt;attr['id']); 注意爬取页面要尽量伪装自己，防止被禁止 123456789101112131415161718192021222324function curl($url){ $ch = curl_init($url); $headers = [ 'DNT' =&gt; 1, 'Referer' =&gt; 'https://www.1kmb.com/', 'sec-ch-ua' =&gt; '&quot; Not A;Brand&quot;;v=&quot;99&quot;, &quot;Chromium&quot;;v=&quot;100&quot;, &quot;Microsoft Edge&quot;;v=&quot;100&quot;', 'sec-ch-ua-mobile' =&gt; '?0', 'sec-ch-ua-platform' =&gt; '&quot;Windows&quot;', 'User-Agent' =&gt; 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 Edg/100.0.1185.50]']; curl_setopt_array($ch, [ CURLOPT_HTTPHEADER =&gt; $headers, CURLOPT_HEADER =&gt; false, CURLOPT_RETURNTRANSFER =&gt; true, CURLOPT_SSL_VERIFYHOST =&gt; false, CURLOPT_SSL_VERIFYPEER =&gt; false, ]); $r = curl_exec($ch); curl_close($ch); return $r;} 尽可能让服务端认为这是一次正常请求。","link":"/2022/05/11/PHP%E5%A6%82%E4%BD%95%E7%88%AC%E5%8F%96%E9%A1%B5%E9%9D%A2%E6%95%B0%E6%8D%AE/"},{"title":"PHP数组相加和array_merge","text":"array_merge 如果输入的数组中有相同的字符串键名，则该键名后面的值将覆盖前一个值。然而，如果数组包含数字键名，后面的值将 不会 覆盖原来的值，而是附加到后面。 联合（数组相加） + 运算符把右边的数组元素附加到左边的数组后面，两个数组中都有的键名，则只用左边数组中的，右边的被忽略。 1234567891011121314151617&lt;?php$a = array(&quot;a&quot; =&gt; &quot;apple&quot;, &quot;b&quot; =&gt; &quot;banana&quot;);$b = array(&quot;a&quot; =&gt; &quot;pear&quot;, &quot;b&quot; =&gt; &quot;strawberry&quot;, &quot;c&quot; =&gt; &quot;cherry&quot;);$c = $a + $b; // $a 和 $b 的并集echo &quot;Union of \\$a and \\$b: \\n&quot;;var_dump($c);$c = $b + $a; // $b 和 $a 的并集echo &quot;Union of \\$b and \\$a: \\n&quot;;var_dump($c);$a += $b; // $a += $b 的并集是 $a 和 $becho &quot;Union of \\$a += \\$b: \\n&quot;;var_dump($a);?&gt; array_replace","link":"/2021/10/04/PHP%E6%95%B0%E7%BB%84%E7%9B%B8%E5%8A%A0%E5%92%8Carray_merge/"},{"title":"PHP导出CSV","text":"文档待整理，暂时写这么点 涉及函数123fopenfputsfputcsv 示例代码12345$header = ['第一列', '第二列', '第三列'];$row = ['one', 'two', 'three'];$fp = fopen('./example.csv', 'w+');fputs(chr(239) . chr(187) . chr(191)); // 添加utf-8 bom头fputcsv($fp, $row); 如果不想使用fputcsv函数，可以直接使用,分割拼接数组，但是要注意每一列的逗号应该被处理，否则可能会不能对齐 浏览器下载响应如下头部 1234567header('Content-Type: application/vnd.ms-excel'); // 文件格式header('Content-Type: charset=utf-8'); // 文件编码header('Content-Disposition: attachment; filenaeme='. $filename); // 文件名header('Content-Type: application/octet-stream'); // 二进制流// header(&quot;Accept-Ranges:bytes&quot;);// 表明范围单位为字节，可不写header(&quot;Pragma: no-cache&quot;); // 禁止缓存header(&quot;Expires: 0&quot;);// 有效期时间 实例 1234567891011121314$fp = fopen('./example.csv', 'w+');$count = 0;$max = 100;while($row = $query-&gt;fetch()) { if($count &gt; $max) { ob_flush(); flush(); $count = 0; } $count++; fputcsv($fp, $row); unset($row);}fclose($fp); 细节如果没有写入bom头，则使用Microsoft Excel打开有可能乱码，如果你使用windows,可以将csv以记事本方式打开保存时选择编码为utf-8 bom，你也可以进行转码 1$str = &quot;\\t&quot;.iconv('utf-8', 'gb2312//ignore', $v); // gbk 也可以（建议） 前面加了\\t，这样对于长数字，不会被显示为科学计数法，也可以对应一些特殊字符问题，如果是时间格式，不要在末尾加\\t，否则不可筛选 转码函数还有例如： 12mb_convert_encodingmb_convert_variables BOMBOM（Byte Order Mark），字节顺序标记，出现在文本文件头部，Unicode编码标准中用于标识文件是采用哪种格式的编码。 10xEF 0xBB 0xBF 移除BOM 12$BOM = chr(239).chr(187).chr(191);return str_replace($BOM,”,$contents); 检查是否有BOM 1return substr($string,0,3) == pack(&quot;CCC&quot;,0xef,0xbb,0xbf); 参考PHP文件头BOM头问题 https://www.cnblogs.com/wt645631686/p/6868826.html在 PHP 中使用 BOM 将字符串编码为 UTF-8 https://www.itbaoku.cn/post/1743835/do","link":"/2022/04/21/PHP%E5%AF%BC%E5%87%BACSV/"},{"title":"PHP正则表达式中模式修正符 (Pattern Modifiers)","text":"The current possible PCRE modifiers are listed below. The names in parentheses refer to internal PCRE names for these modifiers. Spaces and newlines are ignored in modifiers, other characters cause error. i (PCRE_CASELESS) If this modifier is set, letters in the pattern match both upper and lower case letters. m (PCRE_MULTILINE) By default, PCRE treats the subject string as consisting of a single “line” of characters (even if it actually contains several newlines). The “start of line” metacharacter (^) matches only at the start of the string, while the “end of line” metacharacter ($) matches only at the end of the string, or before a terminating newline (unless D modifier is set). This is the same as Perl. When this modifier is set, the “start of line” and “end of line” constructs match immediately following or immediately before any newline in the subject string, respectively, as well as at the very start and end. This is equivalent to Perl’s /m modifier. If there are no “\\n” characters in a subject string, or no occurrences of ^ or $ in a pattern, setting this modifier has no effect. s (PCRE_DOTALL) If this modifier is set, a dot metacharacter in the pattern matches all characters, including newlines. Without it, newlines are excluded. This modifier is equivalent to Perl’s /s modifier. A negative class such as [^a] always matches a newline character, independent of the setting of this modifier. x (PCRE_EXTENDED) If this modifier is set, whitespace data characters in the pattern are totally ignored except when escaped or inside a character class, and characters between an unescaped # outside a character class and the next newline character, inclusive, are also ignored. This is equivalent to Perl’s /x modifier, and makes it possible to include commentary inside complicated patterns. Note, however, that this applies only to data characters. Whitespace characters may never appear within special character sequences in a pattern, for example within the sequence (?( which introduces a conditional subpattern. A (PCRE_ANCHORED) If this modifier is set, the pattern is forced to be “anchored”, that is, it is constrained to match only at the start of the string which is being searched (the “subject string”). This effect can also be achieved by appropriate constructs in the pattern itself, which is the only way to do it in Perl. D (PCRE_DOLLAR_ENDONLY) If this modifier is set, a dollar metacharacter in the pattern matches only at the end of the subject string. Without this modifier, a dollar also matches immediately before the final character if it is a newline (but not before any other newlines). This modifier is ignored if m modifier is set. There is no equivalent to this modifier in Perl. S When a pattern is going to be used several times, it is worth spending more time analyzing it in order to speed up the time taken for matching. If this modifier is set, then this extra analysis is performed. At present, studying a pattern is useful only for non-anchored patterns that do not have a single fixed starting character. U (PCRE_UNGREEDY) This modifier inverts the “greediness” of the quantifiers so that they are not greedy by default, but become greedy if followed by ?. It is not compatible with Perl. It can also be set by a (?U) modifier setting within the pattern or by a question mark behind a quantifier (e.g. .*?).Note:It is usually not possible to match more than pcre.backtrack_limit characters in ungreedy mode. X (PCRE_EXTRA) This modifier turns on additional functionality of PCRE that is incompatible with Perl. Any backslash in a pattern that is followed by a letter that has no special meaning causes an error, thus reserving these combinations for future expansion. By default, as in Perl, a backslash followed by a letter with no special meaning is treated as a literal. There are at present no other features controlled by this modifier. J (PCRE_INFO_JCHANGED) The (?J) internal option setting changes the local PCRE_DUPNAMES option. Allow duplicate names for subpatterns. As of PHP 7.2.0 J is supported as modifier as well. u (PCRE_UTF8) This modifier turns on additional functionality of PCRE that is incompatible with Perl. Pattern and subject strings are treated as UTF-8. An invalid subject will cause the preg_* function to match nothing; an invalid pattern will trigger an error of level E_WARNING. Five and six octet UTF-8 sequences are regarded as invalid. 参考文档：https://www.php.net/manual/en/reference.pcre.pattern.modifiers.php","link":"/2021/11/17/PHP%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%AD%E6%A8%A1%E5%BC%8F%E4%BF%AE%E6%AD%A3%E7%AC%A6%20(Pattern%20Modifiers)/"},{"title":"PHP的闭包","text":"#减少foreach的循环的代码 Class synopsis 12345678 final class Closure { /* Methods */ private __construct() public static bind(Closure $closure, ?object $newThis, object|string|null $newScope = &quot;static&quot;): ?Closure public bindTo(?object $newThis, object|string|null $newScope = &quot;static&quot;): ?Closure public call(object $newThis, mixed ...$args): mixed public static fromCallable(callable $callback): Closure} 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?php// 一个基本的购物车，包括一些已经添加的商品和每种商品的数量。// 其中有一个方法用来计算购物车中所有商品的总价格。该方法使用了一个closure作为回调函数。class Cart { const PRICE_BUTTER = 1.00; const PRICE_MILK = 3.00; const PRICE_EGGS = 6.95; protected $products = []; public function add($product, $quantity) { $this-&gt;products[$product] = $quantity; } public function getQuantity($product) { return isset($this-&gt;products[$product]) ? $this-&gt;products[$product] : FALSE; } public function getTotal($tax) { $total = 0.00; $callback = function ($quantity, $product) use ($tax, &amp;$total) { $pricePerItem = constant(__CLASS__ . &quot;::PRICE_&quot; . strtoupper($product)); $total += ($pricePerItem * $quantity) * ($tax + 1.0); }; array_walk($this-&gt;products, $callback); return round($total, 2); }}$my_cart = new Cart;// 往购物车里添加条目$my_cart-&gt;add('butter', 1);$my_cart-&gt;add('milk', 3);$my_cart-&gt;add('eggs', 6);// 打出出总价格，其中有 5% 的销售税.print $my_cart-&gt;getTotal(0.05) . &quot;\\n&quot;;// The result is 54.29?&gt; 这里如果我们改造getTotal函数必然要使用到foreach 减少函数的参数123456789101112&lt;?phpfunction html($code, $id = &quot;&quot;, $class = &quot;&quot;) { if ($id !== &quot;&quot;) { $id = &quot; id = \\&quot;$id\\&quot;&quot;; } $class = ($class !== &quot;&quot;) ? &quot; class =\\&quot;$class\\&quot;&quot; : &quot;&gt;&quot;; $open = &quot;&lt;$code$id$class&quot;; $close = &quot;&lt;/$code&gt;&quot;; return function ($inner = &quot;&quot;) use ($open, $close) { return &quot;$open$inner$close&quot;;};}?&gt; 如果是使用平时的方法，我们会把inner放到html函数参数中，这样不管是代码阅读还是使用都不如使用闭包 解除递归函数12345678910111213141516&lt;?php$fib = function ($n) use (&amp;$fib) { if ($n == 0 || $n == 1) { return 1; } return $fib($n - 1) + $fib($n - 2);};echo $fib(2) . &quot;\\n&quot;; // 2$lie = $fib;$fib = function () {die('error');}; //rewrite $fib variableecho $lie(5); // error because $fib is referenced by closure?&gt; 注意上题中的use使用了&amp;，这里不使用&amp;会出现错误fib(fib(n-1)是找不到function的（前面没有定义fib的类型） 所以想使用闭包解除循环函数的时候就需要使用 12345&lt;?php$recursive = function () use (&amp;$recursive) {// The function is now available as $recursive}?&gt; 关于延迟绑定 如果你需要延迟绑定use里面的变量，你就需要使用引用(&amp;)，否则在定义的时候就会做一份拷贝放到use中 //理解use(&amp;$var) 12345678910111213141516&lt;?php$result = 0;$one = function () { var_dump($result);};$two = function () use ($result) { var_dump($result);};$three = function () use (&amp;$result) { var_dump($result);};$result++;$one(); // outputs NULL: $result is not in scope$two(); // outputs int(0): $result was copied$three(); // outputs int(1) 使用引用和不使用引用就代表了是调用时赋值，还是申明时候赋值","link":"/2021/04/03/PHP%E7%9A%84%E9%97%AD%E5%8C%85/"},{"title":"PHP算法","text":"排序快速排序1234567891011121314151617181920function quickSort($arr){ if (count($arr) &lt;= 1) { return $arr; } else { $key = $arr[0]; $left = []; $right = []; for ($i = 1; $i &lt; count($arr); $i++) { if ($arr[$i] &lt; $key) { $left[] = $arr[$i]; } else { $right[] = $arr[$i]; } } $left = quickSort($left); $right = quickSort($right); return array_merge($left, [$key], $right); } } 无限级分类例如数据格式如下： 1234567891011121314$categories = [ [ 'id' =&gt; 1, 'parent_id' =&gt; 0, ], [ 'id' =&gt; 2, 'parent_id' =&gt; 1, ], [ 'id' =&gt; 3, 'parent_id' =&gt; 2, ]]; 示例方法 123456789101112function get_tree($data) { $items = []; foreach ($data as $v){ $items[$v['id']] = $v; } $tree = array();//格式化好的树 foreach ($items as $item) if (isset($items[$item['parent_id']])) $items[$item['parent_id']]['children'][] = &amp;$items[$item['id']]; else $tree[] = &amp;$items[$item['id']]; return $tree;}; 1234567891011function get_tree($categories, $parent_id = 0){ $arr = []; foreach ($categories as $v) { if ($v['parent_id'] == $parent_id) { $v['children'] = get_tree($categories, $v['id']); $arr[] = $v; } } return $arr;} 最终数据 1234567891011121314151617181920212223242526272829303132array(1) { [0]=&gt; array(3) { [&quot;id&quot;]=&gt; int(1) [&quot;parent_id&quot;]=&gt; int(0) [&quot;children&quot;]=&gt; array(1) { [0]=&gt; array(3) { [&quot;id&quot;]=&gt; int(2) [&quot;parent_id&quot;]=&gt; int(1) [&quot;children&quot;]=&gt; array(1) { [0]=&gt; array(3) { [&quot;id&quot;]=&gt; int(3) [&quot;parent_id&quot;]=&gt; int(2) [&quot;children&quot;]=&gt; array(0) { } } } } } }} 拼手气分红包分配1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 拼手气红包分配算法 * * @param $money 金额 * @param $count 数量 */function redAlgorithm($money, $count){ // 参数校验 if ($count * 0.01 &gt; $money) { throw new \\Exception(&quot;单个红包不能低于0.01元&quot;); } // 存放随机红包 $redpack = []; // 未分配的金额 $surplus = $money; for ($i = 1; $i &lt;= $count; $i++) { // 安全金额 $safeMoney = $surplus - ($count - $i) * 0.01; // 平均金额 $avg = $i == $count ? $safeMoney : bcdiv($safeMoney, ($count - $i), 2); // 随机红包 $rand = $avg &gt; 0.01 ? mt_rand(1, $avg * 100) / 100 : 0.01; // 剩余红包 $surplus = bcsub($surplus, $rand, 2); $redpack[] = $rand; } // 平分剩余红包 $avg = bcdiv($surplus, $count, 2); for ($n = 0; $n &lt; count($redpack); $n++) { $redpack[$n] = bcadd($redpack[$n], $avg, 2); $surplus = bcsub($surplus, $avg, 2); } // 如果还有红包没有分配完时继续分配 if ($surplus &gt; 0) { // 随机抽取分配好的红包，将剩余金额分配进去 $keys = array_rand($redpack, $surplus * 100); // array_rand 第二个参数为 1 时返回的是下标而不是数组 $keys = is_array($keys) ? $keys : [$keys]; foreach ($keys as $key) { $redpack[$key] = bcadd($redpack[$key], 0.01, 2); $surplus = bcsub($surplus, 0.01, 2); } } // 红包分配结果 return $redpack;} 原文地址:https://www.itqaq.com/index/art/352.html ID雪花算法12345678910111213141516171819202122232425262728293031323334&lt;?phpclass Idcreate { const EPOCH = 0; //开始时间,固定一个小于当前时间的毫秒数 const max12bit = 1024; const max41bit = 1099511627888; static $machineId = null; public static function machineId($mId = 0) { self::$machineId = $mId; } public static function createOnlyId() { // 时间戳 42字节 $time = floor(microtime(true) * 1000); // 当前时间 与 开始时间 差值 $time -= self::EPOCH; // 二进制的 毫秒级时间戳 $base = decbin(self::max41bit + $time); // 机器id 10 字节 if(!self ::$machineId) { $machineid = self ::$machineId; } else { $machineid = str_pad(decbin(self ::$machineId),10,&quot;0&quot;,STR_PAD_LEFT); } $random = str_pad(decbin(mt_rand(0,self::max12bit)),12,&quot;0&quot;,STR_PAD_LEFT); // 拼接 $base = $base . $machineid . $random; // 转化为 十进制 返回 return bindec($base); }}$obj = new Idcreate;for ($i=0; $i &lt;100 ; $i++) { echo $obj-&gt;createOnlyId().&quot;&lt;br&gt;&quot;;} PHP+Redis生成唯一序列12345678910111213141516171819202122232425$prefix = ‘DS’; //标题前缀$currentCycle = date(‘ymd‘); // 日期拼接成中间$key = &quot;codegen:{$currentCycle}:{$prefix}&quot;; // 生成redis健 健名前缀按照天来更新$Redis = $this-&gt;Redis-&gt;getRedis(); // 连接redis$codeNum = $Redis-&gt;incr($key); // 这里用incr 方法来获取当前自增数量 incr是原子性的 能处理并发// 为1说明是当天的第一条，设置有效期，删除过期keyif ($codeNum == 1) { // 设置有效期1天 $expireAt = strtotime(date('Y-m-d 00:00:00', strtotime(&quot;+1 day&quot;))); $Redis-&gt;expireAt($key, $expireAt); // 删除过期key，加锁，一周期只删一次 setnx锁设置键不存在则设置并返回1，否则返回0 if ($Redis-&gt;setnx(&quot;codegen:{$currentCycle}:rmLock&quot;, 1)) { $lastCycle = date($dateFormat, strtotime(&quot;-1 day&quot;)); $keys = $Redis-&gt;keys(&quot;codegen:{$lastCycle}:*&quot;); foreach ($keys as $k) { $Redis-&gt;del($k); }}$codeNum = str_pad($codeNum, 4, '0', STR_PAD_LEFT); // 拼成固定长度 比如 1 100 返回 0001 0100return $prefix . $codeNum;","link":"/2022/06/11/PHP%E7%AE%97%E6%B3%95/"},{"title":"PHP箭头函数与引用返回","text":"箭头函数文档来自PHP手册： https://www.php.net/manual/zh/functions.arrow.php 箭头函数是 PHP 7.4 的新语法，是一种更简洁的 匿名函数 写法。 匿名函数和箭头函数都是 Closure 类的实现。 箭头函数的基本语法为 1fn (argument_list) =&gt; expr 箭头函数支持与 匿名函数 相同的功能，只是其父作用域的变量总是自动的。 当表达式中使用的变量是在父作用域中定义的，它将被隐式地按值捕获。在下面的例子中，函数 $fn1 和 $fn2 的行为是一样的。 示例 箭头函数自动捕捉变量的值 1234567891011121314&lt;?php$y = 1;$fn1 = fn($x) =&gt; $x + $y;// 相当于 using $y by value:$fn2 = function ($x) use ($y) { return $x + $y;};var_export($fn1(3));?&gt; 示例 箭头函数自动捕捉变量的值，即使在嵌套的情况下 1234567&lt;?php$z = 1;$fn = fn($x) =&gt; fn($y) =&gt; $x * $y + $z;// 输出 51var_export($fn(5)(10));?&gt; 以下均为有效箭头函数例子 12345678910&lt;?phpfn(array $x) =&gt; $x;static fn(): int =&gt; $x;fn($x = 42) =&gt; $x;fn(&amp;$x) =&gt; $x;fn&amp;($x) =&gt; $x;fn($x, ...$rest) =&gt; $rest;?&gt; 箭头函数会自动绑定上下文变量，这相当于对箭头函数内部使用的每一个变量 $x 执行了一个 use($x)。这意味着不可能修改外部作用域的任何值，若要实现对值的修改，可以使用 匿名函数 来替代。 示例 来自外部范围的值不能在箭头函数内修改 12345678&lt;?php$x = 1;$fn = fn() =&gt; $x++; // 不会影响 x 的值$fn();var_export($x); // 输出 1?&gt; 引用返回 字面意思就是函数返回一个引用 方法123456class Test { public function &amp;test () { $a = 1; return $a; }} 函数12345function &amp;test(){ $a = 1; return $a;} 匿名函数1234$a = function &amp;() { $b = 1; return $b;}; 箭头函数1$a = fn &amp;($b) =&gt; $b; 关于引用返回的介绍可以参考官方文档：https://www.php.net/manual/zh/language.references.return.php","link":"/2021/11/02/PHP%E7%AE%AD%E5%A4%B4%E5%87%BD%E6%95%B0%E4%B8%8E%E5%BC%95%E7%94%A8%E8%BF%94%E5%9B%9E/"},{"title":"PHP限速下载","text":"123456789101112131415161718&lt;?php$arr = [ &quot;b798abe6e1b1318ee36b0dcb3fb9e4d3&quot; =&gt; [&quot;./img/img.jpg&quot;, &quot;img.jpg&quot;], &quot;4cf350692a4a3bb54d13daacfe8c683b&quot; =&gt; [&quot;./img/小明.chw&quot;, &quot;小明.chw&quot;]];header(&quot;Content-type:application/octet-stream&quot;);header(&quot;Content-disposition:attachment;filename=&quot; . $arr[$_GET[&quot;file&quot;]][1]);flush();// readfile($arr[$_GET[&quot;file&quot;]][0]);$handler = fopen($arr[$_GET[&quot;file&quot;]][0], &quot;rb&quot;);while (!feof($handler)) { $files = fread($handler, 1&lt;&lt;20); //限速下载 print($files); flush(); usleep(20);}fclose($handler);","link":"/2020/10/29/PHP%E9%99%90%E9%80%9F%E4%B8%8B%E8%BD%BD/"},{"title":"PostgreSQL Copy 命令","text":"COPY – 在表和文件之间拷贝数据 SynopsisCOPY tablename [ ( column [, …] ) ] FROM { ‘filename’ | STDIN } [ [ WITH ] [ BINARY ] [ OIDS ] [ DELIMITER [ AS ] ‘delimiter’ ] [ NULL [ AS ] ‘null string’ ] [ CSV [ QUOTE [ AS ] ‘quote’ ] [ ESCAPE [ AS ] ‘escape’ ] [ FORCE NOT NULL column [, …] ] COPY tablename [ ( column [, …] ) ] TO { ‘filename’ | STDOUT } [ [ WITH ] [ BINARY ] [ OIDS ] [ DELIMITER [ AS ] ‘delimiter’ ] [ NULL [ AS ] ‘null string’ ] [ CSV [ QUOTE [ AS ] ‘quote’ ] [ ESCAPE [ AS ] ‘escape’ ] [ FORCE QUOTEcolumn [, …] ] 描述COPY 在 PostgreSQL表和标准文件系统文件之间交换数据。 COPY TO 把一个表的所有内容都拷贝到一个文件， 而 COPY FROM 从一个文件里拷贝数据到一个表里（把数据附加到表中已经存在的内容里）。 如果声明了一个字段列表，COPY 将只在文件和表之间拷贝声明的字段的数据。 如果表中有任何不在字段列表里的字段，那么 COPY FROM 将为那些字段插入缺省值。 带文件名的 COPY 指示 PostgreSQL 服务器直接从文件中读写数据。 如果声明了文件名，那么该文件必须为服务器可见，而且文件名必须从服务器的角度声明。如果声明的是STDIN 或 STDOUT，数据通过连接在客户前端和服务器之间流动。 参数tablename现存表的名字（可以有模式修饰）。 column可选的待拷贝字段列表。如果没有声明字段列表，那么将使用所有字段。 filename输入或输出文件的绝对路径名。 STDIN声明输入是来自客户端应用。 STDOUT声明输入前往客户端应用。 BINARY使用二进制格式存储和读取，而不是以文本的方式。 在二进制模式下，不能声明 DELIMITERS，NULL 或者 CSV选项。 OIDS声明为每行拷贝内部对象标识（OID）。 （如果给那些没有 OID 的表声明了 OIDS 选项，则抛出一个错误。） delimiter用于在文件中每行中分隔各个字段的单个字符。 在文本模式下，缺省是水平制表符（tab），在 CSV 模式下是一个逗号。 null string个代表 NULL 值的字串。在文本模式下缺省是 \\N （反斜杠-N）， 在 CSV 模式下是一个没有引号的空值。 如果你不想区分空值和空字串，那么即使在文本模式下可能你也会用一个空字串。 注意: 在使用 COPY FROM 的时候，任何匹配这个字串的字串将被存储为 NULL 值， 所以你应该确保你用的字串和COPY TO相同。 CSV打开逗号分隔变量（CSV）模式。 quote声明 CSV 模式里的引号字符。缺省是双引号。 escape声明在 CSV 模式下应该出现在数据里 QUOTE 字符值前面的字符。 缺省是 QUOTE 值（通常是双引号）。 FORCE QUOTE在 CSV COPY TO 模式下，强制在每个声明的字段周围对所有非 NULL 值都使用引号包围。 NULL 从不会被引号包围。 FORCE NOT NULL在 CSV COPY FROM 模式下，把声明的每个字段都当作它们有引号包围来处理， 因此就没有 NULL 值。对于在CSV 模式下的缺省空字串（’’）， 这样导致一个缺失的数值当作一个零长字串输入。 注意COPY 只能用于表，不能用于视图。 BINARY 关键字将强制使用二进制对象而不是文本存储/读取所有数据。 这样做在一定程度上比传统的拷贝命令快，但二进制拷贝文件在不同机器体系间的植性不是很好。 你对任何要COPY TO 出来的数据必须有选取数据的权限，对任何要 COPY FROM 入数据的表必须有插入权限。 COPY 命令里面的文件必须是由服务器直接读或写的文件，而不是由客户端应用读写。 因此，它们必须位于数据库服务器上或者可以为数据库服务器所访问，而不是由客户端做这些事情。 它们必须是PostgreSQL用户（服务器运行的用户 ID）可以访问到并且可读或者可写，而不是客户端。 COPY 到一个命名文件是只允许数据库超级用户进行的，因为它允许读写任意服务器有权限访问的文件。 不要混淆 COPY 和 psql 指令 \\copy。 \\copy 调用 COPY FROM STDIN 或者 COPY TO STDOUT， 然后把数据抓取/存储到一个 psql 客户端可以访问的文件中。 因此，使用 \\copy 的时候，文件访问权限是由客户端而不是服务器端决定的。 我们建议在 COPY 里的文件名字总是使用绝对路径。 在 COPY TO 的时候是由服务器强制进行的， 但是对于COPY FROM，你的确有从一个声明为相对路径的文件里读取的选择。 该路径将解释为相对于服务器的工作目录（在数据目录里的什么地方），而不是客户端的工作目录。 COPY FROM 会激活所有触发器和检查约束。不过，不会激活规则。 COPY 输入和输出是被 DateStyle 影响的。 为了和其它 PostgreSQL 安装移植，（它们可能用的不是缺省DateStyle 设置）， 我们应该在使用 COPY 前把 DateStyle 设置为ISO。 COPY 在第一个错误处停下来。这些在 COPY TO中不应该导致问题， 但在 COPY FROM 时目的表会已经接收到早先的行， 这些行将不可见或不可访问，但是仍然会占据磁盘空间。 如果你碰巧是拷贝很大一块数据文件的话， 积累起来，这些东西可能会占据相当大的一部分磁盘空间。你可以调用 VACUUM 来恢复那些磁盘空间。 文件格式 文本格式当不带 BINARY 或者 CSV 选项使用 COPY 时， 读写的文件是一个文本文件，每行代表表中一个行。 行中的列（字段）用分隔符分开。 字段值本身是由与每个字段类型相关的输出函数生成的字符串， 或者是输入函数可接受的字串。 数据中使用特定的空值字串表示那些为 NULL 的字段。 如果输入文件的任意行包含比预期多或者少的字段，那么 COPY FROM将抛出一个错误。 如果声明了 OIDS，那么 OID 将作为第一个字段读写， 放在所有用户字段前面。 数据的结束可以用一个只包含反斜杠和句点（.）的行表示。 如果从文件中读取数据，那么数据结束的标记是不必要的， 因为文件结束起的作用就很好了；但是在 3.0 之前的客户端协议里，如果在客户端应用之间拷贝数据， 那么必须要有结束标记。 反斜杠字符（\\）可以用在 COPY 里给那些会有歧义的字符进行逃逸（否则那些字符会被当做行或者字段分隔符处理）。 特别是下面的字符如果是字段值的一部分时，必须前缀一个反斜杠：反斜杠本身，换行符，回车，以及当前分隔符。 声明的空字串被 COPY TO 不加任何反斜杠发送；与之相对，COPY FROM 在删除反斜杠之前拿它的输入与空字串比较。因此，像 \\N 这样的空字串不会和实际数据值 \\N 之间混淆（因为后者会表现成 \\N）。 COPY FROM 识别下列特殊反斜杠序列： 序列代表物 \\b反斜杠 (ASCII 8) \\f进纸 (ASCII 12) \\n换行符 (ASCII 10) \\r回车 (ASCII 13) \\tTab (ASCII 9) \\v垂直制表符 (ASCII 11) \\digits反斜杠后面跟着一到三个八进制数，表示ASCII值为该数的字符 目前，COPY TO 将绝不会发出一个八进制反斜杠序列， 但是它的确使用了上面列出的其它字符用于控制字符。 绝对不要把反斜杠放在一个数据字符N或者句点（.）前面。 这样的组合将分别被误认为是空字串或者数据结束标记。 另外一个没有在上面的表中列出的反斜杠字符就是它自己。 我们强烈建议生成 COPY 数据的应用把换行符和回车分别转换成 \\n 和 \\r 序列。 目前我们可以用一个反斜杠和一个回车表示一个数据回车，以及用一个反斜杠和一个换行符表示一个数据换行符。 不过，这样的表示在将来的版本中缺省时可能不会被接受。 并且，如果在不同机器之间传递 COPY 文件，也是非常容易出错的 （比如在 Unix 和 Windows 之间）。 COPY TO 将再每行的结尾是用一个 Unix 风格的换行符(“\\n”)， 或者是在 Microsoft Windows 上运行的服务器上用（”\\r\\n”）标记一行终止，但只是用于COPY到服务器文件里； 为了在不同平台之间一致，COPY TO STDOUT总是发送 “\\n”，不管服务器平台是什么。 COPY FROM 可以处理那些以回车符，或者换行符，或者回车换行符作为行结束的数据。 为了减少在数据中出现的未逃逸的新行或者回车导致的错误，如果输入的行结尾不像上面这些符号， COPY FROM 会发出警告。 CSV 格式这个格式用于输入和输出逗号分隔数值（CSV）文件格式， 许多其它程序都用这个文件格式，比如电子报表。这个模式下生成并识别逗号分隔的 CSV 逃逸机制， 而不是使用PostgreSQL 标准文本模式的逃逸。 每条记录的值都是用 DELIMITER 字符分隔的。 如果数值本身包含分隔字符，QUOTE 字符，NULL 字串， 一个回车，或者进行字符，那么整个数值用 QUOTE 字符前缀和后缀（包围）， 并且数值里任何 QUOTE 字符或者ESCAPE 字符都前导逃逸字符。 你也可以使用 FORCE QUOTE 在输出非 NULL 的指定字段值时强制引号包围。 CSV 格式没有标准的办法区分一个 NULL 值和一个空字串。 PostgreSQL 的 COPY 通过引号包围来处理这些。 一个当作 NULL 输出的 NULL 值是没有引号包围的， 而匹配 NULL字串的数据值是用引号包围的。 因此，使用缺省设置时，一个 NULL 是写做一个无引号包围的空字串， 而一个空字串写做双引号包围（””）。读取数值也遵循类似的规则。 你可以使用 FORCE NOT NULL 来避免为特定字段进行 NULL 比较。 注意: CSV 模式可以识别和生成带有引号包围的回车和进行（hang）的 CVS 文件。 因此这些文件并不像文本模式的文件那样严格地每个数据行一行。 不过，如果任何字段本身包含并不匹配 CVS 文件本身的换行符序列， 那么 PostgreSQL 会拒绝 COPY 输入。通常，输入包含行结束符的数据的时候，用文本或者二进制格式比 CSV 更安全。 注意: 许多程序生成奇怪的并且有时候不正确的 CVS 文件， 所以这个文件格式更像一种惯用格式，而不是一种标准。 因此你可能碰到一些不能使用这个机制输入的文件，而 COPY 也可能生成一些其它程序不能处理的文件。 二进制格式在PostgreSQL 7.4 中的 COPY BINARY 的文件格式做了变化。新格式由一个文件头，零或多条元组， 以及文件尾组成。文件头和数据现在是网络字节序。 文件头文件头由 15 个字节的固定域组成，后面跟着一个变长的头扩展区。 固定域是： 签名11-字节的序列 “PGBCOPY\\n\\377\\r\\n\\0” — 请注意字节零是签名是要求的一部分。 （使用这个签名是为了让我们能够很容易看出文件是否已经被一个非 8 位安全的转换器给糟蹋了。 这个签名会被行结尾转换过滤器，删除字节零，删除高位，或者奇偶的改变而改变。） 标志域32 位整数掩码表示该文件格式的重要方面。 位是从 0（LSB）到 31 （MSB）编码的 — 请注意这个域是以网络字节序存储的（高位在前）， 后继的整数都是如此。位 16 - 31 是保留用做关键文件格式信息的； 如果读者发现一个不认识的位出现在这个范围内，那么它应该退出。 位 0-15 都保留为标志向后兼容的格式使用；读者可以忽略这个范围内的不认识的位。目前只定义了一个标志位，而其它的必须是零： Bit 16如果为 1，那么在数据中包括了 OID；如果为 0，则没有 头扩展范围长度32 位整数，以字节计的头剩余长度，不包括自身。目前，它是零， 后面紧跟第一条元组。对该格式的更多的修改都将允许额外的数据出现在头中。 读者应该忽略任何它不知道该如何处理的头扩展数据。 头扩展数据是一个用来保留一个自定义的数据序列块用的。这个标志域无意告诉读者扩展区的内容是什么。头扩展的具体设计内容留给以后的版本用。 这样设计就允许向下兼容头附加（增加头扩展块，或者设置低位序标志位）以及非向下兼容修改（设置高位标志位以标识这样的修改， 并且根据需要向扩展区域增加支持数据）。 元组每条元组都以一个 16 位整数计数开头，该计数是元组中字段的数目。 （目前，在一个表里的每条元组都有相同的计数，但可能不会永远这样。） 然后后面不断出现元组中的各个字段，字段先是一个 32 位的长度字，后面跟着那么长的字段数据。 （长度字并不包括自己，并且可以为零。）一个特例是：-1 表示一个 NULL 字段值。 在 NULL 情况下，后面不会跟着数值字节。 在数据域之间没有对奇填充或者任何其它额外的数据。 目前，一个 COPY BINARY 文件里的所有数据值都假设是二进制格式的（格式代码为一）。 预计将来的扩展可能增加一个头域，允许为每个字段声明格式代码。 为了判断实际元组数据的正确的二进制格式，你应该阅读 PostgreSQL 源代码， 特别是该字段数据类型的*send 和 *recv 函数（典型的函数可以在源代码的src/backend/utils/adt/ 目录找到）。 如果在文件中包括了 OID，那么该 OID 域立即跟在字段计数字后面。 它是一个普通的字段，只不过它没有包括在字段计数。但它包括长度字 — 这样就允许我们不用花太多的劲就可以处理 4 字节和 8 字节的 OID，并且如果某个家伙允许 OID 是可选的话，那么还可以把 OID 显示成空。 文件尾文件尾包括保存着 -1 的一个 16 位整数字。这样就很容易与一条元组的域计数字相区分。 如果一个域计数字既不是 -1 也不是预期的字段的数目，那么读者应该报错。 这样就提供了对丢失与数据的同步的额外的检查。 例子下面的例子把一个表拷贝到客户端， 使用竖直条（|）作为域分隔符： COPY country TO STDOUT WITH DELIMITER ‘|’;从一个 Unix 文件中拷贝数据到一个country表中： COPY country FROM ‘/usr1/proj/bray/sql/country_data’;下面是一个可以从 STDIN 中拷贝数据到表中的例子： AF AFGHANISTAN AL ALBANIA DZ ALGERIA ZM ZAMBIA ZW ZIMBABWE请注意在这里每行里的空白实际上是一个水平制表符 tab。 下面的是同样的数据，在一台 Linux/i586 机器上以二进制形式输出。 这些数据是用 Unix 工具 od -c 过滤之后输出的。 该表有三个字段；第一个是 char(2)， 第二个是text， 第三个是integer。所有的行在第三个域都是一个 null 值。 0000000 P G C O P Y \\n 377 \\r \\n \\0 \\0 \\0 \\0 \\0 \\0 0000020 \\0 \\0 \\0 \\0 003 \\0 \\0 \\0 002 A F \\0 \\0 \\0 013 A 0000040 F G H A N I S T A N 377 377 377 377 \\0 003 0000060 \\0 \\0 \\0 002 A L \\0 \\0 \\0 007 A L B A N I 0000100 A 377 377 377 377 \\0 003 \\0 \\0 \\0 002 D Z \\0 \\0 \\0 0000120 007 A L G E R I A 377 377 377 377 \\0 003 \\0 \\0 0000140 \\0 002 Z M \\0 \\0 \\0 006 Z A M B I A 377 377 0000160 377 377 \\0 003 \\0 \\0 \\0 002 Z W \\0 \\0 \\0 \\b Z I 0000200 M B A B W E 377 377 377 377 377 377 兼容性在 SQL 标准里没有 COPY 语句。 PostgreSQL 7.3 以前使用下面的语法，现在仍然支持： COPY [ BINARY ] tablename [ WITH OIDS ] FROM { ‘filename’ | STDIN } [ [USING] DELIMITERS ‘delimiter’ ] [ WITH NULL AS ‘null string’ ] COPY [ BINARY ] tablename [ WITH OIDS ] TO { ‘filename’ | STDOUT } [ [USING] DELIMITERS ‘delimiter’ ] [ WITH NULL AS ‘null string’ ]————————————————版权声明：本文为CSDN博主「DemonHunter211」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/kwame211/article/details/75968013","link":"/2021/04/02/PostgreSQL%20Copy%20%E5%91%BD%E4%BB%A4/"},{"title":"RBAC权限系统分析、设计与实现","text":"转载请备注来源： 《RBAC权限系统分析、设计与实现》 | shuwoom.com 最近，因为项目上需要设计实现一个权限管理模块，所以专门整理总结了RBAC的一些知识。 目前，使用最普遍的权限管理模型正是RBAC（Role-Based Access Control）模型，这篇文章也主要是介绍基于RBAC的权限管理系统，我会从RBAC是什么、如何设计RBAC两部分来介绍。 一、RBAC是什么1、RBAC模型概述RBAC模型（Role-Based Access Control：基于角色的访问控制）模型是20世纪90年代研究出来的一种新模型，但其实在20世纪70年代的多用户计算时期，这种思想就已经被提出来，直到20世纪90年代中后期，RBAC才在研究团体中得到一些重视，并先后提出了许多类型的RBAC模型。其中以美国George Mason大学信息安全技术实验室（LIST）提出的RBAC96模型最具有代表，并得到了普遍的公认。 RBAC认为权限授权的过程可以抽象地概括为：Who是否可以对What进行How的访问操作，并对这个逻辑表达式进行判断是否为True的求解过程，也即是将权限问题转换为What、How的问题，Who、What、How构成了访问权限三元组，具体的理论可以参考RBAC96的论文，这里我们就不做详细的展开介绍，大家有个印象即可。 2、RBAC的组成在RBAC模型里面，有3个基础组成部分，分别是：用户、角色和权限。 RBAC通过定义角色的权限，并对用户授予某个角色从而来控制用户的权限，实现了用户和权限的逻辑分离（区别于ACL模型），极大地方便了权限的管理 下面在讲解之前，先介绍一些名词： User（用户）：每个用户都有唯一的UID识别，并被授予不同的角色 Role（角色）：不同角色具有不同的权限 Permission（权限）：访问权限 用户-角色映射：用户和角色之间的映射关系 角色-权限映射：角色和权限之间的映射 它们之间的关系如下图所示： 例如下图，管理员和普通用户被授予不同的权限，普通用户只能去修改和查看个人信息，而不能创建创建用户和冻结用户，而管理员由于被授 予所有权限，所以可以做所有操作。 例如下图，管理员和普通用户被授予不同的权限，普通用户只能去修改和查看个人信息，而不能创建创建用户和冻结用户，而管理员由于被授予所有权限，所以可以做所有操作。 3、RBAC支持的安全原则RBAC支持三个著名的安全原则：最小权限原则、责任分离原则和数据抽象原则 最小权限原则：RBAC可以将角色配置成其完成任务所需的最小权限集合 责任分离原则：可以通过调用相互独立互斥的角色来共同完成敏感的任务，例如要求一个计账员和财务管理员共同参与统一过账操作 数据抽象原则：可以通过权限的抽象来体现，例如财务操作用借款、存款等抽象权限，而不是使用典型的读、写、执行权限 4、RBAC的优缺点（1）优点： 简化了用户和权限的关系 易扩展、易维护 （2）缺点： RBAC模型没有提供操作顺序的控制机制，这一缺陷使得RBAC模型很难适应哪些对操作次序有严格要求的系统 5、RBAC的3种模型（1）RBAC0RBAC0，是最简单、最原始的实现方式，也是其他RBAC模型的基础。 在该模型中，用户和角色之间可以是多对多的关系，即一个用户在不同场景下是可以有不同的角色，例如：项目经理也可能是组长也可能是架构师。同时每个角色都至少有一个权限。这种模型下，用户和权限被分离独立开来，使得权限的授权认证更加灵活。 （2）RBAC1基于RBAC0模型，引入了角色间的继承关系，即角色上有了上下级的区别。 角色间的继承关系可分为一般继承关系和受限继承关系。一般继承关系仅要求角色继承关系是一个绝对偏序关系，允许角色间的多继承。而受限继承关系则进一步要求角色继承关系是一个树结构，实现角色间的单继承。 这种模型适合于角色之间层次分明，可以给角色分组分层。 （3）RBAC2RBAC2，基于RBAC0模型的基础上，进行了角色的访问控制。 RBAC2中的一个基本限制是互斥角色的限制，互斥角色是指各自权限可以互相制约的两个角色。对于这类角色一个用户在某一次活动中只能被分配其中的一个角色，不能同时获得两个角色的使用权。 该模型有以下几种约束： 互斥角色 ：同一用户只能分配到一组互斥角色集合中至多一个角色，支持责任分离的原则。互斥角色是指各自权限互相制约的两个角色。对于这类角色一个用户在某一次活动中只能被分配其中的一个角色，不能同时获得两个角色的使用权。常举的例子：在审计活动中，一个角色不能同时被指派给会计角色和审计员角色。 基数约束 ：一个角色被分配的用户数量受限；一个用户可拥有的角色数目受限；同样一个角色对应的访问权限数目也应受限，以控制高级权限在系统中的分配。例如公司的领导人有限的； 先决条件角色 ：可以分配角色给用户仅当该用户已经是另一角色的成员；对应的可以分配访问权限给角色，仅当该角色已经拥有另一种访问权限。指要想获得较高的权限，要首先拥有低一级的权限。就像我们生活中，国家主席是从副主席中选举的一样。 运行时互斥 ：例如，允许一个用户具有两个角色的成员资格，但在运行中不可同时激活这两个角色。 二、如何设计RBAC这一节，我会介绍设计基于RBAC模型的权限系统的功能模块组成、流程以及数据库的设计。 1、RBAC的功能模块 2、RBAC执行流程 3、RBAC数据库设计 转载请备注来源： 《RBAC权限系统分析、设计与实现》 | shuwoom.com","link":"/2022/01/05/RBAC%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E5%88%86%E6%9E%90%E3%80%81%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"title":"RabbitMQ安装","text":"Docker安装RabbitMQ下载镜像1docker pull rabbitmq:management #management标签的含义是下载的镜像包含manage模块。包含web管理页面。 安装1docker run -dit --name myrabbitmq -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=admin -p 15672:15672 -p 5672:5672 rabbitmq:management -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=admin指定manage模块的用户名和密码，我执行完后是报错的，也可以完全省略参数。如果不指定默认用户名密码，系统会有默认用户名密码：guest guest所以，可以用下面命令。 1docker run -d --hostname my-rabbit --name rabbit -p 15672:15672 -p 5673:5672 rabbitmq:management 现在可以通过访问http://linuxip:15672，访问web界面，这里的用户名和密码默认都是guest。 如果访问失败，可能是没有开启manage模块。通过docker ps -a查看部署的mq容器id，在通过 docker exec -it 容器id /bin/bssh 进入容器内部在运行：rabbitmq-plugins enable rabbitmq_management，执行完毕后重新访问web界面即可。 原文地址：docker安装rabbitmq - chenxizhaolu - 博客园 (cnblogs.com) Ubuntu18.04安装RabbitMQ安装erlang由于rabbitMq需要erlang语言的支持，在安装rabbitMq之前需要安装erlang 1sudo apt-get install erlang-nox 安装Rabbitmq更新源 1sudo apt-get update 安装 1sudo apt-get install rabbitmq-server 启动、停止、重启、状态RabbitMQ命令 1234sudo rabbitmq-server start sudo rabbitmq-server stopsudo rabbitmq-server restartsudo rabbitmqctl status 添加admin，并赋予administrator权限添加admin用户，密码设置为admin。 1sudo rabbitmqctl add_user admin admin 赋予权限 1sudo rabbitmqctl set_user_tags admin administrator 赋予virtual host中所有资源的配置、写、读权限以便管理其中的资源 1sudo rabbitmqctl set_permissions -p / admin '.*' '.*' '.*' Web管理器连接浏览器访问http://192.168.1.42:15672 使用刚刚创建的admin就可以登录，密码也为admin 原文地址：Ubuntu18.04安装RabbitMQ - Ellisonzhang - 博客园 (cnblogs.com)","link":"/2022/01/23/RabbitMQ%E5%AE%89%E8%A3%85/"},{"title":"SQL优化相关总结","text":"SQL执行顺序原文链接：https://blog.csdn.net/u011277123/article/details/54691260 #Pgsql 执行计划http://mysql.taobao.org/monthly/2018/11/06/ 其他在数据库应用中，程序员们通过不断的实践总结了很多经验，这些经验是一些普遍适用的规则。每一个程序员都应该了解并记住它们，在构造SQL语句时，养成良好的习惯。以下10条比较重要的原则供大家参考。 原则1：尽量避免在列上做运算，这样会导致索引失败。例如原句为： 1SELECT * FROM t WHERE YEAR(d) &gt;= 2011; 优化为： 1SELECT * FROM t WHERE ｄ &gt;= ‘2011-01-01’; 原则2：使用join时，应该用小结果集驱动大结果集。同时把复杂的join查询拆分成多个query。因为join多个表时，可能导致更多的锁定和堵塞。例如： 1234567SELECT * FROM a JOIN b ON a.id = b.idLEFT JOIN c ON c.time = a.dateLEFT JOIN d ON c.pid = b.aidLEFT JOIN e ON e.cid = a.did 原则3：注意like模糊查询的使用，避免%%。例如原句为： 1SELECT * FROM t WHERE name LIKE ‘%de%’ 优化为： 1SELECT * FROM t WHERE name &gt;= ‘de’AND name &lt;= ‘df’ 原则4：仅列出需要查询的字段，这对速度不会有明显的影响，主要考虑节省内存。例如原句为： 1SELECT * FROM Member； 优化为： 1SELECT id,name,pwd FROM Member; 原则5：使用批量插入语句节省交互。例如原句为： 12345INSERT INTO t(id,name)VALUES(1,’a’);INSERT INTO t(id,name)VALUES(2,’b’);INSERT INTO t(id,name)VALUES(3,’c’); 优化为： 1INSERT INTO t(id,name)VALUES(1,’a’),(2,’b’),(3,’c’); 原则6：limit的基数比较大的时候使用between。例如原句为： 1SELECT * FROM article AS article RODER BY id LIMIT 1000000,10; 优化为： 1SELECT * FROM article AS article WHERE id BETWEEN 1000000 AND 1000010 RODER BY id; Between限定比limit快，所以海量数据访问时，建议between或是where替换掉limit。但是between也有缺陷，如果id中间有断行或是中间部分id不读取的情况，总读取的数量会少于预计数量！ 在取比较后面的数据时，通过desc方式把数据反向查找，以减少对前段数据的扫描，让limit的基数越小越好！ 原则7：不要使用rand()函数获取多条随机记录。例如： 1select * from table order by rand() limit 20; 使用下面的语句代替： 1Select * from ‘table’as t1 join(select rand(rand() * ((select max(id) from ‘table’)-(select min(id) from ‘table’))+(select min(id) from ‘table’))as id) as t2 where t1.id &gt;= t2.id order by t1.id limit 1; 这是获取一条随机记录，这样即使执行20次，也比原来的语句高效。或者先用php产生随机数，把这个字符串传给MySQL，MySQL里用in查询。 原则8：避免使用null。 原则9：不要使用count(*)，而应该是count(1)。 原则10：不要做无谓的排序操作，而尽可能在索引中完成排序。","link":"/2021/07/06/SQL%E4%BC%98%E5%8C%96%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/"},{"title":"SQL注入、XSS以及CSRF分别是什么？","text":"#SQL注入 SQL注入是属于注入式攻击，这种攻击是因为在项目中没有将代码与数据（比如用户敏感数据）隔离，在读取数据的时候，错误的将数据作为代码的一部分执行而导致的。 典型的例子就是当对SQL语句进行字符串拼接的时候，直接使用未转义的用户输入内容作为变量。这时，只要在sql语句的中间做修改，比如加上drop、delete等关键字，执行之后后果不堪设想。 说到这里，那么该怎么处理这种情况呢？三个方面： 1、过滤用户输入参数中的特殊字符，降低风险。 2、禁止通过字符串拼接sql语句，要严格使用参数绑定来传入参数。 3、合理使用数据库框架提供的机制。就比如Mybatis提供的传入参数的方式 #{}，禁止使用${}，后者相当于是字符串拼接sql，要使用参数化的语句。 总结下，就是要正确使用参数化绑定sql变量。 #XSS XSS：跨站脚本攻击，Cross-Site Scripting，为了和前端的css避免重名，简称为XSS，是指通过技术手段，向正常用户请求的HTML页面中插入恶意脚本，执行。 这种攻击主要是用于信息窃取和破坏等目的。比如2011年的微博XSS攻击事件，攻击者利用了微博发布功能中未对action-data漏洞做有效的过滤，在发布微博信息的时候带上了包含攻击脚本的URL，用户访问就会加载恶意脚本，导致大量用户被攻击。 关于防范XSS上，主要就是通过对用户输入的数据做过滤或者是转义，可以使用框架提供的工具类HtmlUtil。另外前端在浏览器展示数据的时候，要使用安全的API展示数据。比如使用innerText而不是innerHTML。 #CSRF 跨站请求伪造，在用户并不知情的情况下，冒充用户发送请求，在当前已经登录的web网站上执行恶意操作，比如恶意发帖，修改密码等。 大致来看，与XSS有重合的地方，前者是黑客盗用用户浏览器中的登录信息，冒充用户去执行操作。后者是在正常用户请求的HTML中放入恶意代码，XSS问题出在用户数据没有转义，过滤；CSRF问题出现在HTTP接口没有防范不守信用的调用。 #防范CSRF的漏洞方式 1、CSRF Token验证，利用浏览器的同源限制，在HTTP接口执行前验证Cookie中的Token，验证通过才会继续执行请求。 2、人机交互，例如短信验证码、界面的滑块。 以上就是什么是SQL注入、XSS和CSRF？的详细内容，更多请关注php中文网其它相关文章！ #PHP如何防止XSS攻击 PHP防止XSS跨站脚本攻击的方法:是针对非法的HTML代码包括单双引号等，使用htmlspecialchars()函数 。 在使用htmlspecialchars()函数的时候注意第二个参数, 直接用htmlspecialchars($string) 的话,第二个参数默认是ENT_COMPAT,函数默认只是转化双引号(“), 不对单引号(‘)做转义. 所以,htmlspecialchars函数更多的时候要加上第二个参数, 应该这样用: htmlspecialchars($string,ENT_QUOTES).当然,如果需要不转化任何引号,用htmlspecialchars($string,ENT_NOQUOTES). 另外, 尽量少用htmlentities, 在全部英文的时候htmlentities和htmlspecialchars没有区别,都可以达到目的.但是,中文情况下, htmlentities却会转化所有的html代码，连同里面的它无法识别的中文字符也给转化了。 htmlentities和htmlspecialchars这两个函数对 ‘之类的字符串支持不好,都不能转化, 所以用htmlentities和htmlspecialchars转化的字符串只能防止XSS攻击,不能防止SQL注入攻击. 所有有打印的语句如echo，print等 在打印前都要使用htmlentities() 进行过滤，这样可以防止Xss，注意中文要写出htmlentities($name,ENT_NOQUOTES,GB2312) 。 (1).网页不停地刷新 &lt;meta http-equiv=&quot;refresh&quot; content=&quot;0&quot;&gt; (2).嵌入其它网站的链接 除了通过正常途径输入XSS攻击字符外，还可以绕过JavaScript校验，通过修改请求达到XSS攻击的目的. 123456789101112131415161718192021222324252627282930313233343536373839&lt;?php//php防注入和XSS攻击通用过滤$_GET &amp;&amp; SafeFilter($_GET);$_POST &amp;&amp; SafeFilter($_POST);$_COOKIE &amp;&amp; SafeFilter($_COOKIE); function SafeFilter (&amp;$arr) { $ra=Array('/([\\x00-\\x08,\\x0b-\\x0c,\\x0e-\\x19])/','/script/','/javascript/','/vbscript/','/expression/','/applet/' ,'/meta/','/xml/','/blink/','/link/','/style/','/embed/','/object/','/frame/','/layer/','/title/','/bgsound/' ,'/base/','/onload/','/onunload/','/onchange/','/onsubmit/','/onreset/','/onselect/','/onblur/','/onfocus/', '/onabort/','/onkeydown/','/onkeypress/','/onkeyup/','/onclick/','/ondblclick/','/onmousedown/','/onmousemove/' ,'/onmouseout/','/onmouseover/','/onmouseup/','/onunload/'); if (is_array($arr)) { foreach ($arr as $key =&gt; $value) { if (!is_array($value)) { if (!get_magic_quotes_gpc()) //不对magic_quotes_gpc转义过的字符使用addslashes(),避免双重转义。 { $value = addslashes($value); //给单引号（'）、双引号（&quot;）、反斜线（\\）与 NUL（NULL 字符） #加上反斜线转义 } $value = preg_replace($ra,'',$value); //删除非打印字符，粗暴式过滤xss可疑字符串 $arr[$key] = htmlentities(strip_tags($value)); //去除 HTML 和 PHP 标记并转换为 HTML 实体 } else { SafeFilter($arr[$key]); } } }}?&gt;$str = 'www.90boke.com&lt;meta http-equiv=&quot;refresh&quot; content=&quot;0;&quot;&gt;';SafeFilter ($str); //如果你把这个注释掉，提交之后就会无休止刷新echo $str; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071//------------------------------php防注入和XSS攻击通用过滤-----Start--------------------------------------------//function string_remove_xss($html) { preg_match_all(&quot;/\\&lt;([^\\&lt;]+)\\&gt;/is&quot;, $html, $ms); $searchs[] = '&lt;'; $replaces[] = '&lt;'; $searchs[] = '&gt;'; $replaces[] = '&gt;'; if ($ms[1]) { $allowtags = 'img|a|font|div|table|tbody|caption|tr|td|th|br|p|b|strong|i|u|em|span|ol|ul|li|blockquote'; $ms[1] = array_unique($ms[1]); foreach ($ms[1] as $value) { $searchs[] = &quot;&lt;&quot;.$value.&quot;&gt;&quot;; $value = str_replace('&amp;', '_uch_tmp_str_', $value); $value = string_htmlspecialchars($value); $value = str_replace('_uch_tmp_str_', '&amp;', $value); $value = str_replace(array('\\\\', '/*'), array('.', '/.'), $value); $skipkeys = array('onabort','onactivate','onafterprint','onafterupdate','onbeforeactivate','onbeforecopy','onbeforecut','onbeforedeactivate', 'onbeforeeditfocus','onbeforepaste','onbeforeprint','onbeforeunload','onbeforeupdate','onblur','onbounce','oncellchange','onchange', 'onclick','oncontextmenu','oncontrolselect','oncopy','oncut','ondataavailable','ondatasetchanged','ondatasetcomplete','ondblclick', 'ondeactivate','ondrag','ondragend','ondragenter','ondragleave','ondragover','ondragstart','ondrop','onerror','onerrorupdate', 'onfilterchange','onfinish','onfocus','onfocusin','onfocusout','onhelp','onkeydown','onkeypress','onkeyup','onlayoutcomplete', 'onload','onlosecapture','onmousedown','onmouseenter','onmouseleave','onmousemove','onmouseout','onmouseover','onmouseup','onmousewheel', 'onmove','onmoveend','onmovestart','onpaste','onpropertychange','onreadystatechange','onreset','onresize','onresizeend','onresizestart', 'onrowenter','onrowexit','onrowsdelete','onrowsinserted','onscroll','onselect','onselectionchange','onselectstart','onstart','onstop', 'onsubmit','onunload','javascript','script','eval','behaviour','expression','style','class'); $skipstr = implode('|', $skipkeys); $value = preg_replace(array(&quot;/($skipstr)/i&quot;), '.', $value); if (!preg_match(&quot;/^[\\/|\\s]?($allowtags)(\\s+|$)/is&quot;, $value)) { $value = ''; } $replaces[] = empty($value) ? '' : &quot;&lt;&quot; . str_replace('&quot;', '&quot;', $value) . &quot;&gt;&quot;; } } $html = str_replace($searchs, $replaces, $html); return $html;}//php防注入和XSS攻击通用过滤 function string_htmlspecialchars($string, $flags = null) { if (is_array($string)) { foreach ($string as $key =&gt; $val) { $string[$key] = string_htmlspecialchars($val, $flags); } } else { if ($flags === null) { $string = str_replace(array('&amp;', '&quot;', '&lt;', '&gt;'), array('&amp;', '&quot;', '&lt;', '&gt;'), $string); if (strpos($string, '&amp;#') !== false) { $string = preg_replace('/&amp;((#(\\d{3,5}|x[a-fA-F0-9]{4}));)/', '&amp;\\\\1', $string); } } else { if (PHP_VERSION &lt; '5.4.0') { $string = htmlspecialchars($string, $flags); } else { if (!defined('CHARSET') || (strtolower(CHARSET) == 'utf-8')) { $charset = 'UTF-8'; } else { $charset = 'ISO-8859-1'; } $string = htmlspecialchars($string, $flags, $charset); } } } return $string;}//------------------php防注入和XSS攻击通用过滤-----End--------------------------------------------// PHP中的设置PHP5.2以上版本已支持HttpOnly参数的设置，同样也支持全局的HttpOnly的设置，在php.ini中 123----------------------------------------------------- session.cookie_httponly = ----------------------------------------------------- 设置其值为1或者TRUE，来开启全局的Cookie的HttpOnly属性，当然也支持在代码中来开启： 123&lt;?php ini_set(&quot;session.cookie_httponly&quot;, 1); // or session_set_cookie_params(0, NULL, NULL, NULL, TRUE); ?&gt; Cookie操作函数setcookie函数和setrawcookie函数也专门添加了第7个参数来做为HttpOnly的选项，开启方法为： 1234&lt;?php setcookie(&quot;abc&quot;, &quot;test&quot;, NULL, NULL, NULL, NULL, TRUE); setrawcookie(&quot;abc&quot;, &quot;test&quot;, NULL, NULL, NULL, NULL, TRUE); ?&gt;","link":"/2021/04/03/SQL%E6%B3%A8%E5%85%A5%E3%80%81XSS%E4%BB%A5%E5%8F%8ACSRF%E5%88%86%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/"},{"title":"Shell笔记","text":"#let let 命令是 BASH 中用于计算的工具，用于执行一个或多个表达式，变量计算中不需要加上 $ 来表示变量。如果表达式中包含了空格或其他特殊字符，则必须引起来。 1let arg [arg ...] 实例：自加操作：let no++ 自减操作：let no-- 简写形式 let no+=10，let no-=20，分别等同于 let no=no+10，let no=no-20。 以下实例计算 a 和 b 两个表达式，并输出结果： 1234#!/bin/bashlet a=5+4let b=9-3 echo $a $b 上条命令执行成功 123if [ $? -eq 0 ]; then echo &quot;OK&quot;fi 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253-s file 文件大小非0时为真[ -f &quot;somefile&quot; ] ：判断是否是一个文件[ -x &quot;/bin/ls&quot; ] ：判断/bin/ls是否存在并有可执行权限[ -n &quot;$var&quot; ] ：判断$var变量是否有值[ &quot;$a&quot; = &quot;$b&quot; ] ：判断$a和$b是否相等 -r file 用户可读为真-w file 用户可写为真-x file 用户可执行为真-f file 文件为正规文件为真-d file 文件为目录为真-c file 文件为字符特殊文件为真-b file 文件为块特殊文件为真-s file 文件大小非0时为真 -s file true if the file has nonzero size-t file 当文件描述符(默认为1)指定的设备为终端时为真 -a file exists.-b file exists and is a block special file.-c file exists and is a character special file.-d file exists and is a directory.-e file exists (just the same as -a).-f file exists and is a regular file.-g file exists and has its setgid(2) bit set.-G file exists and has the same group ID as this process.-k file exists and has its sticky bit set.-L file exists and is a symbolic link.-n string length is not zero.-o Named option is set on.-O file exists and is owned by the user ID of this process.-p file exists and is a first in, first out (FIFO) special file ornamed pipe.-r file exists and is readable by the current process.-s file exists and has a size greater than zero.-S file exists and is a socket.-t file descriptor number fildes is open and associated with aterminal device.-u file exists and has its setuid(2) bit set.-w file exists and is writable by the current process.-x file exists and is executable by the current process.-z string length is zero. shell判断字符串为空的方法 Linux 下判断字符串是否为空，可以使用两个参数： ● -z ：判断 string 是否是空串 ● -n ：判断 string 是否是非空串 例子： 1#!/bin/sh`` ` `STRING=`` ` `if` `[ -z ``&quot;$STRING&quot;` `]; then`` ``echo` `&quot;STRING is empty&quot;``fi`` ` `if` `[ -n ``&quot;$STRING&quot;` `]; then`` ``echo` `&quot;STRING is not empty&quot;``fi`` ` `root@desktop:~# ./zerostring.sh ``STRING is ``empty 注：在进行字符串比较时， 用引号将字符串界定起来 ，是一个非常好的习惯！ 其他方法： 1if` `[ ``&quot;$str&quot;` `= ``&quot;&quot;` `] shell中的2&gt;&amp;1A.首先了解下1和2在Linux中代表什么在Linux系统中0 1 2是一个文件描述符 名称 代码 操作符 Java中表示 Linux 下文件描述符（Debian 为例) 标准输入(stdin) 0 &lt; 或 &lt;&lt; System.in /dev/stdin -&gt; /proc/self/fd/0 -&gt; /dev/pts/0 标准输出(stdout) 1 &gt;, &gt;&gt;, 1&gt; 或 1&gt;&gt; System.out /dev/stdout -&gt; /proc/self/fd/1 -&gt; /dev/pts/0 标准错误输出(stderr) 2 2&gt; 或 2&gt;&gt; System.err /dev/stderr -&gt; /proc/self/fd/2 -&gt; /dev/pts/0 上面表格引用自这里从上表看的出来，我们平时使用的 1echo &quot;hello&quot; &gt; t.log 其实也可以写成 1echo &quot;hello&quot; 1&gt; t.log B.关于2&gt;&amp;1的含义（关于输入/输出重定向本文就不细说了，不懂的可以参考这里，主要是要了解&gt; &lt; &lt;&lt; &gt;&gt; &lt;&amp; &gt;&amp; 这6个符号的使用） 含义：将标准错误输出重定向到标准输出符号&gt;&amp;是一个整体，不可分开，分开后就不是上述含义了。比如有些人可能会这么想：2是标准错误输入，1是标准输出，&gt;是重定向符号，那么”将标准错误输出重定向到标准输出”是不是就应该写成”2&gt;1”就行了？是这样吗？如果是尝试过，你就知道2&gt;1的写法其实是将标准错误输出重定向到名为”1”的文件里去了写成2&amp;&gt;1也是不可以的C.为什么2&gt;&amp;1要放在后面考虑如下一条shell命令 1nohup java -jar app.jar &gt;log 2&gt;&amp;1 &amp; (最后一个&amp;表示把条命令放到后台执行，不是本文重点，不懂的可以自行Google)为什么2&gt;&amp;1一定要写到&gt;log后面，才表示标准错误输出和标准输出都定向到log中？我们不妨把1和2都理解是一个指针,然后来看上面的语句就是这样的： 本来1—–&gt;屏幕 （1指向屏幕） 执行&gt;log后， 1—–&gt;log (1指向log) 执行2&gt;&amp;1后， 2—–&gt;1 (2指向1，而1指向log,因此2也指向了log) 再来分析下 1nohup java -jar app.jar 2&gt;&amp;1 &gt;log &amp; 本来1—–&gt;屏幕 （1指向屏幕） 执行2&gt;&amp;1后， 2—–&gt;1 (2指向1，而1指向屏幕,因此2也指向了屏幕) 执行&gt;log后， 1—–&gt;log (1指向log，2还是指向屏幕) 所以这就不是我们想要的结果。简单做个试验测试下上面的想法：java代码如下： 123456public class Htest { public static void main(String[] args) { System.out.println(&quot;out1&quot;); System.err.println(&quot;error1&quot;); }} javac编译后运行下面指令： 1java Htest 2&gt;&amp;1 &gt; log 你会在终端上看到只输出了”error1”，log文件中则只有”out1” D.每次都写”&gt;log 2&gt;&amp;1”太麻烦，能简写吗？有以下两种简写方式 123&amp;&gt;log&amp;log 比如上面小节中的写法就可以简写为： 1nohup java -jar app.jar &amp;&gt;log &amp; 上面两种方式都和&gt;log 2&gt;&amp;1一个语义。那么 上面两种方式中&amp;&gt;和&gt;&amp;有区别吗？语义上是没有任何区别的，但是第一中方式是最佳选择，一般使用第一种 输出带颜色字体输出特效格式控制：*\\033[0m* 关闭所有属性 *\\033[1m* 设置高亮度 *\\03[4m* 下划线 *\\033[5m* 闪烁 *\\033[7m* 反显 *\\033[8m* 消隐 *\\033[30m – \\033[37m* 设置前景色 *\\033[40m – \\033[47m* 设置背景色 光标位置等的格式控制：\\033[nA 光标上移n行\\03[nB 光标下移n行\\033[nC 光标右移n行\\033[nD 光标左移n行\\033[y;xH设置光标位置\\033[2J 清屏\\033[K 清除从光标到行尾的内容\\033[s 保存光标位置\\033[u 恢复光标位置\\033[?25l 隐藏光标 \\33[?25h 显示光标 整理： 编码 颜色/动作 0 重新设置属性到缺省设置 1 设置粗体 2 设置一半亮度(模拟彩色显示器的颜色) 4 设置下划线(模拟彩色显示器的颜色) 5 设置闪烁 7 设置反向图象 22 设置一般密度 24 关闭下划线 25 关闭闪烁 27 关闭反向图象 30 设置黑色前景 31 设置红色前景 32 设置绿色前景 33 设置棕色前景 34 设置蓝色前景 35 设置紫色前景 36 设置青色前景 37 设置白色前景 38 在缺省的前景颜色上设置下划线 39 在缺省的前景颜色上关闭下划线 40 设置黑色背景 41 设置红色背景 42 设置绿色背景 43 设置棕色背景 44 设置蓝色背景 45 设置紫色背景 46 设置青色背景 47 设置白色背景 49 设置缺省黑色背景特效可以叠加，需要使用“;”隔开，例如：闪烁+下划线+白底色+黑字为 \\033[5;4;47;30m闪烁+下划线+白底色+黑字为\\033[0m下面是一段小例子 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#!/bin/bash##下面是字体输出颜色及终端格式控制#字体色范围：30-37echo -e &quot;\\033[30m 黑色字 \\033[0m&quot;echo -e &quot;\\033[31m 红色字 \\033[0m&quot;echo -e &quot;\\033[32m 绿色字 \\033[0m&quot;echo -e &quot;\\033[33m 黄色字 \\033[0m&quot;echo -e &quot;\\033[34m 蓝色字 \\033[0m&quot;echo -e &quot;\\033[35m 紫色字 \\033[0m&quot;echo -e &quot;\\033[36m 天蓝字 \\033[0m&quot;echo -e &quot;\\033[37m 白色字 \\033[0m&quot;#字背景颜色范围：40-47echo -e &quot;\\033[40;37m 黑底白字 \\033[0m&quot;echo -e &quot;\\033[41;30m 红底黑字 \\033[0m&quot;echo -e &quot;\\033[42;34m 绿底蓝字 \\033[0m&quot;echo -e &quot;\\033[43;34m 黄底蓝字 \\033[0m&quot;echo -e &quot;\\033[44;30m 蓝底黑字 \\033[0m&quot;echo -e &quot;\\033[45;30m 紫底黑字 \\033[0m&quot;echo -e &quot;\\033[46;30m 天蓝底黑字 \\033[0m&quot;echo -e &quot;\\033[47;34m 白底蓝字 \\033[0m&quot;#控制选项说明#\\033[0m 关闭所有属性#\\033[1m 设置高亮度#\\033[4m 下划线echo -e &quot;\\033[4;31m 下划线红字 \\033[0m&quot;#闪烁echo -e &quot;\\033[5;34m 红字在闪烁 \\033[0m&quot;#反影echo -e &quot;\\033[8m 消隐 \\033[0m &quot;#\\033[30m-\\033[37m 设置前景色#\\033[40m-\\033[47m 设置背景色#\\033[nA光标上移n行#\\033[nB光标下移n行echo -e &quot;\\033[4A 光标上移4行 \\033[0m&quot;#\\033[nC光标右移n行#\\033[nD光标左移n行#\\033[y;xH设置光标位置#\\033[2J清屏#\\033[K清除从光标到行尾的内容echo -e &quot;\\033[K 清除光标到行尾的内容 \\033[0m&quot;#\\033[s 保存光标位置#\\033[u 恢复光标位置#\\033[?25| 隐藏光标#\\033[?25h 显示光标echo -e &quot;\\033[?25l 隐藏光标 \\033[0m&quot;echo -e &quot;\\033[?25h 显示光标 \\033[0m&quot;","link":"/2021/04/05/Shell%E7%AC%94%E8%AE%B0/"},{"title":"SSH设置公钥实现免密登录","text":"前提准备： 机器A需要使用免密登录连接机器B。测试机器为笔记本一台【wsl2 ubuntu】， centos7.6一台 准备步骤一、首先在机器A上执行下面的命令1ssh-keygen -t rsa 执行结果如下： 123456789101112131415161718192021222324root@DESKTOP-1SDORV4:~/.ssh# ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa):/root/.ssh/id_rsa already exists.Overwrite (y/n)? yEnter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /root/.ssh/id_rsaYour public key has been saved in /root/.ssh/id_rsa.pubThe key fingerprint is:SHA256:u5Su/vifiFGxYSj8B6+7kLBAgX1iPrSL0scpPK6E4JM root@DESKTOP-1SDORV4The key's randomart image is:+---[RSA 3072]----+|.o ||. *.. . || = +o o + ||. + o + + ||o+.+ .. S ||*.Bo+. + o ||oE.+o o + ||. o . B o . ||.. .B=*.o |+----[SHA256]-----+root@DESKTOP-1SDORV4:~/.ssh# 然后会在当前用户家目录下的.ssh文件夹下生成一个id_rsa.pub的文件，执行下面的命令复制文本内容 1cat id_rsa.pub 步骤二、登录机器B进入用户家目录的.ssh目录，新建或者修改authorized_keys 文件，将准备中的key 粘贴进去，保存。 测试123456789root@DESKTOP-1SDORV4:~/.ssh# ssh user@chengyao.xyzLast failed login: Tue May 4 16:46:04 CST 2021 from 175.190.126.17* on ssh:nottyThere were 6 failed login attempts since the last successful login.Last login: Tue May 4 16:40:39 2021 from 111.19.83.22*Welcome to Alibaba Cloud Elastic Compute Service !manpath: can't set the locale; make sure $LC_* and $LANG are correct[user@iZ2zeir6up2905ofunx6tdZ ~]# 至此说明你的免密登录成功了。 常见问题在查看网上相关资料的时候发现很多人出了一些莫名奇妙的问题，有的人给的解决方案是将.ssh目录的权限设置为0700,将下面的文件权限设置为0600 ，大家遇到问题可以检查下是不是权限的问题。","link":"/2021/05/04/SSH%E8%AE%BE%E7%BD%AE%E5%85%AC%E9%92%A5%E5%AE%9E%E7%8E%B0%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/"},{"title":"SVN使用笔记","text":"常用svn命令 svnadmin create . svn [–username 用户名 –password 密码] checkout checkout代码 svn co svn://svnbucket.com/xxx/xxx更新代码 svn up提交代码 svn commit -m “提交描述”添加新文件到版本库 svn add filename添加当前目录下所有php文件 svn add .php递归添加当前目录下的所有新文件 svn add . –no-ignore –force查看指定文件的所有log svn log test.php查看指定版本号的log svn svn log -r 100撤销本地文件的修改（还没提交的） svn revert test.php svn revert -r 目录名撤销目录下所有本地修改 svn revert –recursive 目录名查看当前工作区的所有改动 svn diff查看当前工作区test.php文件与最新版本的差异 svn diff test.php指定版本号比较差异 svn diff -r 200:201 test.php查看当前工作区和版本301中bin目录的差异 svn diff -r 301 bin查看当前工作区的状态 svn status查看svn信息 svn info查看文件列表，可以指定-r查看，查看指定版本号的文件列表 svn ls svn ls -r 100显示文件的每一行最后是谁修改的（出了BUG，经常用来查这段代码是谁改的） svn blame filename.php查看指定版本的文件内容，不加版本号就是查看最新版本的 svn cat test.py -r 2清理 svn cleanup若想创建了一个文件夹，并且把它加入版本控制，但忽略文件夹中的所有文件的内容 svn mkdir spool svn propset svn:ignore ‘‘ spool svn ci -m ‘Adding “spool” and ignoring its contents.’若想创建一个文件夹，但不加入版本控制，即忽略这个文件夹 svn mkdir spool svn propset svn:ignore ‘spool’ . svn ci -m ‘Ignoring a directory called “spool”.’切换当前项目到指定分支。服务器上更新新版本我们经常就用这个命令来把当前代码切换到新的分支 svn switch svn://svnbucket.com/test/branches/online1.0重定向仓库地址到新地址 svn switch –relocate 原svn地址 新svn地址创建分支，从主干创建一个分支保存到branches/online1.0 svn cp -m “描述内容” http://svnbucket.com/repos/trunk http://svnbucket.com/repos/branches/online1.0合并主干上的最新代码到分支上 cd branches/online1.0 svn merge http://svnbucket.com/repos/trunk分支合并到主干 svn merge –reintegrate http://svnbucket.com/repos/branches/online1.0删除分支 svn rm http://svnbucket.com/repos/branches/online1.0查看SVN帮助 svn help查看指定命令的帮助信息 svn help commit参考： https://easydoc.net/s/78711005/uSJD1CDg/33195524","link":"/2022/04/07/SVN%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"},{"title":"Springboot实践","text":"创建一个springboot项目(50条消息) 创建一个Spring Boot项目_慕北丶的博客-CSDN博客_创建springboot项目 Maven更换仓库从官方仓库http://repo.maven.apache.org/maven2/ 下载较慢，可以设置maven仓库源为国内镜像，加快依赖的下载。 修改Maven默认的下载仓库 可以在pom.xml中设置如下代码：12345678910111213&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;name&gt;nexus-aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 也可以在本地maven子目录/conf/settings.xml中settings.xml中配置：想要修改Maven默认的下载仓库，其实我们只需要找到Maven的settings.xml文件。如果使用的是IDEA默认的Maven，那么settings.xml默认存放地址为IDEA安装路劲下的：\\JetBrains\\IntelliJ IDEA xxx.xxx\\plugins\\maven\\lib\\maven3\\conf 复制一份settings.xml 到：C:\\Users\\You user.m2(默认本地存放下载的jar包位置为当前用户文件下下的.m2文件中)下也就是你的本地maven仓库下。 1234567&lt;mirror&gt; &lt;!--This sends everything else to /public --&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;&lt;/mirror&gt; maven缺少依赖包，强制更新依赖命令1mvn clean install -e -U -Dmaven.test.skip=true -e详细异常，-U强制更新 -DskipTests，不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下。 -Dmaven.test.skip=true，不执行测试用例，也不编译测试用例类。 使用maven.test.skip，不但跳过单元测试的运行，也跳过测试代码的编译。 1mvn package -Dmaven.test.skip=true Error:java: 错误: 不支持发行版本 5 解决方法(50条消息) Error:java: 错误: 不支持发行版本 5 解决方法（详细）_哇咔咔i的博客-CSDN博客_java错误不支持发行版本5","link":"/2022/07/10/Springboot%E5%AE%9E%E8%B7%B5/"},{"title":"Supervisor 使用踩坑笔记 【配置syncd】","text":"前言 之前有使用hyperf这样的框架开发过，但是线上部署没有实操，也不清楚进程监控怎么配置，所以学习了一下，记录一篇笔记。 我主要是看了这篇文章的讲解：https://www.1kmb.com/note/284.html内容很不错，推荐在这里。 实操根据教程配置了syncd的监控配置如下 123456789101112[program:syncd]directory=/root/syncd-deploycommand=/root/syncd-deploy/bin/syncdautostart=trueautorestart=truestartsecs=1;user=rootstderr_logfile=/data/logs/syncd.logstdout_logfile=/data/logs/syncd.logredirect_stderr=truestdout_logfile_maxbytes=30MBstrout_logfile_backups=20 注意这个配置文件的后缀是ini，之前不小心建成conf文件，导致使用supervisorctl start syncd 的时候出现了下面的报错 更正：系统不同配置后缀不同 1syncd: ERROR (no such process) 查看/etc/supervisord.conf 里面会有[include]一节，files就是其他进程的配置文件 更改后使用supervisorctl update 命令更新配置提示错误 1error: &lt;class 'xmlrpclib.Fault'&gt;, &lt;Fault 92: &quot;CANT_REREAD: The directory named as part of the path /data/logs/syncd.log does not exist in section 'program:syncd' (file: '/etc/supervisord.d/syncd.ini')&quot;&gt;: file: /usr/lib64/python2.7/xmlrpclib.py line: 794 原来是日志目录不存在，新建目录后再次执行提示 1syncd: added process group 再次执行 1supervisorctl start syncd 提示 1syncd: ERROR (spawn error) 执行 1supervisorctl status 提示 1syncd FATAL Exited too quickly (process log may have details) 查看日志 1less /data/logs/syncd.log 一堆 1/root/syncd-deploy/bin/syncd: /root/syncd-deploy/bin/syncd: cannot execute binary file 原来是因为之前启动不了。以为要加什么解释器，于是配置文件里面就出现了 1command=bash /root/syncd-deploy/bin/syncd 但是这个syncd是go编译后的二进制文件，所以报错了。。。 在上面的配置中已经去掉了。 更改上面的bug后执行 1supervisorctl update 提示 12syncd: stoppedsyncd: updated process group 查看下状态 12[root@VM-0-10-centos ~]# supervisorctl statussyncd RUNNING pid 20999, uptime 0:00:04 然后根据syncd配置的端口访问下，正常。 总结配置文件不要搞错， 涉及日志目录的要确保目录存在，命令怎么执行要写完整。","link":"/2021/10/30/Supervisor%20%E4%BD%BF%E7%94%A8%E8%B8%A9%E5%9D%91%E7%AC%94%E8%AE%B0%20%E3%80%90%E9%85%8D%E7%BD%AEsyncd%E3%80%91/"},{"title":"Supervisor使用详解","text":"一、supervisor简介Supervisor是用Python开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。它是通过fork/exec的方式把这些被管理的进程当作supervisor的子进程来启动，这样只要在supervisor的配置文件中，把要管理的进程的可执行文件的路径写进去即可。也实现当子进程挂掉的时候，父进程可以准确获取子进程挂掉的信息的，可以选择是否自己启动和报警。supervisor还提供了一个功能，可以为supervisord或者每个子进程，设置一个非root的user，这个user就可以管理它对应的进程。 注：本文以centos7为例，supervisor版本3.4.0。 二、supervisor安装 配置好yum源后，可以直接安装 1yum install supervisor Debian/Ubuntu可通过apt安装 1apt-get install supervisor pip安装 1pip install supervisor easy_install安装 1easy_install supervisor 三、supervisor使用supervisor配置文件：/etc/supervisord.conf注：supervisor的配置文件默认是不全的，不过在大部分默认的情况下，上面说的基本功能已经满足。 子进程配置文件路径：/etc/supervisord.d/注：默认子进程配置文件为ini格式，可在supervisor主配置文件中修改。 四、配置文件说明supervisor.conf配置文件说明：1234567891011121314151617181920212223242526272829303132333435363738394041424344[unix_http_server]file=/tmp/supervisor.sock ;UNIX socket 文件，supervisorctl 会使用;chmod=0700 ;socket文件的mode，默认是0700;chown=nobody:nogroup ;socket文件的owner，格式：uid:gid ;[inet_http_server] ;HTTP服务器，提供web管理界面;port=127.0.0.1:9001 ;Web管理后台运行的IP和端口，如果开放到公网，需要注意安全性;username=user ;登录管理后台的用户名;password=123 ;登录管理后台的密码 [supervisord]logfile=/tmp/supervisord.log ;日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ;日志文件大小，超出会rotate，默认 50MB，如果设成0，表示不限制大小logfile_backups=10 ;日志文件保留备份数量默认10，设为0表示不备份loglevel=info ;日志级别，默认info，其它: debug,warn,tracepidfile=/tmp/supervisord.pid ;pid 文件nodaemon=false ;是否在前台启动，默认是false，即以 daemon 的方式启动minfds=1024 ;可以打开的文件描述符的最小值，默认 1024minprocs=200 ;可以打开的进程数的最小值，默认 200 [supervisorctl]serverurl=unix:///tmp/supervisor.sock ;通过UNIX socket连接supervisord，路径与unix_http_server部分的file一致;serverurl=http://127.0.0.1:9001 ; 通过HTTP的方式连接supervisord ; [program:xx]是被管理的进程配置参数，xx是进程的名称[program:xx]command=/opt/apache-tomcat-8.0.35/bin/catalina.sh run ; 程序启动命令autostart=true ; 在supervisord启动的时候也自动启动startsecs=10 ; 启动10秒后没有异常退出，就表示进程正常启动了，默认为1秒autorestart=true ; 程序退出后自动重启,可选值：[unexpected,true,false]，默认为unexpected，表示进程意外杀死后才重启startretries=3 ; 启动失败自动重试次数，默认是3user=tomcat ; 用哪个用户启动进程，默认是rootpriority=999 ; 进程启动优先级，默认999，值小的优先启动redirect_stderr=true ; 把stderr重定向到stdout，默认falsestdout_logfile_maxbytes=20MB ; stdout 日志文件大小，默认50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数，默认是10; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile=/opt/apache-tomcat-8.0.35/logs/catalina.outstopasgroup=false ;默认为false,进程被杀死时，是否向这个进程组发送stop信号，包括子进程killasgroup=false ;默认为false，向进程组发送kill信号，包括子进程 ;包含其它配置文件[include]files = relative/directory/*.ini ;可以指定一个或多个以.ini结束的配置文件 子进程配置文件说明：给需要管理的子进程(程序)编写一个配置文件，放在/etc/supervisor.d/目录下，以.ini作为扩展名（每个进程的配置文件都可以单独分拆也可以把相关的脚本放一起）。如任意定义一个和脚本相关的项目名称的选项组（/etc/supervisord.d/test.conf）： 1234567891011121314151617181920212223242526#项目名[program:blog]#脚本目录directory=/opt/bin#脚本执行命令command=/usr/bin/python /opt/bin/test.py#supervisor启动的时候是否随着同时启动，默认Trueautostart=true#当程序exit的时候，这个program不会自动重启,默认unexpected，设置子进程挂掉后自动重启的情况，有三个选项，false,unexpected和true。如果为false的时候，无论什么情况下，都不会被重新启动，如果为unexpected，只有当进程的退出码不在下面的exitcodes里面定义的autorestart=false#这个选项是子进程启动多少秒之后，此时状态如果是running，则我们认为启动成功了。默认值为1startsecs=1#脚本运行的用户身份 user = test#日志输出 stderr_logfile=/tmp/blog_stderr.log stdout_logfile=/tmp/blog_stdout.log #把stderr重定向到stdout，默认 falseredirect_stderr = true#stdout日志文件大小，默认 50MBstdout_logfile_maxbytes = 20MB#stdout日志文件备份数stdout_logfile_backups = 20 子进程配置示例：123456789#说明同上[program:test] directory=/opt/bin command=/opt/bin/testautostart=true autorestart=false stderr_logfile=/tmp/test_stderr.log stdout_logfile=/tmp/test_stdout.log #user = test 五、supervisor命令说明常用命令123456supervisorctl status //查看所有进程的状态supervisorctl stop es //停止essupervisorctl start es //启动essupervisorctl restart //重启essupervisorctl update //配置文件修改后使用该命令加载新的配置supervisorctl reload //重新启动配置中的所有程序 注：把es换成all可以管理配置中的所有进程。直接输入supervisorctl进入supervisorctl的shell交互界面，此时上面的命令不带supervisorctl可直接使用。 注意事项使用supervisor进程管理命令之前先启动supervisord，否则程序报错。 使用命令supervisord -c /etc/supervisord.conf启动。 若是centos7： 12systemctl start supervisord.service //启动supervisor并加载默认配置文件systemctl enable supervisord.service //将supervisor加入开机启动项 常见问题 unix:///var/run/supervisor.sock no such file 问题描述：安装好supervisor没有开启服务直接使用supervisorctl报的错 解决办法：supervisord -c /etc/supervisord.conf command中指定的进程已经起来，但supervisor还不断重启 问题描述：command中启动方式为后台启动，导致识别不到pid，然后不断重启，这里使用的是elasticsearch，command指定的是$path/bin/elasticsearch -d 解决办法：supervisor无法检测后台启动进程的pid，而supervisor本身就是后台启动守护进程，因此不用担心这个 启动了多个supervisord服务，导致无法正常关闭服务 问题描述：在运行supervisord -c /etc/supervisord.conf之前，直接运行过supervisord -c /etc/supervisord.d/xx.conf导致有些进程被多个superviord管理，无法正常关闭进程。 解决办法：使用ps -fe | grep supervisord查看所有启动过的supervisord服务，kill相关的进程。 更多信息请移步Supervisor官网：http://supervisord.org来源： Supervisor使用详解 - 简书 (jianshu.com)","link":"/2022/03/06/Supervisor%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3/"},{"title":"Typescript学习笔记","text":"类型any / number / 元组 / 枚举 / never 元组1let map : [string, number] = [&quot;str&quot;, 123] 枚举12enum Color {Red, Blue, Green}let c Color = Color.Red 类型断言12345678interface foo { bar number}const f1 = &lt;foo&gt;{}f.bar = 1const f2 = {} as foo 12var str = '1' var str2:number = &lt;number&gt; &lt;any&gt; str //str、str2 是 string 类型 类型断言是编译时语法，类型转换通常意味着某种运行时支持， typescript支持类型推断，如果不能推断出类型，那么默认是动态any类型 变量作用域 全局作用域： 全局变量定义在程序结构的外部，它可以在你代码的任何位置使用 类作用域：也可成为字段，声明在类内方法外，可以在类对象访问，静态变量可以用类访问 局部作用域：只能在代码块中使用 循环123for ( init; condition; increment ){ statement(s);} 123for (var val in list) { //语句 } 12345let someArray = [1, &quot;string&quot;, false]; for (let entry of someArray) { console.log(entry); // 1, &quot;string&quot;, false} for…of 语句创建一个循环来迭代可迭代的对象。在 ES6 中引入的 for…of 循环，以替代 for…in 和 forEach() ，并支持新的迭代协议。for…of 允许你遍历 Arrays（数组）, Strings（字符串）, Maps（映射）, Sets（集合）等可迭代的数据结构等。 123456let list = [4, 5, 6];list.forEach((val, idx, array) =&gt; { // val: 当前值 // idx：当前index // array: Array}); 12345678let list = [4, 5, 6];list.every((val, idx, array) =&gt; { // val: 当前值 // idx：当前index // array: Array return true; // Continues // Return false will quit the iteration}); forEach、every 和 some 是 JavaScript 的循环语法，TypeScript 作为 JavaScript 的语法超集，当然默认也是支持的。因为 forEach 在 iteration 中是无法返回的，所以可以使用 every 和 some 来取代 forEach 1234567while(true) { // do something}do { // do something} while (); 函数参数可选参数123function func1 (name ?: string) { console.log(name)} 默认参数 参数不能同时设置为默认和可选 123function func2 (name : string = &quot;zhangsan&quot;) { console.log(name) } 剩余参数123function done(...names: string[]) { console.log(names)} 函数的最后一个命名参数 names 以 … 为前缀，它将成为一个由剩余参数组成的数组，索引值从0（包括）到 names.length（不包括） 构造函数TypeScript 也支持使用 JavaScript 内置的构造函数 Function() 来定义函数 1var res = new Function ([arg1[, arg2[, ...argN]],] functionBody) arg1, arg2, … argN：参数列表。 functionBody：一个含有包括函数定义的 JavaScript 语句的字符串 12var func = new Function(&quot;a&quot;, &quot;b&quot;, &quot;return a+b&quot;);console.log(func(&quot;zhang&quot;, &quot;san&quot;)); Lambda123456789var foo = (x :number) =&gt; { console.log(x)}var bar = (y :number) =&gt; console.log(y)// var bar = y =&gt; console.log(y)console.log(foo(1)) 函数重载 重载是方法名字相同，而参数不同，返回类型可以相同也可以不同。每个重载的方法（或者构造函数）都必须有一个独一无二的参数类型列表。如果参数类型不同，则参数类型应设置为 any。参数数量不同你可以将不同的参数设置为可选。 123456789function disp(s1:string):void; function disp(n1:number,s1:string):void; function disp(x:any,y?:any):void { console.log(x); console.log(y); } disp(&quot;abc&quot;) disp(1,&quot;xyz&quot;); 定义函数重载需要定义重载签名和一个实现签名。重载签名定义函数的形参和返回类型，没有函数体。一个函数可以有多个重载签名(不可调用) prototype 实例1234567function employ(name: string) { this.name = name}var n = new employ(&quot;zhangsan&quot;);console.log(n) 类型String1var b = new String(&quot;guanyu&quot;); prototype123456function user(name: string) { this.name = name}var u = new user(&quot;xiaohong&quot;);user.prototype.age = 25;console.log(u.age) 方法12345678910111213141516171819chatAt()charCodeAt()concat()indexOf()lastIndexOf()localeCompare()match()replace()search()slice()splice()substr()substring()toLocaleLowerCase()toLocaleUpperCase()toLowerCase()toUpperCase()toString()valueOf() number1var a = new Number(10); 属性1234567MAX_VALUEMIN_VALUENaNNEGATIVE_INFINITYPOSITIVE_INFINITYprototypeconstructor 方法123456toExponential()toFixed()toLocaleString()toPrecision()toString()valueOf() Array初始化12345var a1 = new Array(5); // 指定长度var a2 = new Array(&quot;小荷才露尖尖角&quot;); // 初始化数组元素console.log(a1, a2) 数组解构12345var poetry = new Array(&quot;小荷才露尖尖角&quot;, &quot;早有蜻蜓立上头&quot;);var [first, last] = poetryconsole.log(first, last) 多维数组123var seat: number[][] = [[1, 2, 3], [4, 5, 6]]console.log(seat) 方法1234567891011121314151617181920concat()every()filter()forEach()indexOf()join()lastIndexOf()map()pop()push()reduce()reduceRight()reverse()shift()slice()some()sort()splice()toString()unshift() Map对象 保存键值对，且可以记住键的原始插入顺序，是ES6引入的新数据结构 1let m = new Map() 1234let a = new Map([ [&quot;key1&quot;, &quot;value1&quot;], [&quot;key2&quot;, &quot;value2&quot;],]) 如果编译报错 error TS2583: Cannot find name ‘Map’. Do you need to change your target library? Try changing the ‘lib’ compiler option to ‘es2015’ or later. 可以给编译参数加上–terget es6 选项，例如 1tsc app.ts --target es6; node app.js 方法12345678clear()set()get()has()delete()size()keys()values() 使用for…of 迭代map12345678910111213141516171819var m = new Map()m.set(&quot;jey&quot;, &quot;ds&quot;)for (let key of m.keys()) { console.log(key)}for (let value of m.values()) { console.log(value)}for (let entry of m.entries()) { console.log(entry)}for (let [k, v] of m) { console.log(k, v)} 元组1var a :[string, number] = [&quot;杜甫&quot;, 80]; 1234var b = [&quot;李白&quot;, 20];b.push(&quot;陶渊明&quot;);b.pop();console.log(b[0]) 联合类型12345var unionTypeVariable : string | number = 10unionTypeVariable = &quot;王维&quot;// 数组也可以作为联合类型var unionTypeVariable2 : string[] | number[] = [&quot;李清照&quot;] 接口 接口是一系列抽象方法的声明，是一些方法特征的集合 123456789101112131415161718interface animal { type: string run(): void eat(): void}var panda: animal = { type: &quot;panda&quot;, run(): void { console.log(this.type + &quot; run&quot;) }, eat(): void { console.log(this.type + &quot; eat&quot;) }}panda.run()panda.eat() 在接口中使用联合类型 123interface controller { action: string | string[] | (() =&gt; string)} 接口继承1234567891011121314151617interface person { name: string}interface man extends person { height: number}interface baby extends man { age: number}const ba: baby = &lt;baby&gt;{}ba.age = 10ba.height = 100ba.name = &quot;张择端&quot;console.log(ba) 多继承可以使用逗号分割 类1234567891011121314151617181920212223242526272829303132interface AuthManager { name: string}class Auth implements AuthManager { name: string constructor(name: string) { this.name = name } protected login(): string { return this.name + &quot; auth&quot;; } private logout() { // ... }}class JwtAuth extends Auth { static type: string = &quot;jwt&quot; // 重写login方法 ，并将访问权限更改为public public login(): string { return this.name + &quot; jwt auth&quot; }}var auth = new JwtAuth(&quot;刘备&quot;)var data = auth.login()console.log(auth, data, JwtAuth.type, auth instanceof Auth) 给构造函数参数加入public修饰，等同于创建了同名的成员变量 1234567class User { constructor(public name: string) { console.log(this.name) }}var user = new User(&quot;user&quot;) 对象12345678var obj = { name: &quot;user&quot;, say: function () { console.log(this.name) }}console.log(obj.say()) 对象也可以作为参数传递 123function Test (func: () =&gt; string) { // 接收一个返回类型为string的闭包} 命名空间如果一个命名空间在一个单独的 TypeScript 文件中，则应使用三斜杠 /// 引用它，语法格式如下： 1/// &lt;reference path = &quot;SomeFileName.ts&quot; /&gt; 12345678910namespace Max { // 嵌套命名空间 export namespace Di { export class Container { } }}var container = new Max.Di.Container() 模块报错 ReferenceError: define is not defined编译选项添加 –module commonjs 参考：https://segmentfault.com/a/1190000018249137","link":"/2022/09/18/Typescript%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"Systemctl和service、chkconfig命令的关系","text":"systemctl systemctl命令：是一个systemd工具，主要负责控制systemd系统和服务管理器。 1234567systemctl list-unitssystemctl start firewalld systemctl restart firewalldsystemctl stop fitrwalldsystemctl disable firewalldsystemctl enable firewalldsystemctl is-active firewallsystemctl is-enabled firewalldsystemctl status firewalld service service命令：可以启动、停止、重新启动和关闭系统服务，还可以显示所有系统服务的当前状态。 123service network restart/start/stopservice network statusservice --status-all [补充] chkconfig chkconfig命令：是管理系统服务(service)的命令行工具。所谓系统服务(service)，就是随系统启动而启动，随系统关闭而关闭的程序。 123chkconfig ntpd on/off/reset(永久关闭某个服务)chkconfig list systemctl命令是系统服务管理器指令，它实际上将 service 和 chkconfig 这两个命令组合到一起。systemctl是RHEL 7 的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。可以使用它永久性或只在当前会话中启用/禁用服务。所以systemctl命令是service命令和chkconfig命令的集合和代替。 来源：https://www.cnblogs.com/hx1998/p/10923993.html [有补充]","link":"/2021/05/01/Systemctl%E5%92%8Cservice%E3%80%81chkconfig%E5%91%BD%E4%BB%A4%E7%9A%84%E5%85%B3%E7%B3%BB/"},{"title":"Ubuntu20.04 中文显示不正确的解决方案","text":"今天又买了一台腾讯云，想学学linux，就没有安装宝塔。搭建好网站后发现中文显示有问题。查阅一番资料后知道原来需要安装语言包。如下图是没有安装语言包的文件列表: 1234567891011121314151617drwxr-xr-x 11 root root 4096 Jun 14 09:52 ./drwxr-xr-x 4 root root 4096 Jun 14 09:53 ../-rwxr-xr-x 1 root root 18 Apr 28 22:24 .htaccess*-rw-r--r-- 1 root root 47 Oct 22 2020 .user.inidrwxr-xr-x 6 root root 4096 May 23 22:21 app/-rwxr-xr-x 1 root root 684 May 5 11:32 composer.json*-rwxr-xr-x 1 root root 23126 Jun 10 22:57 composer.lock*drwxr-xr-x 2 root root 4096 Jun 6 10:35 config/drwxr-xr-x 2 root root 4096 Apr 28 22:24 extend/-rwxr-xr-x 1 root root 506 Apr 28 22:24 max*drwxr-xr-x 4 root root 4096 Jun 14 10:14 public/drwxr-xr-x 2 root root 4096 Apr 28 22:24 routes/drwxrwxrwx 4 root root 4096 Jun 12 14:36 storage/drwxr-xr-x 8 root root 4096 Jun 14 10:47 vendor/drwxr-xr-x 3 root root 4096 May 18 14:05 views/drwxr-xr-x 2 root root 4096 Jun 12 05:51 ''$'\\346\\226\\207\\346\\241\\243'/ 下面介绍下一般的解决办法： 首先安装语言包 1sudo apt-get install language-pack-zh-hans 安装完成后需要将我们的LANG设置为中文。 1locale -a 上面命令查看安装的语言 1234567root@VM-0-10-ubuntu:/var/www/chengyao.xyz# locale -aCC.UTF-8POSIXen_US.utf8zh_CN.utf8zh_SG.utf8 接下来 1export LANG=zh_CN.utf8 然后看下文件列表 12345678910111213141516drwxr-xr-x 11 root root 4096 6月 14 09:52 ./drwxr-xr-x 4 root root 4096 6月 14 09:53 ../drwxr-xr-x 2 root root 4096 6月 12 05:51 文档/drwxr-xr-x 6 root root 4096 5月 23 22:21 app/-rwxr-xr-x 1 root root 684 5月 5 11:32 composer.json*-rwxr-xr-x 1 root root 23126 6月 10 22:57 composer.lock*drwxr-xr-x 2 root root 4096 6月 6 10:35 config/drwxr-xr-x 2 root root 4096 4月 28 22:24 extend/-rwxr-xr-x 1 root root 18 4月 28 22:24 .htaccess*-rwxr-xr-x 1 root root 506 4月 28 22:24 max*drwxr-xr-x 4 root root 4096 6月 14 10:14 public/drwxr-xr-x 2 root root 4096 4月 28 22:24 routes/drwxrwxrwx 4 root root 4096 6月 12 14:36 storage/-rw-r--r-- 1 root root 47 10月 22 2020 .user.inidrwxr-xr-x 8 root root 4096 6月 14 10:47 vendor/drwxr-xr-x 3 root root 4096 5月 18 14:05 views/ 文档被显示出来了。 最后我将他添加到家目录下的.bashrc文件里 1export LANG=zh_CN.utf8 就可以一直正常显示中文了。","link":"/2021/06/15/Ubuntu20.04%20%E4%B8%AD%E6%96%87%E6%98%BE%E7%A4%BA%E4%B8%8D%E6%AD%A3%E7%A1%AE%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"title":"URI和URL的区别比较与理解","text":"#什么是URI URI，通一资源标志符(Uniform Resource Identifier， URI)，表示的是web上每一种可用的资源，如 HTML文档、图像、视频片段、程序等都由一个URI进行标识的。 #URI的结构组成 URI通常由三部分组成： ①资源的命名机制； ②存放资源的主机名； ③资源自身的名称。 （注意：这只是一般URI资源的命名方式，只要是可以唯一标识资源的都被称为URI，上面三条合在一起是URI的充分不必要条件） #URI举例 如：https://www.chengyao.xyz/notes/edit/152 我们可以这样解释它： ①这是一个可以通过https协议访问的资源， ②位于主机 www.chengyao.xyz上， ③通过“/notes/edit/152”可以对该资源进行唯一标识（注意，这个不一定是完整的路径） 注意：以上三点只不过是对实例的解释，以上三点并不是URI的必要条件，URI只是一种概念，怎样实现无所谓，只要它唯一标识一个资源就可以了。 URLURL是URI的一个子集。它是Uniform Resource Locator的缩写，译为“统一资源定位 符”。 通俗地说，URL是Internet上描述信息资源的字符串，主要用在各种WWW客户程序和服务器程序上。 采用URL可以用一种统一的格式来描述各种信息资源，包括文件、服务器的地址和目录等。URL是URI概念的一种实现方式。 URL的一般格式为(带方括号[]的为可选项)： protocol :// hostname[:port] / path / [;parameters][?query]#fragment URL的格式由三部分组成： ①第一部分是协议(或称为服务方式)。 ②第二部分是存有该资源的主机IP地址(有时也包括端口号)。 ③第三部分是主机资源的具体地址，如目录和文件名等。 第一部分和第二部分用“://”符号隔开， 第二部分和第三部分用“/”符号隔开。 第一部分和第二部分是不可缺少的，第三部分有时可以省略。 URI和URL之间的区别从上面的例子来看，你可能觉得URI和URL可能是相同的概念，其实并不是，URI和URL都定义了资源是什么，但URL还定义了该如何访问资源。URL是一种具体的URI，它是URI的一个子集，它不仅唯一标识资源，而且还提供了定位该资源的信息。URI 是一种语义上的抽象概念，可以是绝对的，也可以是相对的，而URL则必须提供足够的信息来定位，是绝对的。 更新:看了一下大家的疑问,其实大家对uri可以认为只是唯一识别的编号,类似于大家的身份证号,而url就是身份证住址+姓名,这样是不是就很明显了~~ 更新2:针对大部分同学的疑问，其实纠结的就是URI到底是什么，怎么它就是URI不是URL了，其实文章中都已交代，只要能唯一标识资源的就是URI，在URI的基础上给出其资源的访问方式的就是URL，这是最简单的总结了，希望对大家有所帮助，祝好~~","link":"/2021/04/03/URI%E5%92%8CURL%E7%9A%84%E5%8C%BA%E5%88%AB%E6%AF%94%E8%BE%83%E4%B8%8E%E7%90%86%E8%A7%A3/"},{"title":"Ubuntu下安装PHP的一系列笔记","text":"查看配置可以通过命令查看 1php -i | grep configure 12php --iniphp -m 安装PHP 源码下载源码包解压 1234567891011121314151617181920apt -y install makeapt -y install build-essentialapt -y install libxml2-devapt -y install libssl-devapt -y install libpng-devapt -y install libsqlite3-devapt -y install zlib1g-dev // apt-get install libbz2-dev apt -y install libcurl4-openssl-devapt -y install libtidy-devapt -y install autoconfapt -y install libtoolapt -y install pkg-configgit clone https://github.com/kkos/oniguruma.git onigurumacd oniguruma./autogen.sh./configuremakemake install 12345678910111213141516171819sudo apt install gcc -y &amp;&amp;sudo apt install make -y &amp;&amp;sudo apt install openssl -y &amp;&amp;sudo apt install curl -y &amp;&amp;sudo apt install libbz2-dev -y &amp;&amp;sudo apt install libxml2-dev -y &amp;&amp;sudo apt install libjpeg-dev -y &amp;&amp;sudo apt install libpng-dev -y &amp;&amp;sudo apt install libfreetype6-dev -y &amp;&amp;sudo apt install libzip-dev -y &amp;&amp;sudo apt install libssl-dev -y &amp;&amp;sudo apt install libsqlite3-dev -y &amp;&amp;sudo apt install libcurl4-openssl-dev -y &amp;&amp;sudo apt install libgmp3-dev -y &amp;&amp;sudo apt install libonig-dev -y &amp;&amp;sudo apt install libreadline-dev -y &amp;&amp;sudo apt install libxslt1-dev -y &amp;&amp;sudo apt install libffi-dev -y 模块对应的依赖（可选择性的安装） 1234567891011121314151617181920212223242526272829303132xmlsudo apt-get install -y libxml2-devpcresudo apt-get install -y libpcre3-devjpegsudo apt-get install -y libjpeg62-devfreetypesudo apt-get install -y libfreetype6-devpngsudo apt-get install -y libpng12-dev libpng3 libpnglite-deviconvsudo apt-get install -y libiconv-hook-dev libiconv-hook1mycryptsudo apt-get install -y libmcrypt-dev libmcrypt4mhashsudo apt-get install -y libmhash-dev libmhash2opensslsudo apt-get install -y libltdl-dev libssl-devcurlsudo apt-get install -y libcurl4-openssl-devmysqlsudo apt-get install -y libmysqlclient-devimagicksudo apt-get install -y libmagickcore-dev libmagickwand-devreadlinesudo apt-get install -y libedit-devubuntu 无法找到 iconvsudo ln -s /usr/lib/libiconv_hook.so.1.0.0 /usr/lib/libiconv.sosudo ln -s /usr/lib/libiconv_hook.so.1.0.0 /usr/lib/libiconv.so.1安装PHP扩展sudo apt-get install -y autoconf automake m4 去掉单引号后如下 1./configure --prefix=/usr/local/php/81 --with-config-file-path=/usr/local/php/81/etc --enable-pcntl --enable-fpm --enable-inline-optimization --disable-debug --disable-rpath --enable-shared --with-xmlrpc --with-mhash --with-sqlite3 --with-zlib --enable-bcmath --with-iconv --with-bz2 --with-openssl --enable-calendar --with-curl --with-cdb --enable-dom --enable-exif --enable-fileinfo --enable-filter --with-openssl-dir --with-zlib-dir --enable-gd-jis-conv --with-gettext --with-gmp --with-mhash --enable-json --enable-mbstring --enable-mbregex --enable-pdo --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-pdo-sqlite --with-readline --enable-session --enable-shmop --enable-simplexml --enable-sockets --enable-sysvmsg --enable-sysvsem --enable-sysvshm --with-xsl --enable-mysqlnd-compression-support --with-pear --enable-opcache --with-zip --enable-gd --with-ffi 1make -j &amp;&amp; make install 配置文件 123cp php.ini-development /usr/local/php/8.1/etc/php.ini cd /opt/php/74/etc &amp;&amp; cp php-fpm.conf.default php-fpm.confcd /opt/php/74/etc/php-fpm.d &amp;&amp; cp www.conf.default www.conf vim /opt/php/74/etc/php-fpm.conf，pid = run/php-fpm.pid #去掉； 1pid = run/php-fpm.pid vim /opt/php/74/etc/php-fpm.d/www.conf 增加 12user = wwwgroup = www 增加php环境变量(我使用的zsh 如果是bash 请编辑 .bashrc 文件 ) 1vim ~/.zshrc 加入 12export PHP_HOME=/opt/php/74export PATH=$PHP_HOME/bin:$PATH 增加www用户用户组 12sudo groupadd wwwsudo useradd -g www www php-fpm服务化（Systemd） 12sudo touch /lib/systemd/system/php-fpm.servicesudo vim /lib/systemd/system/php-fpm.service 12345678910111213[Unit]Description=The PHP FastCGI Process ManagerAfter=syslog.target network.target[Service]Type=forkingPIDFile=/opt/php/74/var/run/php-fpm.pidExecStart=/opt/php/74/sbin/php-fpmExecReload=/bin/kill -USR2 $MAINPIDPrivateTmp=true[Install]WantedBy=multi-user.target 服务开机启动 1sudo systemctl enable php-fpm.service 启动、停止、重启、状态 1234sudo systemctl start php-fpm.servicesudo systemctl stop php-fpm.servicesudo systemctl restart php-fpm.servicesudo systemctl status php-fpm.service 参考：https://blog.csdn.net/hiqiming/article/details/105245227 apt安装首先，请确保您的系统中具有add-apt-repository命令实用程序。 1sudo apt-get install software-properties-common 现在，您可以添加存储库并更新系统中的程序包缓存。 12sudo add-apt-repository ppa:ondrej/phpsudo apt-get update 最后，要在Linux系统中安装PHP 8，请使用安装命令。 1sudo apt install php8.1 安装pecl12wget http://pear.php.net/go-pear.pharphp go-pear.phar 或者 1apt install php-pear 安装扩展amqp准备怼最新版https://github.com/alanxz/rabbitmq-c/releases 下载后解压 安装没有安装cmake的需要先安装 1apt install cmake 解压后进入解压目录执行 123mkdir build &amp;&amp; cd buildcmake -DCMAKE_INSTALL_PREFIX=/usr/local/rabbitmq-c ..make &amp;&amp; make install pecl 1pecl install amqp 指定下librabbmitmq的位置，回车再按照添加配置 源码 pecl下载源码包， 12phpize./configure --with-php-config=/path-to/php-config --with-amqp --with-librabbitmq-dir=/usr/local/rabbitmq-c 源码安装如果报错 123/usr/local/rabbitmq-c-0.11.0/lib -lrabbitmq.../usr/bin/ld: cannot find -lrabbitmq 那就找到rabbitmq-c的链接库做下软连接 12ln -s /usr/local/rabbitmq-c-0.11.0/lib/x86_64-linux-gnu/librabbitmq.so /usr/local/rabbitmq-c-0.11.0/lib/ln -s /usr/local/rabbitmq-c-0.11.0/lib/x86_64-linux-gnu/librabbitmq.so.4 /usr/local/rabbitmq-c-0.11.0/lib/ pecl卸载扩展1pecl uninstall swoole fpm配置添加到服务项 12cp php-fpm.service /etc/systemd/system/ 1234service php-fpm startservice php-fpm stopservice php-fpm restartservice php-fpm reload 报错解决方案 php拓展安装报错：Warning: PHP Startup: Invalid library (maybe not a PHP library) ‘*.so’ in Unknown on lin 解决方法：make clean 然后重新phpize,configure –with-php-config=,make,make install走安装流 编译参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364`configure' configures PHP 7.4.0-dev to adapt to many kinds of systems. Usage: ./configure [OPTION]... [VAR=VALUE]... To assign environment variables (e.g., CC, CFLAGS...), specify them asVAR=VALUE. See below for descriptions of some of the useful variables. Defaults for the options are specified in brackets. Configuration: -h, --help display this help and exit --help=short display options specific to this package --help=recursive display the short help of all the included packages -V, --version display version information and exit -q, --quiet, --silent do not print `checking ...' messages --cache-file=FILE cache test results in FILE [disabled] -C, --config-cache alias for `--cache-file=config.cache' -n, --no-create do not create output files --srcdir=DIR find the sources in DIR [configure dir or `..'] Installation directories: --prefix=PREFIX install architecture-independent files in PREFIX [/usr/local] --exec-prefix=EPREFIX install architecture-dependent files in EPREFIX [PREFIX] By default, `make install' will install all the files in`/usr/local/bin', `/usr/local/lib' etc. You can specifyan installation prefix other than `/usr/local' using `--prefix',for instance `--prefix=$HOME'. For better control, use the options below. Fine tuning of the installation directories: --bindir=DIR user executables [EPREFIX/bin] --sbindir=DIR system admin executables [EPREFIX/sbin] --libexecdir=DIR program executables [EPREFIX/libexec] --sysconfdir=DIR read-only single-machine data [PREFIX/etc] --sharedstatedir=DIR modifiable architecture-independent data [PREFIX/com] --localstatedir=DIR modifiable single-machine data [PREFIX/var] --libdir=DIR object code libraries [EPREFIX/lib] --includedir=DIR C header files [PREFIX/include] --oldincludedir=DIR C header files for non-gcc [/usr/include] --datarootdir=DIR read-only arch.-independent data root [PREFIX/share] --datadir=DIR read-only architecture-independent data [DATAROOTDIR] --infodir=DIR info documentation [DATAROOTDIR/info] --localedir=DIR locale-dependent data [DATAROOTDIR/locale] --mandir=DIR man documentation [DATAROOTDIR/man] --docdir=DIR documentation root [DATAROOTDIR/doc/php] --htmldir=DIR html documentation [DOCDIR] --dvidir=DIR dvi documentation [DOCDIR] --pdfdir=DIR pdf documentation [DOCDIR] --psdir=DIR ps documentation [DOCDIR] Program names: --program-prefix=PREFIX prepend PREFIX to installed program names --program-suffix=SUFFIX append SUFFIX to installed program names --program-transform-name=PROGRAM run sed PROGRAM on installed program names System types: --build=BUILD configure for building on BUILD [guessed] --host=HOST cross-compile to build programs to run on HOST [BUILD] --target=TARGET configure for building compilers for TARGET [HOST] Optional Features and Packages: --disable-option-checking ignore unrecognized --enable/--with options --disable-FEATURE do not include FEATURE (same as --enable-FEATURE=no) --enable-FEATURE[=ARG] include FEATURE [ARG=yes] --with-PACKAGE[=ARG] use PACKAGE [ARG=yes] --without-PACKAGE do not use PACKAGE (same as --with-PACKAGE=no) --with-libdir=NAME Look for libraries in .../NAME rather than .../lib --disable-rpath Disable passing additional runtime library search paths --enable-re2c-cgoto Enable -g flag to re2c to use computed goto gcc extension --disable-gcc-global-regs whether to enable GCC global register variables SAPI modules: --with-apxs2[=FILE] Build shared Apache 2.0 Handler module. FILE is the optional pathname to the Apache apxs tool [apxs] --disable-cli Disable building CLI version of PHP (this forces --without-pear) --enable-embed[=TYPE] EXPERIMENTAL: Enable building of embedded SAPI library TYPE is either 'shared' or 'static'. [TYPE=shared] --enable-fpm Enable building of the fpm SAPI executable --with-fpm-user[=USER] Set the user for php-fpm to run as. (default: nobody) --with-fpm-group[=GRP] Set the group for php-fpm to run as. For a system user, this should usually be set to match the fpm username (default: nobody) --with-fpm-systemd Activate systemd integration --with-fpm-acl Use POSIX Access Control Lists --with-litespeed Build PHP as litespeed module --enable-phpdbg Build phpdbg --enable-phpdbg-webhelper Build phpdbg web SAPI support --enable-phpdbg-debug Build phpdbg in debug mode --enable-phpdbg-readline Enable readline support in phpdbg (depends on static ext/readline) --disable-cgi Disable building CGI version of PHP --with-valgrind=DIR Enable valgrind support General settings: --enable-gcov Enable GCOV code coverage (requires LTP) - FOR DEVELOPERS ONLY!! --enable-debug Compile with debugging symbols --enable-rtld-now Use dlopen with RTLD_NOW instead of RTLD_LAZY --with-layout=TYPE Set how installed files will be laid out. Type can be either PHP or GNU [PHP] --with-config-file-path=PATH Set the path in which to look for php.ini [PREFIX/lib] --with-config-file-scan-dir=PATH Set the path where to scan for configuration files --enable-sigchild Enable PHP's own SIGCHLD handler --enable-libgcc Enable explicitly linking against libgcc --disable-short-tags Disable the short-form &lt;? start tag by default --enable-dmalloc Enable dmalloc --disable-ipv6 Disable IPv6 support --enable-dtrace Enable DTrace support --enable-fd-setsize Set size of descriptor sets Extensions: --with-EXTENSION=shared[,PATH] NOTE: Not all extensions can be build as 'shared'. Example: --with-foobar=shared,/usr/local/foobar/ o Builds the foobar extension as shared extension. o foobar package install prefix is /usr/local/foobar/ --disable-all Disable all extensions which are enabled by default --disable-libxml Disable LIBXML support --with-libxml-dir[=DIR] LIBXML: libxml2 install prefix --with-openssl Include OpenSSL support (requires OpenSSL &gt;= 1.0.1) --with-kerberos[=DIR] OPENSSL: Include Kerberos support --with-system-ciphers OPENSSL: Use system default cipher list instead of hardcoded value --with-external-pcre Use external library for PCRE support --with-pcre-jit Enable PCRE JIT functionality --with-pcre-valgrind=DIR Enable PCRE valgrind support. Developers only! --without-sqlite3[=DIR] Do not include SQLite3 support. DIR is the prefix to SQLite3 installation directory. --with-zlib Include ZLIB support (requires zlib &gt;= 1.2.0.4) --enable-bcmath Enable bc style precision math functions --with-bz2[=DIR] Include BZip2 support --enable-calendar Enable support for calendar conversion --disable-ctype Disable ctype functions --with-curl Include cURL support --enable-dba Build DBA with bundled modules. To build shared DBA extension use --enable-dba=shared --with-qdbm[=DIR] DBA: QDBM support --with-gdbm[=DIR] DBA: GDBM support --with-ndbm[=DIR] DBA: NDBM support --with-db4[=DIR] DBA: Oracle Berkeley DB 4.x or 5.x support --with-db3[=DIR] DBA: Oracle Berkeley DB 3.x support --with-db2[=DIR] DBA: Oracle Berkeley DB 2.x support --with-db1[=DIR] DBA: Oracle Berkeley DB 1.x support/emulation --with-dbm[=DIR] DBA: DBM support --with-tcadb[=DIR] DBA: Tokyo Cabinet abstract DB support --with-lmdb[=DIR] DBA: Lightning memory-mapped database support --without-cdb[=DIR] DBA: CDB support (bundled) --disable-inifile DBA: INI support (bundled) --disable-flatfile DBA: FlatFile support (bundled) --disable-dom Disable DOM support --with-libxml-dir[=DIR] DOM: libxml2 install prefix --with-enchant[=DIR] Include enchant support. GNU Aspell version 1.1.3 or higher required. --enable-exif Enable EXIF (metadata from images) support --with-ffi Include FFI support --disable-fileinfo Disable fileinfo support --disable-filter Disable input filter support --enable-ftp Enable FTP support --with-openssl-dir[=DIR] FTP: openssl install prefix --enable-gd Include GD support --with-external-gd Use external libgd --with-webp GD: Enable WEBP support --with-jpeg GD: Enable JPEG support --with-xpm GD: Enable XPM support --with-freetype GD: Enable FreeType 2 support --enable-gd-jis-conv GD: Enable JIS-mapped Japanese font support --with-gettext[=DIR] Include GNU gettext support --with-gmp[=DIR] Include GNU MP support --with-mhash[=DIR] Include mhash support --without-iconv[=DIR] Exclude iconv support --with-imap[=DIR] Include IMAP support. DIR is the c-client install prefix --with-kerberos[=DIR] IMAP: Include Kerberos support. DIR is the Kerberos install prefix --with-imap-ssl[=DIR] IMAP: Include SSL support. DIR is the OpenSSL install prefix --with-interbase[=DIR] Include Firebird support. DIR is the Firebird base install directory [/opt/firebird] --enable-intl Enable internationalization support --disable-json Disable JavaScript Object Serialization support --with-ldap[=DIR] Include LDAP support --with-ldap-sasl[=DIR] LDAP: Include Cyrus SASL support --enable-mbstring Enable multibyte string support --disable-mbregex MBSTRING: Disable multibyte regex support --with-mysqli[=FILE] Include MySQLi support. FILE is the path to mysql_config. If no value or mysqlnd is passed as FILE, the MySQL native driver will be used --with-mysql-sock[=SOCKPATH] MySQLi/PDO_MYSQL: Location of the MySQL unix socket pointer. If unspecified, the default locations are searched --with-oci8[=DIR] Include Oracle Database OCI8 support. DIR defaults to $ORACLE_HOME. Use --with-oci8=instantclient,/path/to/instant/client/lib to use an Oracle Instant Client installation --with-odbcver[=HEX] Force support for the passed ODBC version. A hex number is expected, default 0x0350. Use the special value of 0 to prevent an explicit ODBCVER to be defined. --with-adabas[=DIR] Include Adabas D support [/usr/local] --with-sapdb[=DIR] Include SAP DB support [/usr/local] --with-solid[=DIR] Include Solid support [/usr/local/solid] --with-ibm-db2[=DIR] Include IBM DB2 support [/home/db2inst1/sqllib] --with-empress[=DIR] Include Empress support $EMPRESSPATH (Empress Version &gt;= 8.60 required) --with-empress-bcs[=DIR] Include Empress Local Access support $EMPRESSPATH (Empress Version &gt;= 8.60 required) --with-custom-odbc[=DIR] Include user defined ODBC support. DIR is ODBC install base directory [/usr/local]. Make sure to define CUSTOM_ODBC_LIBS and have some odbc.h in your include dirs. f.e. you should define following for Sybase SQL Anywhere 5.5.00 on QNX, prior to running this configure script: CPPFLAGS=&quot;-DODBC_QNX -DSQLANY_BUG&quot; LDFLAGS=-lunix CUSTOM_ODBC_LIBS=&quot;-ldblib -lodbc&quot; --with-iodbc[=DIR] Include iODBC support [/usr/local] --with-esoob[=DIR] Include Easysoft OOB support [/usr/local/easysoft/oob/client] --with-unixODBC[=DIR] Include unixODBC support [/usr/local] --with-dbmaker[=DIR] Include DBMaker support --disable-opcache Disable Zend OPcache support --disable-huge-code-pages Disable copying PHP CODE pages into HUGE PAGES --enable-pcntl Enable pcntl support (CLI/CGI only) --disable-pdo Disable PHP Data Objects support --with-pdo-dblib[=DIR] PDO: DBLIB-DB support. DIR is the FreeTDS home directory --with-pdo-firebird[=DIR] PDO: Firebird support. DIR is the Firebird base install directory [/opt/firebird] --with-pdo-mysql[=DIR] PDO: MySQL support. DIR is the MySQL base directory. If no value or mysqlnd is passed as DIR, the MySQL native driver will be used --with-zlib-dir[=DIR] PDO_MySQL: Set the path to libz install prefix --with-pdo-oci[=DIR] PDO: Oracle OCI support. DIR defaults to $ORACLE_HOME. Use --with-pdo-oci=instantclient,/path/to/instant/client/lib for an Oracle Instant Client installation. --with-pdo-odbc=flavour,dir PDO: Support for 'flavour' ODBC driver. The include and lib dirs are looked for under 'dir'. The 'flavour' can be one of: ibm-db2, iODBC, unixODBC, generic. If ',dir' part is omitted, default for the flavour you have selected will be used. e.g.: --with-pdo-odbc=unixODBC will check for unixODBC under /usr/local. You may attempt to use an otherwise unsupported driver using the 'generic' flavour. The syntax for generic ODBC support is: --with-pdo-odbc=generic,dir,libname,ldflags,cflags. When built as 'shared' the extension filename is always pdo_odbc.so --with-pdo-pgsql[=DIR] PDO: PostgreSQL support. DIR is the PostgreSQL base install directory or the path to pg_config --without-pdo-sqlite[=DIR] PDO: sqlite 3 support. DIR is the sqlite base install directory [BUNDLED] --with-pgsql[=DIR] Include PostgreSQL support. DIR is the PostgreSQL base install directory or the path to pg_config --disable-phar Disable phar support --disable-posix Disable POSIX-like functions --with-pspell[=DIR] Include PSPELL support. GNU Aspell version 0.50.0 or higher required --with-libedit Include libedit readline replacement (CLI/CGI only) --with-readline[=DIR] Include readline support (CLI/CGI only) --with-recode[=DIR] Include recode support --disable-session Disable session support --with-mm[=DIR] SESSION: Include mm support for session storage --enable-shmop Enable shmop support --disable-simplexml Disable SimpleXML support --with-libxml-dir=DIR SimpleXML: libxml2 install prefix --with-snmp[=DIR] Include SNMP support --with-openssl-dir[=DIR] SNMP: openssl install prefix --enable-soap Enable SOAP support --with-libxml-dir=DIR SOAP: libxml2 install prefix --enable-sockets Enable sockets support --with-sodium[=DIR] Include sodium support --with-password-argon2[=DIR] Include Argon2 support in password_*. DIR is the Argon2 shared library path --enable-sysvmsg Enable sysvmsg support --enable-sysvsem Enable System V semaphore support --enable-sysvshm Enable the System V shared memory support --with-tidy[=DIR] Include TIDY support --disable-tokenizer Disable tokenizer support --disable-xml Disable XML support --with-libxml-dir=DIR XML: libxml2 install prefix --with-libexpat-dir=DIR XML: libexpat install prefix (deprecated) --disable-xmlreader Disable XMLReader support --with-libxml-dir=DIR XMLReader: libxml2 install prefix --with-xmlrpc[=DIR] Include XMLRPC-EPI support --with-libxml-dir=DIR XMLRPC-EPI: libxml2 install prefix --with-libexpat-dir=DIR XMLRPC-EPI: libexpat dir for XMLRPC-EPI (deprecated) --with-iconv-dir=DIR XMLRPC-EPI: iconv dir for XMLRPC-EPI --disable-xmlwriter Disable XMLWriter support --with-libxml-dir=DIR XMLWriter: libxml2 install prefix --with-xsl[=DIR] Include XSL support. DIR is the libxslt base install directory (libxslt &gt;= 1.1.0 required) --enable-zend-test Enable zend-test extension --enable-zip Include Zip read/write support --with-libzip[=DIR] ZIP: use libzip --enable-mysqlnd Enable mysqlnd explicitly, will be done implicitly when required by other extensions --disable-mysqlnd-compression-support Disable support for the MySQL compressed protocol in mysqlnd --with-zlib-dir[=DIR] mysqlnd: Set the path to libz install prefix PEAR: --with-pear[=DIR] Install PEAR in DIR [PREFIX/lib/php] Zend: --enable-maintainer-zts Enable thread safety - for code maintainers only!!(安全线程) --disable-inline-optimization If building zend_execute.lo fails, try this switch --disable-zend-signals whether to enable zend signal handling TSRM: --with-tsrm-pth[=pth-config] Use GNU Pth --with-tsrm-st Use SGI's State Threads --with-tsrm-pthreads Use POSIX threads (default) Libtool: --enable-shared=PKGS Build shared libraries default=yes --enable-static=PKGS Build static libraries default=yes --enable-fast-install=PKGS Optimize for fast installation default=yes --with-gnu-ld Assume the C compiler uses GNU ld default=no --disable-libtool-lock Avoid locking (might break parallel builds) --with-pic Try to use only PIC/non-PIC objects default=use both --with-tags=TAGS Include additional configurations automatic Ubuntu 18.04 安装 php7.4 –enable-maintainer-ztsPHP 编译安装 PHP各参数配置详解","link":"/2021/10/15/Ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85PHP%E7%9A%84%E4%B8%80%E7%B3%BB%E5%88%97%E7%AC%94%E8%AE%B0/"},{"title":"Ubuntu的messages Log开启","text":"ubuntu开启messages logless /etc/rsyslog.d/50-default.conf 1234#*.=info;*.=notice;*.=warn;\\# auth,authpriv.none;\\# cron,daemon.none;\\# mail,news.none -/var/log/messages 删掉以上部分的注释，重启rsyslog 1service rsyslog restart 使用以下命令查看log文件1tail -f /var/log/messages 1tail -10 /var/log/messages","link":"/2021/04/21/Ubuntu%E7%9A%84messages%20Log%E5%BC%80%E5%90%AF/"},{"title":"Vscode使用小技巧","text":"vscode删除重复行并排序`安装插件:Transformer ctrl + a 全选文字ctrl + shift + P 打开命令窗口输入： 1Transform:Unique Lines //删除重复行 或 1Transform:Sort Lines //排序 更多功能，查看插件页面，有git动画示例 vscode删除行前的空格 输入^\\s选择使用正则表达式vscode删除行尾的空格 输入\\s$选择使用正则表达式 VScode多行编辑的设置VScode对多行编辑有两种模式。 第一种模式 1Alt+Shift 竖列选择 这种模式下只可以选择竖列，不可以随意插入光标。所以只限制于同一列且不间隔的情况下。 第二种模式 12Shift+Ctrl 竖列选择Ctrl+光标点击 选择多个编辑位点 这种模式下不仅可以选择竖列，同时还可以在多个地方插入光标。 两种模式的切换使用Shift+Ctrl+p快捷键调用查询输入栏，输入cursor，列表中会出现“切换多行修改键”这个选项。选择这个选项就可以在两种模式下切换。 同时选中多个相同字符 多行 编辑 ctrl + shift + L 同时选中多个相同的字符使用步骤如下，比如：冒号 使用鼠标选中 冒号 ctrl + shift + L 使用键盘左右箭头 ← → 可以移动至需要位置 输入需要的数值 alt + 鼠标左键点击单个选择 同时选中多行不同位置使用步骤如下，比如：冒号 按住alt + 鼠标左键选择第一行目标位置 重复第一步，选择目标行目标位置 使用键盘左右箭头 ← → 可以移动至需要位置 输入需要的数值 alt + shift + 鼠标左键竖拉 IDEA 选中多行相同的内容，快捷键ctrl+alt+shift+j 其他选中字母后多次按下 ALT + J 选中多个相同的字母 解决VSCODE”因为在此系统上禁止运行脚本”报错 以管理员身份运行vscode; 执行：get-ExecutionPolicy，显示Restricted，表示状态是禁止的; 执行：set-ExecutionPolicy RemoteSigned; 这时再执行get-ExecutionPolicy，就显示RemoteSigned;","link":"/2021/04/07/Vscode%E4%BD%BF%E7%94%A8%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"title":"Vue操作select","text":"Vue操作select html如下 123456789&lt;div id=&quot;app&quot;&gt; &lt;select v-model=&quot;category&quot; v-on:change=&quot;switchCategory($event, 1)&quot;&gt; &lt;option v-for=&quot;(category, index) in categories&quot; :key=&quot;index&quot; v-bind:value=&quot;category.id&quot;&gt; {{category.name}} &lt;/option&gt; &lt;/select&gt;&lt;/div&gt; js如下 123456789101112131415161718192021222324252627Vue.createApp({ data() { return { category: 0, categories: [ { id: 1, name: &quot;PHP&quot;, }, { id: 2, name: &quot;Go&quot;, }, { id: 3, name: &quot;Java&quot;, }, ], }; }, methods: { switchCategory($event, p) { console.log($event.target.value, p, this.category); }, },}).mount(&quot;#app&quot;);","link":"/2022/05/22/Vue%E6%93%8D%E4%BD%9Cselect/"},{"title":"Vue中watch用法详解","text":"基本用法： 当firstName值变化时，watch监听到并且执行 123456789101112131415161718&lt;div&gt; &lt;p&gt;FullName: {{fullName}}&lt;/p&gt; &lt;p&gt;FirstName: &lt;input type=&quot;text&quot; v-model=&quot;firstName&quot;&gt;&lt;/p&gt;&lt;/div&gt; new Vue({ el: '#root', data: { firstName: 'Dawei', lastName: 'Lou', fullName: '' }, watch: { firstName(newName, oldName) { this.fullName = newName + ' ' + this.lastName; } } }) handler方法和immediate属性： 上面的例子是值变化时候，watch才执行，我们想让值最初时候watch就执行就用到了handler和immediate属性 123456789watch: { firstName: { handler(newName, oldName) { this.fullName = newName + ' ' + this.lastName; }, // 代表在wacth里声明了firstName这个方法之后立即先去执行handler方法，如果设置了false，那么效果和上边例子一样 immediate: true }} deep属性（深度监听，常用语对象下面属性的改变）：123456789101112131415161718192021&lt;div&gt; &lt;p&gt;obj.a: {{obj.a}}&lt;/p&gt; &lt;p&gt;obj.a: &lt;input type=&quot;text&quot; v-model=&quot;obj.a&quot;&gt;&lt;/p&gt;&lt;/div&gt; new Vue({ el: '#root', data: { obj: { a: 123 } }, watch: { obj: { handler(newName, oldName) { console.log('obj.a changed'); }, immediate: true } } }) 我们在在输入框中输入数据视图改变obj.a的值时，我们发现是无效的。受现代 JavaScript 的限制 (以及废弃 Object.observe)，Vue 不能检测到对象属性的添加或删除。由于 Vue 会在初始化实例时对属性执行 getter/setter 转化过程，所以属性必须在 data 对象上存在才能让 Vue 转换它，这样才能让它是响应的。 默认情况下 handler 只监听obj这个属性它的引用的变化，我们只有给obj赋值的时候它才会监听到，比如我们在 mounted事件钩子函数中对obj进行重新赋值： 12345mounted: { this.obj = { a: '456' }} 那么我们需要监听obj里的属性a的值呢？这时候deep属性就派上用场了: 123456789watch: { obj: { handler(newName, oldName) { console.log('obj.a changed'); }, immediate: true, deep: true }} 这样的方法对性能影响很大，修改obj里面任何一个属性都会触发这个监听器里的 handler。我们可以做如下处理： 123456789watch: { 'obj.a': { handler(newName, oldName) { console.log('obj.a changed'); }, immediate: true, // deep: true }} watch的注销这里就不在多说了，实际开发中，watch会随着组件一并销毁。 链接：https://www.jianshu.com/p/b70f1668d08f","link":"/2022/05/21/Vue%E4%B8%ADwatch%E7%94%A8%E6%B3%95%E8%AF%A6%E8%A7%A3/"},{"title":"a标签的download属性","text":"a标签加上downlaod属性后，就可完成对href属性链接文件的下载，但仅仅是限于同源文件，如果是非同源，download属性会失效。没有download属性的时候，a标签的默认行为是链接跳转进行预览，而针对浏览无法预览的文件，也可达到下载的效果。怎么解决下载非同源文件的问题？？ 例如image图片 方法： 通过canvas绘制，生成临时路径 ( data协议路径 // data:image/jpeg;base64,/9j/4AAQSkZJRgABAQ…9oADAMBAAIRAxEAPwD/AD/6AP/Z”)，这个路径就是一个同源路径，然后传入下载函数进行下载。 123456789101112let img = new Image();img.setAttribute('crossOrigin', 'anonymous')img.src = data.entry;img.onload = function(data) { let canvas = document.createElement('canvas'); canvas.width = img.width; canvas.height = img.height; let context = canvas.getContext('2d'); context.drawImage(img, 0, 0, canvas.width, canvas.height); let url = canvas.toDataURL('image/png'); downLoadByLink(url,&quot;小程序码&quot;);} 12345678910111213141516const downLoadByLink = (url, filename) =&gt;{ //如果提供filename，则filename需要包含扩展名 var link, evt; link = document.createElement('a'); link.href = url; filename &amp;&amp; link.setAttribute('download', filename); if(document.fireEvent) { window.open(link.href); }else { evt = document.createEvent('MouseEvents'); evt.initEvent('click', true, true); link.dispatchEvent(evt); }};","link":"/2022/06/14/a%E6%A0%87%E7%AD%BE%E7%9A%84download%E5%B1%9E%E6%80%A7/"},{"title":"WSL2 使用笔记","text":"安装 官方文档 https://docs.microsoft.com/zh-cn/windows/wsl/install-manual https://docs.microsoft.com/zh-cn/windows/wsl/install 登录相关停止wsl21wsl --shutdown wsl切换用户需要输入密码 可以根据下面文档去掉密码：https://www.1kmb.com/note/232.html 默认使用root用户运行cmd/powershell, 运行下面的命令 123ubuntu1804 config --default-user rootwsl --shutdownubuntu1804 如果你的发行版是其他版本，修改ubuntu1804 即可 ip相关WSL2 每次重启后ip会变，网上提供了响应教程可以固定，实际上使用localhost就可以。如果你的子系统安装了nginx，建立虚拟机，绑定域名后在windows的hosts中将域名指向127.0.0.1 IO问题wsl2 和 windows之间的io速度很慢，所以可以安装俩子系统发行版，一个使用wsl1， 一个使用wsl2 1wsl --set-version Ubuntu-18.04 1 # 将Ubuntu-18.04设置为wsl1 1wsl -l -v # 查看所有版本 windows访问wsl在文件资源管理器输入 1\\\\wsl$","link":"/2021/11/05/WSL2%20%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"},{"title":"composer使用笔记","text":"安装12wget https://mirrors.cloud.tencent.com/composer/composer.pharmv composer.phar /usr/local/bin/composer #更换源 首先要分清楚是局部换源还是全局换源 1、局部换源(仅对当前项目有效)在当前项目下的composer.json中添加 12345678910111213141516171819{&quot;repositories&quot;: [ { &quot;type&quot;: &quot;composer&quot;, &quot;url&quot;: &quot;http://packages.example.com&quot; //第一个源 }, { &quot;type&quot;: &quot;composer&quot;, &quot;url&quot;: &quot;http://packages.example.com&quot; //第二个源 }, { &quot;type&quot;: &quot;git&quot;, &quot;url&quot;: &quot;https://git.url&quot; }, { &quot;type&quot;: &quot;path&quot;, &quot;url&quot;: &quot;D:/php/pacakge&quot; }} 寻找包的过程是先从第一个源中寻找，如果找不到就从第二个源中寻找，这里可以配置多个composer资源库 2、全局换源打开命令行 首先把默认的源给禁用掉1composer config -g secure-http false 修改镜像源12composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/ # 阿里composer config -g repos.packagist composer https://mirrors.cloud.tencent.com/composer/ # 腾讯 更换为原来的源1composer config -g repo.packagist composer https://repo.packagist.org 修改成功后可以先查看一下配置1composer config -g -l 第二行repositories.packagist.org.url 如果是阿里的就代表成功注意:如果修改了全局的话 就不用再去项目下修改composer.json配置文件了 如果当前项目的composer.json已经配置过，那会是当前项目下指定的源 文章来源：composer更换源 常用命令composer outdated 更新命令 1composer self-update --preview 1composer update -vvv 清除缓存命令 1composer clearcache 更新到composer2 1composer self-update --2 如果使用apt或者yum等方式安装可能需要其他方法具体见官方文档。 搜索扩展包 1composer search max/max #自动加载 我们在开发项目中会经常用到第三方的类库插件，但是如果每次需要使用的时候都会在代码的某一处去引入，然后在实例化，这样做感觉很不方便，那么怎么实现自动加载呢，下面简单介绍使用composer实现自动加载： 安装安装地址（中国镜像）: https://pkg.phpcomposer.com/#how-to-install-composer根据它的说明一步一步进行安装 新建目录新建一个目录，这个目录的名称是有要求的，当你看到有提示就说名你的命名不符合要求，该目录就是后面的项目目录！ 初始化打开命令行控制台cmd,进入工作目录,运行composer命令：composer init之后会提示你输入一些包名，作者等信息，运行后会生成一个composer.json文件 Install执行composer install 安装会给你安装依赖，当然你的项目刚建立是没有依赖的，所以他会给你安装composer包，composer包的结构如下： vendor composer autoload_classmap.php autoload_namespaces.php autoload_psr4.php autoload_real.php autoload_static.phpClassLoader.phpinstalled.jsonLICENSE autoload.php composer.json 在你的项目中引入autoload.php就可以进行自动加载了。 你可能需要手动修改/添加一些东西 自动加载配置打开composer.json文件:共有四种方式： PSR-0（不推荐使用); PSR-4; Class-map; Files; 下面演示PSR-4实现自动加载： 1234&quot;autoload&quot;: { &quot;psr-4&quot;: { &quot;app\\\\&quot;: &quot;../application&quot; } 其中app\\表示../application 目录下的类的命名空间是app 命名空间新建src目录，在目录下创建IndexController.php,php文件内容如下: //设置命名空间 namespace src; class IndexController { public function index() { echo 'indexController'; } } 创建类在work根目录创建index.php： //引入vendor下的autoloas.php require 'vendor/autoload.php'; //实例化对象 $index = new src\\\\IndexController(); //调用类中的方法 $index-&gt;index(); 运行后会出现报错: class IndexController not fund 打开控制台,进入到work文件目录,运行composer命令: composer dump-autoload 在运行work下的index.php，不报错误信息说明已经成功实现自动加载了。 使用在work下的index.php文件中我们实例化IndexController类的时,格式为new src\\IndexController();;如果命名空间较长的情况下，看起来不太方便，那我们可以用use来引入关键字，修改index.php代码如下： use src\\IndexController; //引入vendor下的autoloas.php require 'vendor/autoload.php'; //修改后的实例化 $index = new IndexController(); //调用类中的方法 $index-&gt;index(); 在运行index.php结果和上面一样。注意：在配置完composer.json以后一定要运行composer dump-autoload [-o] 不然会出现class not fund;#踩坑 已经安装composer，写好composer.bat，并且设置好了path，在cmd下可以正常使用，但是在git-bash里面不行，显示如下提示： bash: composer: command not found 原因很可能是composer文件没有可执行权限，git-bash是以linux shell方式运行的，linux和windows文件权限管理方式不太一样。切换到composer文件所在目录，执行如下命令修复权限： 1chmod 755 composer.bat 可是我发现上面的命令没有效果，这就尴尬了 其实真正的原因是，git-bash 不识别 composer.bat 文件，需要新建一个 composer 文件，输入如下内容： 123#!/usr/bin/env sh# php /path/to/composer.phar $*php `dirname $0`/composer.phar $* #!/usr/bin/env sh 有个这一行，git-bash 会自动识别为可执行文件，不需要也不能使用 chmod 命令修改权限。 忽略平台要求1composer install --ignore-platform-reqs 指定php版本运行composer 1php /usr/bin/composer create-project max/max . 这里composer需要是完整路径。 文档https://docs.phpcomposer.com/ 版本约束通配符可以使用通配符来设置版本。1.0.相当于&gt;=1.0 &lt;1.1。例子：1.0. 波浪号我们先通过后面这个例子去解释操作符的用法：1.2相当于&gt;=1.2 &lt;2.0.0，而1.2.3相当于&gt;=1.2.3 &lt;1.3.0。对于使用Semantic Versioning作为版本号标准的项目来说，这种版本约束方式很实用。例如1.2定义了最小的小版本号，然后你可以升级2.0以下的任何版本而不会出问题，因为按照Semantic Versioning的版本定义，小版本的升级不应该有兼容性的问题。简单来说，定义了最小的版本，并且允许版本的最后一位版本号进行升级（没懂得话，请再看一边前面的例子）。例子：1.2 需要注意的是，如果作用在主版本号上，例如1，按照上面的说法，Composer可以安装版本1以后的主版本，但是事实上是1会被当作1.0对待，只能增加小版本，不能增加主版本。 折音号 ^^操作符的行为跟Semantic Versioning有比较大的关联，它允许升级版本到安全的版本。例如，^1.2.3相当于&gt;=1.2.3 &lt;2.0.0，因为在2.0版本前的版本应该都没有兼容性的问题。而对于1.0之前的版本，这种约束方式也考虑到了安全问题，例如^0.3会被当作&gt;=0.3.0 &lt;0.4.0对待。例子：^1.2.3 版本稳定性如果你没有显式的指定版本的稳定性，Composer会根据使用的操作符，默认在内部指定为-dev或者-stable。例如： 参考 名称 实例 说明 不指定版本 根据当前Path环境变量中的php版本下载最合适的最新版 确切的版本 6.0.1 指定下载的具体版本号 范围 &gt; &lt; != &gt; 6.0，&lt; 6.0 指定版本范围，自动下载该范围中的最新版 通配符 * 5.，6.0. 5.* 代表版本范围 [5, 6.0) 6.0.* 代表版本范围 [6.0, 6.1) 赋值运算符（最低版本） ~ 1.2，6.1.0 ~1.2 代表版本范围 [1.2, 2.0) ~6.1.0 代表版本范围 [6.1.0, 6.2) 脱字号版本（最低版本） ^ ^1.2.3 ^1.2.3 代表版本范围 [1.2.3, 2.0.0) 约束 内部约束1234567891.2.3 =1.2.3.0-stable&gt;1.2 &gt;1.2.0.0-stable&gt;=1.2 &gt;=1.2.0.0-dev&gt;=1.2-stable &gt;=1.2.0.0-stable&lt;1.3 &lt;1.3.0.0-dev&lt;=1.3 &lt;=1.3.0.0-stable1 - 2 &gt;=1.0.0.0-dev &lt;3.0.0.0-dev~1.3 &gt;=1.3.0.0-dev &lt;2.0.0.0-dev1.4.* &gt;=1.4.0.0-dev &lt;1.5.0.0-dev 例子：1.0 - 2.0如果你想指定版本只要稳定版本，你可以在版本后面添加后缀-stable。minimum-stability 配置项定义了包在选择版本时对稳定性的选择的默认行为。默认是stable。它的值如下（按照稳定性排序）：dev，alpha，beta，RC和stable。除了修改这个配置去修改这个默认行为，我们还可以通过稳定性标识（例如@stable和@dev）来安装一个相比于默认配置不同稳定性的版本。例如： 123456{ &quot;require&quot;: { &quot;monolog/monolog&quot;: &quot;1.0.*@beta&quot;, &quot;acme/foo&quot;: &quot;@dev&quot; }} 版本测试: https://semver.madewithlove.com/ ,地址可能会变更,可以参考composer官方文档","link":"/2021/02/13/composer%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"},{"title":"ajax请求","text":"javascriptXMLHttpRequest 对象 XMLHttpRequest对象是ajax的基础,XMLHttpRequest 用于在后台与服务器交换数据。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。目前所有浏览器都支持XMLHttpRequest 方 法 描 述 abort() 停止当前请求 getAllResponseHeaders() 把HTTP请求的所有响应首部作为键/值对返回 getResponseHeader(“header”) 返回指定首部的串值 open(“method”,”URL”,[asyncFlag],[“userName”],[“password”]) 建立对服务器的调用。method参数可以是GET、POST或PUT。url参数可以是相对URL或绝对URL。这个方法还包括3个可选的参数，是否异步，用户名，密码 send(content) 向服务器发送请求 setRequestHeader(“header”, “value”) 把指定首部设置为所提供的值。在设置任何首部之前必须先调用open()。设置header并和请求一起发送 (‘post’方法一定要 ) post 需要在open后设置header ，需要发送数据直接传递给xhr.send的第一个参数 1xhr.setRequestHeader('Content-Type','application/x-www-form-urlencoded'); 关键字：responseText, readyState, onreadystatechange Jq的ajax方法12345$.get('http://www.aaa.com',data,function(data,status){ if('success' === status){ console.log(data); }},'json') dataType 可以是text,html,xml,script,json,jsonp 将添加一个 “?callback=?” 到 URL 来规定回调,POST方式类似使用$.post 123456789101112131415161718192021222324252627282930313233343536$.ajax({ url:'http://www.aaa.com', type:'GET', dataType:'json', data:{'name':'bbb'}, traditional:true, //如果你想要用传统的方式来序列化数据，那么就设置为 true。请参考工具分类下面的 jQuery.param 方法。 timeout:'int', //设置请求超时时间（毫秒）。此设置将覆盖全局设置。 scriptCharset:'string',//只有当请求时 dataType 为 &quot;jsonp&quot; 或 &quot;script&quot;，并且 type 是 &quot;GET&quot; 才会用于强制修改 charset。通常只在本地和远程的内容编码不同时使用。 async:true, //true为异步 processData:true, //默认值: true。默认情况下，通过data选项传递进来的数据，如果是一个对象(技术上讲只要不是字符串)，都会处理转化成一个查询字符串，以配合默认内容类型 &quot;application/x-www-form-urlencoded&quot;。如果要发送 DOM 树信息或其它不希望转换的信息，请设置为 false。 ifModified:false,//仅在服务器数据改变时获取新数据。默认值: false。使用 HTTP 包 Last-Modified 头信息判断。在 jQuery 1.4 中，它也会检查服务器指定的 'etag' 来确定数据没有被修改过。 global:true, //是否触发全局 AJAX 事件。默认值: true。设置为 false 将不会触发全局 AJAX 事件，如 ajaxStart 或 ajaxStop 可用于控制不同的 Ajax 事件。 cache:true, //默认值: true，dataType 为 script 和 jsonp 时默认为 false。设置为 false 将不缓存此页面。 contentType:'applicate/x-www-form-urlencoded', //默认值 context:document.body, //这个对象用于设置 Ajax 相关回调函数的上下文。也就是说，让回调函数内 this 指向这个对象（如果不设定这个参数，那么 this 就指向调用本次 AJAX 请求时传递的 options 参数）。比如指定一个 DOM 元素作为 context 参数，这样就设置了 success 回调函数的上下文为这个 DOM 元素。 xhr:function(){ //需要返回一个 XMLHttpRequest 对象。默认在 IE 下是 ActiveXObject 而其他情况下是 XMLHttpRequest 。用于重写或者提供一个增强的 XMLHttpRequest 对象。这个参数在 jQuery 1.3 以前不可用。 } dataFilter:function(data,Type){ }, beforeSend:function(XHR){ }, success:function(e){ }, error:function(e){ }, complete:function(XHR, TS){ //请求完成后回调函数 (请求成功或失败之后均调用)。 }, jsonpCallback:'string', //为 jsonp 请求指定一个回调函数名。这个值将用来取代 jQuery 自动生成的随机函数名。这主要用来让 jQuery 生成度独特的函数名，这样管理请求更容易，也能方便地提供回调函数和错误处理。你也可以在想让浏览器缓存 GET 请求的时候，指定这个回调函数名。 password:'string', //用于响应 HTTP 访问认证请求的密码}) getScript1$(selector).getScript(url,success(response,status)) getScript() 方法使用 AJAX 的 HTTP GET 请求获取和执行 JavaScript。 status - 包含请求的状态（”success”、”notmodified”、”error”、”timeout”、”parsererror”） fetch es6新语法fetch().then() 12345678910111213141516//GET请求var httpGet = async function (getUrl) { var opts = { method: &quot;GET&quot;, credentials: 'include' // 强制加入凭据头 } await fetch(getUrl, opts).then((response) =&gt; { return response.text(); }).then((responseText) =&gt; { result = responseText; }).then((error) =&gt; { }); return result;}; 12345678910111213141516171819//下载var httpDownLoadFile = async function (getUrl, fileName) { var opts = { method: &quot;GET&quot;, credentials: 'include' // 强制加入凭据头 } await fetch(getUrl, opts).then((response) =&gt; { return response.blob(); }).then((blob) =&gt; { var url = window.URL.createObjectURL(blob); var a = document.createElement('a'); a.href = url; a.download = fileName; a.click(); window.URL.revokeObjectURL(url); }).then((error) =&gt; { });}; 一些发送请求后可以执行的方法: always():一定会执行 catch():执行出错时执行(本体 object) done():执行成功时执行 failed():执行出错时执行(服务器拒绝) pipe():过滤方法 progress():当对象生成进度通知时，调用添加处理程序。 Promise():返回Object(延迟)的Promise（承诺）对象。 state():确定一个Object（延迟）对象的当前状态。 then():当（延迟）对象解决，拒绝或仍在进行中时，调用添加处理程序。 es6 新增fetch().then() formData1234567$('#file_upload').on('change',function(){ var that = this; var files = this.files[0];}var form = new FormData();form.append('file',files); onclick=”return function(){}” 当function返回true执行默认行为为false不执行 fetch12345678fetch('https://...', { method: 'post', body: JSON.stringify(base), headers: { 'Content-Type': 'application/json' } }).then(function(data) {})","link":"/2021/04/02/ajax%E8%AF%B7%E6%B1%82/"},{"title":"css笔记","text":"#文本换行word-wrap: css的 word-wrap 属性用来标明是否允许浏览器在单词内进行断句，这是为了防止当一个字符串太长而找不到它的自然断句点时产生溢出现象。 word-break: css的 word-break 属性用来标明怎么样进行单词内的断句。 white-space:bread-spaces; 文本格式 text-decoration : none || underline || blink || overline || line-through text-decoration:none 无装饰，通常对html下划线标签去掉下划线样式 text-decoration:underline 下划线样式 text-decoration:line-through 删除线样式-贯穿线样式 text-decoration:overline 上划线样式 css的font-style 属性 normal : 正常的字体(默认字体样式，可用于去掉html i斜体标签默认斜体样式) italic : 斜体。对于没有斜体变量的特殊字体，将应用oblique oblique : 倾斜的字体 initialinitial 关键字用于设置 CSS 属性为它的默认值。可用于任何 HTML 元素上的任何 CSS 属性。设置 &lt;div&gt; 元素内的文本颜色为红色，但是为 &lt;h1&gt; 元素保持最初的颜色： 12div {color: red; }h1 {color: initial; } 文本删除线和颜色线体text-decoration:line-through red solid; 块级元素使用float属性块级元素使用float属性后，将其属性变成inline-block，不能改变其块级元素的性质，只是能有块级元素的特性，不独占一行，宽度不会占满父元素，和行内元素排列成一行 行内元素使用float属性后，也是将其属性变成inline-block，可以设置宽高，padding，margin属性 模糊https://developer.mozilla.org/zh-CN/docs/Web/CSS/backdrop-filter 1backdrop-filter: saturate(180%) blur(20px); zoom属性的作用这里介绍一下CSS中的Zoom属性，这个属性一般不为人知，甚至有些CSS手册中都查询不到。但经常会在一些css样式中看到它出现。 Zoom属性是IE浏览器的专有属性，Firefox等浏览器不支持。它可以设置或检索对象的缩放比例。除此之外，它还有其他一些小作用，比如触发ie的hasLayout属性，清除浮动、清除margin的重叠等。 zoom版本：IE5.5+专有属性 继承性：无 语法： zoom : normal | number 参数： normal : 使用对象的实际尺寸number : 百分数|无符号浮点实数。浮点实数值为1.0或百分数为100%时相当于此属性的normal值 说明： CSS中zoom:1的作用兼容IE6、IE7、IE8浏览器，经常会遇到一些问题，可以使用zoom:1来解决，有如下作用：触发IE浏览器的haslayout解决ie下的浮动，margin重叠等一些问题。比如，使用DIV做一行两列显示， HTML代码： 1234567&lt;div class=&quot;h_mainbox&quot;&gt; &lt;h2&gt;推荐文章&lt;/h2&gt; &lt;ul class=&quot;mainlist&quot;&gt; &lt;li&gt;&lt;a href=&quot;#&quot; style=&quot;color:#0000FF&quot; target=&quot;_blank&quot;&gt;测试一&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#&quot; style=&quot;color:#0000FF&quot; target=&quot;_blank&quot;&gt;测试二&lt; /a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; CSS代码： 123456789101112131415161718192021222324252627282930313233 .h_mainbox { border:1px solid #dadada; padding:4px 15px; background:url(../mainbox_bg.gif) 0 1px repeat-x; margin-bottom:6px; overflow:hidden}.h_mainbox h2 { font-size:12px; height:30px; line-height:30px; border-bottom:1px solid #ccc; color:#555;} .h_mainbox h2 span { float:right; font-weight:normal;} .h_mainbox ul { padding:6px 0px; background:#fff; } .mainlist { overflow:auto; zoom:1;} .h_mainbox li { width:268px; float:left; height:24px; overflow:hidden; background:url(../icon3.gif) 0 6px no-repeat; padding:0px 5px 0px 18px; line-height:200%;} .mainlist样式名字那里就可以在IE6、IE7、IE8正常显示效果了。 css中的zoom的作用 1、检查页面的标签是否闭合不要小看这条，也许折腾了你两天都没有解决的 CSS BUG 问题，却仅仅源于这里。毕竟页面的模板一般都是由开发来嵌套的，而他们很容易犯此类问题。快捷提示：可以用 Dreamweaver 打开文件检查，一般没有闭合的标签，会黄色背景高亮。 2、样式排除法有些复杂的页面也许加载了 N 个外链 CSS 文件，那么逐个删除 CSS 文件，找到 BUG 触发的具体 CSS 文件，缩小锁定的范围。对于刚才锁定的问题 CSS 样式文件，逐行删除具体的样式定义，定位到具体的触发样式定义，甚至是具体的触发样式属性。 3、模块确认法有时候我们也可以从页面的 HTML 元素出发。删除页面中不同的 HTML 模块，寻找到触发问题的 HTML 模块。 4、检查是否清除浮动其实有不少的 CSS BUG 问题是因为没有清除浮动造成的。养成良好的清除浮动的习惯是必要的，推荐使用 无额外 HTML 标签的清除浮动的方法（尽量避免使用 overflow:hidden;zoom:1 的类似方法来清除浮动，会有太多的限制性）。 5、检查 IE 下是否触发 haslayout很多的 IE 下复杂 CSS BUG 都与 IE 特有的 haslayout 息息相关。熟悉和理解 haslayout 对于处理复杂的 CSS BUG 会事半功倍。推荐阅读 old9 翻译的 《On having layout》（如果无法翻越穿越伟大的 GFW，可阅读 蓝色上的转帖 ）快捷提示：如果触发了 haslayout，IE 的调试工具 IE Developer Toolbar 中的属性中将会显示 haslayout 值为 -1。 6、边框背景调试法故名思议就是给元素设置显眼的边框或者背景（一般黑色或红色），进行调试。此方法是最常用的调试 CSS BUG 的方法之一，对于复杂 BUG 依旧适用。经济实惠还环保^^。最后想强调一点的是，养成良好的书写习惯，减少额外标签，尽量语义，符合标准，其实可以为我们减少很多额外的复杂 CSS BUG，更多的时候其实是我们自己给自己制造了麻烦。希望你远离 BUG ，生活越来越美好。 https://www.cnblogs.com/besthcp/p/4062950.html","link":"/2020/08/13/css%E7%AC%94%E8%AE%B0/"},{"title":"datatables 使用","text":"来源：https://www.cnblogs.com/showcase/p/11130463.html 一、简介 官网：https://datatables.net/中文官网：http://datatables.club/ Datatables是一款jquery表格插件。它是一个高度灵活的工具，可以将任何HTML表格添加高级的交互功能。 分页，即时搜索和排序 几乎支持任何数据源：DOM， javascript， Ajax 和 服务器处理 支持不同主题 DataTables, jQuery UI, Bootstrap, Foundation 各式各样的扩展: Editor, TableTools, FixedColumns …… 丰富多样的option和强大的API 支持国际化 超过2900+个单元测试 免费开源 二、使用1、引入相关js和css文件123456&lt;!-- DataTables CSS --&gt;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;http://cdn.datatables.net/1.10.15/css/jquery.dataTables.css&quot;&gt;&lt;!-- jQuery --&gt;&lt;script type=&quot;text/javascript&quot; charset=&quot;utf8&quot; src=&quot;http://code.jquery.com/jquery-1.10.2.min.js&quot;&gt;&lt;/script&gt;&lt;!-- DataTables --&gt;&lt;script type=&quot;text/javascript&quot; charset=&quot;utf8&quot; src=&quot;http://cdn.datatables.net/1.10.15/js/jquery.dataTables.js&quot;&gt;&lt;/script&gt; 2、添加HTML代码123456789101112131415161718&lt;table id=&quot;table_id_example&quot; class=&quot;display&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Column 1&lt;/th&gt; &lt;th&gt;Column 2&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Row 1 Data 1&lt;/td&gt; &lt;td&gt;Row 1 Data 2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Row 2 Data 1&lt;/td&gt; &lt;td&gt;Row 2 Data 2&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; 3、初始化Datatables123$(document).ready( function () { $('#table_id_example').DataTable();} ); 4、效果三、常用选项order 应用于表的初始顺序（排序） 123# 参数1 列索引按顺序排列 从0开始 # 参数2 排序的规则&quot;order&quot;: [[ 1, &quot;asc/desc&quot; ],...] stateSave 状态保存 - 页面重新加载时恢复表状态启用或禁用状态保存。启用后，DataTables将存储状态信息，例如分页位置，显示长度，过滤和排序。当最终用户重新加载页面时，表的状态将被更改以匹配他们之前设置的状态。 12# 默认值 falsestateSave: true/false columnDefs 设置列定义初始化属性此参数允许您为表中的列指定特定选项，但在这种情况下，定义的列选项可应用于一个或多个列 1234columnDefs:[ # 索引0列和第8列，不进行排序 {targets:[0,8],orderable:false}] lengthMenu 定义在每页显示记录数的select中显示的选项 1234567$('#example').DataTable({ &quot;lengthMenu&quot;: [ 10, 25, 50, 75, 100 ]});# 或$('#example').DataTable({ &quot;lengthMenu&quot;: [ [10, 25, 50, -1], [10, 25, 50, &quot;所有&quot;] ]}); paging 是否允许表格分页 true/false 默认：true info 控制是否显示表格的信息 true/false 默认：true searching 是否允许Datatables开启本地搜索 true/false 默认：true ordering 是否允许Datatables开启排序 true/false 默认：true processing 是否显示正在处理的状态 true/false 默认：false 四、Ajax使用远程数据 有时从DOM读取数据太慢或太笨重，特别是在处理数千或数百万个数据行时。为了解决这个问题，DataTables的服务器端处理功能提供了一种方法，可以让服务器端的数据库引擎完成所有“繁重的工作” 。 当使用服务器端处理时，DataTables将在页面上每次绘制信息时向服务器发出Ajax请求（即，在分页，排序，搜索等时）。DataTables将向服务器发送许多变量，以允许它执行所需的处理，然后以DataTables所需的格式返回数据。 1、客户端12345678910111213141516171819202122232425262728293031323334353637383940$('#example').DataTable( { // 开启服务器模式 serverSide: true, // ajax发起请求 ajax: { // 请求地址 url: '/data-source', // 请求方式 get/post type: 'POST', // 头信信息 laravel post请求时 csrf headers: { 'X-CSRF-TOKEN' : '{{ csrf_token() }}' }, // 请求的参数 data: { &quot;user_id&quot;: 451 }, /* // 两者写法效果一致 但是它用于搜索 data: function ( d ) { d.user_id = $('#user_id').val(); } */ }, // columns要对tr中的td单元格中的内容进行数据填充 // 注意：如果data接收类似a或b的信息，实际服务器没有返回该信息，那么一定要同时设置defaultContent属性，否则报错 columns: [ // 总的数量与表格的列的数量一致，不多也不少 // 字段名称与sql查询出来的字段时要保持一致，就是服务器返回数据对应的字段名称 // defaultContent 和 className 可选参数 {'data':'字段名称1',&quot;defaultContent&quot;: &quot;默认值&quot;,'className':'类名'}, {'data':'字段名称n',&quot;defaultContent&quot;: &quot;默认值&quot;,'className':'类名'} ], /* 创建tr/td时的回调函数，可以继续修改、优化tr/td的显示，里边有遍历效果，会依次扫描生成的每个tr row:创建好的tr的dom对象 data:数据源，代表服务器端返回的每条记录的实体信息 dataIndex:数据源的索引号码 */ createdRow:function(row,data,dataIndex){} } ); 2、服务端1234567891011121314/*draw: 客户端调用服务器端次数标识recordsTotal: 获取数据记录总条数recordsFiltered: 数据过滤后的总数量data: 获得的具体数据注意：recordsTotal和recordsFiltered都设置为记录的总条数*/$result = [ 'draw' =&gt; $request-&gt;get('draw'), 'recordsTotal' =&gt; $count, 'recordsFiltered' =&gt; $count, 'data' =&gt; $data];return json_encode($result); 3、搜索 datatable对象.api().ajax.reload() 重新加载数据 1234567var table = $('#example').DataTable( { ajax: &quot;data.json&quot;} ); $('#search').on('click',function(){ table.ajax.reload();});","link":"/2020/10/06/datatables%20%E4%BD%BF%E7%94%A8/"},{"title":"dubbo支持哪些通信协议和序列化协议","text":"dubbo支持的通信协议dubbo协议 dubbo://192.168.0.1:20188 默认就是走dubbo协议的，单一长连接，NIO异步通信，基于hessian作为序列化协议 适用的场景就是：传输数据量很小（每次请求在100kb以内），但是并发量很高 为了要支持高并发场景，一般是服务提供者就几台机器，但是服务消费者有上百台，可能每天调用量达到上亿次！此时用长连接是最合适的，就是跟每个服务消费者维持一个长连接就可以，可能总共就100个连接。然后后面直接基于长连接NIO异步通信，可以支撑高并发请求。 否则如果上亿次请求每次都是短连接的话，服务提供者会扛不住。 而且因为走的是单一长连接，所以传输数据量太大的话，会导致并发能力降低。所以一般建议是传输数据量很小，支撑高并发访问。 rmi协议 走java二进制序列化，多个短连接，适合消费者和提供者数量差不多，适用于文件的传输，一般较少用 hessian协议 走hessian序列化协议，多个短连接，适用于提供者数量比消费者数量还多，适用于文件的传输，一般较少用 http协议 走json序列化 webservice 走SOAP文本序列化 dubbo支持的序列化协议 dubbo实际基于不同的通信协议，支持hessian、java二进制序列化、json、SOAP文本序列化多种序列化协议。 但是hessian是其默认的序列化协议。 转自：中华石杉Java工程师面试突击","link":"/2021/04/07/dubbo%E6%94%AF%E6%8C%81%E5%93%AA%E4%BA%9B%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E5%92%8C%E5%BA%8F%E5%88%97%E5%8C%96%E5%8D%8F%E8%AE%AE/"},{"title":"git commit 使用及规范","text":"git commit 使用说明1 概述git提交推荐使用命令行工具，请严格遵循提交格式。 2 提交格式在您git add后，推荐执行git commit进行提交，如无特殊描述信息要添加，也可以git commit -m &lt;mess&gt;进行提交。 要求提交格式如下： 12345&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;&lt;BLANK LINE&gt;&lt;body&gt;&lt;BLANK LINE&gt;&lt;footer&gt; type表示提交类别，scope表示修改范围，subject表示标题行， body表示主体描述内容。 2.1 type说明type在commit的是否必须存在。 feat: 添加新特性 fix: 修复bug docs: 仅仅修改了文档 style: 仅仅修改了空格、格式缩进、逗号等等，不改变代码逻辑 refactor: 代码重构，没有加新功能或者修复bug perf: 优化相关，比如提升性能、体验 test: 增加测试用例 chore: 改变构建流程、或者增加依赖库、工具等 revert: 回滚到上一个版本 2.2 scope说明非必填（建议填写），scope用于说明 commit 影响的范围，建议填写影响的功能模块。 如果你的修改影响了不止一个scope，你可以使用*代替。 2.3 subject说明必填， commit 目的的简短描述，不超过50个字符。 以动词开头，使用第一人称现在时，比如change，而不是changed或changes 第一个字母小写 结尾不加句号 2.4 body说明非必填（建议填写），可描述当前修改的行为详细信息或修改的目的。 2.5 footer说明非必填，一般用于描述BREAKING CHANGE，在项目开发中一般不需要填写，组件研发的工程需要填写。 格式：以BREAKING CHANGE开头，后面是对变动的描述、以及变动理由和迁移方法。 3 提交方式如上2所示格式，本质上是改变文件 .git/COMMIT_EDITMSG 中的文本，实际提交过程如下（推荐命令行提交）： 3.2 cmd（notepad）window系统下默认git编辑工具是vim，如无相关基础，建议使用window默认的文本编辑器（这里不赘述vim相关编辑方法）。 修改git默认文本编辑器： git config core.editor notepad 修改后执行git commit,会弹出文本编辑器。 我们要按照规定的格式在注释前加入要提交的commit信息： 12345feat(人员新增): 增加人员批量导入- 增加批量报盘功能- 增加人员报盘后结果查询功能- 修改人员新增布局 然后保存并关闭，会提示如下信息： [master 756c07e] feat(人员新增): 增加人员批量导入 1 file changed, 2 insertions(+) 在push完成后，gitlab的commit列表中会有如下信息： commit.png 3.2 shell（GNU nano）提交方式在您执行git commit后，命令行会有如下显示： 1projectRoot/.git/COMMIT_EDITMSG # 请为您的变更输入提交说明。以 ‘#’ 开始的行将被忽略，而一个空的提交 # 说明将会终止提交。 # # 位于分支 master # 您的分支与上游分支 ‘origin/master’ 一致。 # # 要提交的变更： # 修改： CHANGELOG.md # # 未跟踪的文件: # .idea/ # 1[ 已读取 13 行 ] ^G 求助 ^O 写入 ^W 搜索 ^K 剪切文字 ^J 对齐 ^C 游标位置 ^X 离开 ^R 读档 ^\\ 替换 ^U 还原剪切 ^T 拼写检查 ^_ 跳行 如上所示，我们要按照规定的格式在注释前加入要提交的commit信息： 12345feat(人员新增): 增加人员批量导入- 增加批量报盘功能- 增加人员报盘后结果查询功能- 修改人员新增布局 输入完成后，根据快捷键提示，按ctrl + O，然后出现要修改的MSG文件名，按回车键。此时提示如下： [ 已写入 19 行 ] 最后按ctrl + X提交完成，提示如下： [master 756c07e] feat(人员新增): 增加人员批量导入 1 file changed, 2 insertions(+) 在push完成后，gitlab的commit列表中会有如下信息： 原文地址 ： https://www.jianshu.com/p/ff4f98695c2c","link":"/2022/04/26/git%20commit%20%E4%BD%BF%E7%94%A8%E5%8F%8A%E8%A7%84%E8%8C%83/"},{"title":"echo -e 命令详解","text":"echo在php中是输入那么在linux中是不是也是输入呢，当然echo在linux也是输入不过它的用法比php强大多了可以带参数及一些东西，下面我们来看一篇关于linux echo命令介绍及-n、-e参数详解吧，具体如下所示。 echo命令用于在shell中打印shell变量的值，或者直接输出指定的字符串。linux的echo命令，在shell编程中极为常用, 在终端下打印变量value的时候也是常常用到的，因此有必要了解下echo的用法echo命令的功能是在显示器上显示一段文字，一般起到一个提示的作用。 语法 echo(选项)(参数)选项 -e：激活转义字符。使用-e选项时，若字符串中出现以下字符，则特别加以处理，而不会将它当成一般文字输出： •\\a 发出警告声；•\\b 删除前一个字符；•\\c 最后不加上换行符号；•\\f 换行但光标仍旧停留在原来的位置；•\\n 换行且光标移至行首；•\\r 光标移至行首，但不换行；•\\t 插入tab；•\\v 与\\f相同；•\\ 插入\\字符；•\\nnn 插入nnn（八进制）所代表的ASCII字符；参数 变量：指定要打印的变量。 实例 用echo命令打印带有色彩的文字： 文字色： echo -e “\\e[1;31mThis is red text\\e[0m”This is red text•\\e[1;31m 将颜色设置为红色•\\e[0m 将颜色重新置回颜色码：重置=0，黑色=30，红色=31，绿色=32，黄色=33，蓝色=34，洋红=35，青色=36，白色=37 背景色： echo -e “\\e[1;42mGreed Background\\e[0m”Greed Background颜色码：重置=0，黑色=40，红色=41，绿色=42，黄色=43，蓝色=44，洋红=45，青色=46，白色=47 文字闪动： echo -e “\\033[37;31;5mMySQL Server Stop…\\033[39;49;0m”红色数字处还有其他数字参数：0 关闭所有属性、1 设置高亮度（加粗）、4 下划线、5 闪烁、7 反显、8 消隐 echo -n 不换行输出$echo -n “123”$echo “456” 最终输出123456 而不是123456echo -e 处理特殊字符 若字符串中出现以下字符，则特别加以处理，而不会将它当成一般文字输出： \\a 发出警告声；\\b 删除前一个字符；\\c 最后不加上换行符号；\\f 换行但光标仍旧停留在原来的位置；\\n 换行且光标移至行首；\\r 光标移至行首，但不换行；\\t 插入tab；\\v 与\\f相同；\\ 插入\\字符；\\nnn 插入nnn（八进制）所代表的ASCII字符； 下面举例说明一下： $echo -e “a\\bdddd” //前面的a会被擦除dddd $echo -e “a\\adddd” //输出同时会发出报警声音adddd $echo -e “a\\ndddd” //自动换行adddd 我们在使用linux的过程中，经常会去下载安装包，下载时候的那个进度提示是不是比较好玩，下载进度的百分比在不断变化，利用echo -e和-n参数我们也可以实现这个效果了。 echo -e “\\033[背景颜色;字体颜色m字符串\\033[0m格式: echo -e “\\033[字背景颜色;字体颜色m字符串\\033[0m” 例如:echo -e “\\033[41;36m something here \\033[0m” 其中41的位置代表底色, 36的位置是代表字的颜色 那些ascii code 是对颜色调用的始末.\\033[ ; m …… \\033[0m 字背景颜色范围:40—-4940:黑41:深红42:绿43:黄色44:蓝色45:紫色46:深绿47:白色 字颜色:30———–3930:黑31:红32:绿33:黄34:蓝色35:紫色36:深绿37:白色 ===============================================ANSI控制码的说明\\33[0m 关闭所有属性\\33[1m 设置高亮度\\33[4m 下划线\\33[5m 闪烁\\33[7m 反显\\33[8m 消隐\\33[30m – \\33[37m 设置前景色\\33[40m – \\33[47m 设置背景色\\33[nA 光标上移n行\\33[nB 光标下移n行\\33[nC 光标右移n行\\33[nD 光标左移n行\\33[y;xH设置光标位置\\33[2J 清屏\\33[K 清除从光标到行尾的内容\\33[s 保存光标位置\\33[u 恢复光标位置\\33[?25l 隐藏光标\\33[?25h 显示光标","link":"/2021/04/18/echo%20-e%20%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"},{"title":"git 使用笔记","text":"记录了一些常用git命令 命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748git initgit config -e # 编辑配置文件git config user.name 'username'git config user.email 'email'git clone [-b] branch xxx.git 拉取git status git log [-p]/[-n] ---n代表数字git log --stat ---简单信息git log --name-status ---可以显示新增、修改、删除的文件清单git commit [-m '']git push 远程 本地git pull 远程 本地git pull origin 1.x:dev 将远程origin的1.x分支拉取到本地dev分支git push origin dev:1.x 将本地dev分支推送到远程1.x分支git fetch origin test:example fetch远程test到本地example(原本不存在)git tag test_tag c809ddbf83939a89659e51dc2a5fe183af384233 //在某个commit 上打taggit tag [tag] 新建或者list taggit tag -d &lt;tag&gt; 删除本地taggit push origin :refs/tags/test_tag //本地tag删除了，再执行该句，删除线上taggit push origin :&lt;tag&gt;/&lt;branch&gt; 删除远程tag/分支git remote add origin https://git.comgit remote set-url origin https://&lt;token&gt;@github.com/&lt;username&gt;/&lt;repo&gt;.gitgit remote set-url --add origin https://&lt;token&gt;@github.com/&lt;username&gt;/&lt;repo&gt;.git # 添加多个git remote get-url origingit remote -v # 列出所有git remote rename 原名 新名git remote remove 名字git add xx命令可以将xx文件添加到暂存区，如果有很多改动可以通过 git add -A .来一次添加所有改变的文件。注意 -A 选项后面还有一个句点。 git add -A表示添加所有内容， git add . 表示添加新文件和编辑过的文件不包括删除的文件; git add -u 表示添加编辑或者删除的文件，不包括新添加的文件git commit -m &quot;提交注释&quot;git branch 查看本地所有分支git branch -r查看远程所有分支 一般当前本地分支前带有“*”号且为绿色，远程分支为红色git branch -agit branch -vvgit branch [-f] &lt;branchname&gt; 新建分支但是不切换git branch -d[-D] &lt;branchname&gt;删除本地分支[强制(相当于 --delete --force)]git branch -d -r &lt;branchname&gt;删除远程分支，其中&lt;branchname&gt;为本地分支名git branch (-m | -M) &lt;oldbranch&gt; &lt;newbranch&gt; //修改branch名称git checkout -b &lt;branchname&gt; 新建并切换至新分支git push origin 分支名称，一般使用：git push origin mastergit branch --set-upstream 本地关联远程分支git push --set-upstream origin mastergit remote rmgit config --global core.autocrlf false 禁用Git默认配置替换回车换行成统一的CRLFgit diff 分支1 分支2 --stat （加上 --stat 是显示文件列表, 否则是文件内容diff）git cherry-pick &lt;commitHash&gt; 将commitHash的提交应用于当前分支 git cherry-pick &lt;branch&gt; 会转移该分支的最新一次提交git cherry-pick &lt;hash1&gt; &lt;hash2&gt; 转移这两次提交git cherry-pick &lt;hash1&gt;..&lt;hash10&gt; 转移hash1到hash10的提交（hash1必须比hash10早，默认不包含1, 如果要包含，需要&lt;hash1^&gt;, 例如：git cherry-pick A^..B ） 更多cherry-pick用法可以参考：https://ruanyifeng.com/blog/2020/04/git-cherry-pick.html 或者官方文档 1git cherry-pick --help 选项1234567-d --delete：删除-D --delete --force的快捷键-f --force：强制-m --move：移动或重命名-M --move --force的快捷键-r --remote：远程-a --all：所有 常见问题最近使用git pull的时候多次碰见下面的情况： There is no tracking information for the current branch.Please specify which branch you want to merge with.See git-pull(1) for details. git pull If you wish to set tracking information for this branch you can do so with: git branch –set-upstream-to=origin/ release 其实，输出的提示信息说的还是比较明白的。使用git在本地新建一个分支后，需要做远程分支关联。如果没有关联，git会在下面的操作中提示你显示的添加关联。关联目的是在执行git pull, git push操作时就不需要指定对应的远程分支，你只要没有显示指定，git pull的时候，就会提示你。解决方法就是按照提示添加一下呗：git branch –set-upstream-to=origin/remote_branch your_branch其中，origin/remote_branch是你本地分支对应的远程分支；your_branch是你当前的本地分支。 恢复到之前的文件对于恢复修改的文件，就是将文件从仓库中拉到本地工作区，即 仓库区 —-&gt; 暂存区 —-&gt; 工作区。 对于修改的文件有两种情况： 只是修改了文件，没有任何 git 操作 修改了文件，并提交到暂存区（即编辑之后，gitadd但没有gitadd但没有 git commit -m ….） 修改了文件，并提交到仓库区（即编辑之后，gitadd和gitadd和 git commit -m ….） 情况I：只是修改了文件，没有任何 git 操作，直接一个命令就可回退： 1$ git checkout -- aaa.txt # aaa.txt为文件名 情况II：修改了文件，并提交到暂存区（即编辑之后，gitadd但没有 git commit -m ….） 123$ git log --oneline # 可以省略$ git reset HEAD # 回退到当前版本$ git checkout -- aaa.txt # aaa.txt为文件名 情况III：修改了文件，并提交到仓库区（即编辑之后，gitadd和gitadd和 git commit -m ….） 123$ git log --oneline # 可以省略$ git reset HEAD^ # 回退到上一个版本$ git checkout -- aaa.txt # aaa.txt为文件名 情况II 和 情况III 只有回退的版本不一样， 对于 情况II，并没有 $ git commit，仓库版本也就不会更新和记录，所以回退的是当前版本 对于情况III，一旦 $ git commit，仓库版本就会更新并记录，所以要回退的也就是上一个版本 git reset 版本号 —- 将暂缓区回退到指定版本 根据 $ git log –oneline 显示的版本号（下图黄色的字），可以回退到任何一个版本，也可通过 HEAD 来指定版本（下图红色的字）。 合并一、开发分支（dev）上的代码达到上线的标准后，要合并到 master 分支 12345git checkout devgit pullgit checkout mastergit merge devgit push -u origin master 二、当master代码改动了，需要更新开发分支（dev）上的代码 12345git checkout master git pull git checkout devgit merge master git push -u origin dev 删除已经add的文件git rm --cached &lt;文件路径&gt;，不删除物理文件，仅将该文件从缓存中删除； git rm --f &lt;文件路径&gt;，不仅将该文件从缓存中删除，还会将物理文件删除（不会回收到垃圾桶）。 git reset HEAD 用版本库内容清空暂存区，（谨慎使用） 常见错误You can only push commits that were committed with one of your own verified emails.报错1234remote: GitLab: You cannot push commits for 'mailto:xxxx.sss@trip.com'. You can only push commits that were committed with one of your own verified emails.To git.dev.sh.1kmb.com:amd.yes/hello-world.git ! [remote rejected] master -&gt; master (pre-receive hook declined)error: failed to push some refs to 'git@git.dev.sh.1kmb.com:amd.yes/hello-world.git' 原因1commit的时候邮箱不一致 解决1234$ git log$ git reset --hard 9e76350248a46a16b68fef25d27e25fcd4d65312 # 回滚到没错$ git config --global user.email &quot;你的邮箱地址&quot;改下邮箱，重新conmmit Github使用token1git remote set-url origin https://&lt;token&gt;@github.com/&lt;username&gt;/&lt;repo&gt;.git 恢复版本git 如何恢复到指定版本查看git的提交版本和id 拿到需要恢复的版本号 命令：git log 2. 恢复到指定版本 命令：git reset –hard 44f994dd8fc1e10c9ed557824cae50d1586d0cb3 //后面这一大串44f994dd8fc1e10c9ed557824cae50d1586d0cb3就是版本id 3. 强制push 命令：git push -f origin master 【Git】pull遇到错误：error: Your local changes to the following files would be overwritten by merge:首先取决于你是否想要保存本地修改。（是 /否） 是别急我们有如下三部曲 git stash git pull origin master git stash pop git stash的时候会把你本地快照，然后git pull 就不会阻止你了，pull完之后这时你的代码并没有保留你的修改。惊了！ 别急，我们之前好像做了什么？ STASH这时候执行git stash pop你去本地看会发现发生冲突的本地修改还在，这时候你该commit push啥的就悉听尊便了。 否既然不想保留本地的修改，那好办。直接将本地的状态恢复到上一个commit id 。然后用远程的代码直接覆盖本地就好了。 12git reset --hard git pull origin master","link":"/2020/12/15/git%20%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"},{"title":"htop使用详解","text":"一．Htop的使用简介 大家可能对top监控软件比较熟悉，今天我为大家介绍另外一个监控软件Htop，姑且称之为top的增强版，相比top其有着很多自身的优势。如下： 两者相比起来，top比较繁琐 默认支持图形界面的鼠标操作 可以横向或纵向滚动浏览进程列表，以便看到所有的进程和完整的命令行 杀进程时不需要输入进程号等 二．软件的获取与安装 Htop的安装，既可以通过源码包编译安装，也可以配置好yum源后网络下载安装 2.1源码安装 在htop的项目官方网站上：http://sourceforge.net/projects/htop/直接下载即可 由于我已经安装过了，因此大家看个以上每个编译过程后面都会^c，是不执行此行操作Ctrl+c取消的，此处只是告知如何编译安装的，各人的环境不同，可能编译过程中会出现错误，根据错误，解决后即可。 2.2 yum和rpm包安装 个人推荐yum安装，能够自动的解决软件包依赖关系，安装即可。 三．Htop的使用 安装完成后，命令行中直接敲击htop命令，即可进入htop的界面 各项从上至下分别说明如下： 左边部分从上至下，分别为，cpu、内存、交换分区的使用情况，右边部分为：Tasks为进程总数，当前运行的进程数、Load average为系统1分钟，5分钟，10分钟的平均负载情况、Uptime为系统运行的时间。 以上各项分别为： PID：进行的标识号 USER：运行此进程的用户 PRI：进程的优先级 NI：进程的优先级别值，默认的为0，可以进行调整 VIRT：进程占用的虚拟内存值 RES：进程占用的物理内存值 SHR：进程占用的共享内存值 S：进程的运行状况，R表示正在运行、S表示休眠，等待唤醒、Z表示僵死状态 %CPU：该进程占用的CPU使用率 %MEM：该进程占用的物理内存和总内存的百分比 TIME+：该进程启动后占用的总的CPU时间 COMMAND：进程启动的启动命令名称 F1：显示帮助信息 h, ? F1 查看htop使用说明 S F2 htop 设定 / F3 搜索进程 \\ F4 增量进程过滤器 t F5 显示树形结构 &lt;, &gt; F6 选择排序方式 [ F7 可减少nice值可以提高对应进程的优先级 ] F8 可增加nice值，降低对应进程的优先级 k F9 可对进程传递信号 q F10 结束htop u 只显示一个给定的用户的过程 U 取消标记所有的进程 H 显示或隐藏用户线程 K 显示或隐藏内核线程 F 跟踪进程 P 按CPU 使用排序 M 按内存使用排序 T 按Time+ 使用排序 l 显示进程打开的文件 I 倒转排序顺序 s 选择某进程，按s:用strace追踪进程的系统调用 F2 Htop设定 鼠标点击Setup或者按下F2 之后进入htop 设定的页面， Setup 选项下的： 1.Meters 设定顶端的 显示信息，分为左右两侧，Left column 表示左侧的显示的信息，Right column表示右侧显示的信息，如果要新加选项，可以选择Available meters添加，F5新增到上方左侧，F6新增到上方右侧。Left column和Right column下面的选项，可以选定信息的显示方式，有LED、Bar(进度条)、Text(文本模式)，可以根据个人喜好进行设置 2. Display options 选择要显示的内容，按空格 x表示显示，选择完后，按F10保存 3.Colors 设定界面以什么颜色来显示，个人认为用处不大，各人喜好不同，假如我们选择Black on White后显示效果如下 4.Colums 作用是增加或取消要显示的各项内容，选择后F7(向上移动)、F8(向下移动)、F9(取消显示、F10(保存更改))此处增加了PPID、PGRP，根据各人需求，显示那些信息。 F3 搜索进程 在界面下按F3或直接输入”/”就可以直接进入搜索模式，是按照进程名进行搜索的。例如 搜索到的进程会用设定的颜色标记出来，方便查看 F4：过滤器 相当于模糊查找，不区分大小写，下方输入要搜索的内容后，则界面只显示搜索到的内容，更加方便查看，例如： F5:以树形方式显示 F6：排序方式 按下F6后会跳转至上图界面，让您选择以什么方式进行排序,在Sort by下选择您要以什么来排序 F7,F8：调整进程nice值 F7表示减小nice值(增大优先级),F8增大nice值(减小优先级)，选择某一进程，按F7或F8来增大或减小nice值，nice值范围为-20-19，此处我把apache的nice值调整到了19 F9：杀死进程 选择某一进程按F9即可杀死此进程，很方便 F10:退出htop 四．结束 以上就是htop的基本用法，感谢您的观看，相信大家能够感觉到Htop比top的优势。如果有什么错误之处，麻烦留言告知，方便下次更改，谢谢。 参考文档https://blog.csdn.net/freeking101/article/details/79173903http://www.open-open.com/lib/view/open1417612210323.html","link":"/2022/03/12/htop%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3/"},{"title":"golang中如何获取变量的类型？","text":"在golang中并没有提供内置函数来获取变量的类型，但是通过一定的方式也可以获取，下面提供两种思路 通过格式化使用格式化字符%T(注意为大写的T)便可以获取到对应的类型 12345678910111213package mainimport ( &quot;fmt&quot;)func main(){ var v int = 64 fmt.Printf(&quot;v的值为: %v, v的类型为: %T\\n&quot;, v, v) // 如果想要保存类型到字符串中，可以使用 typ := fmt.Sprintf(&quot;%T&quot;, v)} 通过反射机制reflect包中提供了相应的手段 1234567891011package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)func main(){ var v int = 64 fmt.Println(reflect.TypeOf(v))}","link":"/2021/05/29/golang%E4%B8%AD%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E5%8F%98%E9%87%8F%E7%9A%84%E7%B1%BB%E5%9E%8B%EF%BC%9F/"},{"title":"jQuery 学习笔记","text":"去除表单空值123$(&quot;input&quot;, &quot;#submForm&quot;).each(function(){ $(this).val() == &quot;&quot; &amp;&amp; $(this).remove();}) 或者 1$(&quot;input:text[value=&quot;&quot;]&quot;, &quot;#submForm&quot;).remove(); 串行化1var serialized = $(&quot;#submForm&quot;).serialize() 获取表单所有值$(“form”).serialize() 过滤12345678$(document).ready(function () { $(&quot;#myForm&quot;).submit(function () { $(this).find(&quot;:input&quot;).filter(function () { return $.trim(this.value).length &gt; 0 }).serialize(); alert(&quot;JavaScript done&quot;); });}); $.trim() 函数用于去除字符串两端的空白字符 jQuery 监听元素内容变化的方法 我们可以用 onchange 事件来完成元素值发生改变触发的监听。但是 onchange 比较适用于&lt;input&gt;、&lt;textarea&gt;以及 &lt;select&gt; 元素,对于 div，span 等元素就不能使用了。 当 $(“span”).html() 获取的是个空，或者获取的不是自己想要的。原因是当我们获取的时候，元素的内容还没有发生改变，这个时候就需要监听这个 span 内容了。 下面举两个小例子 123$(&quot;#test-editormd-view2&quot;).bind(&quot;DOMNodeInserted&quot;, function (e) { console.log($(e.target).html());}); 123$(&quot;#test-editormd-view2&quot;).on(&quot;DOMNodeInserted&quot;, function () { $(&quot;#content-loading&quot;).remove();}); ajax 实现文件上传我在写 jQuery 接口上传文件的时候，遇到一个特头疼的问题，那就是上传图片，刚开始那我以为一个简单的 form 表单就搞定了，没想到写了两个小时都没写出来，心情那个烦躁啊，有一种想砸电脑的冲动，最后那我就用下面的方法实现了这个功能，突然发现好简单，分享给大家！废话不多说，直接上干货，代码走起。。。。 代码块html 代码段12&lt;input type=&quot;file&quot; name=&quot;photo&quot; id=&quot;photo&quot; value=&quot;&quot; placeholder=&quot;免冠照片&quot;&gt;&lt;input type=&quot;button&quot; onclick=&quot;postData();&quot; value=&quot;下一步&quot; name=&quot;&quot; style=&quot;width:100px;height:30px;&quot;&gt; jQuery 代码段123456789101112131415161718192021222324&lt;script type=&quot;text/javascript&quot;&gt;function postData(){ var formData = new FormData(); formData.append(&quot;photo&quot;,$(&quot;#photo&quot;)[0].files[0]); formData.append(&quot;service&quot;,'App.Passion.UploadFile'); formData.append(&quot;token&quot;,token); $.ajax({ url:'http://www.baidu.com/', /*接口域名地址*/ type:'post', data: formData, contentType: false, processData: false, success:function(res){ console.log(res.data); if(res.data[&quot;code&quot;]==&quot;succ&quot;){ alert('成功'); }else if(res.data[&quot;code&quot;]==&quot;err&quot;){ alert('失败'); }else{ console.log(res); } } })} 12345678910111213141516171819202122&lt;script&gt; $(function() {$(&quot;.but&quot;).click(function () { data = new FormData($(&quot;#form1&quot;)[0]); console.log(data); // $.post('up.php',{p:2},function(data){ // alert(data); // }) $.ajax({ url: &quot;up.php&quot;, type: &quot;POST&quot;, data: data, dataType: &quot;JSON&quot;, cache: false, processData: false, //不处理发送的数据，因为data值是FormData对象，不需要对数据做处理 contentType: false, //不设置Content-type请求头 }).done(function (ret) { console.log(ret); }); })} )&lt;/script&gt; jquery 判断点击事件是否在目标区域很多时候需要在鼠标点击非目标区域 div 将目标 div 隐藏的效果，这是需要判断点击事件是否在目标区域内 jquery 的实现方法是：(最近更新,未测) 123456789$(document).click(function(e){ e = window.event || e; // 兼容IE7 obj = $(e.srcElement || e.target); if ($(obj).is(&quot;#elem,#elem *&quot;)) { // alert('内部区域'); } else { alert('你的点击不在目标区域'); }}); 这样就可以进行其他效果的操作了,另外一种类似思路:jquery判断点击区域 隐藏/显示其他区域 原始写法:(不兼容ff) 1234567$(document).click(function(){ if ($(event.srcElement).is(&quot;#elem,#elem \\*&quot;)) { // alert('内部区域'); } else { alert('你的点击不在目标区域'); } }); jQuery选择器获取第一个子元素以及带空格的classjQuery选择器选取第一个子元素 123456$(&quot;p:first&quot;)````jQuery选择器选取HTML 中 class=&quot;hov_bg hov2&quot; class中带有空格的这类元素```javascript$(&quot;.hov_bg.hov2&quot;); 该选择器可以筛选出同时拥有class=”hov_bg hov2”样式的HTML元素 1$(&quot;.hov2&quot;); 该选择器可以筛选出class=”hov2”和class=”hov_bg hov2”的元素 例子: 123456789101112131415161718192021&lt;div class=&quot;container&quot;&gt;simple&lt;/div&gt;&lt;div class=&quot;layer container&quot;&gt;complex&lt;/div&gt;&lt;script type=&quot;text/javascript&quot;&gt;alert($(&quot;.container.layer&quot;).html());&lt;/script&gt;````class 中带空格不是指一个 class，而是指两种 class 中的任意一种。下面是详解：CSS 多类选择器在上一节中，我们处理了 class 值中包含一个词的情况。在 HTML 中，一个 class 值中可能包含一个词列表，各个词之间用空格分隔。例如，如果希望将一个特定的元素同时标记为重要（important）和警告（warning），就可以写作：&lt;p class=&quot;important warning&quot;&gt; This paragraph is a very important warning. &lt;/p&gt;这两个词的顺序无关紧要，写成 warning important 也可以。我们假设 class 为 important 的所有元素都是粗体，而 class 为 warning 的所有元素为斜体，class 中同时包含 important 和 warning 的所有元素还有一个银色的背景 。就可以写作：```CSS.important {[font-weight](https://www.baidu.com/s?wd=font-weight&amp;tn=SE_PcZhidaonwhc_ngpagmjz&amp;rsv_dl=gh_pc_zhidao):bold;}.warning {[font-weight](https://www.baidu.com/s?wd=font-weight&amp;tn=SE_PcZhidaonwhc_ngpagmjz&amp;rsv_dl=gh_pc_zhidao):italic;}.important.warning {background:silver;} 监听滚动事件1234567891011121314$(document).scroll(function () { var scroH = $(document).scrollTop(); //滚动高度 var viewH = $(window).height(); //可见高度 var contentH = $(document).height(); //内容高度 if (scroH &gt; 100) { //距离顶部大于100px时 } if (contentH - (scroH + viewH) &lt;= 100) { //距离底部高度小于100px } if ((contentH = scroH + viewH)) { //滚动条滑到底部啦 }}); jquery 获取所有选中的 checkbox获取所有 name 为 spCodeId 的 checkbox 123456789var spCodesTemp = &quot;&quot;;$(&quot;input:checkbox[name=spCodeId]:checked&quot;).each(function (i) { if (0 == i) { spCodesTemp = $(this).val(); } else { spCodesTemp += &quot;,&quot; + $(this).val(); }});$(&quot;#txt_spCodes&quot;).val(spCodesTemp); 以类型查找 1$(&quot;input[type='checkbox'][checked]&quot;) 以名称查找 1$(&quot;input:checkbox[name='the checkbox name']:checked&quot;) //如果是在某一些标签下查找的话，为了防止查找到 table #tbTemplate 元素以外的 checkbox：checked，我们可以这样来限制： 1234567891011$(&quot;table#tbTemplate input:checkbox[name='the checkbox name']:checked&quot;)``` 原生态的用法```JavaScript$($(&quot;table#tbTemplate input[type='checkbox']&quot;),function(i,checkbox){ if(checkbox.checked){ // keep the state. or log this checked...... }}); 判断多选框是否有选中 123if (!$(&quot;input[type='checkbox']&quot;).is(':checked')) { $('#sitetable').hide(); } 123456789101112131415161718192021222324252627282930&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0&quot; /&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot; /&gt; &lt;title&gt;Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;input type=&quot;checkbox&quot; name=&quot;use&quot; data-id=&quot;1&quot; /&gt; &lt;input type=&quot;checkbox&quot; name=&quot;usr&quot; data-id=&quot;3&quot; /&gt; &lt;input type=&quot;checkbox&quot; name=&quot;use&quot; data-id=&quot;5&quot; /&gt; &lt;input type=&quot;checkbox&quot; name=&quot;ser&quot; data-id=&quot;7&quot; /&gt; &lt;input type=&quot;checkbox&quot; name=&quot;uer&quot; data-id=&quot;9&quot; /&gt; &lt;input type=&quot;button&quot; value=&quot;选择&quot; /&gt; &lt;script src=&quot;/static/admin/js/core/jquery.3.2.1.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; $(() =&gt; { $(&quot;input:button&quot;).click(() =&gt; { $(&quot;input:checkbox:checked&quot;).each((e, w) =&gt; { console.log($(w).attr(&quot;data-id&quot;)); }); }); }); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;","link":"/2020/11/19/jQuery%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"js学习笔记","text":"自定义函数in_array123456789function in_array(stringToSearch, arrayToSearch) { for (s = 0; s &lt; arrayToSearch.length; s++) { thisEntry = arrayToSearch[s].toString(); if (thisEntry == stringToSearch) { return true; } } return false;} ##判断文件后缀 1234567var location=$(&quot;input[name='file']&quot;).val(); var point = location.lastIndexOf(&quot;.&quot;); var type = location.substr(point); if(type==&quot;.jpg&quot;||type==&quot;.gif&quot;||type==&quot;.JPG&quot;||type==&quot;.GIF&quot;){ } 其他方法 jquery:validate /datatable document.forms[formName][inputName] datatable.api.ajax.reload() window.location.reload() $(‘.row’).find(‘td:eq(1)’).html() trim函数可以去掉空格 事件委托：$(‘父节点’).on(‘触发方法’,’子节点’,function(){}) 对应off去掉拥有的事件 evt.preventDefault() /return false; 取消默认事件 JQ对象.bind(‘事件[多个可以使用空格分割]’).triggle(‘select’) 触发选中事件 获取checkbox的选中项：$(‘input:checkbox[name=”box”]:checked’) var arr = $(‘’).split(‘\\n’) 将字符串使用\\n分割为数组12.stop方法，停止当前运行的动画13.is方法 跳转1&lt;meta http-equiv=&quot;refresh&quot; content=&quot;3&quot; ; url=&quot;index.html&quot;&gt; 12345678910111213141516window.location.href=&quot;index.html&quot;$('location').attr('href','index.html')document.referrer //获取referersetTimeout(&quot;javascrpt:location.href='index.html'&quot;,5000) //定时跳转window.location.search //可以获取地址栏的query_stringwindow.history.go(-1) / back(-1) //返回上一页&lt;a onclick=&quot;javascript:history.go(-1)&quot;&gt;window.navigate('http://www.1kmb.com') //使用navigate方式跳转window.open('http://www.1kmb.com') //打开新网页window.location.href=&quot;http://www.1kmb.com/index.php?ref=&quot;+window.location.hreflocation.reload([bForceGet]) //bForceGet可选，默认FALSE，用HTTP头If-Modified-Since来检测服务器上的文档是否已经改变，如果改变会重新下载文档，否则从客户端缓存里取当前页,TRUE则以get方式从服务器获取最新页面，相当于F5刷新location.replace(URL)location.assign(LOCATION)document.execCommand('Refresh')document.URL=location.href$(document).attr('location',document.referer) 事件dblclick() jquery双击事件 .bind() 123456789101112131415161718192021222324252627//绑定多个选择器$(document).on('click','#header a,#sidebar a',function(){})//绑定多个事件$('table tr').on({ mouseenter:function(){ }, mouseleave:function(){ }, click:function(){ }},'td')//同时绑定多个选择器和多个事件$(document).on({ mouseenter:function(){ }, mouseleave:function(){ }, click:function(){ },},'') 123456&lt;script&gt;$( document ) .ready ( function(){$( '.comments .active ' ).css( &quot;pointer-events &quot; , &quot; none&quot; )}）;&lt;/script&gt; layer.js #js-监听页面滚动 ##一、原生js通过window.onscroll监听 123456window.onscroll = function() { //为了保证兼容性，这里取两个值，哪个有值取哪一个 //scrollTop就是触发滚轮事件时滚轮的高度 var scrollTop = document.documentElement.scrollTop || document.body.scrollTop; console.log(&quot;滚动距离&quot; + scrollTop);} ##二、Jquery通过$(window).scroll()监听 123456$(window).scroll(function() { //为了保证兼容性，这里取两个值，哪个有值取哪一个 //scrollTop就是触发滚轮事件时滚轮的高度 var scrollTop = document.documentElement.scrollTop || document.body.scrollTop; console.log(&quot;滚动距离&quot; + scrollTop);}) ##Javascript获取一个盒子的宽和高； 12var width = document.getElementById(&quot;box2&quot;).offsetWidth;//宽度var height = document.getElementById(&quot;box2&quot;).offsetHeight;// ##jq判断元素是否存在于数组中 1$.inArray(element,array); 存在返回元素下标，否则返回-1，可以使用arr.splice($.inArray('test',arr),1); 删除某一个元素，删除前需要判断元素是否存在否则当数组中只有一个值的时候会删除该值【未测试】。 jq点击复制1234567891011121314151617&lt;script src=&quot;http://libs.baidu.com/jquery/1.9.0/jquery.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/clipboard.js/1.5.12/clipboard.min.js&quot;&gt;&lt;/script&gt; 微信号：&lt;span id=&quot;target&quot;&gt;xyz2018&lt;/span&gt;&lt;button class=&quot;btn&quot; data-clipboard-action=&quot;copy&quot; data-clipboard-target=&quot;#target&quot; id=&quot;copy_btn&quot;&gt; 点击复制 &lt;/button&gt; &lt;script&gt; $(document).ready(function(){ var clipboard = new Clipboard('#copy_btn'); clipboard.on('success', function(e) { alert(&quot;微信号复制成功&quot;,1500); e.clearSelection(); console.log(e.clearSelection); }); }); &lt;/script&gt; void 0 相关void其实是javascript中的一个函数，接受一个参数，返回值永远是undefined。可以说，使用void目的就是为了得到javascript中的undefined 为什么不直接使用undefined呢？ 使用void 0比使用undefined能够减少3个字节。虽然这是个优势，个人但感觉意义不大，牺牲了可读性和简单性，undefined并不是javascript中的保留字，我们可以使用undefined作为变量名字，然后给它赋值,, 但在chrome 中打印出来的是 undefined 1undefined === void 0 // true","link":"/2020/09/26/js%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"golang 终止协程","text":"1.手动终止调用 runtime.Goexit() 来手动终止协程 goroutine作为Golang并发的核心，我们不仅要关注它们的创建和管理，当然还要关注如何合理的退出这些协程，不（合理）退出不然可能会造成阻塞、panic、程序行为异常、数据结果不正确等问题。 2.1 使用for-range退出for-range是使用频率很高的结构，常用它来遍历数据，**range能够感知channel的关闭，当channel被发送数据的协程关闭时，range就会结束，接着退出for循环。它在并发中的使用场景是：当协程只从1个channel读取数据，然后进行处理，处理后协程退出。下面这个示例程序，当in通道被关闭时，协程可自动退出。** 1234567go func(in &lt;-chan int) { // Using for-range to exit goroutine // range has the ability to detect the close/end of a channel for x := range in { fmt.Printf(&quot;Process %d\\n&quot;, x) }}(inCh) 2.2使用,ok退出for-select也是使用频率很高的结构，select提供了多路复用的能力，所以for-select可以让函数具有持续多路处理多个channel的能力。但select没有感知channel的关闭，这引出了2个问题： 1）继续在关闭的通道上读，会读到通道传输数据类型的零值。 2）继续在关闭的通道上写，将会panic。问题2可使用的原则是，通道只由发送方关闭，接收方不可关闭，即某个写通道只由使用该select的协程关闭，select中就不存在继续在关闭的通道上写数据的问题。 第一种：如果某个通道关闭后，需要退出协程，直接return即可。示例代码中，该协程需要从in通道读数据，还需要定时打印已经处理的数量，有2件事要做，所有不能使用for-range，需要使用for-select，当in关闭时，ok=false，我们直接返回。 123456789101112131415go func() { // in for-select using ok to exit goroutine for { select { case x, ok := &lt;-in: if !ok { return } fmt.Printf(&quot;Process %d\\n&quot;, x) processedCnt++ case &lt;-t.C: fmt.Printf(&quot;Working, processedCnt = %d\\n&quot;, processedCnt) } }}() 第二种：如果某个通道关闭了，不再处理该通道，而是继续处理其他case，退出是等待所有的可读通道关闭。我们需要使用select的一个特征：select不会在nil的通道上进行等待。这种情况，把只读通道设置为nil即可解决。 123456789101112131415161718192021222324go func() { // in for-select using ok to exit goroutine for { select { case x, ok := &lt;-in1: if !ok { in1 = nil } // Process case y, ok := &lt;-in2: if !ok { in2 = nil } // Process case &lt;-t.C: fmt.Printf(&quot;Working, processedCnt = %d\\n&quot;, processedCnt) } // If both in channel are closed, goroutine exit if in1 == nil &amp;&amp; in2 == nil { return } }}() 2.3使用退出通道退出使用,ok来退出使用for-select协程，解决是当读入数据的通道关闭时，没数据读时程序的正常结束。想想下面这2种场景，,ok还能适用吗？ 接收的协程要退出了，如果它直接退出，不告知发送协程，发送协程将阻塞。 启动了一个工作协程处理数据，如何通知它退出？ 使用一个专门的通道，发送退出的信号，可以解决这类问题。以第2个场景为例，协程入参包含一个停止通道stopCh，当stopCh被关闭，case &lt;-stopCh会执行，直接返回即可。 当我启动了100个worker时，只要main()执行关闭stopCh，每一个worker都会都到信号，进而关闭。如果main()向stopCh发送100个数据，这种就低效了。 12345678910111213141516func worker(stopCh &lt;-chan struct{}) { go func() { defer fmt.Println(&quot;worker exit&quot;) // Using stop channel explicit exit for { select { case &lt;-stopCh: fmt.Println(&quot;Recv stop signal&quot;) return case &lt;-t.C: fmt.Println(&quot;Working .&quot;) } } }() return} 总结： 发送协程主动关闭通道，接收协程不关闭通道。技巧：把接收方的通道入参声明为只读(&lt;-chan)，如果接收协程关闭只读协程，编译时就会报错。 协程处理1个通道，并且是读时，协程优先使用for-range，因为range可以关闭通道的关闭自动退出协程。 ,ok可以处理多个读通道关闭，需要关闭当前使用for-select的协程。 显式关闭通道stopCh可以处理主动通知协程退出的场景。","link":"/2022/06/14/golang%20%E7%BB%88%E6%AD%A2%E5%8D%8F%E7%A8%8B/"},{"title":"js怎么存取cookie","text":"js存入cookie12345678function Setcookie (name, value){ //设置名称为name,值为value的Cookie var expdate = new Date(); //初始化时间 expdate.setTime(expdate.getTime() + 30 * 60 * 1000); //时间单位毫秒 document.cookie = name+&quot;=&quot;+value+&quot;;expires=&quot;+expdate.toGMTString()+&quot;;path=/&quot;;//即document.cookie= name+&quot;=&quot;+value+&quot;;path=/&quot;; 时间默认为当前会话可以不要，但路径要填写，因为JS的默认路径是当前页，如果不填，此cookie只在当前页面生效！} js取出cookie1234567891011121314function getCookie(c_name){//判断document.cookie对象里面是否存有cookieif (document.cookie.length&gt;0){ c_start=document.cookie.indexOf(c_name + &quot;=&quot;) //如果document.cookie对象里面有cookie则查找是否有指定的cookie，如果有则返回指定的cookie值，如果没有则返回空字符串 if (c_start!=-1){ c_start=c_start + c_name.length+1 c_end=document.cookie.indexOf(&quot;;&quot;,c_start) if (c_end==-1) c_end=document.cookie.length return unescape(document.cookie.substring(c_start,c_end)) } }return &quot;&quot;} jq存取cookie首先引入下面的文件 12/*! jquery.cookie v1.4.1 | MIT */!function(a){&quot;function&quot;==typeof define&amp;&amp;define.amd?define([&quot;jquery&quot;],a):&quot;object&quot;==typeof exports?a(require(&quot;jquery&quot;)):a(jQuery)}(function(a){function b(a){return h.raw?a:encodeURIComponent(a)}function c(a){return h.raw?a:decodeURIComponent(a)}function d(a){return b(h.json?JSON.stringify(a):String(a))}function e(a){0===a.indexOf('&quot;')&amp;&amp;(a=a.slice(1,-1).replace(/\\\\&quot;/g,'&quot;').replace(/\\\\\\\\/g,&quot;\\\\&quot;));try{return a=decodeURIComponent(a.replace(g,&quot; &quot;)),h.json?JSON.parse(a):a}catch(b){}}function f(b,c){var d=h.raw?b:e(b);return a.isFunction(c)?c(d):d}var g=/\\+/g,h=a.cookie=function(e,g,i){if(void 0!==g&amp;&amp;!a.isFunction(g)){if(i=a.extend({},h.defaults,i),&quot;number&quot;==typeof i.expires){var j=i.expires,k=i.expires=new Date;k.setTime(+k+864e5*j)}return document.cookie=[b(e),&quot;=&quot;,d(g),i.expires?&quot;; expires=&quot;+i.expires.toUTCString():&quot;&quot;,i.path?&quot;; path=&quot;+i.path:&quot;&quot;,i.domain?&quot;; domain=&quot;+i.domain:&quot;&quot;,i.secure?&quot;; secure&quot;:&quot;&quot;].join(&quot;&quot;)}for(var l=e?void 0:{},m=document.cookie?document.cookie.split(&quot;; &quot;):[],n=0,o=m.length;o&gt;n;n++){var p=m[n].split(&quot;=&quot;),q=c(p.shift()),r=p.join(&quot;=&quot;);if(e&amp;&amp;e===q){l=f(r,g);break}e||void 0===(r=f(r))||(l[q]=r)}return l};h.defaults={},a.removeCookie=function(b,c){return void 0===a.cookie(b)?!1:(a.cookie(b,&quot;&quot;,a.extend({},c,{expires:-1})),!a.cookie(b))}}); a)设置新的cookie:$.cookie(‘name’，’dumplings’); //设置一个值为’dumplings’的cookie设置cookie的生命周期 $.cookie(‘key’, ‘value’, { expires: 7 }); //设置为7天，默认值：浏览器关闭 设置cookie的域名：$.cookie(‘name’，’dumplings’, {domain:’qq.com’}); //设置一个值为’dumplings’的在域名’qq.com’的cookie设置cookie的路径： $.cookie(‘name’，’dumplings’, {domain:’qq.com’，path:’/‘});//设置一个值为’dumplings’的在域名’qq.com’的路径为’/‘的cookie b)删除cookie$.removeCookie(‘name’,{ path: ‘/‘}); //path为指定路径，直接删除该路径下的cookie$.cookie(‘name’,null,{ path: ‘/‘}); //将cookie名为&amp;lsquo;openid&amp;rsquo;的值设置为空，实际已删除 c)获取cookie$.cookie(‘name’) //dumplings 踩过的坑：cookie的域名和路径都很重要，如果没有设置成一致，则会有不同域名下或者不同路径下的同名cookie，为了避免这种情况，建议在设置cookie和删除cookie的时候，配置路径和域名。 https://www.cnblogs.com/hellofangfang/p/9626797.html","link":"/2020/08/12/js%E6%80%8E%E4%B9%88%E5%AD%98%E5%8F%96cookie/"},{"title":"js监听input输入框值的实时变化实例","text":"情景：监听input输入框值的实时变化实例 解决方法：1.在元素上同时绑定oninput和onporpertychanger事件 实例： &lt;script type=&quot;text/JavaScript&quot;&gt; function watch(){ consolo.log(&quot;in&quot;) } &lt;/script&gt; &lt;input type=&quot;text&quot; oninput=&quot;watch(event)&quot; onporpertychange=&quot;watch(event)&quot; /&gt; 2.原生js 123456789101112&lt;script type=&quot;text/javascript&quot;&gt; $(function(){ if(&quot;\\v&quot;==&quot;v&quot;){//true为IE浏览器，感兴趣的同学可以去搜下，据说是现有最流行的判断浏览器的方法 document.getElementById(&quot;a&quot;).attachEvent(&quot;onporpertychange&quot;,function(e){ console.log(&quot;inputting!!&quot;); } }else{ document.getElementById(&quot;a&quot;).addEventListener(&quot;onporpertychange&quot;,function(e){ console.log(&quot;inputting!!&quot;); } }});&lt;/script&gt;&lt;input type=&quot;text&quot; id=&quot;a&quot;/&gt; 3.使用jQuery绑定事件 12345678&lt;script type=&quot;text/javascript&quot;&gt; $(function(){ $(&quot;#a&quot;).bind('input porpertychange',function(){ console.log(&quot;e&quot;); }); });&lt;/script&gt;&lt;input type=&quot;text&quot; id=&quot;a&quot;/&gt;","link":"/2020/08/12/js%E7%9B%91%E5%90%ACinput%E8%BE%93%E5%85%A5%E6%A1%86%E5%80%BC%E7%9A%84%E5%AE%9E%E6%97%B6%E5%8F%98%E5%8C%96%E5%AE%9E%E4%BE%8B/"},{"title":"js获取当前位置的地理坐标（经纬度）","text":"1234567891011if(navigator.geolocation) { navigator.geolocation.getCurrentPosition( function (position) { console.log( position.coords.longitude ); console.log( position.coords.latitude ); }, function (e) { throw(e.message); } ) }","link":"/2021/04/16/js%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%9C%B0%E7%90%86%E5%9D%90%E6%A0%87%EF%BC%88%E7%BB%8F%E7%BA%AC%E5%BA%A6%EF%BC%89/"},{"title":"linux lsof命令详解","text":"#简介lsof(list open files)是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 #输出信息含义在终端下输入lsof即可显示系统打开的文件，因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。 直接输入lsof部分输出为: COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME init 1 root cwd DIR 8,1 4096 2 / init 1 root rtd DIR 8,1 4096 2 / init 1 root txt REG 8,1 150584 654127 /sbin/init udevd 415 root 0u CHR 1,3 0t0 6254 /dev/null udevd 415 root 1u CHR 1,3 0t0 6254 /dev/null udevd 415 root 2u CHR 1,3 0t0 6254 /dev/null udevd 690 root mem REG 8,1 51736 302589 /lib/x86_64-linux-gnu/libnss_files-2.13.so syslogd 1246 syslog 2w REG 8,1 10187 245418 /var/log/auth.log syslogd 1246 syslog 3w REG 8,1 10118 245342 /var/log/syslog dd 1271 root 0r REG 0,3 0 4026532038 /proc/kmsg dd 1271 root 1w FIFO 0,15 0t0 409 /run/klogd/kmsg dd 1271 root 2u CHR 1,3 0t0 6254 /dev/null 每行显示一个打开的文件，若不指定条件默认将显示所有进程打开的所有文件。 lsof输出各列信息的意义如下： COMMAND：进程的名称 PID：进程标识符 USER：进程所有者 FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等 TYPE：文件类型，如DIR、REG等 DEVICE：指定磁盘的名称 SIZE：文件的大小 NODE：索引节点（文件在磁盘上的标识） NAME：打开文件的确切名称 FD 列中的文件描述符cwd 值表示应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改,txt 类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /sbin/init 程序。 其次数值表示应用程序的文件描述符，这是打开该文件时返回的一个整数。如上的最后一行文件/dev/initctl，其文件描述符为 10。u 表示该文件被打开并处于读取/写入模式，而不是只读 ® 或只写 (w) 模式。同时还有大写 的W 表示该应用程序具有对整个文件的写锁。该文件描述符用于确保每次只能打开一个应用程序实例。初始打开每个应用程序时，都具有三个文件描述符，从 0 到 2，分别表示标准输入、输出和错误流。所以大多数应用程序所打开的文件的 FD 都是从 3 开始。 与 FD 列相比，Type 列则比较直观。文件和目录分别称为 REG 和 DIR。而CHR 和 BLK，分别表示字符和块设备；或者 UNIX、FIFO 和 IPv4，分别表示 UNIX 域套接字、先进先出 (FIFO) 队列和网际协议 (IP) 套接字。 #常用参数lsof语法格式是： lsof ［options］ filename lsof abc.txt 显示开启文件abc.txt的进程 lsof -c abc 显示abc进程现在打开的文件 lsof -c -p 1234 列出进程号为1234的进程所打开的文件 lsof -g gid 显示归属gid的进程情况 lsof +d /usr/local/ 显示目录下被进程开启的文件 lsof +D /usr/local/ 同上，但是会搜索目录下的目录，时间较长 lsof -d 4 显示使用fd为4的进程 lsof -i 用以显示符合条件的进程情况 lsof -i[46] [protocol][@hostname|hostaddr][:service|port] 46 –&gt; IPv4 or IPv6 protocol –&gt; TCP or UDP hostname –&gt; Internet host name hostaddr –&gt; IPv4地址 service –&gt; /etc/service中的 service name (可以不止一个) port –&gt; 端口号 (可以不止一个) #lsof使用实例##查找谁在使用文件系统 在卸载文件系统时，如果该文件系统中有任何打开的文件，操作通常将会失败。那么通过lsof可以找出那些进程在使用当前要卸载的文件系统，如下： # lsof /GTES11/ COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME bash 4208 root cwd DIR 3,1 4096 2 /GTES11/ vim 4230 root cwd DIR 3,1 4096 2 /GTES11/ 在这个示例中，用户root正在其/GTES11目录中进行一些操作。一个 bash是实例正在运行，并且它当前的目录为/GTES11，另一个则显示的是vim正在编辑/GTES11下的文件。要成功地卸载/GTES11，应该在通知用户以确保情况正常之后，中止这些进程。 这个示例说明了应用程序的当前工作目录非常重要，因为它仍保持着文件资源，并且可以防止文件系统被卸载。这就是为什么大部分守护进程（后台进程）将它们的目录更改为根目录、或服务特定的目录（如 sendmail 示例中的 /var/spool/mqueue）的原因，以避免该守护进程阻止卸载不相关的文件系统。 ##恢复删除的文件 当Linux计算机受到入侵时，常见的情况是日志文件被删除，以掩盖攻击者的踪迹。管理错误也可能导致意外删除重要的文件，比如在清理旧日志时，意外地删除了数据库的活动事务日志。有时可以通过lsof来恢复这些文件。 当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。除了该进程之外，这个文件是不可见的，因为已经删除了其相应的目录索引节点。 在/proc 目录下，其中包含了反映内核和进程树的各种文件。/proc目录挂载的是在内存中所映射的一块区域，所以这些文件和目录并不存在于磁盘中，因此当我们对这些文件进行读取和写入时，实际上是在从内存中获取相关信息。大多数与 lsof 相关的信息都存储于以进程的 PID 命名的目录中，即 /proc/1234 中包含的是 PID 为 1234 的进程的信息。每个进程目录中存在着各种文件，它们可以使得应用程序简单地了解进程的内存空间、文件描述符列表、指向磁盘上的文件的符号链接和其他系统信息。lsof 程序使用该信息和其他关于内核内部状态的信息来产生其输出。所以lsof 可以显示进程的文件描述符和相关的文件名等信息。也就是我们通过访问进程的文件描述符可以找到该文件的相关信息。 当系统中的某个文件被意外地删除了，只要这个时候系统中还有进程正在访问该文件，那么我们就可以通过lsof从/proc目录下恢复该文件的内容。 假如由于误操作将/var/log/messages文件删除掉了，那么这时要将/var/log/messages文件恢复的方法如下： 首先使用lsof来查看当前是否有进程打开/var/logmessages文件，如下： # lsof |grep /var/log/messages syslogd 1283 root 2w REG 3,3 5381017 1773647 /var/log/messages (deleted) 从上面的信息可以看到 PID 1283（syslogd）打开文件的文件描述符为 2。同时还可以看到/var/log/messages已经标记被删除了。因此我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下： # head -n 10 /proc/1283/fd/2 Aug 4 13:50:15 holmes86 syslogd 1.4.1: restart. Aug 4 13:50:15 holmes86 kernel: klogd 1.4.1, log source = /proc/kmsg started. Aug 4 13:50:15 holmes86 kernel: Linux version 2.6.22.1-8 (root@everestbuilder.linux-ren.org) (gcc version 4.2.0) #1 SMP Wed Jul 18 11:18:32 EDT 2007 Aug 4 13:50:15 holmes86 kernel: BIOS-provided physical RAM map: Aug 4 13:50:15 holmes86 kernel: BIOS-e820: 0000000000000000 - 000000000009f000 (usable) Aug 4 13:50:15 holmes86 kernel: BIOS-e820: 000000000009f000 - 00000000000a0000 (reserved) Aug 4 13:50:15 holmes86 kernel: BIOS-e820: 0000000000100000 - 000000001f7d3800 (usable) Aug 4 13:50:15 holmes86 kernel: BIOS-e820: 000000001f7d3800 - 0000000020000000 (reserved) Aug 4 13:50:15 holmes86 kernel: BIOS-e820: 00000000e0000000 - 00000000f0007000 (reserved) Aug 4 13:50:15 holmes86 kernel: BIOS-e820: 00000000f0008000 - 00000000f000c000 (reserved) 从上面的信息可以看出，查看 /proc/8663/fd/15 就可以得到所要恢复的数据。如果可以通过文件描述符查看相应的数据，那么就可以使用 I/O 重定向将其复制到文件中，如: cat /proc/1283/fd/2 &gt; /var/log/messages 对于许多应用程序，尤其是日志文件和数据库，这种恢复删除文件的方法非常有用。 可以列出被进程所打开的文件的信息。被打开的文件可以是 1.普通的文件，2.目录 3.网络文件系统的文件，4.字符设备文件 5.(函数)共享库 6.管道，命名管道 7.符号链接 8.底层的socket字流，网络socket，unix域名socket 9.在linux里面，大部分的东西都是被当做文件的…..还有其他很多 #怎样使用lsof 这里主要用案例的形式来介绍lsof 命令的使用 1.列出所有打开的文件: lsof 备注: 如果不加任何参数，就会打开所有被打开的文件，建议加上一下参数来具体定位 查看谁正在使用某个文件 lsof /filepath/file 3.递归查看某个目录的文件信息 lsof +D /filepath/filepath2/ 备注: 使用了+D，对应目录下的所有子目录和文件都会被列出 比使用+D选项，遍历查看某个目录的所有文件信息 的方法 lsof | grep ‘/filepath/filepath2/’ 列出某个用户打开的文件信息 lsof -u username 备注: -u 选项，u其实是user的缩写 列出某个程序所打开的文件信息 lsof -c mysql 备注: -c 选项将会列出所有以mysql开头的程序的文件，其实你也可以写成lsof | grep mysql,但是第一种方法明显比第二种方法要少打几个字符了 列出多个程序多打开的文件信息 lsof -c mysql -c apache 列出某个用户以及某个程序所打开的文件信息 lsof -u test -c mysql 列出除了某个用户外的被打开的文件信息 lsof -u ^root 备注：^这个符号在用户名之前，将会把是root用户打开的进程不让显示 通过某个进程号显示该进行打开的文件 lsof -p 1 列出多个进程号对应的文件信息 lsof -p 123,456,789 列出除了某个进程号，其他进程号所打开的文件信息 lsof -p ^1 13 . 列出所有的网络连接 lsof -i 列出所有tcp 网络连接信息 lsof -i tcp 列出所有udp网络连接信息 lsof -i udp 列出谁在使用某个端口 lsof -i :3306 列出谁在使用某个特定的udp端口 lsof -i udp:55 特定的tcp端口 lsof -i tcp:80 列出某个用户的所有活跃的网络端口 lsof -a -u test -i 列出所有网络文件系统 lsof -N 20.域名socket文件 lsof -u 21.某个用户组所打开的文件信息 lsof -g 5555 根据文件描述列出对应的文件信息 lsof -d description(like 2) 根据文件描述范围列出文件信息 lsof -d 2-3 #实用命令 lsof which httpd //那个进程在使用apache的可执行文件 lsof /etc/passwd //那个进程在占用/etc/passwd lsof /dev/hda6 //那个进程在占用hda6 lsof /dev/cdrom //那个进程在占用光驱 lsof -c sendmail //查看sendmail进程的文件使用情况 lsof -c courier -u ^zahn //显示出那些文件被以courier打头的进程打开，但是并不属于用户zahn lsof -p 30297 //显示那些文件被pid为30297的进程打开 lsof -D /tmp 显示所有在/tmp文件夹中打开的instance和文件的进程。但是symbol文件并不在列lsof -u1000 //查看uid是100的用户的进程的文件使用情况 lsof -utony //查看用户tony的进程的文件使用情况 lsof -u^tony //查看不是用户tony的进程的文件使用情况(^是取反的意思) lsof -i //显示所有打开的端口 lsof -i:80 //显示所有打开80端口的进程 lsof -i -U //显示所有打开的端口和UNIX domain文件 lsof -i UDP@[url]www.akadia.com:123 //显示那些进程打开了到www.akadia.com的UDP的123(ntp)端口的链接 lsof -i tcp@ohaha.ks.edu.tw:ftp -r //不断查看目前ftp连接的情况(-r，lsof会永远不断的执行，直到收到中断信号,+r，lsof会一直执行，直到没有档案被显示,缺省是15s刷新) lsof -i tcp@ohaha.ks.edu.tw:ftp -n //lsof -n 不将IP转换为hostname，缺省是不加上-n参数 来自：CNBLOGS","link":"/2021/01/28/linux%20lsof%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"},{"title":"js遍历数组","text":"JS中遍历数组经常用到，这里总结了6种遍历方法，以及各种方法的优劣。 1. for 遍历数组1.1 for 的普通遍历12345var name = ['Peter','Stark','Jack'];// for 循环for(var i = 0; i &lt; name.length; i++) { console.log(name[i]);} 1.2 for 优化版遍历12345var name = ['Peter','Stark','Jack'];// 先缓存 name.lengthfor(var i = 0, len = name.length; i &lt; len; i++) { console.log(name[i]);} 2、while 遍历数组1234567891011// while 循环var i = 0;while (i &lt; name.length) { console.log(name[i]); i++;}//while 逆向遍历var i = name.length;while (i--) { console.log(name[i]);} 3. for…in 方法数组既可遍历对象，也可遍历数组。遍历数组时也会遍历非数字键名,所以不推荐 for..in 遍历数组 3.1 遍历数组1234567var a = [1, 2, 3];for (var key in a) { console.log(a[key]);}/* 1 2 3 */ 3.2 遍历对象12345678const object = { name: 'Peter', age: 12, isHuman: true};for (let key in object) { console.log(key + '---' + object[key]);} 4. for…of 方法 (ES6)1234var arr = ['a','b','c'];for(let item of arr) { console.log(item);} 5. forEach() 方法用来遍历数组中的每一项，不影响原数组，性能差 缺陷 你不能使用break语句中断循环，也不能使用return语句返回到外层函数。 5.1 遍历普通数组1234var arr = [1,2,3,4];arr.forEach = (function(item) { console.log(item);}) 5.2 forEach() 遍历对象类型数组1234567891011const info = [ {id: 1000, name: 'zhangsan'}, {id: 1001, name: 'lisi'}, {id: 1002, name: 'wangwu'}]arr.forEach( function(item) { console.log(item.id + '---' + item.name);})/* 1---zhangsan 2---lisi 3---wangwu */ 6. map() 方法支持return，相当与原数组克隆了一份，把克隆的每项改变了，不影响原数组 1234var arr = [1,2,3,4];arr.map( function(item) { return item;}) 当然有了 箭头函数 =&gt; 后更方便 123var arr = ['a','b','c'];var newArray = arr.map(x =&gt; x);alert(newArray); // ['a','b''c'] map() 方法创建一个新数组，其结果是该数组中的每个元素都调用一个提供的函数后返回的结果 123var newArray = arr.map(function (item) { return [expression];}) 例如 12345var arr = [1,2,3,4];var newArray = arr.map( x =&gt; x * x)alert(newArray); // [1,4,9,16]","link":"/2022/07/23/js%E9%81%8D%E5%8E%86%E6%95%B0%E7%BB%84/"},{"title":"ll 命令排序详解","text":"1234ll 默认按照文件名字母顺序排序，A在最前ll -SX 按照文件类型排序，扩展名首字母排序，文件夹最前ll -St 按照创建时间排序，最近的最前ll -SS 按照大小排序，最大的最前 选项 123456789101112131415-S按文件大小排序 --sort = WORD按WORD而不是名称排序：无（-U），大小（-S）， 时间（-t），版本（-v），扩展名（-X） --time =带有-l的WORD，将时间显示为WORD而不是默认值 修改时间：一次或访问或使用（-u） ctime或状态（-c）；也使用指定的时间 作为排序键，如果--sort = time --time-style =带有-l的样式，使用样式STYLE显示时间： 全ISO，长ISO，ISO，区域设置或+ FORMAT; FORMAT的解释方式类似于'date'；如果格式 是FORMAT1 &lt;newline&gt; FORMAT2，则FORMAT1适用 非最新文件，FORMAT2到最近文件； 如果STYLE带有'posix-'前缀，则为STYLE 仅在POSIX语言环境外生效 -t按修改时间排序，最新的优先","link":"/2021/05/16/ll%20%E5%91%BD%E4%BB%A4%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/"},{"title":"linux基本命令grep egrep fgrep zgrep用法以及正则表达式","text":"一、grep、egrep、fgrep命令 本文中主要介绍了linux系统下grep egrep fgrep命令和正则表达式的基本参数和使用格式、方法。 1.1、基本定义： grep（global search regular RE ) and print out the line,全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它只能使用基本的正则表达式来搜索文本，并把匹配的行打印出来。 grep是很常见也很常用的命令，它的主要功能是进行字符串数据的比较，然后符合用户需求的字符串打印出来，但是主意，grep在数据中查找一个字符串时，是以“整行”为单位进行数据筛选的。 egrep命令等同于grep -E，利用此命令可以使用扩展的正则表达式对文本进行搜索，并把符合用户需求的字符串打印出来。 fgrep命令等同于grep -F，它利用固定的字符串来对文本进行搜索，但不支持正则表达式的引用，所以此命令的执行速度也最快。 1.2、命令基本用法1grep [option] '搜索字符串' filename grep常用选项： 12345678910111213-a :在二进制文件中，以文本文件的方式搜索数据-c :计算找到'搜索字符串'的次数-i :忽略大小写-v :反向查找，即显示没有'搜索字符串'内容的那行-o :只显示被模式匹配的字符串-n :输出行号--colour（color）:颜色显示 12345-A：显示匹配到字符那行的后面n行-B：显示匹配到字符那行的前面n行-C：显示匹配到字符那行的前后n行 二、正则表达式2.1、基本定义： 正则表达使用单个字符串来描述、匹配一系列符合某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些符合某个模式的文本。简而言之，正则表达式就是处理字符串的方法，以行为单位进行字符串的处理，通过一些特殊符号的辅助，可以让用户轻松搜索/替换某特定的字符串。 正则表达式分为两类：基本的正则表达式和扩展的正则表达式。 2.2、正则表达式详细介绍2.2.1、基本的正则表达式： （1）元字符： ​ . :匹配任意单个字符 ​ fg：查找包含student且student后面带一个字符的行 ​ grep ‘student.’ /etc/passwd （模式可以用单引号和双引号，如果模式中要做变量替换时则必须用双引） ​ [] :匹配指定范围内的任意单个字符,[abc],[a-z],[0-9],[a-zA-Z] ​ fg：查找带有数字的行 1grep '[0-9]' /etc/passwd ​ [^] :匹配指定范围外的任意单个字符 ​ fg：查找没有小写字母的行。 1grep '[^a-z]' /etc/inittab [:space:]: 表示空白字符[:punct:]: 表示所有标点符号的集合[:lower:]: 表示所有的小写字母[:upper:]: 表示所有的大写字母[:alpha:]: 表示大小写字母[:digit:]: 表示数子[:alnum:]: 表示数字和大小写字母—–使用格式:alnum:等 （2）次数匹配： ​ * :匹配其前面的字符任意次 ​ fg：查找root出现0次或0次以上的行 1grep 'root*' /etc/passwd ​ .* :任意字符 ​ fg：查找包含root的行 1grep 'root.*' /etc/passwd ​ ?：匹配其前面的字符1次或0次 ​ {m,n} :匹配其前字符最少m，最多n次） ​ (3) 字符锚定： ​ ^:锚定行首，此字符后面的任意内容必须出现在行首 ​ fg：查找行首以#开头的行 ​ grep ‘^#’ /etc/inittab ​ $:锚定行尾，此字符前面的任意内容必须出现在行尾 ​ fg：查找行首以root结尾的行 ​ grep ‘root$’ /etc/inittab ​ ^$:锚定空白行，可以统计空白行 ​ &lt;或者\\b:锚定词首，其后面的任意字符必须做为单词首部出现 ​ fg:查找root且root前面不包含任何字符的行 ​ grep ‘\\ ​ &gt;或者\\b:锚定词尾，其前面的任意字符必须做为单词尾部出现 fg：\\ 查找root单词 grep “&quot; =grep “\\broot\\b” 2.2.2、扩展的正则表达式：​ 扩展的正则表达只是在基本的正则表达上作出了小小的一点修改，其修改如下： 在扩展的正则表达中把( ) 写成()、{ } 写成{ }，另外加入了+：次数匹配，匹配其前面的字符至少出现一次，无上限、|: 或者(二取一），其余的都一样， 基本正则表达式，使用( ) { } . ? |都需要转义,在扩展正则表达中不需要加\\，（这里测试了以下|是需要转义的）其详细信息如下： ​ (1) 字符匹配的命令和用法与基本正则表达式的用法相同，这里不再重复阐述。 ​ (2) 次数匹配： ​ * :匹配其前面字符的任意次 ​ ？:匹配其前面字符的0此或着1此 ​ + :匹配其前面字符至少1此 ​ fg：至少一个空白符： ‘[[:space:]]+’ ​ {m,n} :匹配其前面字符m到n次 ​ (3) 字符锚定的用法和基本正则表达式的用法相同，在此不再阐述。 ​ （4）特殊字符： ​ | : 代表或者的意思。 ​ fg：grep -E ‘c|cat’ file：表示在文件file内查找包含c或者cat ​ .:\\表示转义字符，此表示符号. 三、grep命令利用小实例(1)显示/etc/inittab 中以#开头，且后面跟一个或者多个空白符，而后又跟了任意非空白符的行 grep ‘#[[:space:]]*[^[:space:]]’ /etc/inittab (2) 输出不是数字开关的行grep ‘^[^0-9]’ /etc/passwd (3)输出行首是1或2 1grep '^\\(1\\|2\\)' /etc/inittab 或 1grep -E '^(1|2)' /etc/inittab (4)查找前面是rc中间接任意字符而后跟/rc 1grep '.*\\(rc\\).*\\/\\1.*' /etc/inittab (5）取出当前电脑上的IP 1ifconfig |grep -A 1 &quot;^eth0&quot; |grep &quot;\\&lt;[0-9.]\\{1,\\} |cut -d: -f2 (6)查找当前系统上名字为student（必须出现在行首）的用户账户的相关信息，文件为/etc/passwd 1grep &quot;^student&quot; /etc/passwd zgrephttp://einverne.github.io/post/2017/11/zgrep-grep-gz-file.html Linux 下按照正则过滤文本的命令 grep 非常强大，grep 能够把正则匹配的行打印出来。而 zgrep 则能够对压缩包内容进行正则匹配。zgrep 全称是 search compressed files for a regular expression grep 的命令格式是 1grep [option] pattern files 他的工作方式是，在一个或者多个文件中根据正则搜索匹配内容，将搜索的结果输出到标准输出，不更改源文件内容。 grep 常用的一些选项1-i 忽略字符大小写区别-v 显示不包含正则的所有行 关于更多的 grep 的内容可以参考另外一篇文章，zgrep 和 grep 用法类似，不过操作的对象是压缩的内容。支持 bzip2，gzip，lzip， xz 等等。 zgrep 使用但如果想要过滤 Nginx 的 access_log.gz 的压缩文件的内容，如果先解压，然后过滤出有用的文本，再把文件压缩回去，这就变的非常不方便。 1gunzip access_log.gzgrep &quot;/api&quot; access_loggzip access_log 需要使用三个命令来实现文件的过滤，其实 Linux 下可以使用 zgrep 来一步完成 1zgrep &quot;/api&quot; access_log.gz 和 grep 类似， zgrep 也可以指定多个文件同时进行搜索过滤 1zgrep &quot;/api&quot; access_log.gz access_log_1.gz 延伸既然提到了不解压搜索压缩包内容，.gz 的文件可以使用 zgrep ，而对于 .tar.gz 文件 1zcat access.tar.gz | grep -a '/api'zgrep -a &quot;/api&quot; access.tar.gz 其实这些带 z 的命令都包含在 Zutils 这个工具包中，这个工具包还提供了 1zcat 解压文件并将内容输出到标准输出zcmp 解压文件并且 byte by byte 比较两个文件zdiff 解压文件并且 line by line 比较两个文件zgrep 解压文件并且根据正则搜索文件内容ztest - Tests integrity of compressed files.zupdate - Recompresses files to lzip format. 这些命令支持 bzip2, gzip, lzip and xz 格式。","link":"/2021/05/01/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4grep%20egrep%20fgrep%20zgrep%E7%94%A8%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"title":"log4j里面的info，debug，error级别有什么区别","text":"一共分为五个级别：DEBUG、INFO、WARN、ERROR和FATAL。 这五个级别是有顺序的，DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，明白这一点很重要，这里Log4j有一个规则：假设设置了级别为P，如果发生了一个级别Q比P高，则可以启动，否则屏蔽掉。DEBUG: 这个级别最低的东东，一般的来说，在系统实际运行过程中，一般都是不输出的。因此这个级别的信息，可以随意的使用，任何觉得有利于在调试时更详细的了解系统运行状态的东东，比如变量的值等等，都输出来看看也无妨。INFO：这个应该用来反馈系统的当前状态给最终用户的，所以，在这里输出的信息，应该对最终用户具有实际意义，也就是最终用户要能够看得明白是什么意思才行。从某种角度上说，Info 输出的信息可以看作是软件产品的一部分（就像那些交互界面上的文字一样），所以需要谨慎对待，不可随便。WARN、ERROR和FATAL：警告、错误、严重错误，这三者应该都在系统运行时检测到了一个不正常的状态，他们之间的区别，要区分还真不是那么简单的事情。我大致是这样区分的： 所谓警告，应该是这个时候进行一些修复性的工作，应该还可以把系统恢复到正常状态中来，系统应该可以继续运行下去。 所谓错误，就是说可以进行一些修复性的工作，但无法确定系统会正常的工作下去，系统在以后的某个阶段，很可能会因为当前的这个问题，导致一个无法修复的错误（例如宕机），但也可能一直工作到停止也不出现严重问题。 所谓Fatal，那就是相当严重的了，可以肯定这种错误已经无法修复，并且如果系统继续运行下去的话，可以肯定必然会越来越乱。这时候采取的最好的措施不是试图将系统状态恢复到正常，而是尽可能地保留系统有效数据并停止运行。 也就是说，选择 Warn、Error、Fatal 中的具体哪一个，是根据当前的这个问题对以后可能产生的影响而定的，如果对以后基本没什么影响，则警告之，如果肯定是以后要出严重问题的了，则Fatal之，拿不准会怎么样，则 Error 之。","link":"/2022/06/12/log4j%E9%87%8C%E9%9D%A2%E7%9A%84info%EF%BC%8Cdebug%EF%BC%8Cerror%E7%BA%A7%E5%88%AB%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/"},{"title":"mysql导出csv文件","text":"CSV格式，其要点包括： 字段之间以逗号分隔，数据行之间以\\r\\n分隔； 字符串以半角双引号包围，字符串本身的双引号用两个双引号表示。 准备首先需要查看下一个变量 1SHOW VARIABLES LIKE &quot;secure_file_priv&quot;; 可以看到，本地value的值为NULL。解释如下 （1）NULL，表示禁止。 （2）如果value值有文件夹目录，则表示只允许该目录下文件（PS：测试子目录也不行）。 （3）如果为空，则表示不限制目录。 修改 把导入文件放入secure-file-priv目前的value值对应路径 把secure-file-priv的value值修改为准备导入文件的放置路径 去掉导入的目录限制。可修改mysql配置文件（Windows下为my.ini, Linux下的my.cnf），在[mysqld]下面，查看是否有: secure_file_priv = 这样一行内容，表示不限制目录，等号一定要有，否则mysql无法启动。 修改完配置文件后，重启mysql生效。 重启后： 12service mysqld stopservice mysqld start 如果不修改可能会有如下报错 1The MySQL server is running with the --secure-file-priv option so it cannot execute this statement. 开始CSV代表逗号分隔值。 您经常使用CSV文件格式在Microsoft Excel，Open Office，Google Docs等应用程序之间交换数据。 以CSV文件格式从MySQL数据库中获取数据将非常有用，因为您可以按照所需的方式分析和格式化数据。 MySQL提供了一种将查询结果导出到位于数据库服务器中的CSV文件的简单方法。 在导出数据之前，必须确保： MySQL服务器的进程对包含目标CSV文件的目标文件夹具有写访问权限。 要导出的目标CSV文件不能存在。 以下查询从orders表中查询选择已取消的订单： 123456SELECT orderNumber, status, orderDate, requiredDate, commentsFROM ordersWHERE status = 'Cancelled'; 要将此结果集导出为CSV文件，请按如下方式向上述查询添加一些子句： 1234567891011SELECT orderNumber, status, orderDate, requiredDate, commentsFROM ordersWHERE status = 'Cancelled' INTO OUTFILE 'F:/worksp/mysql/cancelled_orders.csv' FIELDS ENCLOSED BY '&quot;' TERMINATED BY ';' ESCAPED BY '&quot;' LINES TERMINATED BY '\\r\\n'; 该语句在F:/worksp/mysql/目录下创建一个包含结果集，名称为cancelled_orders.csv的CSV文件。 CSV文件包含结果集中的行集合。每行由一个回车序列和由LINES TERMINATED BY '\\r\\n'子句指定的换行字符终止。文件中的每行包含表的结果集的每一行记录。 每个值由FIELDS ENCLOSED BY '&quot;'子句指示的双引号括起来。 这样可以防止可能包含逗号(，)的值被解释为字段分隔符。 当用双引号括住这些值时，该值中的逗号不会被识别为字段分隔符。 将数据导出到文件名包含时间戳的CSV文件我们经常需要将数据导出到CSV文件中，该文件的名称包含创建文件的时间戳。 为此，您需要使用MySQL准备语句。 以下命令将整个orders表导出为将时间戳作为文件名的一部分的CSV文件。 12345678910111213SET @TS = DATE_FORMAT(NOW(),'_%Y%m%d_%H%i%s');SET @FOLDER = 'F:/worksp/mysql/';SET @PREFIX = 'orders';SET @EXT = '.csv';SET @CMD = CONCAT(&quot;SELECT * FROM orders INTO OUTFILE '&quot;,@FOLDER,@PREFIX,@TS,@EXT, &quot;' FIELDS ENCLOSED BY '\\&quot;' TERMINATED BY ';' ESCAPED BY '\\&quot;'&quot;, &quot; LINES TERMINATED BY '\\r\\n';&quot;);PREPARE statement FROM @CMD;EXECUTE statement; 下面，让我们来详细讲解上面的命令。 首先，构造了一个具有当前时间戳的查询作为文件名的一部分。 其次，使用PREPARE语句FROM命令准备执行语句。 第三，使用EXECUTE命令执行语句。 可以通过事件包装命令，并根据需要定期安排事件的运行。 使用列标题导出数据如果CSV文件包含第一行作为列标题，那么该文件更容易理解，这是非常方便的。 要添加列标题，需要使用UNION语句如下： 1234567(SELECT 'Order Number','Order Date','Status')UNION (SELECT orderNumber,orderDate, statusFROM ordersINTO OUTFILE 'F:/worksp/mysql/orders_union_title.csv'FIELDS ENCLOSED BY '&quot;' TERMINATED BY ';' ESCAPED BY '&quot;'LINES TERMINATED BY '\\r\\n'); 如查询所示，需要包括每列的列标题。 处理NULL值如果结果集中的值包含NULL值，则目标文件将使用“N/A”来代替数据中的NULL值。要解决此问题，您需要将NULL值替换为另一个值，例如不适用(N/A)，方法是使用IFNULL函数，如下： 12345678SELECT orderNumber, orderDate, IFNULL(shippedDate, 'N/A')FROM orders INTO OUTFILE 'F:/worksp/mysql/orders_null2na.csv' FIELDS ENCLOSED BY '&quot;' TERMINATED BY ';' ESCAPED BY '&quot;' LINES TERMINATED BY '\\r\\n'; 我们用N/A字符串替换了shippingDate列中的NULL值。 CSV文件将显示N/A而不是NULL值。 给导出文件添加列名 1select * into outfile '/tmp/test1.csv' fields terminated by ',' escaped by '' optionally enclosed by '' lisnes terminated by '\\n' from (select 'col1','col2','col3','col4','col5' union select id,user,url,name,age from test) b; 使用MySQL命令结合sed的方法 使用-e参数执行命令，-s是去掉输出结果的各种划线 利用sed将字段之间的tab换成，并且将NULL替换成空字符 如果不想要标题行，可以使用-N参数 1mysql -uroot -p密码 test -e &quot;select * from test where id &gt; 1&quot; -s |sed -e &quot;s/\\t/,/g&quot; -e &quot;s/NULL/ /g&quot; -e &quot;s/\\n/\\r\\n/g&quot; &gt; /tmp/test2.csv 使用mysqldump导出 1mysqldump -uroot -p密码 -t -T/tmp/ test test --fields-terminated-by=',' --fields-escaped-by='' --fields-optionally-enclosed-by='' 1234567test（第一个test） ：导出的数据库；test（第二个test）：导出的数据表；-t ：不导出create 语句，只要数据；-T 指定到处的位置，注意目录权限，注意这里只到目录，默认名字是table_name.txt；–fields-terminated-by=’,’：字段分割符；–fields-enclosed-by=’’ ：字段引号； //更多请阅读：https://www.yiibai.com/mysql/export-table-to-csv.html","link":"/2022/06/18/mysql%E5%AF%BC%E5%87%BAcsv%E6%96%87%E4%BB%B6/"},{"title":"mysql（mariadb）常用命令","text":"首先了解一下SQL的注释 单行语句进行注释 1SELECT * FROM USERS; --查询所有用户信息 多行注释 123456/*切换到USER数据库查询所有表信息*/USE USER;SHOW TABLES; 注释快捷键 选中需要注释的语句先Ctrl+k，再Ctrl+c注释成功取消注释先Crtrl+k，在Ctrl+u 查看支持的表引擎12SHOW ENGINES;SHOW VARIABLES LIKE &quot;%STORAGE_ENGINE%&quot;; 查看创建表语句1SHOW CREATE TABLE `TBALE` 查看表status1SHOW TABLE STATUS FROM `DATABASE` WHERE NAME=`TABLE` \\G 修改表引擎1ALTER TABLE `TBALE` ENGINE=MEMORY 查看mysql的数据文件存放位置1SHOW VARIABLES LIKE &quot;%DIR%&quot;; 数据库文件默认在：cd /usr/share/mysql配置文件默认在：/etc/my.cnf ———————————– 数据库目录：/var/lib/mysql/配置文件：/usr/share/mysql(mysql.server命令及配置文件)相关命令：/usr/bin(mysqladmin、mysqldump等命令)(*mysql的一种安全启动方式：/usr/bin/mysqld_safe –user=root &amp;)启动脚本：/etc/rc.d/init.d/ 首先你可以使用以下的命令来寻找MySQL 1[root@stuhome /]# find / -name “mysql” -print 一般来说mysql是放在/usr/local/mysql/下的。然后在其bin目录下有个mysql_config文件，vi之，你会看见这么一句：ldata=’/usr/local/mysql/var’rpm安装默认目录：数据文件：/var/lib/mysql/配置文件模板：/usr/share/mysqlmysql客户端工具目录：/usr/bin日志目录：/var/log/pid，sock文件目录：/tmp/ 设置组合主键索引使用baiprimary key(字段1, 字段2, …)的语句进行设置。一个表中最du多只能有一个主键，zhi也可以没有。一个主键既可dao以是单一的字段构成，也可以是多个字段联合构成，如果是单一字段，只需在该字段后面标记primary key即可，如果是多个字段联合构成，则需要采用最开始介绍的那种方式设置。在部分数据库的图形化工具中（如Access、SQL Server等），在表设计的界面上，可以按住Ctrl键，然后选择要设置为联合主键的字段，都选好之后再按右键选择“设置为主键”。alter table Table_1 add constraint pk_name primary key (id,name)设置Table_1表的id,name为主键 更改表名1ALTER TABLE table_name RENAME [TO] new_name; ##创建索引 1create index `id_name` on categories (`id`, `name`); 更改字段信息1alter table categories modify column id mediumint auto_increment primary key ; 删除索引1drop index id_name on categories; #其他 1234567891011121314151617181920212223SHOW DATABASES //列出 MySQL Server 数据库。SHOW TABLES [FROM db_name] //列出数据库数据表。SHOW TABLE STATUS [FROM db_name] //列出数据表及表状态信息。SHOW COLUMNS FROM tbl_name [FROM db_name] //列出资料表字段SHOW FIELDS FROM tbl_name [FROM db_name]，DESCRIBE tbl_name [col_name]。SHOW FULL COLUMNS FROM tbl_name [FROM db_name]//列出字段及详情SHOW FULL FIELDS FROM tbl_name [FROM db_name] //列出字段完整属性SHOW INDEX FROM tbl_name [FROM db_name] //列出表索引。SHOW STATUS //列出 DB Server 状态。SHOW VARIABLES //列出 MySQL 系统环境变量。SHOW PROCESSLIST //列出执行命令。SHOW GRANTS FOR user //列出某用户权限 #建表语句 1234567create table files( username varchar(50), file varchar(200) not null, create_time timestamp not null default CURRENT_TIMESTAMP, filename varchar(100) default null, md5 char(32) not null default '', id int(11) not null auto_increment primary key) engine=myisam default charset=utf8mb4 collate=utf8mb4_unicode_ci; #MySQL(Unix时间戳、日期)转换函数 unix_timestamp() 123456mysql&gt; select unix_timestamp();+``------------------+| unix_timestamp() |+``------------------+| 1464590043 |+``------------------+ unix_timestamp(date) 12345678910111213mysql&gt; select unix_timestamp('2016-05-30');+------------------------------+| unix_timestamp('2016-05-30') |+------------------------------+| 1464537600 |+------------------------------+ mysql&gt; select unix_timestamp('2016-05-30 14:35:21');+---------------------------------------+| unix_timestamp('2016-05-30 14:35:21') |+---------------------------------------+| 1464590121 |+---------------------------------------+ from_unixtime(unix_timestamp) 123456mysql&gt; select from_unixtime(1464590043);+---------------------------+| from_unixtime(1464590043) |+---------------------------+| 2016-05-30 14:34:03 |+---------------------------+ from_unixtime(unix_timestamp,format) 123456mysql&gt; select from_unixtime(1464590043, '%Y %D %M %h:%i:%s %x');+---------------------------------------------------+| from_unixtime(1464590043, '%Y %D %M %h:%i:%s %x') |+---------------------------------------------------+| 2016 30th May 02:34:03 2016 |+---------------------------------------------------+ 修改密码ALTER USER ‘root‘@’localhost’ IDENTIFIED WITH mysql_native_password BY ‘123456’; 如何删除mysql 主键索引如果一个主键是自增长的，不能直接删除该列的主键索引，应当先取消自增长，再删除主键特性 1alter table 表名 drop primary key; --【如果这个主键是自增的，先取消自增长.】 具体方法如下: 123alter table articles modify id int ; --【重新定义列类型】alter table articles drop primary key; 添加主键索引innodb逐渐使聚簇索引，myisam不是[待考究] 1ALTER TABLE users ADD PRIMARY KEY (id); 删除 1ALTER TABLE users DROP primary key; --删除前要将auto_increment去掉 添加其他索引1CREATE INDEX index_name ON users(username); MySQL 查看执行计划1EXPLAIN SELECT * FROM users WHERE id &gt; 1; Mysql8.0新增EXPLAIN ANALYZE 1EXPLAIN ANALYZE SELECT * FROM users WHERE id &gt; 0; 执行计划中extra的描述12345Using where：表示优化器需要通过索引回表查询数据；Using index：表示直接访问索引就足够获取到所需要的数据，不需要通过索引回表；Using index condition：在5.6版本后加入的新特性（Index Condition Pushdown）;Using index condition 会先条件过滤索引，过滤完索引后找到所有符合索引条件的数据行，随后用 WHERE 子句中的其他条件去过滤这些数据行；Using where &amp;&amp; Using index 更改表的引擎1ALTER TABLE users ENGINE = myisam; Innodb的count效率在mysql8测试已经不再低于myisam了蠕虫复制1INSERT INTO users SELECT * FROM users_1; 下面的SQL可以指定列，用于解决唯一约束的问题 1INSERT INTO users(username,password) SELECT username,password FROM users_d; 查看状态1show status 1show table status 可以通过Comment字段查看表是不是视图 查看触发器show triggers 权限相关1234show grants for `username`grant all on *.* to `username`@`%`revoke all on *.* from `username`@`%`flush privileges","link":"/2020/08/14/mysql%EF%BC%88mariadb%EF%BC%89%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"title":"npm &amp; yarn 更换源等常用命令或操作","text":"npm 由于node下载第三方依赖包是从国外服务器下载，虽然没有被墙，但是下载的速度是非常的缓慢且有可能会出现异常。所以为了提高效率，我们还是把npm的镜像源替换成淘宝的镜像源。有几种方式供我们选择 使用cnpm使用阿里定制的cnpm命令行工具代替默认的npm，输入以下代码 12npm install -g cnpm --registry=https://registry.npm.taobao.org cnpm -v #检测是否安装成功 安装成功之后，以后安装依赖包的方式和npm的是一样的，只是npm的命令换成是cnpm就可以了 假如你已经习惯了使用npm的安装方式的，不想去下载阿里的cnpm命令工具的话，很简单，我们直接将node的仓库地址换成淘宝仓库地址即可 单次使用1npm install --registry=https://registry.npm.taobao.org 永久使用在开发react-native的时候，不要使用cnpm！cnpm安装的模块路径比较奇怪，packager不能正常识别。所以，为了方便开发，我们最好是直接永久使用淘宝的镜像源 直接命令行的设置 1npm config set registry https://registry.npm.taobao.org 手动修改设置 1.打开.npmrc文件（C:\\Program Files\\nodejs\\node_modules\\npm\\npmrc，没有的话可以使用git命令行建一个(touch .npmrc)，用cmd命令建会报错）2.增加 1registry =https://registry.npm.taobao.org 即可。 检测是否修改成功 1234// 配置后可通过下面方式来验证是否成功npm config listnpm config get registrynpm info express 注：如果想还原npm仓库地址的话，只需要在把地址配置成npm镜像就可以了 1npm config set registry https://registry.npmjs.org/ 查看npm install -g安装位置1npm root -g yarnyarn add1yarn add [package]@[version] 这将安装您的dependencies中的一个或多个包。 用 --dev 或 -D 会在 devDependencies 里安装一个或多个包。 1yarn global add &lt;package...&gt; //全局安装依赖 对于绝大部分包来说，这是个坏习惯，因为它们是隐藏的。 最好本地安装你的依赖，这样它们都是明确的，每用你项目的人都能得到同样的依赖。 注意：yarn add global &lt;package...&gt;会变成本地安装，注意顺序。 yarn cache1yarn cache dir 运行 yarn cache dir 会打印出当前的 yarn全局缓存在哪里。 1yarn cache list --pattern &lt;pattern&gt; //列出匹配指定模式的已缓存的包 示例：yarn cache list –pattern “gulp-(match|newer)” yarn cache clean 运行此命令将清除全局缓存。 将在下次运行 yarn 或 yarn install 时重新填充。 yarn list1yarn list [--depth] [--pattern] 默认情况下，所有包和它们的依赖会被显示。 要限制依赖的深度，你可以给 list 命令添加一个标志 –depth 所需的深度。 示例 1yarn list --depth=0 yarn remove1yarn remove &lt;package...&gt; 运行 yarn remove foo 会从你的直接依赖里移除名为 foo 的包，在此期间会更新你的 package.json 和 yarn.lock 文件。 yarn run1yarn run [script] [&lt;args&gt;] 如果你已经在你的包里定义了 scripts，这个命令会运行指定的 [script]。例如： 运行这个命令会执行你的 package.json 里名为 &quot;test&quot; 的脚本。 yarn upgrade1yarn upgrade [package | package@tag | package@version | @scope/]... [--ignore-engines] [--pattern] 可以选择指定一个或多个包名称。指定包名称时，将只升级这些包。未指定包名称时，将升级所有依赖项。 查看npm上已经全局安装的命令 1npm list -g --depth=0 查看yarn 全局安装的根目录 1yarn global bin 查看npm 全局安装的根目录 1npm bin yarn windows 安装 1choco install yarn 或者 1scoop install yarn 或者下载安装包 yarn指定淘宝源1yarn config set registry http://registry.npm.taobao.org 原文链接：https://www.jianshu.com/p/f5d85e541a99","link":"/2021/01/09/npm%20&%20yarn%20%E6%9B%B4%E6%8D%A2%E6%BA%90%E7%AD%89%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%88%96%E6%93%8D%E4%BD%9C/"},{"title":"ob系列函数总结","text":"ob系列函数中常用函数 ob_start(); //打开一个输出缓冲区，所有的输出信息不再直接发送到浏览器，而是保存在输出缓冲区里面。ob_clean(); //删除内部缓冲区的内容，不关闭缓冲区(不输出)。ob_end_clean(); //删除内部缓冲区的内容，关闭缓冲区(不输出)。ob_get_clean(); //返回内部缓冲区的内容，关闭缓冲区。相当于执行 ob_get_contents() and ob_end_clean()ob_flush(); //发送内部缓冲区的内容到浏览器，删除缓冲区的内容，不关闭缓冲区。ob_end_flush(); //发送内部缓冲区的内容到浏览器，删除缓冲区的内容，关闭缓冲区。ob_get_flush(); //返回内部缓冲区的内容，并关闭缓冲区，再释放缓冲区的内容。相当于ob_end_flush()并返回缓冲区内容。flush(); //将ob_flush释放出来的内容，以及不在PHP缓冲区中的内容，全部输出至浏览器；刷新内部缓冲区的内容，并输出。 ob_get_contents(); //返回缓冲区的内容，不输出。ob_get_length(); //返回内部缓冲区的长度，如果缓冲区未被激活，该函数返回FALSE。ob_get_level(); //Return the nesting level of the output buffering mechanism.ob_get_status(); //Get status of output buffers. ob_implicit_flush(); //打开或关闭绝对刷新，默认为关闭，打开后ob_implicit_flush(true)，所谓绝对刷新，即当有输出语句(e.g: echo)被执行时，便把输出直接发送到浏览器，而不再需要调用flush()或等到脚本结束时才输出。 ob_gzhandler //ob_start回调函数，用gzip压缩缓冲区的内容。ob_list_handlers //List all output handlers in useoutput_add_rewrite_var //Add URL rewriter valuesoutput_reset_rewrite_vars //Reset URL rewriter values 这些函数的行为受php_ini设置的影响：output_buffering //该值为ON时，将在所有脚本中使用输出控制；若该值为一个数字，则代表缓冲区的最大字节限制，当缓存内容达到该上限时将会自动向浏览器输出当前的缓冲区里的内容。output_handler //该选项可将脚本所有的输出，重定向到一个函数。例如，将 output_handler 设置为 mb_output_handler() 时，字符的编码将被修改为指定的编码。设置的任何处理函数，将自动的处理输出缓冲。implicit_flush //作用同ob_implicit_flush，默认为Off。 用PHP的ob_start();控制您的浏览器cache Output Control 函数可以让你自由控制脚本中数据的输出。它非常地有用，特别是对于：当你想在数据已经输出后，再输出文件头的情况。输出控制函数不对使用 header() 或 setcookie(), 发送的文件头信息产生影响,只对那些类似于 echo() 和 PHP 代码的数据块有作用。我们先举一个简单的例子，让大家对Output Control有一个大致的印象：Example 1. 程序代码 123456&lt;?phpob_start(); //打开缓冲区echo \\&quot;Hellon\\&quot;; //输出header(&quot;location:index.php&quot;); //把浏览器重定向到index.phpob_end_flush();//输出全部内容到浏览器?&gt; 所有对header()函数有了解的人都知道，这个函数会发送一段文件头给浏览器，但是如果在使用这个函数之前已经有了任何输出（包括空输出，比如空格，回车和换行）就会提示出错。如果我们去掉第一行的ob_start()，再执行此程序，我们会发现得到了一条错误提示：”Header had all ready send by”！但是加上ob_start，就不会提示出错，原因是当打开了缓冲区，echo后面的字符不会输出到浏览器，而是保留在服务器，直到你使用 flush或者ob_end_flush才会输出，所以并不会有任何文件头输出的错误！ 一、 相关函数简介：1、Flush：刷新缓冲区的内容，输出。函数格式：flush()说明：这个函数经常使用，效率很高。2、ob_start ：打开输出缓冲区函数格式：void ob_start(void)说明：当缓冲区激活时，所有来自PHP程序的非文件头信息均不会发送，而是保存在内部缓冲区。为了输出缓冲区的内容，可以使用ob_end_flush()或flush()输出缓冲区的内容。3 、ob_get_contents ：返回内部缓冲区的内容。使用方法：string ob_get_contents(void)说明：这个函数会返回当前缓冲区中的内容，如果输出缓冲区没有激活，则返回 FALSE 。4、ob_get_length：返回内部缓冲区的长度。使用方法：int ob_get_length(void)说明：这个函数会返回当前缓冲区中的长度；和ob_get_contents一样，如果输出缓冲区没有激活。则返回 FALSE。5、ob_end_flush ：发送内部缓冲区的内容到浏览器，并且关闭输出缓冲区。使用方法：void ob_end_flush(void)说明：这个函数发送输出缓冲区的内容（如果有的话）。6、ob_end_clean：删除内部缓冲区的内容，并且关闭内部缓冲区使用方法：void ob_end_clean(void)说明：这个函数不会输出内部缓冲区的内容而是把它删除！7、ob_implicit_flush：打开或关闭绝对刷新使用方法：void ob_implicit_flush ([int flag])说明：使用过Perl的人都知道$|=x的意义，这个字符串可以打开/关闭缓冲区，而ob_implicit_flush函数也和那个一样，默认为关闭缓冲区，打开绝对输出后，每个脚本输出都直接发送到浏览器，不再需要调用 flush() 二、深入了解： 关于Flush函数：这个函数在PHP3中就出现了，是一个效率很高的函数，他有一个非常有用的功能就是刷新browser的cache.我们举一个运行效果非常明显的例子来说明flush.Example 2.程序代码12345678910111213&lt;?php for($i = 1; $i &lt;= 300; $i++ ) print(&quot; &quot;); // 这一句话非常关键，cache的结构使得它的内容只有达到一定的大小才能从浏览器里输出 // 换言之，如果cache的内容不达到一定的大小，它是不会在程序执行完毕前输出的。经 // 过测试，我发现这个大小的底限是256个字符长。这意味着cache以后接收的内容都会 // 源源不断的被发送出去。 For($j = 1; $j &lt;= 20; $j++) { echo $j.&quot; &quot;; flush(); //这一部会使cache新增的内容被挤出去，显示到浏览器上 sleep(1); //让程序&quot;睡&quot;一秒钟，会让你把效果看得更清楚}?&gt; 注：如果在程序的首部加入ob_implicit_flush()打开绝对刷新,就可以在程序中不再使用flush(),这样做的好处是：提高效率！ 关于ob系列函数：我想先引用我的好朋友y10k的一个例子：Example 3. 比如你用得到服务器和客户端的设置信息，但是这个信息会因为客户端的不同而不同，如果想要保存phpinfo()函数的输出怎么办呢？在没有缓冲区控制之前，可以说一点办法也没有，但是有了缓冲区的控制，我们可以轻松的解决：程序代码 12345678&lt;?phpob_start(); //打开缓冲区phpinfo(); //使用phpinfo函数$info=ob_get_contents(); //得到缓冲区的内容并且赋值给$info$file=fopen(\\'info.txt\\',\\'w\\'); //打开文件info.txtfwrite($file,$info); //写入信息到info.txtfclose($file); //关闭文件info.txt?&gt; 用以上的方法，就可以把不同用户的phpinfo信息保存下来，这在以前恐怕没有办法办到！其实上面就是将一些”过程”转化为”函数”的方法！或许有人会问：”难道就这个样子吗？还有没有其他用途？”当然有了，比如笔者论坛的PHP 语法加亮显示就和这个有关（PHP默认的语法加亮显示函数会直接输出，不能保存结果，如果在每次调用都显示恐怕会很浪费CPU，笔者的论坛就把语法加亮函数显示的结果用控制缓冲区的方法保留了），大家如果感兴趣的话可以来看看 可能现在大家对ob_start()的功能有了一定的了解，上面的一个例子看似简单，但实际上已经掌握了使用ob_start()的要点。&lt;1&gt;.使用ob_start打开browser的cache，这样可以保证cache的内容在你调用flush(),ob_end_flush()（或程序执行完毕）之前不会被输出。&lt;2&gt;.现在的你应该知道你所拥有的优势：可以在任何输出内容后面使用header,setcookie以及session，这是 ob_start一个很大的特点；也可以使用ob_start的参数，在cache被写入后，然后自动运行命令，比如ob_start(\\ “ob_gzhandler&quot;)；而我们最常用的做法是用ob_get_contents()得到cache中的内容，然后再进行处理……&lt;3&gt;.当处理完毕后，我们可以使用各种方法输出，flush(),ob_end_flush(),以及等到程序执行完毕后的自动输出。当然，如果你用的是ob_get_contents()，那么就要你自己控制输出方式了。 来，让我们看看能用ob系列函数做些什么…… 一、 静态模版技术 简介：所谓静态模版技术就是通过某种方式，使得用户在client端得到的是由PHP产生的html页面。如果这个html页面不会再被更新，那么当另外的用户再次浏览此页面时，程序将不会再调用PHP以及相关的数据库，对于某些信息量比较大的网站，例如sina,163,sohu。类似这种的技术带来的好处是非常巨大的。 我所知道的实现静态输出的有两种办法：&lt;1&gt;.通过y10k修改的phplib的一个叫template.inc.php类实现。&lt;2&gt;.使用ob系列函数实现。对于第一种方法，因为不是这篇文章所要研究的问题，所以不再赘述。我们现在来看一看第二种方法的具体实现：Example 4. 程序代码 程序代码 12345678910&lt;?phpob_start();//打开缓冲区?&gt;php页面的全部输出&lt;?$content = ob_get_contents();//取得php页面输出的全部内容$fp = fopen(&quot;output00001.html&quot;, &quot;w&quot;); //创建一个文件，并打开，准备写入fwrite($fp, $content); //把php页面的内容全部写入output00001.html，然后……fclose($fp);?&gt; 这样，所谓的静态模版就很容易的被实现了…… 二、 捕捉输出 以上的Example 4.是一种最简单的情况，你还可以在写入前对$content进行操作……你可以设法捕捉一些关键字，然后去对它进行再处理，比如Example 3.所述的PHP语法高亮显示。个人认为，这个功能是此函数最大的精华所在，它可以解决各种各样的问题，但需要你有足够的想象力…… Example 5. 程序代码 程序代码 1234567891011121314&lt;?phpfunction run_code($code) { If($code) { ob_start(); eval($code); $contents = ob_get_contents(); ob_end_clean(); }else { echo &quot;错误！没有输出&quot;; exit();}return $contents;?&gt;} 以上这个例子的用途不是很大，不过很典型$code的本身就是一个含有变量的输出页面，而这个例子用eval把$code中的变量替换，然后对输出结果再进行输出捕捉，再一次的进行处理…… 二、 输出缓存句柄ob_gzhandler PHP4.0.4有一个新的输出缓存句柄ob_gzhandler，它与前面的类相似，但用法不同。使用ob_gzhandler时要在php.ini中加入的内容如下： output_handler = ob_gzhandler; 这行代码使得PHP激活输出缓存，并压缩它发送出去的所有内容。如果由于某种原因你不想在php.ini中加上这行代码，你还可以通过PHP源文件所在目录的.htaccess文件改变默认的服务器行为（不压缩），语法如下： 1php_value output_handler ob_gzhandler 或者是从PHP代码调用，如下所示： 1ob_start(&quot;ob_gzhandler&quot;); 采用输出缓存句柄的方法确实非常有效，而且不会给服务器带来什么特殊的负荷。但必须注意的是，Netscape Communicator对压缩图形的支持不佳，因此除非你能够保证所有用户都使用IE浏览器，否则你应该禁止压缩JPEG和GIF图形。一般地，对于所有其他文件，这种压缩都有效，但建议你针对各种浏览器都分别进行测试，特别是当你使用了特殊的插件或者数据查看器时这一点尤其重要。注意事项：1、一些Web服务器的output_buffering默认是4069字符或者更大，即输出内容必须达到4069字符服务器才会flush刷新输出缓冲，为了确保flush有效，最好在ob_flush()函数前有以下语句：代码如下: 1print str_repeat(&quot;&quot;, 4096); //以确保到达output_buffering值 2、ob_* 系列函数是操作PHP本身的输出缓冲区，所以ob_flush只刷新PHP自身的缓冲区，而flush是刷新apache的缓冲区。所以，正确使用俩者的顺序是：先ob_flush，然后flush。ob_flush是把数据从PHP的缓冲中释放出来，flush是把缓冲内/外的数据全部发送到浏览器。3、不要误认为用了ob_start()后，脚本的echo/print等输出就永远不会显示在浏览器上了。因为PHP脚本运行结束后，会自动刷新缓冲区并输出内容。","link":"/2020/11/18/ob%E7%B3%BB%E5%88%97%E5%87%BD%E6%95%B0%E6%80%BB%E7%BB%93/"},{"title":"order by 语句对null字段的默认排序","text":"1.oracle 结论 (null 最大) order by colum asc 时，null默认被放在最后 order by colum desc 时，null默认被放在最前 nulls first 时，强制null放在最前，不为null的按声明顺序[asc|desc]进行排序 nulls last 时，强制null放在最后，不为null的按声明顺序[asc|desc]进行排序 2.mysql,sql server 结论 (null 最小)order by colum asc 时，null默认被放在最前order by colum desc 时，null默认被放在最后ORDER BY IF(ISNULL(update_date),0,1) null被强制放在最前，不为null的按声明顺序[asc|desc]进行排序ORDER BY IF(ISNULL(update_date),1,0) null被强制放在最后，不为null的按声明顺序[asc|desc]进行排序 SELECT * FROM t1 where 1=1 ORDER BY IF(ISNULL(order_index),1,0),order_index asc,create_time desc mysql nulls first nulls last解决方案nulls first: order by IF(ISNULL(my_field),0,1),my_field;nulls last: order by IF(ISNULL(my_field),1,0),my_field;ISNULL函数当my_field字段为空是，返回1，当不为空时返回0 IF函数，如果第一个表达式为真，则返回第二个参数的值，否则，返回第三个参数的值。 EXTRACT(unit FROM date) pgsql null排在有值的行前面还是后面通过语法来指定 1234567891011--null值在前select * from tablename order by id nulls first;--null值在后select * from tablename order by id nulls last;--null在前配合desc使用select * from tablename order by id desc nulls first;--null在后配合desc使用select * from tablename order by id desc nulls last;举例:null值在后,先按照count1降序排列,count1相同再按照count2降序排列order by count1 desc nulls last, count2 desc nulls last; mysql的null值排序和pgsql相反https://www.w3school.com.cn/sql/func_extract.asp","link":"/2021/01/19/order%20by%20%E8%AF%AD%E5%8F%A5%E5%AF%B9null%E5%AD%97%E6%AE%B5%E7%9A%84%E9%BB%98%E8%AE%A4%E6%8E%92%E5%BA%8F/"},{"title":"php中日期函数date与gmdate在获取日期上的区别","text":"php中的二个日期格式化函数：date()和gmdate()。 date – 格式化一个本地时间／日期gmdate – 格式化一个 GMT/UTC 日期／时间，返回的是格林威治标准时（GMT）。 假如，现在所在的时区是+8，那么服务器运行以下脚本返回的时间应该为：当前时间假定是2013-03-14 12:15:27 12echo date('Y-m-d H:i:s', time()); 输出为：2013-03-14 12:15:27echo gmdate('Y-m-d H:i:s', time()); 输出为：2013-03-14 04:15:27 以上是在Linux+Apache下运行PHP所得的结果。 在Windows下运行，则2个函数返回都是：2013-03-14 04:15:27。 基于兼容性的考虑，我们需要统一使用gmdate，并手工设置当前时区，改进后的写法如下： 1echo gmdate('Y-m-d H:i:s', time() + 3600 * 8); 有了以上的代码，不管在Linux+Apache下还是Windows下都得到了正确的结果，这样写的另一个好处在于：网站用户只要设置所在的时区，程序自动根据用户设置的时区进行时间计算，数据库中信息发布时间只存当前的time()所生成的时间，那么在中国+8时区看到的发布时间是：2013-03-14 12:15:27，那么在欧洲+2时区用户看到这个信息的发布时间是：2013-03-14 06:15:27，这样信息的时间就全部对应正确了。 参考地址：https://www.cnblogs.com/kaka666/p/9744538.html","link":"/2022/04/23/php%E4%B8%AD%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0date%E4%B8%8Egmdate%E5%9C%A8%E8%8E%B7%E5%8F%96%E6%97%A5%E6%9C%9F%E4%B8%8A%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"php数字表示法和 位运算 与 或 异或 取反","text":"数字表示法1234$a = 1; # 十进制 $b = 0b0101; # 二进制$c = 01; # 八进制 php8.1可以使用 0o01$d = 0x12 # 16进制 进制转换函数bindec() — 二进制转换为十进制decbin() — 十进制转换为二进制dechex() — 十进制转换为十六进制decoct() — 十进制转换为八进制hexdec() — 十六进制转换为十进制octdec() — 八进制转换为十进制base_convert()– 在任意进制之间转换数字 位运算符php中有4个位运算，分别是&amp;与 |或 ^异或 ~取反 &amp; 两位全为1，结果为1 | 有一位为1，结果为1 ^ 一个为0，一个为1，结果为1 ~ 取反0-&gt;1，1-&gt;0 注意： 二进制的最高位是符号位，0表示正数，1表示负数。 正数的原码，反码，补码都一样。 负数的反码=它的原码符号位不变，其它位取反(0-&gt;1,1-&gt;0)。 负数的补码=它的反码+1。 0的反码，补码都是0. php没有无符号数，换言之，php中的数都是有符号的。 在计算机运算的时候，都是以补码的方式来运算的。 推理过程： 113&amp;7 13的补码 00000000 00000000 00000000 000011017的补码 00000000 00000000 00000000 0000011113&amp;7 00000000 00000000 00000000 00000101 = 5 15|4 5的补码 00000000 00000000 00000000 000001014的补码 00000000 00000000 00000000 000001005|4 00000000 00000000 00000000 000000101 =5 1-3^3 -3的补码-3的原码 10000000 00000000 00000000 00000011-3的反码 11111111 11111111 11111111 11111100-3的补码 11111111 11111111 11111111 11111101","link":"/2022/07/17/php%E6%95%B0%E5%AD%97%E8%A1%A8%E7%A4%BA%E6%B3%95%E5%92%8C%20%E4%BD%8D%E8%BF%90%E7%AE%97%20%E4%B8%8E%20%E6%88%96%20%E5%BC%82%E6%88%96%20%E5%8F%96%E5%8F%8D/"},{"title":"php中ob函数的用法","text":"与输出缓冲区有关的配置 在PHP.INI中,有两个跟缓冲区紧密相关的配置项 1.output_buffering 该配置直接影响的是php本身的缓冲区,有3种配置参数.on/off/xK(x为某个整型数值); on - 开启缓冲区 off - 关闭缓冲区 256k - 开启缓冲区,而且当缓冲区的内容超过256k的时候,自动刷新缓冲区(把数据发送到apache); 2.implicit_flush 该配置直接影响apache的缓冲区,有2种配置参数. on/off on - 自动刷新apache缓冲区,也就是,当php发送数据到apache的缓冲区的时候,不需要等待其他指令,直接就把输出返回到浏览器 off - 不自动刷新apache缓冲区,接受到数据后,等待刷新指令 而默认直接是开启缓冲区的，所以我们可以直接不用ob_start()，所以我先把缓冲区关闭 下面几个函数的用法 ob_start() - 打开缓冲区 ob_get_contents() - 返回输出缓冲区的内容 ob_flush() - 冲刷出（送出）输出缓冲区中的内容 ob_clean() - 清空（擦掉）输出缓冲区 ob_end_flush() - 冲刷出（送出）输出缓冲区内容并关闭缓冲 ob_end_clean() - 清空（擦除）缓冲区并关闭输出缓冲 flush() - 刷新输出缓冲 ob_start()在服务器打开一个缓冲区来保存所有的输出。所以在任何时候使用echo ，输出都将被加入缓冲区中，直到程序运行结束或者使用ob_flush()来结束。然后在服务器中缓冲区的内容才会发送到浏览器，由浏览器来解析显示。 123456789ob_start();echo &quot;Hello &quot;;$out1 = ob_get_contents();echo &quot;World&quot;;$out2 = ob_get_contents();123456789 输出： 1Hello World1 如果只是想要存储缓存区而不是输出的话加上ob_end_clean(); 1234567891011ob_start();echo &quot;Hello &quot;;$out1 = ob_get_contents();echo &quot;World&quot;;$out2 = ob_get_contents();ob_end_clean();1234567891011 可以看到浏览器上没有任何输出，这时我们加上var_dump来看看out1、out2两个变量 1234567891011121314ob_start();echo &quot;Hello &quot;;$out1 = ob_get_contents();echo &quot;World&quot;;$out2 = ob_get_contents();ob_end_clean();var_dump($out1, $out2);1234567891011121314 输出： 1string(6) &quot;Hello &quot; string(11) &quot;Hello World&quot;1 接下来讲ob_clean()跟ob_end_clean()的区别 使用 ob_end_clean() 123456789101112131415161718ob_start();echo &quot;Hello &quot;;$out1 = ob_get_contents();echo &quot;World1&quot;;$out2 = ob_get_contents();ob_end_clean();echo &quot;World2&lt;br&gt;&quot;;echo &quot;World3&lt;br&gt;&quot;;$out3 = ob_get_contents();var_dump($out3);123456789101112131415161718 输出： 123World2World3bool(false)123 使用 ob_clean() 123456789101112131415161718ob_start();echo &quot;Hello &quot;;$out1 = ob_get_contents();echo &quot;World1&quot;;$out2 = ob_get_contents();ob_clean();echo &quot;World2&lt;br&gt;&quot;;echo &quot;World3&lt;br&gt;&quot;;$out3 = ob_get_contents();var_dump($out3);123456789101112131415161718 输出： 123456World2World3string(20) &quot;World2World3&quot;12345 这里我们对out3使用转义函数 12var_dump(htmlentities($out3));1 输出： 1234WorldWorldstring(32) &quot;World&lt;br/&gt;World&lt;br/&gt;&quot;123 解释 ob_end_clean() 跟ob_clean() 都是清空了缓冲区，不让echo输出到浏览器,这是共同点，而不同点是ob_end_clean()还关闭了缓冲区 接下来讲ob_end_flush()跟ob_flush()跟flush()的区别 使用ob_end_flush() 123456789101112131415161718192021ob_start();echo &quot;Hello&lt;br/&gt;&quot;;$out1 = ob_get_contents();echo &quot;World1&lt;br/&gt;&quot;;$out2 = ob_get_contents();ob_end_flush();echo &quot;World2&lt;br/&gt;&quot;;echo &quot;World3&lt;br/&gt;&quot;;$out3 = ob_get_contents();var_dump(htmlentities($out3));1234567891011121314151617181920 输出 123456HelloWorld1World2World3string(0) &quot;&quot;12345 补充：这里为了显示容易观察，我全部都给了 使用ob_flush() 123456789101112131415161718192021ob_start();echo &quot;Hello&lt;br/&gt;&quot;;$out1 = ob_get_contents();echo &quot;World1&lt;br/&gt;&quot;;$out2 = ob_get_contents();ob__flush();echo &quot;World2&lt;br/&gt;&quot;;echo &quot;World3br/&gt;&quot;;$out3 = ob_get_contents();var_dump(htmlentities($out3));1234567891011121314151617181920 输出 123456HelloWorld1World2World3string(32) &quot;World2&lt;br/&gt;World3&lt;br/&gt;&quot;12345 使用flush() 1234567891011121314151617181920ob_start();echo &quot;Hello&lt;br/&gt;&quot;;$out1 = ob_get_contents();echo &quot;World1&lt;br/&gt;&quot;;$out2 = ob_get_contents();flush();echo &quot;World2&lt;br/&gt;&quot;;echo &quot;World3br/&gt;&quot;;$out3 = ob_get_contents();var_dump(htmlentities($out3));1234567891011121314151617181920 输出 12345HelloWorld1World2World3string(67) &quot;Hello&lt;br/&gt;World1&lt;br/&gt;World2&lt;br/&gt;World3&lt;br/&gt;&quot;12345 区别 可以看出ob_end_flush() 是输出了缓冲区的内容并且关闭了缓冲区,而ob_flush()只是刷出了缓冲区内容，相当于将缓冲区清空，而flush()输出了缓冲区内容也没有将缓冲区清空，所以下面的缓冲区内容还会继续追加。 总结 只能在实践中继续成长，有什么不对的地方望大家指出。 https://blog.csdn.net/qq_33862778/article/details/80787510 header(“Location:login.php”)应该注意的几个问题header(“Location:login.php”)应该注意的几个问题 header(“Location:”)作为php的转向语句。其实在使用中，他有几点需要注意的地方。 1、要求header前没有任何输出 但是很多时候在header前我们已经输出了好多东西了，此时如果再次header的话，显然是出错的，在这里我们启用了一个ob的概念，ob的意思是在服务器端先存储有关输出，等待适当的时机再输出，而不是像现在这样运行一句，输出一句,发现header语句就只能报错了。 具体的语句有： ob_start(); ob_end_clean();ob_flush();……… 2、在header(“Location:”)后要及时exit 否则他是会继续执行的，虽然在浏览器端你看不到相应的数据出现，但是如果你进行抓包分析的话，你就会看到下面的语句也是在执行的。而且被输送到了浏览器客户端，只不过是没有被浏览器执行为html而已（浏览器执行了header进行了转向操作）。 所以,标准的使用方法是： ob_start(); …….. if ( something ){ ob_end_clean(); header(“Location: yourlocation”)； exit; else{ ………. ob_flush(); //可省略 要想在header前有输出的话，可以修改php.ini文件 output_handler =mb_output_handler 或 output_handler =on Output Control 函数可以让你自由控制脚本中数据的输出。它非常地有用，特别是对于：当你想在数据已经输出后，再输出文件头的情况。输出控制函数不对使用 header() 或 setcookie(), 发送的文件头信息产生影响,只对那些类似于 echo() 和 PHP 代码的数据块有作用。一、 相关函数简介：1、Flush：刷新缓冲区的内容，输出。函数格式：flush()说明：这个函数经常使用，效率很高。2、ob_start ：打开输出缓冲区函数格式：void ob_start(void)说明：当缓冲区激活时，所有来自PHP程序的非文件头信息均不会发送，而是保存在内部缓冲区。为了输出缓冲区的内容，可以使用ob_end_flush()或flush()输出缓冲区的内容。3 、ob_get_contents ：返回内部缓冲区的内容。使用方法：string ob_get_contents(void)说明：这个函数会返回当前缓冲区中的内容，如果输出缓冲区没有激活，则返回 FALSE 。4、ob_get_length：返回内部缓冲区的长度。使用方法：int ob_get_length(void)说明：这个函数会返回当前缓冲区中的长度；和ob_get_contents一样，如果输出缓冲区没有激活。则返回 FALSE。5、ob_end_flush ：发送内部缓冲区的内容到浏览器，并且关闭输出缓冲区。使用方法：void ob_end_flush(void)说明：这个函数发送输出缓冲区的内容（如果有的话）。6、ob_end_clean：删除内部缓冲区的内容，并且关闭内部缓冲区使用方法：void ob_end_clean(void)说明：这个函数不会输出内部缓冲区的内容而是把它删除！7、ob_implicit_flush：打开或关闭绝对刷新使用方法：void ob_implicit_flush ([int flag])说明：使用过Perl的人都知道|=x的意义，这个字符串可以打开/关闭缓冲区，而obimplicitflush函数也和那个一样，默认为关闭缓冲区，打开绝对输出后，每个脚本输出都直接发送到浏览器，不再需要调用flush()obstart()开始输出缓冲,这时PHP停止输出,在这以后的输出都被转到一个内部的缓冲里.obgetcontents()这个函数返回内部缓冲的内容.这就等于把这些输出都变成了字符串.obgetlength()返回内部缓冲的长度.obendflush()结束输出缓冲,并输出缓冲里的内容.在这以后的输出都是正常输出.obendclean()结束输出缓冲,并扔掉缓冲里的内容.举个例子,vardump()函数输出一个变量的结构和内容,这在调试的时候很有用.但如果变量的内容里有&lt;,&gt;等HTML的特殊字符,输出到网页里就看不见了.怎么办呢?用输出缓冲函数能很容易的解决这个问题.obstart();vardump(var);out=obgetcontents();obendclean();这时vardump()的输出已经存在out 里了. 你可以现在就输出:echo ‘' . htmlspecialchars($out) . '‘ ;或者等到将来, 再或者把这个字符串送到模板(Template)里再输出.https://www.cnblogs.com/suizhikuo/archive/2012/11/26/2789101.html","link":"/2020/12/15/php%E4%B8%ADob%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95/"},{"title":"php的三种CLI常量：STDIN,STDOUT,STDERR","text":"PHP CLI(command line interface)中，有三个系统常量，分别是STDIN、STDOUT、STDERR，代表文件句柄。 应用一：12345&lt;?phpwhile($line = fopen('php://stdin','r')){ echo fgets($line);}?&gt; 应用二： 123&lt;?php echo STDIN;?&gt; 在dos命令行下直接返回STDIN文件指针(文件句柄) 应用三： 123&lt;?php echo fgets(STDIN);?&gt; STDIN可以拿到在dos下输入的内容，fgets读取这个STDIN文件句柄，即可打印出刚才输入的内容","link":"/2020/08/13/php%E7%9A%84%E4%B8%89%E7%A7%8DCLI%E5%B8%B8%E9%87%8F%EF%BC%9ASTDIN,STDOUT,STDERR/"},{"title":"PHP笔记","text":"函数 iconv(‘charset in’,’charset out’,$str); mb_convert_encoding($str,’charsetout’,’charsetin’); get_class_methods() 获取类方法，需要传递一个类名字符串 例如 People::class / ‘People’ ，get_class_vars() 获取类属性同上 。以上两个方法只能获取类中的public属性和方法。get_object_vars() set_exception_handler() ord() 返回字符串首个字符的ACSCII array_fill() 填充数组，range() 生成一个范围的数组 json_encode($arr,JSON_UNESCAPED_UNICODE) #256 将unicode转为汉字 zip_open() strpos 这类函数需要注意判断时候使用===false ,并且搜索值都要为字符串，数字要用引号 array_map($call,$arr) $call 只接受一个参数即数组的值 array_walk($arr,$call) $call接受两个参数即数组的值和键,preg_replace_callback() 这三个函数容易和闭包用在一起 pack() unpack() call_user_func() call_user_fuc_array() 第一个参数可以是数组形式的一个类/实例的方法，例如[‘test’,’eat’] 表示test类的eat方法，或者[$a,’eat’]表示$a实例的eat方法 compact() extract()从数组中将变量导入到符号表 php7新特性 $a??$b等同于isset($a) ? $a:$b,$a?:$b 等同于!empty($a) ? $a:$b array_shift() array_pop() array_unshift() array_push() array_merge_recursive() 不会对键进行覆盖而是相同键名递归组成一个数组 substr_count统计“子字符串”在“原始字符串中出现的次数 CLASS获取当前类名，get_class(对象)获取类名，get_called_class() 多用在继承的子类中获取主调类 12345678public static function getInstance() { $class_name = get_called_class(); if (isset(self::$instance[$class_name])) { return self::$instance[$class_name]; } self::$instance[$class_name] = new $class_name; return self::$instance[$class_name]; } constant() 返回一个常量的值 abs()取得绝对值 str_pad() 填补奇数位则右边优先，sprintf(”%05d”,1) 右边补零5个， sprintf(”%01.3f”,1);用一个小数点后最少三位不足三位补零，小数点前最少一位，不足一位补零的浮点数格式化后边的参数，sprintf(format,arg1,arg2,arg++) php可变参数个数，或者使用func_get_args() func_get_arg() func_num_args() 123456&lt;?phpfunction test(...$a){ return $a;}print_r(test(10,1,3)); strlen()计算的是字符串的总字节数，mb_strlen()计算字符个数；gbk中文1.5个（单个时占2个）；utf中文占1个字符（开启mbstring扩展，二是要指定字符集）。 http_build_query()函数的作用是使用给出的关联（或下标）数组生成一个经过 URL-encode 的请求字符串。 PHP中的ignore_user_abort函数是当用户关掉终端后脚本不停止仍然在执行，可以用它来实现计划任务与持续进程 eval() unset() 引用变量时候会检查变量是否还存在引用，存在的话之销毁该变量而不销毁变量的值 realpath(‘..’) dirname() getcwd() session_set_cookie_params(); 获取header ：get_headers() ,$http_response_header ,stream_get_meta_data() ,curl扩展 ob_start() 123456789&lt;?phpob_start();echo 'one';$data[] = ob_get_contents();ob_flush();echo 'two';$data[] = ob_get_contents();print_r($data); quotemeta() 函数在字符串中某些预定义的字符前添加反斜杠。 预定义的字符： 句号（.） 反斜杠（\\） 加号（+） 星号（*） 问号（?） 方括号（[]） 脱字号（^） 美元符号（$） 圆括号（()） 提示：该函数可用于转义拥有特殊意义的字符，比如 SQL 中的 ( )、[ ] 以及 * 。 注释：该函数是二进制安全的。 术语 缓存控制中间件 算力（也称哈希率）是比特币网络处理能力的度量单位。即为计算机（CPU）计算哈希函数输出的速度。比特币网络必须为了安全目的而进行密集的数学和加密相关操作。 例如，当网络达到10Th/s的哈希率时，意味着它可以每秒进行10万亿次计算。 迭代是重复反馈过程的活动，其目的通常是为了逼近所需目标或结果。每一次对过程的重复称为一次“迭代”，而每一次迭代得到的结果会作为下一次迭代的初始值。 重复执行一系列运算步骤，从前面的量依次求出后面的量的过程。此过程的每一次结果，都是由对前一次所得结果施行相同的运算步骤得到的。例如利用迭代法*求某一数学问题的解。 对计算机特定程序中需要反复执行的子程序*(一组指令)，进行一次重复，即重复执行程序中的循环，直到满足某条件为止，亦称为迭代。（php迭代器）生成器是一个简单的迭代器 URI（Uniform Resource Identifier统一资源标识符）标识抽象或者物理资源的紧凑字符串 URL（Uniform Resource Locator统一资源定位器）定位资源主要访问机制的字符串 URN（Uniform Resource Name[统一资源名称）通过特定命名空间中的唯一名称或ID来标识资源 例如：身份证号是URN,家庭地址就是URL。 权重：一指某一因素或指标相对于某一事物的重要程度，其不同于一般的比重，体现的不仅仅是某一因素或指标所占的百分比，强调的是因素或指标的相对重要程度，倾向于贡献度或重要性。通常，权重可通过划分多个层次指标进行判断和计算，常用的方法包括层次分析法、模糊法、模糊层次分析法和专家评价法等；二指贡献度；三指权利、大权。 汉字的ASCII 汉字的ASCII是负数是因为你错误使用有符号的整型观察它，它实质上不是负数。 相关问题细节如下： 英文标准的ASCII码中只有128个符号，只需要7位，但是计算机分配存储的最基本单位是字节，至少是8位，因此最高位为0； 因此常见的西文符号的ASCII都是在0-127之间，无论是有符号还是无符号去观察它们，都是正的。 中文的符号远超过256个，因此用一个字节不能存储汉字，早期的GB2312采用了两个字节。 但是很麻烦的问题是一个汉字用两个字节存储在计算机中后，和两个西文字母的ASCII混淆，为了避免这个混淆，汉字两个字节的最高位都是1。 如果用有符号的数去读取一个汉字的内容，最高位的1正好和负号位置相同，因此此时就会发现汉字的内吗是负的。 实质上汉字应该用字符型而不是整型去读取和显示它。## 术语 其他HttpOnly可选,设置了HttpOnly属性的cookie不能使用,JavaScript 经由Document.cookie属性,XMLHttpRequest和Request APIs进行访问，以防范跨站脚本攻击(xSS)。 1.如何设计一个高并发的系统①数据库的优化，包括合理的事务隔离级别、SQL语句优化、索引的优化使用缓存，尽量减少数据库IO 考虑到当前的局限性，在MySQL 5.7的生存期内将继续支持查询缓存。MySQL 8.0将不支持查询缓存，并且鼓励用户升级以使用服务器端查询重写或ProxySQL作为中间人缓存。MySQL 8.0：不再支持查询缓存 分布式数据库、分布式缓存服务器的负载均衡 php如何实现保存网络图片（代码） 123456789101112131415161718192021222324252627282930313233function file_exists_S3($url) { $state = @file_get_contents($url,0,null,0,1);//获取网络资源的字符内容 if($state){ $filename = date(&quot;dMYHis&quot;).'.jpg';//文件名称生成 ob_start();//打开输出 readfile($url);//输出图片文件 $img = ob_get_contents();//得到浏览器输出 ob_end_clean();//清除输出并关闭 $size = strlen($img);//得到图片大小 $fp2 = @fopen($filename, &quot;a&quot;); fwrite($fp2, $img);//向当前目录写入图片文件，并重新命名 fclose($fp2); return 1; } else{ return 0; } } ASCII : 0 -&gt; 48 A -&gt; 65 a -&gt; 97 是一条错误的笔记 在utf8mb4编码下英文占用1字节，一般汉字占用3字节， emoji表情占用4字节。可以使用length(字段)或者char_length(字段)查询长度 优先级 算比逻条赋[赋值大于and|or]逗 GD库1.6.2版以前支持GIF格式，但因GIF格式使用LZW演算法牵涉专利权，因此在GD1.6.2版之后不支持GIF的格式。如果你是WINDOWS的环境，你只要进入PHP.INI文件找到extension=php_gd2.dll，将#去除，重启APACHE即可，如果你是Linux环境，又想支持GIF，PNG，JPEG，你需要去下载libpng，zlib，以及freetype字体并安装。 一般视为无差，utc是以原子时计时，更加精准，适应现代社会的精确计时。不过一般使用不需要精确到秒时，视为等同。gmt是前世界标准时，utc是现世界标准时。每年格林尼治天文台会发调时信息，基于utc。格林尼治bai标准时间（GMT，旧译“格林威治平du均时间”或“zhi格林威治标准时间”）是指位于伦敦郊区的dao皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。UTC表示世界协调时 GMT表示东八区，中国时区，协调世界时(UTC) 英文：Coordinated Universal Time ，别称：世界统一时间，世界标准时间，国际协调时间， 协调世界时，又称世界统一时间，世界标准时间，国际协调时间，简称UTC。它从英文“Coordinated Universal Time”／法文“Temps Universel Cordonné”而来。GMT（Greenwish Mean Time 格林威治平时），这是UTC的民间名称。GMT=UTC。 短语运算符 $a &gt; 0 &amp;&amp; echo ‘$a &gt; 0’; 用ini_set修改session.save_handler要把 “session.auto_start = 1 改成 session.auto_start = 0 常量和变量的性能上的区别：简单数据类型如整数等，常量编译采用立即数方式，要快一点，也节约空间；变量采用间接寻址，慢一两个周期，需要额外空间。如果是复杂数据类型，例如字符串就差不多了。 使用系统类需要加到根空间即\\线，才能调用根空间的类。或者引入use \\PDO,下面就可以不写斜线。异常类也需要加斜线或者引入，出错终止需要封锁运行 self调用静态方法时(本类)，是在子类未实例化调用之前就已经绑定完毕，所以原先在父类中指向的就是父类中的方法。而static是在实例化的时候才进行绑定指向的是此时实例化的类，也就是子类。 计算机字长指的是计算机一次能处理的二进制数的位数，例如16，32，64位，这样的一个数称为一个字，类似的还有双字，多字。 正数的原码法码和补码相同，负数的反码为原码除了符号位之外的数字取反之后加1，补码是为了让计算机更好的计算减法，同时统一符号位和整数位。 在不开启 持久链接 PDO::ATTR_PERSISTENT 情况下脚本结束的时候会自动关闭连接 Heredoc :PHP定界符的作用就是按照原样，包括换行格式什么的，输出在其内部的东西；2.在PHP定界符中的任何特殊字符都不需要转义；3.PHP定界符中的PHP变量会被正常的用其值来替换。这个可以用来保存大段的文本比较有用。 123echo &lt;&lt;&lt;EOT //内容EOT; //前面不能有任何空格或缩进 静态局部变量的初始化是在编译时进行的，因此在程序开始执行的时候就始终存在，也就是说它的生命期为整个源程序，但是其作用域仍与自动变量相同。在定义时用常量或者常量表达式进行赋值。未赋值编译时系统自动赋值为0。静态局部变量具有可继承性。 TP数据库操作，Db类插入数据的insert里第二个参数，传入ture，怎么做到有数据就更新，没有数据就插入 replace into 跟 insert 功能类似，不同点在于：replace into 首先尝试插入数据到表中，如果发现表中已经有此行数据（根据主键或者唯一索引判断）则先删除此行数据，然后插入新的数据。 否则，直接插入新数据。要注意的是：插入数据的表必须有主键或者是唯一索引！否则的话，replace into 会直接插入数据，这将导致表中出现重复的数据。 PHP静态类型变量的销毁1234567891011121314151617181920212223242526272829303132&lt;?phpclass Teacher{ private static $_instance; private $_props = []; private function __construct(){} public function __destruct() { echo '666'; } public static function getInstance() { if (empty(self::$_instance)) { self::$_instance = new self(); } return self::$_instance; } public function setProperty($key, $val) { $this-&gt;_props[$key] = $val; } public function getProperty($key) { return $this-&gt;_props[$key]; }}$t1 = Teacher::getInstance();$t1-&gt;setProperty('name', 'lily');unset($t1);//var_dump($t1);$t2 = Teacher::getInstance();echo $t2-&gt;getProperty('name'); 上例代码中虽然unset了$t1但是$t2仍能取到name的值。但如果不是单例模式是动态的对象存储时则不行。 如果在函数中 unset() 一个静态变量，那么在函数内部此静态变量将被销毁。但是，当再次调用此函数时，此静态变量将被复原为上次被销毁之前的值。来源：http://php.net/manual/zh/function.unset.php 所以，我们要注销一个静态变量，需要重新静态定义该变量为null。 参考如下 ： 123456789101112&lt;?phpfunction test() { static $test; $test++; echo($test . &quot; &quot;); //1 unset($test); $test = 2; echo($test . &quot; &quot;); //2}test();test();test(); 输出 ：1 2 2 2 3 2 因为每次定义static $test时被销毁的值被重新拿了回来并继续向下+1；而下方的$test在函数结束一次调用后即被销毁。 ##获取文件格式码 12345$file = fopen($filename, &quot;rb&quot;);$bin = fread($file, 2); //只读2字节fclose($file);$strInfo = @unpack(&quot;C2chars&quot;, $bin);$typeCode = intval($strInfo['chars1'].$strInfo['chars2']); bindParam和bindValue的区别 PDOStatement::bindParam不能绑定常量，而bindValue可以绑定常量 如 $stm-&gt;bindParam(“:sex”,$sex); //正确 $stm-&gt;bindParam(“:sex”,”female”); //错误 $stm-&gt;bindValue(“:sex”,$sex); //正确 $stm-&gt;bindValue(“:sex”,”female”); //正确 bindParam 变量被以引用方式绑定到点位符上,而且仅仅当调用PDOStatement::execute()时才会去计算具体被绑定变量在PDOStatement::execute()被调用时的值. 例如，使用bindParam方式： bindColumn bindValue bindParam bindparam只能传递引用，而bindvalue可以传递值或者引用 sprintf()参数 format 是转换的格式，以百分比符号 (“%”) 开始到转换字符结束。下面的可能的 format值： %% - 返回百分比符号 %b - 二进制数 %c - 依照 ASCII 值的字符 %d - 带符号十进制数 %e - 可续计数法（比如 1.5e+3） %u - 无符号十进制数 %f - 浮点数(local settings aware) %F - 浮点数(not local settings aware) %o - 八进制数 %s - 字符串 %x - 十六进制数（小写字母） %X - 十六进制数（大写字母） arg1, arg2, ++ 等参数将插入到主字符串中的百分号 (%) 符号处。该函数是逐步执行的。在第一个 % 符号中，插入 arg1，在第二个 % 符号处，插入 arg2，依此类推。 12345&lt;?php $number = 123;$txt = sprintf(&quot;%f&quot;,$number); echo $txt;?&gt; \\3. 格式数字 number_format() 保留两位小数并且四舍五入 12$num = 123213.8889echo sprintf(&quot;%.2f&quot;, $num); 保留两位小数并且不四舍五入 12$num = 123213.666666; echo sprintf(&quot;%.2f&quot;,substr(sprintf(&quot;%.3f&quot;, $num), 0, -2)); php进一法取整 12echo ceil(4.3); // 5 echo ceil(9.999); // 10 php舍去法，取整数 12echo floor(4.3); // 4 echo floor(9.999); // 9 预定义接口 Traversable 可遍历接口Countable 可count接口 XSSXSS又叫CSS（cross-site script）,跨站脚本攻击。恶意攻击者往Web页面里插入恶意html代码，当用户浏览该页时，嵌入其中Web里面的html代码会被执行，从而达到恶意用户的特殊目的 办法：htmlspecialchars()htmlspecialchars()把一些预定义的字符转换为html实体。 PHP包含include和requireinclude与require语句用于在执行流中插入卸载其他文件中的有用的代码。include和require除了处理错误的方式不同之外，在其他地方都是相同的 require生成一个致命错误(E_COMPILE_ERROR),在错误发生后脚本会停止执行 include生成一个警告(E_WARNING)，在错误发生后脚本会继续执行 include_once及require_once只引入一次，且使用后失效，多次引入也只能使用一次Cookiecookie常用于识别用户。是一种服务器留在用户计算机上的小文件，当同一台计算机通过浏览器请求页面时，这台计算机将会发送cookie创建Cookie:setcookie(name,value,expire,path,domain)取回cookie的值：$_COOKIE使用 isset()函数确认是否已经设置了cookie Sessionsession变量用于存储关于用户会话(session)的信息，或者更改用户会话的设置。session变量存储单一用户的信息，并对于应用程序中所有页面都是可用的。session通过在服务器生存储用户信息以便随后使用，会话信息是临时的，在用户离开网站后将被删除。session工作机制：为每个访客创建一个唯一的id（UID），并基于这个UID来存储变量。UID存储在cookie中，或者通过URL进行传导开启session:session_start()存储和获得session变量：$_SESSION销毁session：unset()或者session_destroy()（session_destroy彻底重置session，将失去所有的session数据） 错误处理基本的错误处理:使用die()函数创建自定义错误处理器语法：error_function(error_level,error_message,error_file,error_line,error_context) 参数 描述 error_level 必需。为用户定义的错误规定错误报告级别 error_message 必需。为用户定义的错误规定错误消息 error_file 可选。规定错误发声的文件名 error_line 可选。规定错误发生的行号 error_context 可选。规定一个数组，包含了当错误发生时在用的每个变量和值 设置错误处理程序PHP的默认错误处理程序是内建的错误处理程序。可以修改错误处理程序，使其仅应用到某些错误，这样脚本就能以不同的方式处理不同的错误。set_error_handler(eorr_name,error_level) 错误记录默认情况下，根据在php.ini中的error_log配置，使用error_log()函数，可以向指定文件或远程目的地发送错误记录 Exception异常处理用于在指定的错误发生时改变脚本的正常流程。当异常发生时，通常会： 当前代码状态被保存 代码执行被切换到预定义（自定义）的异常处理器函数 根据情况，处理其也会从保存的代码状态重新开始执行代码，种植脚本执行，或从代码中另外的位置继续执行脚本 注意：异常应该仅仅在错误情况下使用，而不应该用在一个指定的点跳转到代码的另一个位置 过滤器过滤器用于验证和过滤来自非安全来源的数据测试、验证和过滤用户输入或自定义数据是任何Web应用程序的重要组成部分 为什么使用过滤器？几乎所有的Web应用程序都以来外部的输入。这些数据通常来自用户或其他应用程序。通过使用过滤器，能够保证应用程序获取正确的输入类型。什么是外部数据？ 来自表单的输入数据 Cookies Web services data 服务器变量 数据库查询结果 函数和过滤器过滤变量，函数： filter_var()通过一个指定的过滤器来过滤单一的变量 filter_var_array()通过相同或不同的顾虑其来过滤多个变量 filter_input获取一个输入变量，并对它进行过滤 filter_input_array获取多个输入变量，并通过相同的或不同的过滤器对它们进行过滤 Validating 和 SanitizingValidating过滤器： 用于验证用户输入 严格的格式规则 成功则返回预期的类型，否则返回false Sanlitizing过滤器： 用于允许或禁止字符串中指定的字符 无数据格式规则 始终返回字符串 http://blog.kaiot.xyz/read/52.html 进度条1234567891011121314function showProgress(int $total, int $done){ $progress = (int)ceil($done / $total * 100); printf(&quot;\\033[32m%s\\033[0m\\033[33m%s\\033[0m %d%%\\r&quot;, str_repeat('━', $progress), str_repeat('━', 100 - $progress), $progress);}$total = 100;for ($i = 1; $i &lt;= $total; $i++) { usleep(500); showProgress($total, $i);}echo &quot;\\n&quot;;","link":"/2021/03/10/php%E7%AC%94%E8%AE%B0/"},{"title":"php笔试、面试题收录（持续更新）","text":"php中isset,empty,is_null,?:,??is_nullbool is_null ( mixed $var ) 当参数满足下面三种情况时，is_null()将返回TRUE，其它的情况就是FALSE1、它被赋值为NULL2、它还没有赋值3、它未定义，相当于unset()处理过的变量issetbool isset ( mixed $var [, mixed $… ] )，参数是一个变量 检测参数已设定，并且不是NULL。如果没有设置变量，变量未赋值，或变量被设为NULL，isset()函数就返回NULL。正好和is_null()函数相反，is_null()为TRUE的情况在isset()中就为FALSE。如果传递多个参数，将取交集。即所有参数全部符合 isset() 时才返回 TRUE。emptybool empty ( mixed $var ) 判读变量是否为空。empty()为TRUE的情况，若变量不存在，或者变量存在且其值为””、0、”0”、NULL、FALSE、array()、var $var; 以及没有任何属性的对象，则返回 TURE。?:$b = $a?:1等于 $b = !empty($a)?$a:1 ,若$a为空，则赋值为1，否则取$a的值 ??$b = $a??$c等于$b = isset($a)?$a:$c,若$a未设定，返回$c,否则返回$a date类问题strtotime()函数的作用是将日期时间描述解析为 Unix 时间戳 int strtotime ( string time [, int now] ) 示例： echo “今天:”.date(“Y-m-d”);echo “昨天:”.date(“Y-m-d”,strtotime(“-1 day”));echo “明天:”.date(“Y-m-d”,strtotime(“+1 day”));echo “一周后:”.date(“Y-m-d”,strtotime(“+1 week”));echo “一周零两天四小时两秒后:”.date(“Y-m-d G:H:s”,strtotime(“+1 week 2 days 4 hours 2 seconds”));echo “下个星期四:”.date(“Y-m-d”,strtotime(“next Thursday”));echo “上个周一:”.date(“Y-m-d”,strtotime(“last Monday”));echo “一个月前:”.date(“Y-m-d”,strtotime(“last month”));echo “一个月后:”.date(“Y-m-d”,strtotime(“+1 month”));echo “十年后:”.date(“Y-m-d”,strtotime(“+10 year”));主要考虑date()函数和strtotime()函数 require 和 include require是无条件包含也就是如果一个流程里加入require,无论条件成立与否都会先执行require include有返回值，而require没有(可能因为如此require的速度比include快) 包含文件不存在或者语法错误的时候require是致命的错误终止执行,include不是原文地址：https://learnku.com/articles/28758 数据库主从复制、读写分离什么是主从复制主从复制，是用来建立一个和主数据库完全一样的数据库环境，称为从数据库；主从复制的原理：1.数据库有个bin-log二进制文件，记录了所有的sql语句。2.只需要把主数据库的bin-log文件中的sql语句复制。3.让其从数据的relay-log重做日志文件中在执行一次这些sql语句即可。主从复制的作用1.做数据的热备份，作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作，避免数据丢失。2.架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问频率，提高单机的I/O性能3.主从复制是读写分离的基础，使数据库能制成更大 的并发。例如子报表中，由于部署报表的sql语句十分慢，导致锁表，影响前台的服务。如果前台服务使用master，报表使用slave，那么报表sql将不会造成前台所，保证了前台的访问速度。主从复制的几种方式：1.同步复制：所谓的同步复制，意思是master的变化，必须等待slave-1,slave-2,…,slave-n完成后才能返回。2.异步复制：如同AJAX请求一样。master只需要完成自己的数据库操作即可。至于slaves是否收到二进制日志，是否完成操作，不用关心。MYSQL的默认设置。3.半同步复制：master只保证slaves中的一个操作成功，就返回，其他slave不管。这个功能，是由google为MYSQL引入的。关于读写分离在完成主从复制时，由于slave是需要同步master的。所以对于insert/delete/update这些更新数据库的操作，应该在master中完成。而select的查询操作，则落下到slave中。原文地址：https://learnku.com/articles/28758 数据库索引什么是索引索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。（摘自百度百科）索引类型1.FULLTEXT 全文索引 全文索引，仅MyISAM引擎支持。其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。2.HASH 哈希索引 HASH索引的唯一性及类似键值对的形式十分适合作为索引，HASH索引可以一次定位，不需要像树形索引那样逐层参照，因此具有极高的效率。但是这种高效是有条件的。即只在“=”和“in”条件下高效，对于范围查询，排序及组合索引仍然效率不高。3.BTREE 树形索引 BTREE所以是一种将索引按一定算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，一次遍历node，获取leaf。这是MySQL中默认也是最常用的索引类型。4.RTREE RTREE在MySQL中很少使用，仅支持geometry数据类型，支持该存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。相对于BTREE，RTREE的优势在于范围查找。索引种类普通索引：仅加速查询唯一索引：加速查询+列值唯一（可以有null）主键索引：加速查询+列值唯一（不可以有null）+表中只有一个组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并全文索引：对文本内容进行分词，进行搜索外键索引：与主键索引形成联系，保证数据的完整性。索引使用的注意事项1.符合索引遵循前缀原则2.like查询%不能再前，否则索引失效。如有需要，使用全文索引3.column is null可以使用索引4.如果MySQL估计使用索引比全表扫描慢，则放弃使用索引5.如果or前的条件中列有索引，后面的没有，索引不会生效。6.列类型是字符串，查询时，一定要给值加引号，否则索引失效。7.确定order by 和 group by 中只有一个表的列，这样才能使用索引原文地址：https://learnku.com/articles/28758 高并发的解决方案web服务器优化 ：负载均衡流量优化：防盗链处理 将恶意请求屏蔽，前端优化：减少http请求、添加异步请求、启用浏览器缓存和文件压缩、cdn加速、建立独立的图片服务器、服务端优化： 页面静态化、并发处理、队列处理、数据库优化： 数据库缓存、分库分表、分区操作 、读写分离、负载均衡原文地址：https://learnku.com/articles/28758 接口与抽象类的区别 接口（1）对接口的使用是通过关键字implements（2）接口不能定义成员变量（包括类静态变量），能定义常量（3）子类必须实现接口定义的所有方法（4）接口只能定义不能实现该方法（5）接口没有构造函数（6）接口中的方法和实现它的类默认都是public类型的 抽象类（1）对抽象类的使用是通过关键字extends（2）不能被实例化，可以定义子类必须实现的方法（3）子类必须定义父类中的所有抽象方法，这些方法的访问控制必须和父类中一样（或者更为宽松）（4）如一个类中有一个抽象方法，则该类必须定义为抽象类（5）抽象类可以有构造函数（6）抽象类中的方法可以使用private,protected,public来修饰。（7）一个类可以同时实现多个接口，但一个类只能继承于一个抽象类。 Final类/方法（1）final类不能被继承（2）final方法不能被重写 Static类/方法(1)可以不实例化类而直接访问(2)静态属性不可以由对象通过-&gt;操作符来访问,用::方式调用原文地址：https://learnku.com/articles/28758 php获取上级文件目录echo FILE ; // 获取当前所在文件的绝对路径及地址，结果：D:\\aaa\\my.phpecho dirname(FILE); // 取得当前文件所在的绝对目录，结果：D:\\aaa\\echo dirname(dirname(FILE)); //取得当前文件的上一层目录名，结果：D:\\原文：https://blog.csdn.net/viqecel/article/details/80765275 HTTP状态码1**信息，服务器收到请求，需要请求者继续执行操作2**成功，操作被成功接收并处理3**重定向，需要进一步的操作以完成请求4**客户端错误，请求包含语法错误或无法完成请求5**服务器错误，服务器在处理请求的过程中发生了错误详细参照：https://www.runoob.com/http/http-status-codes.html 设计模式简单工厂模式：根据产品接口，创建多个产品类，由一个工厂类返回多种产品对象工厂模式：根据产品接口，创建多个产品类，并创建多个工厂类，由一个工厂使用类调用多个工厂对象来制造多种产品对象单例模式：保证一个类有且只有一个实例，且提供一个访问它的全局控制点策略模式：一个策略接口，多个具体策略类，一个策略使用类 三大范式第一范式：确保每列保持原子性第二范式：确保表中每列都和主键相关第三范式：确保每列都和主键列直接相关，而不是间接相关 面向对象面向过程是具体化的，流程化的，解决一个问题，你需要一步一步的分析，一步一步的实现。面向对象是模型化的，你只需抽象出一个类，这是一个封闭的盒子，在这里你拥有数据也拥有解决问题的方法。需要什么功能直接使用就可以了，不必去一步一步的实现，至于这个功能是如何实现的，管我们什么事？我们会用就可以了。面向对象的底层其实还是面向过程，把面向过程抽象成类，然后封装，方便我们使用的就是面向对象了。面向对象的三大特征和五大基本原则面向对象的三大特征：封装、继承、多态五大基本原则：单一职责原则：类的功能要单一开放封闭原则：模块对于拓展是开放的，修改是封闭的里式替换原则：子类可以代替父类出现在父类可以出现的任何地方依赖倒置原则：高层次的模块不应该依赖于低层次模块，他们都应该依赖于抽象。抽象不应该依赖于具体实现，具体实现应该依赖于抽象。就如同在国外，‘我是中国人’，而不是‘我是**村的人’接口分离原则：接口的功能也具有单一性，需要尽可能的拆分 转载 http://blog.kaiot.xyz/read/55.html","link":"/2020/08/15/php%E7%AC%94%E8%AF%95%E3%80%81%E9%9D%A2%E8%AF%95%E9%A2%98%E6%94%B6%E5%BD%95%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/"},{"title":"postgresql","text":"sudo -i -u postgres 登录\\l列出所有数据库\\c 数据库名 选择数据库\\d 列出数据表\\d 表名 列出数据表的结构create database chengyao; 创建数据库drop database chengyao;删除数据库psql -h localhost -p 5432 -U cheng postgres登录select pg_roles.rolname from pg_roles; 查看角色grant role_name to username; 赋予角色修改一个字段为非null ： alter table users alter username set not null; \\x切换到竖排显示select * from ps_proc;查询存储过程 一、建立数据库连接接入PostgreSQL数据库: psql -h IP地址 -p 端口 -U 数据库名 之后会要求输入数据库密码 二、访问数据库 1、列举数据库：\\l2、选择数据库：\\c 数据库名3、查看该某个库中的所有表：\\dt4、切换数据库：\\c interface5、查看某个库中的某个表结构：\\d 表名6、查看某个库中某个表的记录：select * from apps limit 1;7、显示字符集：\\encoding8、退出psgl：\\q ================================================================================== 列出当前数据库所有表\\dt 列出表名SELECT tablename FROM pg_tables;WHERE tablename NOT LIKE ‘pg%’AND tablename NOT LIKE ‘sql_%’ORDER BY tablename; 列出数据库名\\l或SELECT datname FROM pg_database; 切换数据库\\c 数据库名 1、通过命令行查询\\d 数据库 —— 得到所有表的名字\\d 表名 —— 得到表结构2、通过SQL语句查询“select * from pg_tables” —— 得到当前db中所有表的信息（这里pg_tables是系统视图）“select tablename from pg_tables where schemaname=’public’” —— 得到所有用户自定义表的名字（这里”tablename”字段是表的名字，”schemaname”是schema的名字。用户自定义的表，如果未经特殊处理，默认都是放在名为public的schema下） View Code ================================================================================== postgresql数据管理系统使用命令方式有两种: 内部命令,以反斜线开始 \\ ,如: \\l 显示所有数据库 标准SQL命令,以分号 ; 或 \\g 结束,可以使用多行 数据库的关键操作: 启动服务 2. 登录 3. 建立数据库 4. 建立表 5. 插入记录到表中 更新/删除/查询/修改操作 7. 退出 8. 停止服务 在windows7中安装的postgresql默认使用GBK字符集,经常不能使用显示中文的数据表,解决办法:注意:在windows 7下的postgresql中写操作时要使用GBK,读操作时要用UTF8; 设置字符集为 utf-8 就可以了.postgres=# \\encoding utf-8 // 设置客户端的字元集postgres=# \\encoding // 显示客户端的字元集postgres=# show client_encoding; // 显示客户端的字元集postgres=# show server_encoding; // 显示服务器的字元集 启动服务:net start postgresql-9.5停止服务:net stop postgresql-9.5 获取命令帮助:c:&gt; psql –help 登录( 注意: postgres 是默认用户即管理员 ):路径 psql -h 服务器 -U 用户名 -d 数据库 -p 端口地址 // -U 是大写C:&gt; psql -h localhost -U postgres -p 5432 // 默认打开postgres数据库C:&gt; psql -h 127.0.0.1 -U postgres -d fengdos -p 5432 // 打开fengdos数据库C:&gt; psql -U postgres // 快速登录(全部使用默认设置)// 使用某些有密码的用户的情况下, 会提示输入密码.用户 postgres 的口令: ILoveYou // 输入时不会显示任何字符// 成功后显示:psql (9.5.3)输入 “help” 来获取帮助信息.// 进入postgresql数据库系统提示符状态, ******=# 中=#前面为当前使用的数据库postgres=# help // 获取系统帮助,显示如下: 您正在使用psql, 这是一种用于访问PostgreSQL的命令行界面键入：\\copyright 显示发行条款 \\h 显示 SQL 命令的说明 ? 显示 pgsql 命令的说明 (pgsql内部命令) \\g 或者以分号(;)结尾以执行查询 \\q 退出注: 数据库名称区分大小写的。 postgres=# \\help // 获取SQL命令的帮助,同 \\hpostgres=# \\quit // 退出,同 \\qpostgres=# \\password dlf // 重新设置用户dlf的密码,然后需要 \\q退出后才生效c:&gt;psql exampledb &lt; user.sql // 将user.sql文件导入到exampled数据库中postgres=# \\h select // 精细显示SQL命令中的select命令的使用方法postgres=# \\l // 显示所有数据库postgres=# \\dt // 显示当前数据库中的所有表postgres=# \\d [table_name] // 显示当前数据库的指定表的表结构postgres=# \\c [database_name] // 切换到指定数据库,相当于usepostgres=# \\du // 显示所有用户postgres=# \\conninfo // 显示当前数据库和连接信息postgres=# \\e // 进入记事本sql脚本编辑状态(输入批命令后关闭将自动在命令行中执行)postgres=# \\di // 查看索引(要建立关联)postgres=# \\prompt [文本] 名称 // 提示用户设定内部变数postgres=# \\encoding [字元编码名称] // 显示或设定用户端字元编码*可以将存储过程写在文本文件中aaa.sql,然后在psql状态下:postgres=# \\i aaa.sql // 将aaa.sql导入(到当前数据库)postgres=# \\df // 查看所有存储过程（函数）postgres=# \\df+ name // 查看某一存储过程postgres=# select version(); // 获取版本信息postgres=# select usename from pg_user; // 获取系统用户信息postgres=# drop User 用户名 // 删除用户 其它SQL命令通用如(标准化SQL语句):*创建数据库：create database [数据库名]; *删除数据库：drop database [数据库名]; *创建表：create table ([字段名1] [类型1] ;,[字段名2] [类型2],……&lt;,primary key (字段名m,字段名n,…)&gt;;); *在表中插入数据：insert into 表名 ([字段名m],[字段名n],……) values ([列m的值],[列n的值],……); *显示表内容:select * from student; *重命名一个表：alter table [表名A] rename to [表名B]; *删除一个表：drop table [表名]; *在已有的表里添加字段：alter table [表名] add column [字段名] [类型]; *删除表中的字段：alter table [表名] drop column [字段名]; *重命名一个字段：alter table [表名] rename column [字段名A] to [字段名B]; *给一个字段设置缺省值：alter table [表名] alter column [字段名] set default [新的默认值]; *去除缺省值：alter table [表名] alter column [字段名] drop default; *修改表中的某行某列的数据：update [表名] set [目标字段名]=[目标值] where [该行特征]; *删除表中某行数据：delete from [表名] where [该行特征];delete from [表名]; // 删空整个表 *可以使用pg_dump和pg_dumpall来完成。比如备份sales数据库：pg_dump drupal&gt;/opt/Postgresql/backup/1.bak =================================================================================================== 1.列出所有表名的查询语句SELECT tablename FROM pg_tablesWHERE tablename NOT LIKE ‘pg%’AND tablename NOT LIKE ‘sql_%’ORDER BY tablename; 2.列出表中所有的数据 SELECT * FROM someTable; 3.执行外部脚本#/opt/PostgreSQL/8. 3/bin/psql - Upostgres ;登陆到数据库的控制台界面postgres= # \\i /root/db. sql \\i 命令用于执行一个外部的sql脚本文件。 4.导出数据库为外部的脚本#/opt/PostgreSQL/8. 3/bin/ pg_dump - Upostgres - C - fdb. sql database -C create -f 是导出后的文件名 5.postgresql 插入16进制数INSERT INTO tableAAA VALUES( x’0001f’ : : integer, ‘鉴权’ , ‘Authority’ ) 6.使用 TG_RELNAME 报错ERROR: syntax error at or near “$1” at character [引]http://www.dbmonster.com/Uwe/Forum.aspx/postgresql/2051/TG-RELNAME-problem Perhaps you will get some idea if you read the document:37. 6. 4. Executing Dynamic Commands 改：执行动态语句 EXECUTE ‘INSERT INTO TG_RELNAME VALUES (NEW.start_time , NEW.id , NEW.end_time)’; psql 常用命令a. \\c tesdb1 - - 将当前连接的testdb数据库改变成 testdb1 。b . \\q - - 断开与Postgres服务器的连接c . \\l 列出所有数据库的名字 \\l+ 列出所有数据库的名字以及字符集编码d. \\d [ 名字] 描述表, 索引, 序列, 或者视图 列出表/索引/序列/视图/系统表\\d{t| i| s| v| S} [ 模式] ( 加 “+” 获取更多信息) - - 列出表/索引/序列/视图/系统表\\d tablename - - 查看表的结构\\dt - - 列出数据库中所有表 8.在PostgreSQL中如何删除重复记录 【转】http: / / hi. baidu. com/cicon/blog/item/e14f217f4eeee20429388a0c. html 在PostgreSQL中删除重复记录其实很简单，不论有多少行重复，只要在要删除重复记录的表中table加一列rownum字段( id为table表中的主键) ，类型设置为serial类型即可，然后执行sqldelete from deltest where rownum not in(select max(rownum) from deltest);最后删除列rownum即可 ============================================== 正文： 连接数据库操作： psql是postgresql数据库提供的连接数据库shell命令，格式 psql 【option】 dbname 在终端输入psql 会使用默认的方式连接本地数据库，使用的用户名是登陆linux系统使用的用户名， psql -U username -W pass 以及psql -U username -W pass databasenaem都可以实现连接数据库的功能，第一种方式是使用用户名username密码pass连接默认数据库（具体链接那个数据库还没搞清 楚），第二种方式使用用户名username密码pass连接username数据库。如果登录成功之后将显示类似信息 Welcome to psql 8.0.6, the PostgreSQL interactive terminal. Type: \\copyright for distribution terms \\h for help with SQL commands ? for help with psql commands \\g or terminate with semicolon to execute query \\q to quit 连接成功之后所有的命令都是使用”\\“+ 字符或者word完成相应的功能。现将常用的几个列车 \\l 列出所有数据库 \\dt 列出连接数据库中所有表 \\di 列出连接数据库中所有index \\dv 列出连接数据库中所有view \\h sql命令帮助 ? \\ 所有命令帮助 \\q 退出连接 \\d tablename 列出指定tablename的表结构 可以尝试执行下面两句sql SELECT current_date SELECT version() 是不是nothing happened，这是因为postgresql数据库要求必须使用；结尾否则不予执行，加上；之后就能看到结果了。 如果我们想创建数据库怎么办呢？ 我们知道createdb和dropdb可以创建和删除数据库，但是如果我们这个时候执行出现什么问题呢？可以试一试，提示是个错误。 为什么呢？ createdb和dropdb是shell脚本，所以现在又两种方式执行 （1）.退出连接进入终端，输入createdb test —U user -W pass 稍等提示创建数据库成功 1dropdb test —U user -W pass 提示drop成功 （2）.在未退出连接中使用 ! createdb test —U user -W pass 稍等提示创建数据库成功 1\\! dropdb test —U user -W pass 提示drop成功","link":"/2020/09/28/postgresql/"},{"title":"ssh 与远程机器保持心跳（linux）","text":"在连接远程SSH服务的时候，经常会发生长时间后的断线，或者无响应（无法再键盘输入）。 总体来说有两个方法：一、客户端定时发送心跳1.putty、SecureCRT、XShell都有这个功能，设置请自行搜索 2.此外在Linux下： #修改本机/etc/ssh/ssh_configvim /etc/ssh/ssh_config 添加12ServerAliveInterval 30ServerAliveCountMax 100 即每隔30秒，向服务器发出一次心跳。若超过100次请求，都没有发送成功，则会主动断开与服务器端的连接。 二、服务器端定时向客户端发送心跳（一劳永逸） 修改服务器端 ssh配置 /etc/ssh/sshd_configvim /etc/ssh/sshd_config 添加12ClientAliveInterval 30ClientAliveCountMax 6 ClientAliveInterval表示每隔多少秒，服务器端向客户端发送心跳，是的，你没看错。 下面的ClientAliveInterval表示上述多少次心跳无响应之后，会认为Client已经断开。 所以，总共允许无响应的时间是60*3=180秒。","link":"/2021/05/03/ssh%20%E4%B8%8E%E8%BF%9C%E7%A8%8B%E6%9C%BA%E5%99%A8%E4%BF%9D%E6%8C%81%E5%BF%83%E8%B7%B3%EF%BC%88linux%EF%BC%89/"},{"title":"redis基础","text":"Redis的优势和特点Redis的特点： 内存数据库，速度快，也支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 支持事务 Redis的优势： 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。（事务） 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis与其他key-value存储有什么不同？ Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。 Redis的过期策略和内存淘汰机制Redis 的 key 有两种过期淘汰的方式：被动方式、主动方式。被动过期：用户访问某个 key 的时候，key 被发现过期。 当然，被动方式过期对于那些永远也不会再次被访问的 key 并没有效果。不管怎么，这些 key 都应被过期淘汰，所以 Redis 周期性主动随机检查一部分被设置生存时间的 key，那些已经过期的 key 会被从 key 空间中删除。 Redis每秒执行10次下面的操作： 从带有生存时间的 key 的集合中随机选 20 进行检查。删除所有过期的key。如20里面有超过25%的key过期，立刻继续执行步骤1。这是一个狭义概率算法，我们假设我们选出来的样本 key 代表整个 key 空间，我们继续过期检查直到过期 key 的比例降到 25% 以下。 这意味着在任意时刻已经过期但还占用内存的 key 的数量，最多等于每秒最多写操作的四分之一。 过期策略我们set key的时候，都可以给一个expire time，就是过期时间，指定这个key比如说只能存活1个小时，我们自己可以指定缓存到期就失效。 如果假设你设置一个一批key只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？ 答案是：定期删除+惰性删除 所谓定期删除，指的是redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。 注意，这里可不是每隔100ms就遍历所有的设置过期时间的key，那样就是一场性能上的灾难。 实际上redis是每隔100ms随机抽取一些key来检查和删除的。 但是，定期删除可能会导致很多过期key到了时间并没有被删除掉，所以就得靠惰性删除了。 这就是说，在你获取某个key的时候，redis会检查一下 ，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。 并不是key到时间就被删除掉，而是你查询这个key的时候，redis再懒惰的检查一下 通过上述两种手段结合起来，保证过期的key一定会被干掉。 但是实际上这还是有问题的，如果定期删除漏掉了很多过期key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？ 如果大量过期key堆积在内存里，导致redis内存块耗尽了，怎么办？ 答案是：走内存淘汰机制。 内存淘汰机制如果redis的内存占用过多的时候，此时会进行内存淘汰，有如下一些策略： noeviction：当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的） allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key，这个一般没人用吧 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key（这个一般不太合适） volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除 Redis配置文件全解==基本配置daemonize no 是否以后台进程启动databases 16 创建database的数量(默认选中的是database 0) save 900 1 #刷新快照到硬盘中，必须满足两者要求才会触发，即900秒之后至少1个关键字发生变化。save 300 10 #必须是300秒之后至少10个关键字发生变化。save 60 10000 #必须是60秒之后至少10000个关键字发生变化。stop-writes-on-bgsave-error yes #后台存储错误停止写。rdbcompression yes #使用LZF压缩rdb文件。rdbchecksum yes #存储和加载rdb文件时校验。dbfilename dump.rdb #设置rdb文件名。dir ./ #设置工作目录，rdb文件会写入该目录。 ==主从配置slaveof 设为某台机器的从服务器masterauth 连接主服务器的密码slave-serve-stale-data yes # 当主从断开或正在复制中,从服务器是否应答slave-read-only yes #从服务器只读repl-ping-slave-period 10 #从ping主的时间间隔,秒为单位repl-timeout 60 #主从超时时间(超时认为断线了),要比period大slave-priority 100 #如果master不能再正常工作，那么会在多个slave中，选择优先值最小的一个slave提升为master，优先值为0表示不能提升为master。 repl-disable-tcp-nodelay no #主端是否合并数据,大块发送给slaveslave-priority 100 从服务器的优先级,当主服挂了,会自动挑slave priority最小的为主服 ===安全requirepass foobared # 需要密码rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 #如果公共环境,可以重命名部分敏感命令 如config ===限制maxclients 10000 #最大连接数maxmemory #最大使用内存 maxmemory-policy volatile-lru #内存到极限后的处理volatile-lru -&gt; LRU算法删除过期keyallkeys-lru -&gt; LRU算法删除key(不区分过不过期)volatile-random -&gt; 随机删除过期keyallkeys-random -&gt; 随机删除key(不区分过不过期)volatile-ttl -&gt; 删除快过期的keynoeviction -&gt; 不删除,返回错误信息 #解释 LRU ttl都是近似算法,可以选N个,再比较最适宜T踢出的数据maxmemory-samples 3 ====日志模式appendonly no #是否仅要日志appendfsync no # 系统缓冲,统一写,速度快appendfsync always # 系统不缓冲,直接写,慢,丢失数据少appendfsync everysec #折衷,每秒写1次 no-appendfsync-on-rewrite no #为yes,则其他线程的数据放内存里,合并写入(速度快,容易丢失的多)auto-AOF-rewrite-percentage 100 当前aof文件是上次重写是大N%时重写auto-AOF-rewrite-min-size 64mb aof重写至少要达到的大小 ====慢查询slowlog-log-slower-than 10000 #记录响应时间大于10000微秒的慢查询slowlog-max-len 128 # 最多记录128条 ====服务端命令time 返回时间戳+微秒dbsize 返回key的数量bgrewriteaof 重写aofbgsave 后台开启子进程dump数据save 阻塞进程dump数据lastsave slaveof host port 做host port的从服务器(数据清空,复制新主内容)slaveof no one 变成主服务器(原数据不丢失,一般用于主服失败后) flushdb 清空当前数据库的所有数据flushall 清空所有数据库的所有数据(误用了怎么办?) shutdown [save/nosave] 关闭服务器,保存数据,修改AOF(如果设置) slowlog get 获取慢查询日志slowlog len 获取慢查询日志条数slowlog reset 清空慢查询 info [] config get 选项(支持*通配)config set 选项 值config rewrite 把值写到配置文件config restart 更新info命令的信息 debug object key #调试选项,看一个key的情况debug segfault #模拟段错误,让服务器崩溃object key (refcount|encoding|idletime)monitor #打开控制台,观察命令(调试用)client list #列出所有连接client kill #杀死某个连接 CLIENT KILL 127.0.0.1:43501client getname #获取连接的名称 默认nilclient setname “名称” #设置连接名称,便于调试 ====连接命令===auth 密码 #密码登陆(如果有密码)ping #测试服务器是否可用echo “some content” #测试服务器是否正常交互select 0/1/2… #选择数据库quit #退出连接 启动redis启动redis时直接 redis-server就可以启动服务端了，也可以指定加载的配置文件 1redis-server ./***/redis.conf 默认情况下 redis-server会以非守护进程（简单理解就是后台运行）的形式启动，指定配置文件后就可以实现以守护进程运行。 redis数据类型1type key 使用object encoding key可以判断数据类型，字符串长度大于39,底层数据结构蜕变为rawredis是一种高级的key:redis存储系统，redis的value共支持五种数据类型 字符串(strings)，列表(lists)，哈希散列(hashes)，集合(sets)，有序集合(sorted sets) strings字符串累行是二进制安全（可以存储用二进制表示的文件）。 再遇到数值操作时，redis会将字符串类型转换成数值。 由于INCR等指令本省就具有原子操作的特性，所以我们可以利用redis的INCR、INCRBY、DECR、DECRBY等指令来实现原子计数的效果。 listsredis的lists在底层实现上并不是数组，而是链表，也就是说，lists具有链表所具有的优势，也具有链表所具有的劣势。 lists的常用操作包括 LPUSH、RPUSH、LRANGE等。 1234lrange key start end lrem key count elementlpush key element [element...]lpop key [count] sets集合，是一种无序集合，元素没有先后顺序，但元素唯一 集合操作，诸如添加新元素、删除已有元素、交集、并集、差集等 sorted sets有序集合每个元素都关联一个序号（score）,是排序的依据 有时，也将redis的有序集合成为 zsets，因为在redis中，有序集合的操作都是z开头的，如 zrange、zadd、zrevrange、zrangebyscore等 hasheshashes存储的是字符串和字符串值之间的映射。比如存储一个用户的姓名、年龄、联系方式等。 redis持久化redis长时间挂载在内存上，但有时我们需要其将内容及时拷贝，这时，我们就需要redis的持久化功能 redis提供两种持久化方式，分别是RDB(redis database)和AOF(append only file) RDB就是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上 这是一种类似快照的持久化方法redis在进行数据持久化的过程中，会将数据先写入到一个临时文件中，等到持久化过程都结束了，才会用该临时文件替换上次持久化的文件。 对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化任务，而此时主进程是不会进行任何IO操作的，保证服务的正常高性能进行 如果需要进行大规模数据的恢复，切对于数据恢复的完整性不是非常敏感，那RDB方式比AOF方式更加高效 当数据完整性要求较好高时，redis发生故障，会有一段时间的数据没来得及进行快照，进而导致丢失 AOF将redis执行过的所有指令记录下来，在下次启动时，只要将指令读入再执行一遍，数据就恢复了 默认的AOF持久化策略是没秒 fsync（fsync指把缓存中的写指令记录到磁盘中）,因为在这种情况下，redis仍可以保持很好的性能，即使redis故障，也只丢失了最近1秒的数据 AOF方式的一个好处就是可以进行“情景再现”,若我们不小心清空了redis，当AOF文件还没被重写时，我们就可以修改AOF文件，重启redis在恢复数据 在同样数据规模的情况下，AOF文件比RDB文件大得多，且AOF恢复速度要慢于RDB方式 AOF重写在重写即将开始前，redis会创建（fork）一个重写子进程，该子进程会先读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。 与此同时，主进程会将新接收到的写指令一边积累到内存缓冲区中，一边继续写入到原有的AOF文件中。这样做保证原有的AOF文件的可用性，避免在重写过程中出现意外。 当重写子进程完成重写任务后，他会给主进程发一个信号，主进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中。 当追加结束后，redis就会用心AOF文件来代替旧AOF文件，之后再有新的写指令，就会都追加到新的AOF文件中。 主从用法像mysql一样，redis是支持主从同步的，也支持一主多从及多从结构 主从结构，一是为了纯粹的冗余备份，二是为了提升读性能，如很消耗性能的操作可由从服务器承担 redis的主从同步是异步进行的，意味着主从同步不会影响主逻辑，也不会降低redis的处理性能 主从架构中，可以考虑关闭主服务器的数据持久化功能，只让从服务器进行持久化，可以进一步提高主服务器的处理性能 主从架构中，从服务器通常被设置为只读模式，可以避免从服务器的数据被误改。但从服务器还是可以接受到config等指令，所以还是应该避免将从服务器直接暴露到不安全的网络环境中。 主从同步原理从服务器会向主服务器发出sync（异步）指令，当主服务器接收到此指令后，就会调用BGSAVE指令来创建一个子进程专门进行数据持久化工作，也就是将主服务器的数据写入RDB文件中。在数据持久化期间，主服务器将执行的写指令都缓存在内存中 在BGSAVE指令执行完成后，主服务器会将持久化好的RDB文件发送给从服务器，从服务器接收到此文件后会将其存储到磁盘上，然后再将棋读取到内存中。这个动作完成后，主服务器会将这段时间缓存的写指令再以redis协议的格式发送给从服务器 即使有多个从服务器同时发来sync指令，主服务器也只会执行一次BGSAVE，然后把持久化好的RDB文件发给多个下游。 主服务器会在内存中维护一个缓冲区，缓冲区中存储着将要发给从服务器的内容。从服务器在与主服务器出线网络瞬断之后，从服务器会尝试再次与主服务器连接，一点连接成功，从服务器就会把“希望同步的主服务器ID”和“希望请求的数据偏移位置”发送出去。主服务器接收到这样的同步请求后，首先会验证主服务器ID是否和自己的ID匹配，其次会检查“请求的偏移位置”是否存在于自己的缓冲区中，如果两者都满足的haul，主服务器就会向从服务器发送增量内容 redis的事务处理事务是指“一个完整的动作，要么全部执行，要么全部不执行”redis事务处理： MULTI 用来组装一个事务EXEC 用来执行一个事务DISCARD 用来取消一个事务WATCH 用来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行在用 MULTI 组装驶入时，每一个命令都会进入到内存队列中缓存起来，如果出现 QUEUED 则表示我们这个命令成功插入到缓存队列，在将来执行 EXEC 时，这些被 QUEUED 的命令会被组装成一个事务来执行 有关事务，常见的两类错误： 调用EXEC之前错误调用EXEC之后错误“调用EXEC之前错误”，有可能是由于语法有错误导致，也可能由于内存不足导致。只要出现某个命令无法成功写入缓冲队列的情况，redis都会进行记录，在客户端调用EXEC时，redis会拒绝执行这一事务。 “调用EXEC之后错误”，redsi采取了不同的策略，即redis不会理睬这些错误，而是继续向下执行事务中的其他命令。因为，对于应用层的错误，并不是redis自身需要考虑处理的问题，故，一个事务中某一条命令执行失败，并不影响接下来的其他命令的执行。 watch作用是“监视key是否被改动过”，且支持同时监视多个key，只要还没真正触发事务，WATCH 都会尽职尽责的监视，一旦发现某个key被修改了，在执行EXEC时就会返回 nil ，表示事务无法触发。 redis配置文件redis配置文件分为几大区域： 通用（general） 快照（snapshotting） 复制（replication） 安全（security） 限制（limit） 追加模式（append only mode） LUA脚本（lua scripting） 慢日志（slow log） 事件通知（event notification） PHP秒杀示例1234567891011$redis-&gt;watch('lucky'); // 监听lucky，lucky的值可以是0$value = $redis-&gt;get('lucky'); // 获取lucky的值 $redis-&gt;multi(); // 开启事务if ($value &lt; 20) { // 如果库存足够，则幸运数量加一 $redis-&gt;incr('lucky');}if ($redis-&gt;exec()) { // 如果有其它线程改变了lucky的值，则秒杀失败，否则提交事务，秒杀成功，幸运数量加一 dump('秒杀成功');} else { dump('秒杀失败');}","link":"/2020/08/15/redis%E5%9F%BA%E7%A1%80/"},{"title":"tcpdump详细教程","text":"介绍tcpdump - dump traffic on a network tcpdump是一个用于截取网络分组，并输出分组内容的工具。凭借强大的功能和灵活的截取策略，使其成为类UNIX系统下用于网络分析和问题排查的首选工具 tcpdump 支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息 命令格式12tcpdump [ -DenNqvX ] [ -c count ] [ -F file ] [ -i interface ] [ -r file ] [ -s snaplen ] [ -w file ] [ expression ] tcpdump格式 抓包选项：-c：指定要抓取的包数量。 -i interface：指定tcpdump需要监听的接口。默认会抓取第一个网络接口 -n：对地址以数字方式显式，否则显式为主机名，也就是说-n选项不做主机名解析。 -nn：除了-n的作用外，还把端口显示为数值，否则显示端口服务名。 -P：指定要抓取的包是流入还是流出的包。可以给定的值为”in”、”out”和”inout”，默认为”inout”。 -s len：设置tcpdump的数据包抓取长度为len，如果不设置默认将会是65535字节。对于要抓取的数据包较大时，长度设置不够可能会产生包截断，若出现包截断，：输出行中会出现”[|proto]”的标志(proto实际会显示为协议名)。但是抓取len越长，包的处理时间越长，并且会减少tcpdump可缓存的数据包的数量，：从而会导致数据包的丢失，所以在能抓取我们想要的包的前提下，抓取长度越小越好。 输出选项：-e：输出的每行中都将包括数据链路层头部信息，例如源MAC和目标MAC。 -q：快速打印输出。即打印很少的协议相关信息，从而输出行都比较简短。 -X：输出包的头部数据，会以16进制和ASCII两种方式同时输出。 -XX：输出包的头部数据，会以16进制和ASCII两种方式同时输出，更详细。 -v：当分析和打印的时候，产生详细的输出。 -vv：产生比-v更详细的输出。-vvv：产生比-vv更详细的输出。 其他功能性选项：-D：列出可用于抓包的接口。将会列出接口的数值编号和接口名，它们都可以用于”-i”后。 -F：从文件中读取抓包的表达式。若使用该选项，则命令行中给定的其他表达式都将失效。 -w：将抓包数据输出到文件中而不是标准输出。可以同时配合”-G time”选项使得输出文件每time秒就自动切换到另一个文件。可通过”-r”选项载入这些文件以进行分析和打印。 -r：从给定的数据包文件中读取数据。使用”-“表示从标准输入中读取。 expression 表达式==一个基本的表达式单元格式为”proto dir type ID”== 对于表达式语法，参考 pcap-filter 【pcap-filter - packet filter syntax】 类型 type host, net, port, portrange 例如：host 192.168.201.128 , net 128.3, port 20, portrange 6000-6008’ 目标 dir src, dst, src or dst, src and dst 协议 proto tcp， udp ， icmp，若未给定协议类型，则匹配所有可能的类型 ==表达式单元之间可以使用操作符” and / &amp;&amp; / or / || / not / ! “进行连接，从而组成复杂的条件表达式==。如”host foo and not port ftp and not port ftp-data”，这表示筛选的数据包要满足”主机为foo且端口不是ftp(端口21)和ftp-data(端口20)的包”，常用端口和名字的对应关系可在linux系统中的/etc/service文件中找到。 另外，同样的修饰符可省略，如”tcp dst port ftp or ftp-data or domain”与”tcp dst port ftp or tcp dst port ftp-data or tcp dst port domain”意义相同，都表示包的协议为tcp且目的端口为ftp或ftp-data或domain(端口53)。 使用括号”()”可以改变表达式的优先级，但需要注意的是括号会被shell解释，所以应该使用反斜线””转义为”()”，在需要的时候，还需要包围在引号中。 tcpdump示例==**tcpdump只能抓取流经本机的数据包 **== 1. 默认启动1tcpdump 默认情况下，直接启动tcpdump将监视第一个网络接口(非lo口)上所有流通的数据包。这样抓取的结果会非常多，滚动非常快。 2 . 监视指定网络接口的数据包1tcpdump -i ens33 3. 监视指定主机的数据包，例如所有进入或离开node1的数据包1tcpdump -i ens33 host node1 4. 打印node1&lt;–&gt;node2或node1&lt;–&gt;node3之间通信的数据包1tcpdump -i ens33 host node1 and \\(node2 or node3\\) 5. 打印node1与任何其他主机之间通信的IP数据包,但不包括与node4之间的数据包1tcpdump -i ens33 host node1 and not node4 6. 截获主机node1 发送的所有数据1tcpdump -i ens33 src host node1 7. 监视所有发送到主机node1 的数据包1tcpdump -i ens33 dst host node1 8. 监视指定主机和端口的数据包1tcpdump -i ens33 port 8080 and host node1 9. 监视指定网络的数据包，如本机与192.168网段通信的数据包，”-c 10”表示只抓取10个包1tcpdump -i ens33 -c 10 net 192.168 10. 打印所有通过网关snup的ftp数据包1tcpdump 'gateway snup and (port ftp or ftp-data)' 注意,表达式被单引号括起来了,这可以防止shell对其中的括号进行错误解析 11. 抓取ping包1234tcpdump -c 5 -nn -i ens33 ==指定主机抓ping包==tcpdump -c 5 -nn -i eth0 icmp and src 192.168.100.62 12. 抓取到本机22端口包1tcpdump -c 10 -nn -i ens33 tcp dst port 22 13. 解析包数据1tcpdump -c 2 -q -XX -vvv -nn -i ens33 tcp dst port 22 来源：https://www.jianshu.com/p/d9162722f189","link":"/2022/10/01/tcpdump%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B/"},{"title":"ubuntu 安装ImageMagic","text":"I. 安装ImageMagic 安装： 1sudo apt-get install imagemagick 测试:1). 版本察看简单地执行:引用convert -version 如果看到下面的信息说明安装已经成功引用Version: ImageMagick 6.4.3 2008-08-27 Q16 OpenMP http://www.imagemagick.orgCopyright: Copyright (C) 1999-2008 ImageMagick Studio LLC 2). 压缩图片.当前目录下有一个文件名字叫hill.png,执行引用convert -sample 25%x25% hill.png hill_t.png 将缩小hill.png为原来的25%，生成新的文件名叫hill_t.png 如果出现如下错误提示:引用convert: error while loading shared libraries: libMagickCore.so.1: cannot open shared object file: No such file or directory 将so所在的路径加入到LD_LIBRARY_PATH(前面的安装方式默认安装so到/usr/local/lib目录下)引用 export LD_LIBRARY_PATH=/usr/local/lib 当执行jpg图片缩放的时候,3). 压缩jpg图片引用convert -sample 25%x25% water.png water_t.png 系统提示:引用convert: no decode delegate for this image format water.jpg'. convert: missing an image filename t_water.jpg’. 其他： ImageMagick是一个免费的创建、编辑、合成图片的软件。 原文地址：https://blog.csdn.net/jacke121/article/details/76126245","link":"/2021/08/29/ubuntu%20%E5%AE%89%E8%A3%85ImageMagic/"},{"title":"vim中正则表达式（关于magic）","text":"毋庸多言，在vim中正则表达式得到了十分广泛的应用。最常用的 / 和 :s 命令中，正则表达式都是不可或缺的。下面对vim中的正则表达式的一些难点进行说明 关于magicvim中有个magic的设定，设定方法为： 123:set magic &quot; 设置magic:set nomagic &quot; 取消magic:h magic &quot; 查看帮助 vim毕竟是个编辑器，正则表达式中包含的大量元字符如果原封不动地引用（像perl那样），势必会给不懂正则表达式的人造成麻烦，比如 /foo(1) 命令，大多数人都用它来查找foo(1)这个字符串，但如果按照正则表达式来解释，被查找的对象就成了 foo1 了。 于是，vim就规定，正则表达式的元字符必须用反斜杠进行转义才行，如上面的例子，如果确实要用正则表达式，就应当写成 /foo/(1/) 。但是，像 . * 这种极其常用的元字符，都加上反斜杠就太麻烦了。而且，众口难调，有些人喜欢用正则表达式，有些人不喜欢用…… 为了解决这个问题，vim设置了 magic 这个东西。简单地说， magic就是设置哪些元字符要加反斜杠哪些不用加的。简单来说： magic (/m)：除了 $ . * ^ 之外其他元字符都要加反斜杠。 nomagic (/M)：除了 $ ^ 之外其他元字符都要加反斜杠。 这个设置也可以在正则表达式中通过 /m /M 开关临时切换。 /m 后面的正则表达式会按照 magic 处理，/M 后面的正则表达式按照 nomagic 处理，而忽略实际的magic设置。 例如： 12//m.* # 查找任意字符串//M.* # 查找字符串 .* （点号后面跟个星号） 另外还有更强大的 /v 和 /V。 /v （即 very magic 之意）：任何元字符都不用加反斜杠 /V （即 very nomagic 之意）：任何元字符都必须加反斜杠 例如： 1234//v(a.c){3}$ # 查找行尾的abcaccadc//m(a.c){3}$ # 查找行尾的(abc){3}//M(a.c){3}$ # 查找行尾的(a.c){3}//V(a.c){3}$ # 查找任意位置的(a.c){3}$ 默认设置是 magic，vim也推荐大家都使用magic的设置，在有特殊需要时，直接通过 /v/m/M/V 即可。 本文下面使用的元字符都是 magic 模式下的。 量词vim的量词与perl相比一点也不逊色。 vim Perl 意义 * * 0个或多个(匹配优先) /+ + 1个或多个(匹配优先) /? 或 /= ? 0个或1个(匹配优先)，/?不能在 ? 命令（逆向查找）中使用 /{n,m} {n,m} n个到m个(匹配优先) /{n,} {n,} 最少n个(匹配优先) /{,m} {,m} 最多m个(匹配优先) /{n} {n} 恰好n个 /{-n,m} {n,m}? n个到m个(忽略优先) /{-} *? 0个或多个(忽略优先) /{-1,} +? 1个或多个(忽略优先) /{-,1} ?? 0个或1个(忽略优先) 从上表中可见，vim的忽略优先量词不像perl的 *? +? ?? 那样，而是统一使用 /{- 实现的。这大概跟忽略优先量词不常用有关吧。 环视和固化分组vim居然还支持环视和固化分组的功能，强大，赞一个 关于环视的解释请参考Yurii的《精通正则表达式》 一书吧。 vim Perl 意义 /@= (?= 顺序环视 /@! (?! 顺序否定环视 /@&lt;= (?&lt;= 逆序环视 /@&lt;! (?&lt;! 逆序否定环视 /@&gt; (?&gt; 固化分组 /%(atom/) (?: 非捕获型括号 和perl稍有不同的是，vim中的环视和固化分组的模式的位置与perl不同。例如，查找紧跟在 foo 之后的 bar，perl将模式写在环视的括号内，而vim将模式写在环视的元字符之前。 12345# Perl的写法/(?&lt;=foo)bar/# vim的写法//(foo/)/@&lt;=bar","link":"/2021/04/15/vim%E4%B8%AD%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%EF%BC%88%E5%85%B3%E4%BA%8Emagic%EF%BC%89/"},{"title":"一些SEO相关标签","text":"Normal1234&lt;link rel=&quot;canonical&quot; href=&quot;https://music.163.com/&quot;&gt;&lt;meta name=description content=&quot;网易云音乐是一款专注于发现与分享的音乐产品，依托专业音乐人、DJ、好友推荐及社交功能，为用户打造全新的音乐生活。&quot;&gt;&lt;meta name=&quot;keywords&quot; content=&quot;网易云音乐，音乐，播放器，网易，下载，播放，DJ，免费，明星，精选，歌单，识别音乐，收藏，分享音乐，音乐互动，高音质，320K，音乐社交，官网，music.163.com&quot; /&gt;&lt;meta name=&quot;Author&quot; contect=&quot;CZQ&quot;&gt; Robots1&lt;meta name=&quot;Robots&quot; contect= &quot;all|none|index|noindex|follow|nofollow&quot;&gt; 设定为all：文件将被检索，且页面上的链接可以被查询； 设定为none：文件将不被检索，且页面上的链接不可以被查询； 设定为index：文件将被检索； 设定为follow：页面上的链接可以被查询； 设定为noindex：文件将不被检索，但页面上的链接可以被查询； 设定为nofollow：文件将不被检索，页面上的链接可以被查询 Open Graph Protocol og是一种新的HTTP头部标记，作用是让网页成为一个“富媒体对象”。用了Meta Property=og标签，就是同意了其他网站可以引用本网页内容，目前这种协议被很多SNS网站采用。也就是所谓的富媒体对象。 1234&lt;meta property=&quot;og:title&quot; content=&quot;网易云音乐&quot; /&gt;&lt;meta property=&quot;og:type&quot; content=&quot;website&quot; /&gt;&lt;meta property=&quot;og:image&quot; content=&quot;http://p3.music.126.net/tBTNafgjNnTL1KlZMt7lVA==/18885211718935735.jpg&quot; /&gt;&lt;meta property=&quot;og:url&quot; content=&quot;https://music.163.com/&quot; /&gt;","link":"/2022/03/06/%E4%B8%80%E4%BA%9BSEO%E7%9B%B8%E5%85%B3%E6%A0%87%E7%AD%BE/"},{"title":"什么是POP3、SMTP和IMAP?","text":"POP3POP3是Post Office Protocol 3的简称，即邮局协议的第3个版本,它规定怎样将个人计算机连接到Internet的邮件服务器和下载电子邮件的电子协议。它是因特网电子邮件的第一个离线协议标准,POP3允许用户从服务器上把邮件存储到本地主机（即自己的计算机）上,同时删除保存在邮件服务器上的邮件，而POP3服务器则是遵循POP3协议的接收邮件服务器，用来接收电子邮件的。(与IMAP有什么区别？) **POP3**协议允许电子邮件客户端下载服务器上的邮件，但是在客户端的操作（如移动邮件、标记已读等），不会反馈到服务器上，比如通过客户端收取了邮箱中的3封邮件并移动到其他文件夹，邮箱服务器上的这些邮件是没有同时被移动的 。 而**IMAP**提供webmail 与电子邮件客户端之间的双向通信，客户端的操作都会反馈到服务器上，对邮件进行的操作，服务器上的邮件也会做相应的动作。 同时，IMAP像POP3那样提供了方便的邮件下载服务，让用户能进行离线阅读。IMAP提供的摘要浏览功能可以让你在阅读完所有的邮件到达时间、主题、发件人、大小等信息后才作出是否下载的决定。此外，IMAP 更好地支持了从多个不同设备中随时访问新邮件。 总之，IMAP 整体上为用户带来更为便捷和可靠的体验。POP3 更易丢失邮件或多次下载相同的邮件，但 IMAP 通过邮件客户端与webmail 之间的双向同步功能很好地避免了这些问题。 注：若在web邮箱中设置了“保存到已发送”，使用客户端POP服务发信时，已发邮件也会自动同步到网页端“已发送”文件夹内。 SMTPSMTP 的全称是“Simple Mail Transfer Protocol”，即简单邮件传输协议。它是一组用于从源地址到目的地址传输邮件的规范，通过它来控制邮件的中转方式。SMTP 协议属于 TCP/IP 协议簇，它帮助每台计算机在发送或中转信件时找到下一个目的地。SMTP 服务器就是遵循 SMTP 协议的发送邮件服务器。 SMTP 认证，简单地说就是要求必须在提供了账户名和密码之后才可以登录 SMTP 服务器，这就使得那些垃圾邮件的散播者无可乘之机。 增加 SMTP 认证的目的是为了使用户避免受到垃圾邮件的侵扰。 使用smtp发送邮件：https://www.cnblogs.com/sdgwc/p/3324368.htmlhttps://blog.csdn.net/qq_35644234/article/details/68961603 IMAPIMAP全称是Internet Mail Access Protocol，即交互式邮件存取协议，它是跟POP3类似邮件访问标准协议之一。不同的是，开启了IMAP后，您在电子邮件客户端收取的邮件仍然保留在服务器上，同时在客户端上的操作都会反馈到服务器上，如：删除邮件，标记已读等，服务器上的邮件也会做相应的动作。所以无论从浏览器登录邮箱或者客户端软件登录邮箱，看到的邮件以及状态都是一致的。（与POP3有什么区别？） 文章来源： http://help.163.com/09/1223/14/5R7P6CJ600753VB8.html","link":"/2021/11/02/%E4%BB%80%E4%B9%88%E6%98%AFPOP3%E3%80%81SMTP%E5%92%8CIMAP%EF%80%BF/"},{"title":"使用Postfix发送邮件","text":"下面介绍在Ubuntu下使用Postfix发送邮件的方法 安装Postfix12sudo apt-get install postfix sudo apt-get install mailutils 我这边是按照默认配置安装的。 修改配置1vim /etc/postfix/main.cf 将myhostname修改为localhost 启动Postfix服务1service postfix start 发送1mailx -r root@chengyao.xyz -s &quot;Subject&quot; 987861463@qq.com &lt; ./log.txt 上面步骤没有测试，可行性未知 如果有发送附件但发送失败，可以查看/var/log/mail.log文件，如果是message file too big,可以输入 1postconf -e &quot;message_size_limit=409600000&quot; //设置400MB 将允许的大小改大些。 mailx命令mailx命令相关命令的有：mail,sendmail. 语法 mailx [选项] [名字] 说明 本命令用于发送和接收邮件，名字是收信人的用户名，本命令有许多选项，选项说明如下： 12345678910111213141516171819202122232425262728-A：执行帐户的命令的名称启动文件被读取之后。-a：给定的文件附加到邮件中。-B：使标准输入和标准输出线-缓冲。-b：发送密件副本列表。列表应该是一个逗号分隔的名称列表。-c：送炭复制到地址列表。-D：开始在断开模式; 看到断开的变量的描述选项。-d：启用调试消息和关闭消息的实际交付。 不像-v，此选项仅用于开发目的。-e：只是检查是否有邮件系统邮箱。 如果是，返回零，否则，一个非零值退出状态。-E：如果传出消息，不包含在它的第一个或唯一的消息部分的任何文字，不要把它丢弃，但它静静地，有效地设置在程序启动时的skipemptybody变量。这是一个从发送消息有用 的脚本由启动cron的。-f：阅读在用户的邮箱中的内容（或文件时 ，如果指定）进行处理; 当mailx的是退出，将其写入未删除的邮件恢复该文件。 该字符串作为文件处理描述为文件夹命令如下。-F：保存要发送的消息中的第一个收件人的地址的本地部分命名的文件。-H：打印头汇总所有消息并退出。-h：调用的sendmail与指定的跃点数。此选项没有在使用SMTP发送邮件的效果。-i：TTY忽略中断信号。使用mailx的对噪音的电话线时，这是非常有用的。-I：显示了“ 新闻组：'或' 文章ID：'在标题汇总字段。只有在与-f结合使用时适用。-n：禁止阅读/etc/mail.rc启动时。这个选项应该适用于对多台计算机调用mailx的脚 本来启动，因为文件的内容，它们之间可能有所不同。-N：阅读邮件或编辑邮件文件夹时禁止消息头的初始显示。-q：启动与指定的文件的内容的消息。 可仅在发送模式给出。-r：设置发件人地址。忽略任何从指定的变量环境变量或启动文件。波浪号逃逸被禁用。该-r地址选项被传递到邮件传输代理，除非使用SMTP。此选项存在唯一的相容性;它建议，而不是直接设置从变量。-R：如果打开文件夹的只读打开它们。-s：指定主题的命令行（仅后-s标志作为主题的第一个参数，要注意引用包含空格的科目）。-S：设置内部选项变量变量的可选值的价值 。-T：写“ 邮件ID：”和“ 文章ID：'读入文件名 ??的每个消息头字段。暗示我压缩文件的处理所描述的文件夹命令如下。-t：要发送的消息，预计将包含一个消息头“收件人：”，“抄送”或“密件抄送：”字段给收件人。 在命令行上指定的收件人将被忽略。-u：读取用户的用户的邮箱。-v：详细模式。 递送的详细信息显示在用户的终端上。-V：显示版本信息并退出。- ?：启用波浪逃逸 ，即使不是在交互模式。 命令内说明 12345678910111213141516171819202122232425. 当前信件n 第 n 封信^ 第一封未被处理的信$ 最后一封信* 所有的信n-m 第n封至第m封信/ 字符串 标题中包含字符串的信：c 满足指定类型c的信，类型可为d 已删除的信n 信传送的信o 旧信件r 已读过的信u 未读过的信p 一次显示多封信t 显示某封信的前若干行si 显示信件字符数h 显示信件标题d 删除信件u 恢复信件s [信件表] 文件名将信件存入指定文件中q 退出r 回信~e 编辑信件~r 文件 从文件中读取信件 实例 1mailx -s &quot;test&quot; -a 1.txt 'mytest@ywnz.com' &lt; 2.txt #test为标题,1.txt附 件,2.txt正文,发送给mytest@123.com","link":"/2021/07/10/%E4%BD%BF%E7%94%A8Postfix%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/"},{"title":"关于http响应和连接","text":"HTTP 响应头信息 HTTP请求头提供了关于请求，响应或者其他的发送实体的信息。 Allow 服务器支持哪些请求方法（如GET、POST等）。 Content-Encoding 文档的编码（Encode）方法。只有在解码之后才可以得到Content-Type头指定的内容类型。利用gzip压缩文档能够显著地减少HTML文档的下载时间。Java的GZIPOutputStream可以很方便地进行gzip压缩，但只有Unix上的Netscape和Windows上的IE 4、IE 5才支持它。因此，Servlet应该通过查看Accept-Encoding头（即request.getHeader(“Accept-Encoding”)）检查浏览器是否支持gzip，为支持gzip的浏览器返回经gzip压缩的HTML页面，为其他浏览器返回普通页面。 Content-Length 表示内容长度。只有当浏览器使用持久HTTP连接时才需要这个数据。如果你想要利用持久连接的优势，可以把输出文档写入 ByteArrayOutputStream，完成后查看其大小，然后把该值放入Content-Length头，最后通过byteArrayStream.writeTo(response.getOutputStream()发送内容。 Content-Type 表示后面的文档属于什么MIME类型。Servlet默认为text/plain，但通常需要显式地指定为text/html。由于经常要设置Content-Type，因此HttpServletResponse提供了一个专用的方法setContentType。 Date 当前的GMT时间。你可以用setDateHeader来设置这个头以避免转换时间格式的麻烦。 Expires 应该在什么时候认为文档已经过期，从而不再缓存它？ Last-Modified 文档的最后改动时间。客户可以通过If-Modified-Since请求头提供一个日期，该请求将被视为一个条件GET，只有改动时间迟于指定时间的文档才会返回，否则返回一个304（Not Modified）状态。Last-Modified也可用setDateHeader方法来设置。 Location 表示客户应当到哪里去提取文档。Location通常不是直接设置的，而是通过HttpServletResponse的sendRedirect方法，该方法同时设置状态代码为302。 Refresh 表示浏览器应该在多少时间之后刷新文档，以秒计。除了刷新当前文档之外，你还可以通过setHeader(“Refresh”, “5; URL=http://host/path&quot;)让浏览器读取指定的页面。注意这种功能通常是通过设置HTML页面HEAD区的＜META HTTP-EQUIV=”Refresh” CONTENT=”5;URL=http://host/path&quot;＞实现，这是因为，自动刷新或重定向对于那些不能使用CGI或Servlet的HTML编写者十分重要。但是，对于Servlet来说，直接设置Refresh头更加方便。 注意Refresh的意义是”N秒之后刷新本页面或访问指定页面”，而不是”每隔N秒刷新本页面或访问指定页面”。因此，连续刷新要求每次都发送一个Refresh头，而发送204状态代码则可以阻止浏览器继续刷新，不管是使用Refresh头还是＜META HTTP-EQUIV=”Refresh” …＞。 注意Refresh头不属于HTTP 1.1正式规范的一部分，而是一个扩展，但Netscape和IE都支持它。 Server 服务器名字。Servlet一般不设置这个值，而是由Web服务器自己设置。 Set-Cookie 设置和页面关联的Cookie。Servlet不应使用response.setHeader(“Set-Cookie”, …)，而是应使用HttpServletResponse提供的专用方法addCookie。参见下文有关Cookie设置的讨论。 WWW-Authenticate 客户应该在Authorization头中提供什么类型的授权信息？在包含401（Unauthorized）状态行的应答中这个头是必需的。例如，response.setHeader(“WWW-Authenticate”, “BASIC realm=＼”executives＼””)。注意Servlet一般不进行这方面的处理，而是让Web服务器的专门机制来控制受密码保护页面的访问（例如.htaccess）。 HTTP持久连接 HTTP持久连接（HTTP persistent connection，也称作HTTP keep-alive或HTTP connection reuse）是使用同一个TCP连接来发送和接收多个HTTP请求/应答，而不是为每一个新的请求/应答打开新的连接的方法。 在 HTTP 1.0 中, 没有官方的 keepalive 的操作。通常是在现有协议上添加一个指数。如果浏览器支持 keep-alive，它会在请求的包头中添加：1Connection: Keep-Alive然后当服务器收到请求，作出回应的时候，它也添加一个头在响应中：1Connection: Keep-Alive这样做，连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个连接。这一直继续到客户端或服务器端认为会话已经结束，其中一方中断连接。在 HTTP 1.1 中所有的连接默认都是持续连接，除非特殊声明不支持。HTTP 持久连接不使用独立的 keepalive 信息，而是仅仅允许多个请求使用单个连接。然而， Apache 2.0 httpd 的默认连接过期时间是仅仅15秒，对于 Apache 2.2 只有5秒。短的过期时间的优点是能够快速的传输多个web页组件，而不会绑定多个服务器进程或线程太长时间。 较少的CPU和内存的使用（由于同时打开的连接的减少了） 允许请求和应答的HTTP管线化 降低拥塞控制（TCP连接减少了） 减少了后续请求的延迟（无需再进行握手） 报告错误无需关闭TCP连接 根据RFC 2616 （47页），用户客户端与任何服务器和代理服务器之间不应该维持超过2个链接。代理服务器应该最多使用2&amp;times;N个持久连接到其他服务器或代理服务器，其中N是同时活跃的用户数。这个指引旨在提高HTTP响应时间并避免阻塞。 对于广泛普及的宽带连接来说，Keep-Alive也许并不像以前一样有用。web服务器会保持连接若干秒(Apache中默认15秒)，这与提高的性能相比也许会影响性能。对于单个文件被不断请求的服务(例如图片存放网站)，Keep-Alive可能会极大的影响性能，因为它在文件被请求之后还保持了不必要的连接很长时间。 关于HTTP的持久连接特性HTTP协议是位于传输层之上的应用层协议，其网络层基础通常是TCP协议。TCP协议是面向连接和流的，因此连接的状态和控制对于HTTP协议而言相当重要。同时，HTTP是基于报文的，因此如何确定报文长度也是协议中比较重要的一点。Persistent Connections持久连接目的在使用持久连接前，HTTP协议规定为获取每个URL资源都需要使用单独的一个TCP连接，这增加了HTTP服务端的负载，引起互联网拥塞。例如内嵌图片以及其他类似数据的使用要求一个客户端在很短时间内向同一个服务端发起多个请求。使用持久连接的优点:减少TCP连接数量在一个连接上实现HTTP请求和应答的流水，即允许客户端发出多个请求，而不必在接收到前一请求的应答后才发出下一请求，极大减少时间消耗后续请求延迟减少，无需再在TCP握手上耗时可以更加优雅地实现HTTP协议，由于持续连接的存在无需报告错误后无需关闭连接，因此客户端可使用最新的协议特性发出请求，如果接收到表示错误的应答，则换用更旧的语义。 总体描述HTTP/1.1和之前版本的显著区别是HTTP/1.1默认使用持久连接。即，除非服务端在应答中明确指出，客户端应当假定服务端会维持一个持久连接，即使从服务端收到的应答是报告错误。持久连接对关闭TCP连接的行为提供信号量机制支持。这个信号量是在HTTP头中的Connection域设置，注意Client向Proxy发出请求时该域可能被Proxy-Connection域替换。一旦close信号被表明，客户端绝不能再通过该连接发送更多的请求。 协商(Negotiation)HTTP/1.1 服务端可以假定HTTP/1.1客户端会维持持久连接，除非请求中Connection域的值是”close”.同样的，如果服务端打算在送出应答后立即关闭连接，它应当在应答中包含同样的Connection域。(TCP连接关闭是双向的,此时TCP进入半关闭状态)同样的，HTTP/1.1客户端可以期望连接是持久的，除非如前所述收到表示连接关闭的应答。当然，也可以主动发出一个包含Connection:close的请求以表明终止连接。无论客户端还是服务端发出的报文包含Connection:close，则该请求均为连接上的最后一个请求(服务端发出此应答后关闭，因此不可能接收更多的请求)报文传输长度为保证持久性，连接上的报文都必须有一个自定义的报文传输长度(否则必须通过连接的关闭表示报文结束，因为TCP连接是面向流的)，确定的规则按优先级由高到低排列如下：报文传输长度指报文中出现的报文体的长度(即，不包括头长度，因为报文头的结束可通过连续两个CRLF确定）1.任何绝不能包含报文体(如1xx,204,304)的应答消息总是以头域后的第一个空行结束,无视头中所有的entity类型域的设置，包括Content-Length域。2.Transfer-Encoding域出现，其值为除”identify”以外的其他值，则用”chunked”传输编码方式确定传输长度，具体方式留待下篇分析。3.Content -Length域出现，且Transfer-Encoding域未出现(出现则忽略Content-Length域)。Content-Length域的值为十进制数的字节序，如Content-Length：1234，则1、2、3、4是分别作为一个octet传输的，因此需要atoi转换成数值。4.如果报文使用了”multipart/byteranges”的媒体类型，且没对传输长度做前面的指明，则这种自分割的媒体类型定义了传输长度。具体参见Range头域的说明。5.服务端关闭连接(此方法不可用于客户端发出的请求报文，因为客户端关闭连接则使得服务端无法发送应答).为保持和HTTP/1.0的兼容性, 包含报文体的HTTP/1.1请求必须包含合法的Content-Length头域,除非明确知道服务端是HTTP/1.1兼容的.如果请求包含消息体, 而没有Content-Length域,那么如果服务端无法确定消息长度时,它会返回400(无效请求),或者坚持获取合法Content-Length 而返回411(要求包含长度). 所有接收实体的HTTP/1.1应用程序必须接受”chunked”传输编码, 这样允许当报文长度无法预先确定时可以运用此机制获取报文长度.报文不能同时包含Content-Length头域和非”identity” Transfer-Encoding.如果出现了, Content-Length域必须被忽略.当Content-Length域在允许报文体的报文中存在时, 其域值必须严格等于消息体中的8比特字节.HTTP/1.1 user agent 必须在接收并检测到一个错误的长度时提醒用户.以上方法中，最常见的还是使用Content-Length域表示报文体长度，Transfer-Encoding需要按格式解码才能还原出发送编码前的报文。 流水支持持久连接的客户端可以流水发送请求，服务端必须按发送的顺序发送应答。假定持久连接和连接后即可流水的客户端应当做好在第一次流水失败后重新尝试此连接。在这样的尝试中，在确定连接是持久的之前，客户端不能再流水。客户端同样必须准备好在服务端送回所有相关应答前就关闭连接时重发请求。不应流水non-idempotent方法 Proxy Servers对于代理服务端而言，正确实现Connection头域指定的属性尤为重要。代理服务端必须分立通告它的客户端和连接的原始服务端持久连接的属性，每个持久连接设置仅针对一个传输连接。 实践考量超时值，服务端通常会为每个连接维护一个定时器，一旦某个连接不活跃超过一定时间值，服务端会关闭此连接。考虑到一个客户端可能通过代理服务端发出更多连接，代理服务端通常会将超时值设置得更高。还有一些关于从异步关闭中恢复的讨论。 报文传输要求使用TCP流控制来解决服务端临时负载过高问题，而不是简单的依赖客户端重连而关闭连接。监视连接情况以获取错误状态消息关于使用100(继续)状态码100状态码用于客户端发送请求体之前测试是否可以发送该请求，对于Proxy，有以下要求：1.如果代理服务端接收到包含Expect头域值为”100-continue”的请求, 而不明确知道下一跳服务不支持HTTP/1.1以上版本, 则它必须转发这个请求, 包括Expect头域.2.如果代理知道下一跳服务端为HTTP/1.0或者更低版本, 则它不能转发此请求, 且必须以407应答客户端.3.如果明确知道发出请求的客户端版本为HTTP/1.0或者更低，则代理服务端绝不能转发100应答,这条规则凌驾于转发1xx应答的一般准则. Connection头域说明BNF文法：Connection = “Connection” “:” 1#(connection-token)connection-token = tokenConnection头域中的token用于指定对于特定连接有意义的选项，因此proxy在转发前要扫描此域，从头中去除和token同名的域。例如Connection:Range,则要去掉Range域。HTTP/1.1定义了close这个token，发送者用此token表示在完成这个报文所属请求/应答的收发后连接将关闭。 HTTP的持久连接对Web服务性能的影响我们的 Web 页面通常有很多对像(Object)组成。如：jss 样式表、图片、scripts、文档等。所以用户浏览一个网页文件时候，要向 Web 服务器发送多次请求(要从服务器上获取一个Object就要向服务器发送一个请求)，浏览器根据 jss 样式表把从服务器获取的这些html页面对象合成一个完整的html页面展示给用户。 最早我们的浏览器是单线程的，意味着一次只能向浏览器发送一个Object请求，等到该Object传输完成了，再向服务发送第二个Object的请求。我们把它称为串行事务处理。串行事务处理，使得我们的连接时延会叠加，用户的体验效果差。如，页面有多幅图片，页面正在加载一幅图片时，页面上其它地方都没有动静，也会让人门觉得很慢。后来出现了多线程的浏览器，当用户点击打开一个页面时，会同时向服务器同时发起多个用户请求(也就是并行处理方式)，减少了连接时延叠加，同时加速了一个web页面对象的加载速度，让用户有更好的体验效果。 虽然采用多线程的浏览器加速了页面的加载速度，但是如果我们只对连接进行简单的管理(如不使用 keep alive)，浏览器每获得一个Web对像都要使用一个新的TCP连接。意思是说我们加载的html页面有多少个页面对象，浏览器与服务器要建立多少条TCP连接。大家都知道使用TCP传输数据之前，要先经过三次握手，三次握手成功以后，双方才能够进行数据的传输。所以说，我们使用TCP/IP进行数据网络传输必定会造成延迟的。双方完成数据的传输以后还要经过TCP的四次断开的过程。一个TCP的连接要经过：建立连接 、传输数据、拆除连接。 TCP的建立连接和拆除连接是很费时的，有时候甚至比数据传输的时间还长。所以，虽然浏览器采用了并发处理方式，加速了页面的加载速度。但是请求一个页面对像就需要与服务器建立一条TCP连接。如果用户浏览的页面文件有1000个object的话，从服务器请求数据到展示给用户， 最基本延迟时间 = 1000*(平均每个TCP连接建立时间 + 平均每个TCP连接拆除时间)。 随着我们的页面对像的增加，这个延迟时间是不断增长的。客户端每请求一个object，就要与服务器建立一条TCP连接，服务器每维护一条TCP连接是要消耗一定的资源(如内存)。所以，也加速了服务器的负担。对服务器的并发用户数也造成很大影响。所以后来 HTTP/1.1 使用了重用TCP连接功能来消除连接及关闭时延。允许HTTP设备在事务处理结束之后将TCP连接保持在打开状态，以便为后续的HTTP请求重用现存的TCP连接。在事务处理结束之后仍然保持在打开状态的TCP连接被称为持久连接。也称为 TCP 重用。 是如何重用TCP连接的呢？ 假如，浏览的网页文件有400个object.我们的浏览器是4线程的，浏览器会并行向 Web 服务器发送4个 TCP连接请求。当这4个TCP请求与服务器建立连接完成数据传输以后，并不是 把它拆除掉。浏览器与web服务器协定使用 keep-alive 功能时。HTTP设备就会在事务处理结束之后将该4条TCP连接保持在打开状态。浏览器就使用这4条TCP连接完成后续的396个object的数据转输。 持久连接降低了时延和连接建立的开销，将连接保持在已调谐状态，而且减少了打开连接的潜在数量。但是，管理 持久连接时要特别小心，不然就会累积出大量的空闲连接，耗费客户端和服务器上的资源。下面是 Apache web 服务器管理持久连接的一些配置： [root@node2 ~]# vim /etc/httpd/extra/httpd-default.conf…#KeepAlive OnKeepAlive On# MaxKeepAliveRequests: The maximum number of requests to allowduring a persistent connection. Set to 0 to allow an unlimited amount.We recommend you leave this number high, for maximum performance.保持连接允许传输的最大请求数MaxKeepAliveRequests 100 KeepAliveTimeout: Number of seconds to wait for the next request from thesame client on the same connection.在同一个客户端的连接，等待下一个请求的超时时间KeepAliveTimeout 5…说明： 这些就是 Keep-Alive选项。注意，Keep-Alive 首部只是请求将连接保持在活跃状态。发出 keep-alive 请求之后，客户端和服务器并不一定会同意进行 keep-alive 会话。它们可以在任意时刻关半空闲的 keep-alive 连接，并可随意限制 keep-alive 连接所处理事务的数量。 下面来看看，客户端与服务器怎样商量它们是否使用HTTP协议的持久连接功能的呢？实现 HTTP/1.0 keep-alive 连接的客户端可以通过包含 Connection: Keep-Alive 首部请求将一条连接保持在打开状态。 通过 Google Chrome 浏览器的开发者工具来查看，访问 http://192.168.203.99/index.html 的请求头信息。 Request HeaderAccept:text/html,application/xhtml+xml,application/xml;q=0.9,p_w_picpath/webp,/;q=0.8Accept-Encoding:gzip,deflate,sdchAccept-Language:zh-CN,zh;q=0.8Cache-Control:no-cacheConnection:keep-alive —–&gt; 请求将一条连接保持在打开状态。Cookie:2c407_ol_offset=97; 2c407_ipstate=1402781651; 2c407_jobpop=0; 2c407_winduser=BD4OUFQKBQkLVgReBgsAAFsDVlMKB1MGUQ4LAwcFUlgBBms; 2c407_ck_info=%2F%09; 2c407_lastpos=index; 2c407_lastvisit=49%091402713397%09%2Findex.phpHost:192.168.203.99Pragma:no-cacheUser-Agent:Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.137 Safari/537.36通过工具 crul 获得的响应头信息。 [root@node2 ~]# curl -I http://192.168.203.99/index.htmlHTTP/1.1 200 OKServer: nginx/1.0.11Date: Sat, 14 Jun 2014 09:17:15 GMTContent-Type: text/htmlContent-Length: 151Last-Modified: Thu, 01 May 2014 04:21:03 GMTConnection: keep-aliveAccept-Ranges: bytes说明： 如果服务器愿意为下一条请求将连接保持在打开状态(意思是说下一次请求数据时，可以通过该TCP连接传输数据，不需要建立新的TCP连接了)， 就在响应中包含相同的首部 Connection: keep-alive。 如果响应中没有 Connection: keep-alive 首部，客户端就认为服务器不支持 keep-alive,会在发回响应报文之后关闭连接@。 从上在请求首部和响应首部分析，我们使用了HTTP 持久连接的功能。 总结： Keep-Alive 连接的限制和规则： 1、在 HTTP/1.0 中，keep-alive 并不是默认使用的，客户端必须发送一个 Connection: Keep-Alive 请求首部来激活 keep-alive 连接。 2、Connection: Keep-Alive 首部必须随所有希望保持持久连接的报文一起发送。如果客户端没有发 送 Connection: Keep-Alive 首部，服务器就会在那条请求之后关闭连接。 3、客户端探明响应中没有 Connection: Keep-Alive 响应首部，就可以知道服务器发出响应之后是否 会关闭连接了。 4、为了避免出现大量的空闲的TCP连接，要定义持久连接的超时时间 timeout. 限制操持连接的TCP 连接最多能完成多少个事务 MaxKeepAliveRequests 转载于:https://blog.51cto.com/9528du/1426695","link":"/2020/08/15/%E5%85%B3%E4%BA%8Ehttp%E5%93%8D%E5%BA%94%E5%92%8C%E8%BF%9E%E6%8E%A5/"},{"title":"关于apt-get remove 与 apt-get purge","text":"今天在Ubuntu服务器上安装supervisor，部署没成功想卸载重来，sudo apt-get remove supervisor 后发现配置文件还在，便手动删除了配置文件。再次安装，提示配置文件不存在，WTF！配置文件不该你软件给我创建吗？我想。 查阅资料才知，还有 apt-get purge 这一选项，purge 清除。 划重点：apt-get remove 会删除软件包而保留软件的配置文件apt-get purge 会同时清除软件包和软件的配置文件 但是为什么重新安装会失败呢？系统中存在dpkg这么一个工具，会记录软件包的状态，不只是安装和未安装两种状态，会记录以下这些状态： not-installed - The package is not installed on this systemconfig-files - Only the configuration files are deployed to this systemhalf-installed - The installation of the package has been started, but not completedunpacked - The package is unpacked, but not configuredhalf-configured - The package is unpacked and configuration has started but not completedtriggers-awaited - The package awaits trigger processing by another packagetriggers-pending - The package has been triggeredinstalled - The packaged is unpacked and configured OK 当执行apt-get install时，apt软件包管理工具会先检查要安装的软件的状态，向我这种情况下，手动删除了软件配置后，并不会引起dpkg中记录的状态的改变，即仍为 config-files 状态，所以安装过程会直接跳过创建配置文件这一过程。于是当软件想要启动进程的时候，才发现找不到文件。 所以当你想彻底地删除软件包的时候，用 apt-get purge 吧 原文：http://bencane.com/2014/08/18/removing-packages-and-configurations-with-apt-get/","link":"/2020/08/14/%E5%85%B3%E4%BA%8Eapt-get%20remove%20%E4%B8%8E%20apt-get%20purge/"},{"title":"几个书签","text":"GoLang内存逃逸 https://www.cnblogs.com/linguoguo/p/10956685.html https://zhuanlan.zhihu.com/p/145468000 https://blog.justwe.site/post/go-escape-heap/ GC https://blog.csdn.net/u010649766/article/details/80582153 https://segmentfault.com/q/1010000010813711 https://segmentfault.com/a/1190000010753702?_ea=2426880 https://www.zhihu.com/question/65426766 https://www.golangtc.com/t/582be338b09ecc08ce0003b4 Map https://blog.csdn.net/u011957758/article/details/82846609 https://blog.csdn.net/raoxiaoya/article/details/111469483 https://blog.csdn.net/zhounixing/article/details/107334087 https://www.modb.pro/db/226546 结构体 https://www.codercto.com/a/72000.html GORM https://zhuanlan.zhihu.com/p/486959472 image处理 https://zhuanlan.zhihu.com/p/387753099 锁 https://blog.csdn.net/weixin_45901764/article/details/121020888 切片 https://blog.csdn.net/alwaysrun/article/details/107749174 runtime https://blog.csdn.net/inthat/article/details/118531656 其他 https://developer.mozilla.org/zh-CN/docs/Web/CSS/%40font-face https://www.itqaq.com/index/art/272.html https://www.cnblogs.com/yuyangphpweibo/p/9044374.html https://www.php.net/manual/zh/book.dom.php https://blog.csdn.net/xushiyu1996818/article/details/104298486 https://www.cnblogs.com/pureLaw/p/14779725.html http://www.rbtree.cn/ https://www.w3cschool.cn/wkspring/j3181mm3.html https://docs.mongodb.com/manual/reference/configuration-options/#security.authorization https://blog.csdn.net/weidu01/article/details/105946606Screen命令","link":"/2021/12/05/%E5%87%A0%E4%B8%AA%E4%B9%A6%E7%AD%BE/"},{"title":"关于linux中日语的编码问题","text":"对于日语的编码 windows ： Shift-JIS Linux ： 2.4内核使用EUC编码，2.6内核中使用UTF8编码 检查文件编码 nkf -g filename 通常处理字符编码都使用iconv这个命令，但是iconv命令只能用来处理文件名，但对于文本内容的编码就无法处理了， 要想对文本内容的字符编码进行转换，就要用到nkf了 -j : 转换为 JIS 编码(ISO-2022-JP)，默认-e : 转换为 EUC 编码-s : 转换为 Shift-JIS 编码-w : 转换为 UTF-8 编码（无BOM）-Lu : 转换为 unix 换行格式(LF)-Lw : 转换为 windows 换行格式(CRLF)-Lm : 转换为 macintosh 换行格式(CR)-g(–guess) : 自动判断编码并显示–version : 显示版本–help : 显示帮助linux中转换成window ： nkf -sxLw nkf -swLwwindow转换成linux ： nkf -wxLu 在vim中输入:e ++enc=utf8可以快速解决vim乱码问题，即使语言配置不正确，也可以快速解决乱码问题。 这种方式的原理是: 当vim无法识别文档的编码的时候，会使用latin-1去读取，导致文档显示上出现乱码，上述命令，就会让vim用utf-8编码的方式重新加载一遍，当然如果你的文档是用gbk编码的，可以使用: e ++=enc=gbk的方式来转换。 设置编码还可以用set encoding / set fileencoding","link":"/2020/11/12/%E5%85%B3%E4%BA%8Elinux%E4%B8%AD%E6%97%A5%E8%AF%AD%E7%9A%84%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98/"},{"title":"去掉sudo的密码","text":"sudo执行命令的时候老是让输入密码，真的好烦，下面为去掉密码的方法： 首先打开/etc/sudoers “sudo visudo” 或 “sudo vi /etc/sudoers” 建议用以下命令打开”sudo visudo”，用该命令编辑sudoers后保存时如果有语法错误系统会给出提示，而用“vi /etc/sudoers”就不会给出错误提示。 内容如下： 123456789root ALL=(ALL:ALL) ALL# Members of the admin group may gain root privileges%admin ALL=(ALL) ALL# Allow members of group sudo to execute any command%sudo ALL=(ALL:ALL) NOPASSWD:ALL# See sudoers(5) for more information on &quot;#include&quot; directives: 接下来有二种方法(以下操作必须谨慎，使用出错与小站无关) 方法一： 找到 %admin ALL=(ALL) ALL这一行，将其修改为 %admin ALL=(ALL) NOPASSWD:ALL，或者直接给sudo加上NOPASSWD，如上代码方法二： 在%admin ALL=(ALL) ALL这一行的下面添加一行 username ALL = NOPASSWD:ALL 一定要在%admin ALL=(ALL) ALL行的下面，否则系统会先加载username ALL = NOPASSWD:ALL”再加载“%admin ALL=(ALL) ALL 由于username属于admin组所以会将对username的设置覆盖。 注：username是你登录的用户名。 顺便附加一个介绍sudo的博客：https://blog.csdn.net/zahuopuboss/article/details/8909891","link":"/2021/10/20/%E5%8E%BB%E6%8E%89sudo%E7%9A%84%E5%AF%86%E7%A0%81/"},{"title":"加快你的Github访问速度","text":"有时候打开Github是真的慢，紧急时刻总是打不开，所以在这里写下加快Github访问的一些步骤，供大家参考 前期准备云服务器一台我使用了Docker, 你也可以直接装到当前系统， 服务器的话国外的最好，因为国外访问Github是比较快的。 拉取Nginx镜像https://registry.hub.docker.com/_/nginx 1docker pull nginx 这个版本是真的新啊 启动1docker run -itd -p 89:80 --name nginx nginx 以下操作均在容器中进行 官网下载Nginx源码http://nginx.org/en/download.html 1wget http://nginx.org/download/nginx-1.21.4.tar.gz 下载要新增的模块https://github.com/chobits/ngx_http_proxy_connect_module 1git clone https://github.com/chobits/ngx_http_proxy_connect_module.git 重新编译Nginx查看Nginx编译参数1nginx -V 将编译参数保存起来 编译解压下载的Nginx和模块 如果需要的话 1tar -zxf nginx-***.tar.gz 进入Nginx源码路径，根据你的Nginx版本及下面的对应关系，执行类似下面的命令 nginx version enable REWRITE phase patch 1.4.x ~ 1.12.x NO proxy_connect.patch 1.4.x ~ 1.12.x YES proxy_connect_rewrite.patch 1.13.x ~ 1.14.x NO proxy_connect_1014.patch 1.13.x ~ 1.14.x YES proxy_connect_rewrite_1014.patch 1.15.2 YES proxy_connect_rewrite_1015.patch 1.15.4 ~ 1.16.x YES proxy_connect_rewrite_101504.patch 1.17.x ~ 1.18.0 YES proxy_connect_rewrite_1018.patch 1.19.x ~ 1.21.0 YES proxy_connect_rewrite_1018.patch 1.21.1 YES proxy_connect_rewrite_102101.patch 123patch -p1 &lt; /path/to/ngx_http_proxy_connect_module/patch/proxy_connect.patch./configure --add-module=/path/to/ngx_http_proxy_connect_modulemake &amp;&amp; make install 注意，上面的编译参数要把你刚刚复制的那段加上去安装完成 添加配置我们需要修改一下配置， 123456789101112131415server { listen 80; resolver 8.8.8.8; proxy_connect; proxy_connect_allow 443 563; proxy_connect_connect_timeout 10s; proxy_connect_read_timeout 10s; proxy_connect_send_timeout 10s; # 下面这个配置应该需要改下 location / { proxy_pass $scheme://$host/; proxy_set_header Host $host; } } 这个配置你可能需要根据需要做相应修改，例如你需要转发某个header头，你可以使用 1proxy_set_header Accpet &quot;*/*&quot; 然后重载一下 1nginx -s reload 或者直接重启 使用修改你电脑或者浏览器的代理配置，如下 这里的127.0.0.1是你服务器的ip地址，89是你映射到nginx的端口，可以看下 如果远程地址是[你服务器ip]:89 就说明成功了，如果你使用的是国外的机器那么速度应该会很快。 最后教程是前几天搭建之后总结的，总结的时候并没有再操作一遍，所以可能会有一些问题，如果有问题可以留言给我。 还可以使用nginx代理socket，可以参考下面两篇文章 Nginx折腾－TCP代理和负载均衡 Nginx支持Socket转发过程详解","link":"/2021/11/14/%E5%8A%A0%E5%BF%AB%E4%BD%A0%E7%9A%84Github%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6/"},{"title":"回车和换行","text":"12'\\r'是回车，前者使光标到行首，（carriage return）'\\n'是换行，后者使光标下移一格，（line feed） 对于换行这个动作，unix下一般只有一个0x0A表示换行(“\\n”），windows下一般都是0x0D和0x0A两个字符(“\\r\\n”)，苹果机(MAC OS系统)则采用回车符CR表示下一行(\\r)Unix系统里，每行结尾只有“&lt;换行&gt;”，即“\\n”；Windows系统里面，每行结尾是“&lt;回车&gt;&lt;换行&gt;”，即“\\r\\n”；Mac系统里，每行结尾是“&lt;回车&gt;”,即“\\r”。 windows采用回车+换行CR/LF表示下一行,即^M$（$不是换行符的表示，换行符没有表示出来，$是文本结束EOF的表示）","link":"/2022/03/13/%E5%9B%9E%E8%BD%A6%E5%92%8C%E6%8D%A2%E8%A1%8C/"},{"title":"堆栈数据的进出原则是什么","text":"堆栈数据的进出原则是什么？堆栈数据的进出原则是先进后出。 栈堆的原理栈区（stack）由操作系统自动分配释放 ，存放函数的参数值，局部变量的某值等等。其操作方式类似于数据结构中的栈。 堆区（heap）一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表 栈的特点：栈是一种数据结构，它按照先进后出的原则存储数据，先进入的数据被压入栈底，最后的数据在栈顶，需要读数据的时候从栈顶开始弹出数据（最后一个数据被第一个读出来）。 栈是只能在某一端插入和删除的特殊线性表。用桶堆积物品，先堆进来的压在底下，随后一件一件往堆。取走时，只能从上面一件一件取。堆和取都在顶部进行，底部一般是不动的。 栈就是一种类似桶堆积物品的数据结构，进行删除和插入的一端称栈顶，另一堆称栈底。插入一般称为进栈（PUSH），删除则称为退栈（POP）。 栈也称为后进先出表（LIFO表） 原文地址：https://www.php.cn/faq/483124.html 更多推荐：https://www.cnblogs.com/mysticCoder/p/4921724.html","link":"/2021/11/25/%E5%A0%86%E6%A0%88%E6%95%B0%E6%8D%AE%E7%9A%84%E8%BF%9B%E5%87%BA%E5%8E%9F%E5%88%99%E6%98%AF%E4%BB%80%E4%B9%88/"},{"title":"如何使用Telnet","text":"退出telnet使用ctrl + ] 再 ctrl + d 发送HTTP请求打开连接1telnet chengyao.xyz 80 发送数据123GET / HTTP/1.1Host: localhost\\r\\n 这里的Host是必须的，否则会400 发送Content-Length 头后服务端会等待输入相应长度的内容后才返回POST 提交的时候需要添加Content-Type 结果12345678910111213141516171819202122cheng@DESKTOP-845LJ9G:/mnt/c/Users/ChengYao$ telnet chengyao.xyz 80Trying 1.14.70.42...Connected to chengyao.xyz.Escape character is '^]'.GET / HTTP/1.1Host: localhostHTTP/1.1 200 OKServer: nginxDate: Sun, 21 Nov 2021 07:04:56 GMTContent-Type: text/htmlContent-Length: 1326Last-Modified: Wed, 26 Apr 2017 08:03:47 GMTConnection: keep-aliveVary: Accept-EncodingETag: &quot;59005463-52e&quot;Accept-Ranges: bytes&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt; 其他请求头 12345If-Modified-SinceIf-None-Mathch````服务端响应 ETag 1234567891011121314151617181920212223242526272829303132如果客户端没有过期，服务端不在发送，返回304，而是从本地取使用307重定向可以保持数据，例如post提交到a.php， a.php重定向到b.php，则可以用307重定向# 连接SMTP服务器```shelltelnet smtp.qq.com 25Trying 14.18.175.202...Connected to smtp.qq.com.Escape character is '^]'.220 newxmesmtplogicsvrsza9.qq.com XMail Esmtp QQ Mail Server.HELO localhost250-newxmesmtplogicsvrsza5.qq.com-9.22.14.83-79972670250-SIZE 73400320250 OKAUTH LOGIN334 VXNlcm5hbWU6OTg3ODYxNDY4QHFxLmNvb1==334 UGFzc3dvcmQ6Y2xqYXB5aWJlRTd1mRiaA==235 Authentication successfulMAIL FROM: &lt;987861463@qq.com&gt;250 OKRCPT TO: &lt;bigyao@139.com&gt;250 OKDATA354 End data with &lt;CR&gt;&lt;LF&gt;.&lt;CR&gt;&lt;LF&gt;.Dear, hello, thank you..250 OK: queued as.","link":"/2021/11/21/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Telnet/"},{"title":"如何设计可以动态扩容缩容的分库分表方案","text":"设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是32库 * 32表。 比如4台服务器，每台服务器上8个库，每个库32张表。 路由的规则，orderId%32 = 库，orderId / 32 %32 = 表 扩容的时候，申请增加更多的数据库服务器，装好mysql，倍数扩容，4台服务器，扩到8台服务器，16台服务器 由dba负责将原先数据库服务器的库，迁移到新的数据库服务器上去，很多工具，库迁移，比较便捷 我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址 重新发布系统，上线，原先的路由规则变都不用变，直接可以基于2倍的数据库服务器的资源，继续进行线上系统的提供服务 转自：中华石杉Java工程师面试突击","link":"/2021/04/07/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E5%8F%AF%E4%BB%A5%E5%8A%A8%E6%80%81%E6%89%A9%E5%AE%B9%E7%BC%A9%E5%AE%B9%E7%9A%84%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%96%B9%E6%A1%88/"},{"title":"安装Ubuntu后另外磁盘出现只读的解决办法","text":"mountblkidsudo ntfsfix /dev/sdb1mount -a 其他卸载硬盘：chen@ilaptop:/$ sudo umount /dev/sdb1 读写挂载硬盘chen@ilaptop:/$ sudo mount -o rw /dev/sdb1 参考：https://jakting.com/archives/ubuntu-rw-windows-files.html","link":"/2022/02/12/%E5%AE%89%E8%A3%85Ubuntu%E5%90%8E%E5%8F%A6%E5%A4%96%E7%A3%81%E7%9B%98%E5%87%BA%E7%8E%B0%E5%8F%AA%E8%AF%BB%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"},{"title":"开发时缓存很烦人，修改不能实时生效的解决方法","text":"Opcache 简介 ¶OPcache 通过将 PHP 脚本预编译的字节码存储到共享内存中来提升 PHP 的性能， 存储预编译字节码的好处就是 省去了每次加载和解析 PHP 脚本的开销。 PHP 5.5.0 及后续版本中已经绑定了 OPcache 扩展。 对于 PHP 5.2，5.3 和 5.4 版本可以使用 » PECL 扩展中的 OPcache 库。 原文地址： https://www.php.net/manual/zh/intro.opcache.php 今天在使用thinkphp开发的过程中，发现修改路由后要等好久才能生效，而且删除tp缓存，浏览器缓存都不起作用。 原来是php开启了opcahce 。 下面是禁用 opcache 的方式: 找到php配置文件的路径，因为我是在命令行下启的服务，所以可以通过以下方式 php –ini php -i | grep -i configure 也可以通过phpinfo来查看php.ini文件的路径。在phpinfo页面中通过查看 Loaded Configuration File来获取php.ini文件的路径。 在php.ini文件中禁用。找到 opcache.enable 将其设置为0 重启apache服务器或者重载fpm","link":"/2020/07/05/%E5%BC%80%E5%8F%91%E6%97%B6%E7%BC%93%E5%AD%98%E5%BE%88%E7%83%A6%E4%BA%BA%EF%BC%8C%E4%BF%AE%E6%94%B9%E4%B8%8D%E8%83%BD%E5%AE%9E%E6%97%B6%E7%94%9F%E6%95%88%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"},{"title":"实用的 FFmpeg 脚本合集","text":"分享一些使用的FFmpeg脚本 FFMPEG实例(50条消息) FFmpeg命令实例合集_张雨zy的博客-CSDN博客_ffmpeg gblur 淡入淡出效果（fade）参数123456789101112131415161718192021222324•type, t指定类型是in代表淡入，out代表淡出，默认为in•start_frame, s指定应用效果的开始时间，默认为0.•nb_frames, n应用效果的最后一帧序数。对于淡入，在此帧后将以本身的视频输出，对于淡出此帧后将以设定的颜色输出，默认25.•alpha如果设置为1，则只在透明通道实施效果（如果只存在一个输入），默认为0•start_time, st指定按秒的开始时间戳来应用效果。如果start_frame和start_time都被设置，则效果会在更后的时间开始，默认为0•duration, d按秒的效果持续时间。对于淡入，在此时后将以本身的视频输出，对于淡出此时后将以设定的颜色输出。如果duration和nb_frames同时被设置，将采用duration值。默认为0（此时采用nb_frames作为默认）•color, c设置淡化后（淡入前）的颜色，默认为&quot;black&quot;. 例1234567891011121314151617181920•30帧开始淡入fade=in:0:30•等效上面fade=t=in:s=0:n=30•在200帧视频中从最后45帧淡出fade=out:155:45 fade=type=out:start_frame=155:nb_frames=45•对1000帧的视频25帧淡入，最后25帧淡出:fade=in:0:25, fade=out:975:25•让前5帧为黄色，然后在5-24淡入:fade=in:5:20:color=yellow•仅在透明通道的第25开始淡入fade=in:0:25:alpha=1•设置5.5秒的黑场，然后开始0.5秒的淡入:fade=t=in:st=5.5:d=0.5 实例1ffmpeg -i 1.mp4 -vf fade=in:0:50 out3.mp4 使用高斯模糊为视频生成一个模糊背景（gblur）参数123456789101112131415Apply Gaussian blur filter.The filter accepts the following options:sigmaSet horizontal sigma, standard deviation of Gaussian blur. Default is 0.5.stepsSet number of steps for Gaussian approximation. Default is 1.planesSet which planes to filter. By default all planes are filtered.sigmaVSet vertical sigma, if negative it will be same as sigma. Default is -1. 命令1ffmpeg -i 纸短情长.mp4 -filter_complex [0:v]crop=(ih/16*9):ih,scale=iw/10:-2,gblur=sigma=5,scale=720:1280[vbg];[vbg][0:v]overlay=0:(H-h)/2 -y out.mp4 命令解析输入的原视频是一个1280x720的横屏视频命令核心在于滤镜filter_complex可以拆解成两部分。 背景的生成 原视频与背景的叠加 生成背景1[0:v]crop=(ih/16*9):ih,scale=iw/10:-2,gblur=sigma=5,scale=720:1280[vbg]; crop=(ih/16*9)，从原视频中裁剪出一个竖屏区域作为背景 scale=iw/10:-2，对裁剪后的视频缩小未原来的1/10以便高斯模糊（速度快） gblur=sigma=5，对缩小后的视频背景进行高斯模糊 scale=720:1280[vbg]，对高斯模糊后的视频进行放大，并保存到vbg变量中 背景与原视频的叠加1[vbg][0:v]overlay=0:(H-h)/2 overlay的参数x,y。 0为x的坐标 (H-h)/2是y的坐标，也就是高度居中叠加 alphamerge实现溶图效果合成命令1ffmpeg -i ceshi2.png -i mask.png -filter_complex [1:v]alphaextract[mask];[0:v][mask]alphamerge -y out.png 注意的是：两个输入源（这里是两个图片）的尺寸要一致，如果不一致的话，可以在滤镜中先用scale命令缩放到一致的大小。 alphaextract可以提取一个透明图中的透明通道。黑色代表透明，白色代表不透明。 1ffmpeg -i mask.png -vf alphaextract -y extract.png alphamerge可以将透明通道图，和另一个素材图合并。实现最终的效果。 colorkey，chromakey抠图的使用123456789101112131415colorThe color which will be replaced with transparency.用于抠图的背景色。这个色值将会被替换成透明色similaritySimilarity percentage with the key color.0.01 matches only the exact key color, while 1.0 matches everything.相似度，范围[0.01-1]，1的话匹配所有色值blendBlend percentage.0.0 makes pixels either fully transparent, or not transparent at all.Higher values result in semi-transparent pixels, with a higher transparency the more similar the pixels color is to the key color.透明度[0-1]，默认0，完全透明，例如0.5则是50%的透明度 colorkey抠图1ffmpeg -i pic1.png -vf colorkey=0xc9c8c8:0.3 -y colorkey_test_1.png edgedetect边缘检测1234567891011121314151617181920212223242526272829303132333435363738394041Detect and draw edges. The filter uses the Canny Edge Detection algorithm.边缘检测，使用canny边缘算法The filter accepts the following options:滤镜接收一下参数lowhighSet low and high threshold values used by the Canny thresholding algorithm.设置Canny阈值算法使用的低阈值和高阈值。The high threshold selects the &quot;strong&quot; edge pixels, which are then connected through 8-connectivity with the &quot;weak&quot; edge pixels selected by the low threshold.高阈值选择“强”边缘像素，然后通过8-连通性与低阈值选择的“弱”边缘像素连接四连通区域是11011其中0代表中心点，4个1代表上下左右四个方向。八连通区域是111101111也就是除了上下左右四个方向外，还有左上、右上、左下、右下。low and high threshold values must be chosen in the range [0,1], and low should be lesser or equal to high.必须在[0,1]范围内选择低阈值和高阈值，低阈值应小于或等于高阈值。Default value for low is 20/255, and default value for high is 50/255.“低”的默认值为20/255，“高”的默认值为50/255modeDefine the drawing mode.定义绘图模式‘wires’Draw white/gray wires on black background.如上图，黑白‘colormix’Mix the colors to create a paint/cartoon effect.最后生成图，类似油画效果，卡通效果‘canny’Apply Canny edge detector on all selected planes.Default value is wires.planesSelect planes for filtering. By default all available planes are filtered. ffmpeg edgedetect Canny边缘检测算法 overlay动画，右移动画，左侧入场命令1ffmpeg -i 11.jpg -vf color=c=green:s=720x1280[vbg];[vbg][0:v]overlay=x='if(lte(t,5),-w+(W+w)/2/5*t,(W-w)/2)':y=(H-h)/2 -t 5 -y move.mp4 解析123456789101112131415161718//输入文件-i 11.jpg//创建一个绿色的底板color=c=green:s=720x1280[vbg]//两个层叠加[vbg][0:v]overlay=x='if(lte(t,5),-w+(W+w)/2/5*t,(W-w)/2)':y=(H-h)/2//x的坐标x='if(lte(t,5),-w+(W+w)/2/5*t,(W-w)/2)'//y的坐标y=(H-h)/2//总时长5秒-t 5//生成并覆盖文件-y move.mp4 核心12345678910核心是x的坐标计算x='if(lte(t,5),-w+(W+w)/2/5*t,(W-w)/2)'lte(t,5)当t小于等于5的时候，执行-w+(W+w)/2/5*t其中最核心的是-w+(W+w)/2/5*t1.移动距离(W+w)/22.移动速度(W+w)/2/53.当前时刻的移动距离(W+w)/2/5*t4.当前位置-w+(W+w)/2/5*t 比特率码率（-b）、帧率（-r）和文件大小（-fs）相关操作帧率 帧率（Frame rate）也叫帧频率，帧率是视频文件中每一秒的帧数，肉眼想看到连续移动图像至少需要15帧。 帧率 12ffmpeg –i input –r 25 output # 用 -r 参数设置帧率ffmpeg -i 1.mp4 -vf fps=fps=25 11.mp4 # 用fps的filter设置帧率 例如设置帧率为29.97fps，下面三种方式具有相同的结果： 123ffmpeg -i input.avi -r 29.97 output.mp4ffmpeg -i input.avi -r 30000/1001 output.mp4ffmpeg -i input.avi -r netsc output.mp4 码率 码率也叫比特率（Bit rate）(也叫数据率)是一个确定整体视频/音频质量的参数，秒为单位处理的字节数，码率和视频质量成正比，在视频文件中中比特率用bps来表达。 12ffmpeg -i 1.mp4 -b 1.5M 2.mp4 # 设置参数-bffmpeg -i input.avi -b:v 1500k output.mp4 # 音频：-b:a ,视频： -b:v 设置视频码率为1500kbps 文件大小123456控制输出文件大小-fs (file size首字母缩写) ffmpeg -i input.avi -fs 1024K output.mp4计算输出文件大小 (视频码率+音频码率) * 时长 /8 = 文件大小 crop裁剪相关参数1234crop的参数格式为w:h:x:y，w、h为输出视频的宽和高，x、y标记输入视频中的某点，将该点作为基准点，向右下进行裁剪得到输出视频。 如果x y不写的话，默认居中剪切 例如12ffmpeg -i 3.mp4 -vf crop=400:400 33.mp4 -yffmpeg -i 3.mp4 -vf crop=400:400:0:0 333.mp4 -y vflip，hflip实现视频对称效果，镜面水面效果，上下对称，左右对称上下对称，水面效果 1ffmpeg -i 1.mp4 -filter_complex &quot;[0:v]pad=h=2*ih[a];[0:v]vflip[b];[a][b]overlay=y=h&quot; duichen3.mp4 -y 左右对称，镜面效果 ffmpeg -i 1.mp4 -filter_complex &quot;[0:v]pad=w=2*iw[a];[0:v]hflip[b];[a][b]overlay=x=w&quot; duichen2.mp4 -y 将视频的上半部分翻转，并覆盖在下半部分的区域 1ffmpeg -i 4.mp4 -vf &quot;split [main][tmp];[tmp] crop=iw:ih/2:0:0, vflip [flip];[main][flip] overlay=0:H/2&quot; 44.mp4 -y split，pad，crop，scale，hflip，overlay1234567891011121314151617181920212223242526272829301.mp4原视频2.mp4将视频宽度放大一倍，高不变，视频被横向拉伸ffmpeg -i 1.mp4 -vf scale=iw*2:ih 2.mp43.mp4宽高各放大一倍ffmpeg -i 1.mp4 -vf scale=iw*2:ih*2 3.mp44.mp4将宽度扩展一倍，不是缩放，不是拉伸，而是加长，用黑色填充。ffmpeg -i 1.mp4 -vf pad=2*iw 4.mp45.mp4视频水平翻转hflip 如果是竖直翻转vflipffmpeg -i 1.mp4 -vf hflip 5.mp46.mp4将视频4和5结合，5放在4的空白区域内ffmpeg -i 4.mp4 -i 5.mp4 -filter_complex overlay=w:0 6.mp47.mp4使用过滤器链，一句命令搞定4，5，6步ffmpeg -i 1.mp4 -vf split[a][b];[a]pad=2*iw[1];[b]hflip[2];[1][2]overlay=w:0 7.mp4 F1: split过滤器创建两个输入文件的拷贝并标记为[a],[b] F2: [a]作为pad过滤器的输入，pad过滤器产生2倍宽度并输出到[1]. F3: [b]作为hflip过滤器的输入，vflip过滤器水平翻转视频并输出到[2]. F4: 用overlay过滤器把 [2]覆盖到[1]的旁边. 分辨率相关的操作（-s 和 -scale filter）调整视频分辨率-s12345671、用-s参数设置视频分辨率，参数值wxh，w宽度单位是像素，h高度单位是像素ffmpeg -i input_file -s 320x240 output_file2、预定义的视频尺寸 下面两条命令有相同效果 ffmpeg -i input.avi -s 640x480 output.avi ffmpeg -i input.avi -s vga output.avi Scale filter调整分辨率123456789101112Scale filter的优点是可以使用一些额外的参数 Scale=width:height[:interl={1|-1}] 下面两条命令有相同效果 ffmpeg -i input.mpg -s 320x240 output.mp4 ffmpeg -i input.mpg -vf scale=320:240 output.mp4对输入视频成比例缩放改变为源视频一半大小 ffmpeg -i input.mpg -vf scale=iw/2:ih/2 output.mp4改变为原视频的90%大小： ffmpeg -i input.mpg -vf scale=iw*0.9:ih*0.9 output.mp4 在未知视频的分辨率时，保证调整的分辨率与源视频有相同的横纵比。 可能会有错误，不推荐使用，最好传入明确的缩放值。另外，scale只能接受偶数，否则height not divisible by 2 12345宽度固定400，高度成比例： ffmpeg -i input.avi -vf scale=400:-2相反地，高度固定300，宽度成比例： ffmpeg -i input.avi -vf scale=-2:300 crop（宽高xy） scale（宽高） overlay（xy） 参数区别crop视频裁剪区域，宽高xy1234567891011w, out_wThe width of the output video. It defaults to iw. This expression is evaluated only once during the filter configuration, or when the ‘w’ or ‘out_w’ command is sent.h, out_hThe height of the output video. It defaults to ih. This expression is evaluated only once during the filter configuration, or when the ‘h’ or ‘out_h’ command is sent.xThe horizontal position, in the input video, of the left edge of the output video. It defaults to (in_w-out_w)/2. This expression is evaluated per-frame.yThe vertical position, in the input video, of the top edge of the output video. It defaults to (in_h-out_h)/2. This expression is evaluated per-frame. 1crop=w=100:h=100:x=12:y=34 scale缩放，宽高1234567891011width, wheight, hSet the output video dimension expression. Default value is the input dimension.If the width or w value is 0, the input width is used for the output. If the height or h value is 0, the input height is used for the output.If one and only one of the values is -n with n &gt;= 1, the scale filter will use a value that maintains the aspect ratio of the input image, calculated from the other specified dimension. After that it will, however, make sure that the calculated dimension is divisible by n and adjust the value if necessary.If both values are -n with n &gt;= 1, the behavior will be identical to both values being set to 0 as previously detailed.See below for the list of accepted constants for use in the dimension expression. 12scale=w=200:h=100scale=w=iw/2:h=ih/2 overlay视频叠加，xy123456xySet the expression for the x and y coordinates of the overlaid video on the main video.Default value is &quot;0&quot; for both expressions. In case the expression is invalid, it is set to a huge value (meaning that the overlay will not be displayed within the output visible area) 1overlay=0:0 scale宽高只能接受偶数，否则出错 height not divisible by 2例如想要把视频缩放到1111x1111，则会报错 height not divisible by 2 1ffmpeg -i 10.mp4 -vf scale=1111:1111 101010.mp4 FFmpeg中的scale命令后面的宽高，只能接受偶数 1ffmpeg -i 10.mp4 -vf scale=1110:1110 101010.mp4 可行的方案是：在scale中加入处理trunc类似于int取整，对1111/2取整，最后在*2，结果一定是偶数 1ffmpeg -i 10.mp4 -vf scale=trunc(1111/2)*2:trunc(1111/2)*2 101010.mp4 另一个简单的方案：高度使用-2，负数代表自动按比例缩放，2代表结果取2的倍数 1ffmpeg -i in.mp4 -vf scale=iw:-2 out.mp4 另外：crop命令裁剪的时候，会自动裁剪成偶数 -map命令的使用介绍标题理解-map参数的最好办法就是想像一下怎么去告诉ffmpeg你要从源文件中选择/拷贝哪个流到输出文件。输出文件的stream顺序取决于在命令行中-map的参数顺序。 默认默认操作（没有指定map参数），比如： 1ffmpeg -i INPUT OUTPUT 本质上，是从所有输入中发现“最高质量”（单个）视频输入流和“最高质量”（单个）音频输入流，并“发送”到OUTPUT。所有其他输入流实质上都被丢弃了。 如果我们想用map命令“显示”与上面命令相同的操作，它会是这样的： 1ffmpeg -i INPUT -map single_highest_quality_video_stream_from_all_inputs -map single_highest_quality_audio_stream_from_all_inputs OUTPUT 此处输出将有两个流，一个音频，一个视频。 当你想要控制哪些流被包含，或者在输出中包含不止一个流时，你需要/想要手动指定“-map”命令，并修改这些参数。 输入文件在下面的所有示例中，我们将使用一个类似下面的示例输入文件： 1234567891011# fmpeg -i input.mkvffmpeg version ... Copyright (c) 2000-2012 the FFmpeg developers...Input #0, matroska,webm, from 'input.mkv': Duration: 01:39:44.02, start: 0.000000, bitrate: 5793 kb/s Stream #0:0(eng): Video: h264 (High), yuv420p, 1920x800, 23.98 fps, 23.98 tbr, 1k tbn, 47.95 tbc (default) Stream #0:1(ger): Audio: dts (DTS), 48000 Hz, 5.1(side), s16, 1536 kb/s (default) Stream #0:2(eng): Audio: dts (DTS), 48000 Hz, 5.1(side), s16, 1536 kb/s Stream #0:3(ger): Subtitle: text (default)At least one output file must be specified 例子1那么现在，我们说我们想要： 将视频流复制将德语音频流编码为MP3（128kbps）和AAC（96kbps）（在输出中创建两个音频流）将英语音频流删除将字幕流复制这可以用以下的ffmpeg命令来完成： 1234567ffmpeg -i input.mkv \\ -map 0:0 -map 0:1 -map 0:1 -map 0:3 \\ -c:v copy \\ -c:a:0 libmp3lame -b:a:0 128k \\ -c:a:1 libfaac -b:a:1 96k \\ -c:s copy \\ output.mkv 注意一下参数里没有“-map 0:2”，并且“-map 0:1”被写了两次。 使用“-map 0:0 -map 0:1 -map 0:1 -map 0:3”，我们告诉ffmpeg选择/映射指定的输入流按相应顺序输出。 因此，我们的输出将具有以下流： 12345Output #0, matroska, to 'output.mkv': Stream #0:0(eng): Video ... Stream #0:1(ger): Audio ... Stream #0:2(ger): Audio ... Stream #0:3(ger): Subtitle ... 在我们选择好在输出中包含哪些流之后，使用“-map”选项，我们为输出中的每个流指定相应的编解码器。 视频和字幕流已经被复制，德语的音频流被编码成了两个新的音频流，MP3和AAC。 我们使用“-c?️0”来指定输出的第一路音频流编解码器（codec），且用“-c?️1”来指定输出的第二路音频流编解码器（codec）。 注意，“a:0”指的是输出的第一路音频流（本例中为0:1）,“a:1”指的是输出的第二路音频流（也映射到输入流0:1），等。 结果将会是： 12345678910Output #0, matroska, to 'output.mkv': Stream #0:0(eng): Video ... Stream #0:1(ger): Audio ... Stream #0:2(ger): Audio ... Stream #0:3(ger): Subtitle ...Stream mapping: Stream #0:0 -&gt; #0:0 (copy) Stream #0:1 -&gt; #0:1 (dca -&gt; libmp3lame) Stream #0:2 -&gt; #0:2 (dca -&gt; libfaac) Stream #0:3 -&gt; #0:3 (copy) 例子2如果说我们想要倒序排列输入流，比如类似这样的输出： 1234Stream #0:0(ger): Subtitle: text (default)Stream #0:1(eng): Audio: dts (DTS), 48000 Hz, 5.1(side), s16, 1536 kb/sStream #0:2(ger): Audio: dts (DTS), 48000 Hz, 5.1(side), s16, 1536 kb/s (default)Stream #0:3(eng): Video: h264 (High), yuv420p, 1920x800, 23.98 fps, 23.98 tbr, 1k tbn, 47.95 tbc (default) 这可以简单地使用下面的命令行来完成： 1ffmpeg -i input.mkv -map 0:3 -map 0:2 -map 0:1 -map 0:0 -c copy output.mkv 注意，我们指定了所有的输入流，输出中的流顺序也会按照输入流的顺序生成。 选项“-c copy”告诉ffmpeg在所有流上使用“复制”操作。 例子3如果我们想从同一个输入文件中仅提取音频流，那么我们可以这样做： 1ffmpeg -i input.mkv -map 0:1 -map 0:2 -c copy output.mkv 例子4如果我们想重新编码视频流，但复制所有其他流（如音频、字幕、附件等），我们可能会使用这样的东西： 1ffmpeg -i input.mkv -map 0 -c copy -c:v mpeg2video output.mkv 这将会告诉ffmpeg： 读取输入文件“‘input.mkv’”选择要处理的所有输入流（第一个input＝0）（使用“-map 0”）标记所有流被复制到输出（使用“-c copy”）标记要重新编码的视频流（使用“-c:v mpeg2video”）写入输出文件到“output.mkv” 例子5你可以使用”-map”命令来创建多路文件输出，比如： 1ffmpeg -i input.mkv -map 0:1 -map 0:2 audios_only.mkv -map 0:0 video_only.mkv 默认是将“最高质量视频”和“最高质量音频”映射到每个输出文件（基本上为每个输出重复使用），更多请参考创建多个输出。 例子6你可以使用一个滤镜（filtergraph）做为map参数来控制输出： 1ffmpeg -i INPUT -filter_complex &quot;[0] scale=100x100[smaller_sized]&quot; -map &quot;[smaller_sized]&quot; out.mp4 这（在我们的示例中）与更精确地指定流是相同的，并且完全一样。 1ffmpeg -i INPUT -filter_complex “[0:0] scale=100x100[smaller_sized]” -map “[smaller_sized]” out.mp4 例子7还有一些流选择快捷方式，比如你也可以使用“0:v”： 1ffmpeg -i input -map 0:v -map 0:a output.mkv # chooses video and audio from input 0 具体请参见流指示器 例子8MPEG流的选择： 最棘手的部分是从MPEG TS流选择时它可能会有多个流/通道，如果你正在接收“实时数据”（live data）,仅仅指定索引可能是不行的，因为索引可以在运行时有所变化，所以： 1ffmpeg -i INPUT -map 0:6 OUTPUT # 每次运行产生的结果可能都不一样，请不要这样使用! 假设您的文件是MPEG，您可以运行“ffmpeg -i INPUT”（不指定输出）来查看它包含的程序ID和流ID，比如这个示例（对其进行分析，以帮助“确保”它接收到其中的所有流，可能并不总是需要的）。 12345678910111213141516171819$ ffmpeg -probesize 50M -analyzeduration 50M -i INPUT...Input #0, mpegts, from 'INPUT': Duration: N/A, start: 22159.226833, bitrate: N/A Program 1344 Metadata: service_name : 7 Digital service_provider: Seven Network Stream #0:0[0x401]: Video: mpeg2video (Main) ([2][0][0][0] / 0x0002), yuv420p(tv), 720x576 [SAR 64:45 DAR 16:9], max. 14950 kb/s, 25 fps, 25 tbr, 90k tbn, 50 tbc Stream #0:1[0x402](eng): Audio: mp2 ([3][0][0][0] / 0x0003), 48000 Hz, stereo, s16p, 256 kb/s Program 1346 Metadata: service_name : 7TWO service_provider: Seven Network Stream #0:3[0x406]: Unknown: none ([5][0][0][0] / 0x0005) Stream #0:6[0x421]: Video: mpeg2video (Main) ([2][0][0][0] / 0x0002), yuv420p(tv), 720x576 [SAR 64:45 DAR 16:9], max. 14950 kb/s, 25 fps, 25 tbr, 90k tbn, 50 tbc Stream #0:7[0x422](eng): Audio: mp2 ([3][0][0][0] / 0x0003), 48000 Hz, stereo, s16p, 192 kb/s Stream #0:8[0x424](eng): Subtitle: dvb_teletext ([6][0][0][0] / 0x0006), 492x250 Stream #0:4[0x499]: Unknown: none ([11][0][0][0] / 0x000B) 你可以通过程序ID指定所需的流： 1ffmpeg -i INPUT -map 0:p:1344 OUTPUT # 从程序1344中输入两个输入，在本例子中是通道“7 digital” 或指定子流： 1ffmpeg -i INPUT -map i:0x401 OUTPUT # 从找到的任何地方用PID（MPEG Packet ID [stream identifier]）`0x401拉入单个输入流，在本例中，它是“7 digital”中的视频流 其他类似的，请参阅其说明符示例。注意，如果你有“未知”的流在那里，你可能需要添加-ignore_unknown标志。 还请注意，如果输入流包含多个程序ID，则可以使用相同的ffmpeg实例和这里描述的map命令同时来记录它们。 例子9包括“全部”输入到输出。默认行为是只复制一个音频和一个视频通道。如果你想复制“所有”频道，请使用“-map”： 12ffmpeg -i input -map 0 output.mp4 # 从一个输入重新编码所有视频和音频通道 ffmpeg -i input -map 0 -c copy output.mp4 # 将所有视频和音频通道从一个输入复制到输出，而不是仅一个视频 英文原文地址：http://trac.ffmpeg.org/wiki/Map 视频的倒放1234567Reverse a video clip.Warning: This filter requires memory to buffer the entire clip, so trimming is suggested.ExamplesTake the first 5 seconds of a clip, and reverse it.trim=end=5,reverse 1ffmpeg -i G:\\1\\c6cfb2d13929eb4967417e0bd81c314c.mp4 -vf reverse -y reverse.mp4 生成YUV、PCM原始数据YUV提取YUV数据 123456789ffmpeg -i input.mp4 -an -c:v rawvideo -pixel_format yuv420p out.yuv-c:v rawvideo 指定将视频转成原始数据-pixel_format yuv420p 指定转换格式为yuv420p播放这个ffplay -s wxh out.yuvYUV转H264ffmpeg -f rawvideo -pix_fmt yuv420p -s 320x240 -r 30 -i out.yuv -c:v libx264 -f rawvideo out.h264 PCM12345678提取PCM数据ffmpeg -i out.mp4 -vn -ar 44100 -ac 2 -f s16le out.pcm播放PCMffplay -ar 44100 -ac 2 -f s16le -i out.pcmPCM转WAVffmpeg -f s16be -ar 8000 -ac 2 -acodec pcm_s16be -i input.raw output.wav 举例： 12345//特效边框+底板视频，生成yuv视频ffmpeg -i a3.mp4 -stream_loop -1 -i partPlay_color_video_12.mp4 -stream_loop -1 -i partPlay_gray_video_12.mp4 -filter_complex [1:v][2:v]alphamerge[vTheme];[0:v][vTheme]overlay=(W-w)/2:(H-h)/2 -an -c:v rawvideo -pixel_format yuv420p -t 100 -y outTest.yuv//播放这个视频ffplay -s 1280x720 outTest.yuv 音频设置采样率，和声道数原始音频信息，采样率44100 Hz，双声道stereo 12Duration: 00:11:23.60, start: 0.025057, bitrate: 128 kb/sStream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s 12345ffmpeg -i C:\\Users\\Administrator\\Desktop\\materials\\蕊希.mp3 -ac 1 -ar 48000 -y test.mp3其中：-ac 1 设置声道数为1-ar 48000 设置采样率为48000Hz 转码后的音频，采样率48000 Hz，单声道mono 12Duration: 00:11:23.59, start: 0.023021, bitrate: 64 kb/sStream #0:0: Audio: mp3, 48000 Hz, mono, fltp, 64 kb/s volume 和 -vol 调大调小音视频的音量volume12//音量翻倍，写在滤镜里，例如ffmpeg -i 1.wav -af volume=2 -y 2.wav vol12//音量翻倍，不写在滤镜中，例如ffmpeg -i 1.wav -vol 2000 -y 2.wav 为视频添加关键帧，可以解决播放器无法SeekTo到关键帧的问题12345678910111213141516171819202122//每隔10帧设置一个关键帧，如果是30帧的视频，则代表每秒3个关键帧ffmpeg -i 2.mp4 -c:v libx264 -x264opts keyint=10 -y keyint10.mp4//每帧都是关键帧ffmpeg -i 2.mp4 -c:v libx264 -x264opts keyint=1 -y keyint11.mp4//每秒一个关键帧ffmpeg -i 2.mp4 -c:v libx264 -x264opts keyint=30 -y keyint12.mp4-i 2.mp4输入文件-c:v libx264编码器使用libx264-x264opts keyint=10视频文件每隔 10帧设置一个关键帧-y keyint10.mp4输出文件 视频的旋转rotate1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950Rotate video by an arbitrary angle expressed in radians.The filter accepts the following options:A description of the optional parameters follows.angle, aSet an expression for the angle by which to rotate the input video clockwise, expressed as a number of radians. A negative value will result in a counter-clockwise rotation. By default it is set to &quot;0&quot;.This expression is evaluated for each frame.out_w, owSet the output width expression, default value is &quot;iw&quot;. This expression is evaluated just once during configuration.out_h, ohSet the output height expression, default value is &quot;ih&quot;. This expression is evaluated just once during configuration.bilinearEnable bilinear interpolation if set to 1, a value of 0 disables it. Default value is 1.fillcolor, cSet the color used to fill the output area not covered by the rotated image. For the general syntax of this option, check the (ffmpeg-utils)&quot;Color&quot; section in the ffmpeg-utils manual. If the special value &quot;none&quot; is selected then no background is printed (useful for example if the background is never shown).Default value is &quot;black&quot;.The expressions for the angle and the output size can contain the following constants and functions:nsequential number of the input frame, starting from 0. It is always NAN before the first frame is filtered.ttime in seconds of the input frame, it is set to 0 when the filter is configured. It is always NAN before the first frame is filtered.hsubvsubhorizontal and vertical chroma subsample values. For example for the pixel format &quot;yuv422p&quot; hsub is 2 and vsub is 1.in_w, iwin_h, ihthe input video width and heightout_w, owout_h, ohthe output width and height, that is the size of the padded area as specified by the width and height expressionsrotw(a)roth(a)the minimal width/height required for completely containing the input video rotated by a radians.These are only available when computing the out_w and out_h expressions. 12//T为旋转一周的时长，如果为视频的时长，则旋转一圈，正好可以播放完ffmpeg -i a3.mp4 -vf rotate=PI*2/T*t rotate8.mp4 rotate的第一个参数angle的单位是弧度1°=π/180360°=2π 例如将视频旋转90°，注意此种方式，并没有改变水平尺寸1ffmpeg -i a3.mp4 -vf rotate=PI/2 rotate9.mp4 视频的翻转vflip、hflip，旋转rotate、转置transpose翻转hflip12//水平翻转ffmpeg -i fan.jpg -vf hflip -y hflip.png 旋转rotate12//旋转60°，是带有黑底的。图片的原始宽高并没有改变ffmpeg -i fan.jpg -vf rotate=PI/3 -y rotate60.png 转置transpose 1234//逆时针旋转90°ffmpeg -i fan.jpg -vf transpose=2 -y transpose2.png//逆时针旋转90°，然后垂直翻转ffmpeg -i fan.jpg -vf transpose=0 -y transpose0.png 视频的旋转rotate升级版，rotate，alphamerge给视频加上mask后，旋转，并叠加在另一个视频上1234567891011121314151617181920212223//方案1 （有黑底）ffmpeg -loop 1 -i 圆形.png -i maskBase.mp4 -i a3.mp4 -filter_complex [0:v]alphaextract[vMaskAlpha];[1:v][vMaskAlpha]alphamerge[vTop];[vTop]rotate=PI*2/10*t[vRotate];[2:v][vRotate]overlay=(W-w)/2:(H-h)/2 -y maskRotateOverlay.mp4// 方案二：分成两步// 1.视频加上Mask以后，并且旋转// mask和底部视频尺寸要一致，时长也要一致，所以加上了-loop 1ffmpeg -loop 1 -i 圆形.png -i maskBase.mp4 -filter_complex [0:v]alphaextract[vMaskAlpha];[1:v][vMaskAlpha]alphamerge[vTop];[vTop]rotate=PI*2/10*t[vRotate];color=c=black:s=648x648[vBg];[vBg][vRotate]overlay -t 10 -y maskRotate.mp4// 2.去掉黑底，并且overlayffmpeg -i a3.mp4 -i maskRotate.mp4 -filter_complex [1]split[m][a];[a]geq='if(gt(lum(X,Y),50),255,0)',hue=s=0[al];[m][al]alphamerge[ovr];[0][ovr]overlay=(W-w)/2:(H-h)/2 -y maskRotateOverlay2.mp4// 不够完美，黑色去掉的有点多了，有好的方案在改吧// 方案三：最终方案// 在方案一的基础上给rotate加一个参数c=noneffmpeg -loop 1 -i 圆形.png -i maskBase.mp4 -i a3.mp4 -filter_complex [0:v]alphaextract[vMaskAlpha];[1:v][vMaskAlpha]alphamerge[vTop];[vTop]rotate=PI*2/10*t:c=none[vRotate];[2:v][vRotate]overlay=(W-w)/2:(H-h)/2 -y maskRotateOverlay33.mp4// 方案四：如果顶部是一个方形的视频// 可以看到就像扑克牌一样，一帧帧的铺开，所以要用圆形来旋转，即使加上eof_action=pass，也只是最后播放完成后，顶层视频帧一起消失ffmpeg -i maskBase.mp4 -i a3.mp4 -filter_complex [0:v]format=bgra,rotate='PI*2/10*t:ow=hypot(iw,ih):oh=ow:c=none'[vRotate];[1:v][vRotate]overlay=(W-w)/2:(H-h)/2 -t 3 -y maskRotateOverlay55.mp4// 最终方案，核心，c=0x00000000 给一个透明色即可ffmpeg -loop 1 -i 1567495070237.bmp -i a3.mp4 -filter_complex [0:v]format=bgra,rotate='PI*2/10*t:ow=hypot(iw,ih):oh=ow:c=0x00000000'[vRotate];[1:v][vRotate]overlay=(W-w)/2:(H-h)/2 -t 3 -y noBlackPad.mp4 为视频设置透明度的几种方案方案一：1ffmpeg -i a2.mp4 -i a3.mp4 -filter_complex [0:v]format=yuva444p,colorchannelmixer=aa=0.5[valpha];[1:v][valpha]overlay=(W-w)/2:(H-h)/2 -ss 0 -t 5 -y overlay4.mp4 方案二： 对图片有效，经过测试1ffmpeg -i in4.png -i a3.mp4 -filter_complex [0:v]geq=a='122':lum='lum(X,Y)':cb='cb(X,Y)':cr='cr(X,Y)'[topV];[1:v][topV]overlay=(W-w)/2:(H-h)/2 -ss 0 -t 5 -y overlay3.mp4 方案三：同方案二，只是先将视频转换成一张张帧序列然后再使用方案二此处经过测试，同样在ffmpeg 4.13下。Windows，Android，iOS 只有IOS下可以对视频进行geq，所以其他平台只能先转换成图片序列，然后再做geq 12//此处经过测试，同样在ffmpeg 4.13下。Windows，Android，iOS 只有IOS下可以对视频进行geqffmpeg -i a2.mp4 -i a3.mp4 -filter_complex [0:v]geq=a='122':lum='lum(X,Y)':cb='cb(X,Y)':cr='cr(X,Y)'[topV];[1:v][topV]overlay=(W-w)/2:(H-h)/2 -ss 0 -t 5 -y overlay2.mp4 视频添加个黑色的遮罩数值越大越不透明color命令可以新建一个颜色图层，然后使用overlay叠加在视频上 1ffmpeg -i out3.mp4 -filter_complex color=s=1000x1000:c=black@.3[vc];[0:v][vc]overlay[out] -ss 0 -to 10 -map [out] -y ou4.mp4 1ffmpeg -i 123.mov -filter_complex color=s=1000x1000:c=black@.9[vc];[0:v][vc]overlay[out] -ss 0 -to 10 -map [out] -y ou4.mp4 视频与图片互转，视频转gif，单张图片合成视频，提取封面，单帧视频转gif123456视频转gifffmpeg -i out.mp4 -ss 00:00:00 -t 10 out.gif t的格式 -t 1.1 -t 00:00:01 -r 帧率每秒的帧数，数值越大越流畅 视频中提取任意一帧图片12345ffmpeg -i test.asf -y -f image2 -ss 00:01:00 -vframes 1 test1.jpgorffmpeg -i test.asf -y -f image2 -ss 60 -vframes 1 test1.jpg//png格式不会压缩ffmpeg -i 1.avi -f image2 -ss 2 -vframes 1 test1.png 视频转图片视频转图片，-r 帧率每秒钟转化1张，image2为image协议的第二版 1ffmpeg -i 2.mp4 -r 1 -f image2 image-%d.jpg 图片转视频注意：png需要特殊处理，如下图片转视频，jpg例子从一个文件序列 img-1.jpeg, img-2.jpeg, …,创建视频，帧率为10: 1234567891011ffmpeg -framerate 10 -i img-%d.jpeg out.mkvffmpeg -framerate 30 -i image-%d.jpg -y out.mp4//png图片的合成，如果没有特殊加背景，则背景是黑色的。ffmpeg -framerate 30 -i image-%d.png -c:v libx264 -pix_fmt yuv420p -y out3.mp4类似上例，但开始的数字是100，即索引是从100开始计数:ffmpeg -framerate 10 -start_number 100 -i 'img-%d.jpeg' out.mkv读取&quot;*.png&quot; 以通配符模式处理，这将包含所有&quot;.png&quot;结尾的文件:ffmpeg -framerate 10 -pattern_type glob -i &quot;*.png&quot; out.mkv 单张图片合成视频 12//单张图片合成视频，这里需要用到-loop 1 开启循环，和-t 10 设置为10秒ffmpeg -r 1 -f image2 -loop 1 -i 1.png -t 10 out.mp4 -y 单张图片生成视频，通过滤镜完成 1ffmpeg -i 1.png -filter_complex color=s=500x500:c=black,trim=0:5[vbg];[0:v]scale=500x500[sv];[vbg][sv]overlay[vout] -map [vout] -y 1.mp4 1ffmpeg -i 1.jpg -filter_complex color=s=720x1280:c=black[vbg];[0:v]scale=720x1280[sv];[vbg][sv]overlay[vout] -map [vout] -ss 0 -to 10 -y 1.mp4 1234567891011ffmpeg -i 1.png -filter_complex color=s=500x500:c=black,trim=0:5[vbg];[0:v]scale=500x500[sv];[vbg][sv]overlay[vout] -map [vout] -y 1.mp4 为视频添加一个循环播放的背景音乐（混声）方案1（不推荐）（混声）1ffmpeg -i E:\\1\\subtitle\\out3.mp4 -i E:\\1\\subtitle\\music3D.wav -filter_complex [1:a]aloop=loop=-1:size=2e+09[out];[out][0:a]amix -ss 0 -t 60 -y out.mp4 -i E:\\1\\subtitle\\out3.mp4 //输入视频，最好选一个大于一分钟的尝试 -i E:\\1\\subtitle\\music3D.wav //输入背景音，最好短一点，方便测试是否循环 -filter_complex //滤镜 [1:a]aloop=loop=-1:size=2e+09[out]; //将背景音无限循环 [out][0:a]amix //将背景音和视频中的音频混合 -ss 0 -t 60 //裁剪总时长，裁剪到60秒 -y out.mp4 //输出 方案2（推荐）（混声）1ffmpeg -i video.mp4 -stream_loop -1 -i audio.wav -filter_complex [0:a][1:a]amix -t 60 -y out.mp4 其中 -stream_loop -1 -i audio.wav -stream_loop -1 参数-1代表循环输入源 [0:a][1:a]amix 将0和1号的音频流进行混合 -t 60 裁剪60秒 方案3（推荐）（音频替换）1ffmpeg -an -i video.mp4 -stream_loop -1 -i audio.wav -t 60 -y out2.mp4 其中 1-an -i video.mp4 代表消除视频中的音频 方案4（推荐）（音频替换，优化加快合成速度）1ffmpeg -an -i video.mp4 -stream_loop -1 -i audio.wav -c:v copy -t 60 -y out.mp4 -c:v copy 对视频流进行复制，不需要重新编解码（前提是输入流和输出流一致），速度极快 这里音频必须编码的原因在于，输入源是一个wav的音频，而最后输出MP4文件中需要一个aac的音频，所以必须重新编码，否则会报错。 方案5（原视频无音轨的情况）为无音轨的视频添加一个循环的背景音乐原视频无音轨的情况下不需要混声，直接导入两个源文件（源视频，背景音） 1ffmpeg -i video_no_audio.mp4 -stream_loop -1 -i 世界这么大.wav -ss 0 -t 30 -y out.mp4 drawtext在视频上添加文字官方文档drawtext 默认值 123默认字体 Sans默认颜色 black默认字体大小 16 最简单的demo，全部使用默认字符中间有空格，最外层需要双引号引用 1ffmpeg -i a3.mp4 -vf drawtext=&quot;text=test test&quot; -y out1.mp4 绘制位置，字体大小100，背景色blue 1ffmpeg -i a3.mp4 -vf drawtext=&quot;text=test test:x=100:y=100:fontsize=100:fontcolor=white:box=1:boxcolor=blue&quot; -y out2.mp4 中心区域绘制文字1ffmpeg -i a3.mp4 -vf drawtext=&quot;fontsize=100:fontcolor=white:text='hello world':x=(w-text_w)/2:y=(h-text_h)/2&quot; -y out3.mp4 setpts，atempo视频音频加减速1234567891011121314视频加速ffmpeg -i 1.mp4 -vf &quot;setpts=0.5*PTS&quot; 1jiasu.mp4视频减速ffmpeg -i 2.mp4 -vf &quot;setpts=2.0*PTS&quot; 2jiansu.mp4音频加速&quot;atempo&quot;滤镜对音频速度调整限制在0.5 到 2.0 之间，（即半速或倍速）2倍速ffmpeg -i 1jiasu.mp4 -af &quot;atempo=2.0&quot; 1quanbujiasu.mp44倍速ffmpeg -i 1jiasu.mp4 -af &quot;atempo=2.0,atempo=2.0&quot; 1quanbujiasu.mp4使用更复杂的滤镜，可以同时加速视频和音频：ffmpeg -i 1.mp4 -filter_complex &quot;[0:v]setpts=0.5*PTS[v];[0:a]atempo=2.0[a]&quot; -map &quot;[v]&quot; -map &quot;[a]&quot; 11quanbu.mp4 混音（混声）命令12345678910111213141516inputsThe number of inputs. If unspecified, it defaults to 2.//输入的数量，如果没有指明，默认为2. durationHow to determine the end-of-stream.//决定了流的结束 longest The duration of the longest input. (default)//最长输入的持续时间 shortest The duration of the shortest input.//最短输入的持续时间 first The duration of the first input.//第一个输入的持续时间 dropout_transitionThe transition time, in seconds, for volume renormalization when an input stream ends. The default value is 2 seconds.//指一个输入流结束时音量从正常到无声渐止效果，默认为2秒 1ffmpeg -i INPUT1 -i INPUT2 -i INPUT3 -filter_complex amix=inputs=3:duration=first:dropout_transition=3 OUTPUT 快速将视频转换为小而清晰的 GIF12$ ffmpeg -an -skip_frame nokey -i 输入文件 -vf scale=导出分辨率:flags=fast_bilinear,palettegen=max_colors=色彩数量:stats_mode=diff 色板文件$ ffmpeg -an -i 输入文件 -i 色板文件 -r 输出文件帧率 -lavfi &quot;framestep=原视频帧率/输出文件帧率*变速速率,setpts=PTS/变速速率,scale=导出分辨率:flags=lanczos [x]; [x][1:v] paletteuse=dither=bayer&quot; 输出文件 此脚本比较复杂，需要将汉字部分按下表进行填写替换： 参数名 填写示例 说明 输入文件 input.mp4 输入视频文件的路径 导出分辨率 320:240 长和宽必须都是2的倍数 色彩数量 128 可接受的值为[4, 256]；值越大，色彩越保真，但输出的文件体积也越大； 色板文件 palette.png GIF调色板文件。在第一行生成，并第二行使用到 视频帧率 60 输入的视频的帧率 输出文件帧率 10 输出的GIF的帧率 变速速率 1.0 如果不需要变速，填写1.0；二倍速则填写2.0，依此类推 输出文件 output.gif 输出GIF文件的路径 光流法补帧1$ ffmpeg -i input.mp4 -filter:v &quot;minterpolate='fps=60:mi_mode=mci:mc_mode=aobmc:vsbmc=1'&quot; optical_flow.mp4 60为目标帧率。 速度较慢，效果可能没有Premiere Pro的光流法好。 降低视频抖动12$ ffmpeg -i input.mp4 -vf vidstabdetect=shakiness=10:result=&quot;mytransforms.trf&quot; -f null -$ ffmpeg -i input.mp4 -vf vidstabtransform=smoothing=30:input=&quot;mytransforms.trf&quot;,unsharp=5:5:0.8:3:3:0.4 stabilized.mp4 此操作需要两行：第一行分析视频input.mp4的内容，并将结果保存至mytransforms.trf；第二行生成稳定后的视频stabilized.mp4。 速度较慢，且效果不如Google Photos和Premiere Pro好。 获取媒体文件属性1$ ffprobe -v error -show_format -show_streams input.mp4 上面将返回媒体文件的所有属性。 1$ ffprobe -v quiet -select_streams V:0 -show_entries stream=width,height,r_frame_rate,bit_rate -of csv=p=0:sv=fail -i input.mp4 有时只需要媒体文件中的特定几项信息，可以通过类似这样的方式指定。（这条脚本将返回视频流的宽、高、帧率、比特率，中间以逗号分隔，如1920,1080,30/1,11895227） 压缩音频为无损 FLAC1$ ffmpeg -i input.wav -c:a flac -compression_level 12 output.flac 压缩音频为有损 Opus1$ ffmpeg -i input.wav -c:a libopus -b:a 128k output.ogg 128k为比特率。 Opus可能是目前压缩率最佳的音频编码器，在极低的比特率下也能提供优秀的音质，且大部分软件都兼容此格式。 从一堆ts文件生成m3u8文件的脚本1234567891011121314151617181920#!/bin/bashecho '#EXTM3U'echo '#EXT-X-VERSION:3'echo '#EXT-X-MEDIA-SEQUENCE:1'maxDuration=0while read f; do duration=&quot;$(ffprobe -v error -select_streams v:0 -show_entries stream=duration -of default=noprint_wrappers=1:nokey=1 &quot;$f&quot; | grep -E '^[0-9]+(\\.[0-9]+)?$' | head -n1)&quot; echo &quot;#EXTINF:$duration,&quot; echo $f if [ `echo &quot;$duration &gt; $maxDuration&quot; | bc` -eq 1 ]; then maxDuration=&quot;$duration&quot; fidoneecho '#EXT-X-ENDLIST'echo &quot;#EXT-X-TARGETDURATION:$maxDuration&quot; 依赖： ffprobe命令，可通过安装ffmpeg软件包得到。 bc命令，可通过安装bc软件包得到。 12# 在Debian上安装依赖sudo apt install ffmpeg bc 用法：123wget -O gen_ts_m3u8.sh https://vkceyugu.cdn.bspapp.com/VKCEYUGU-cc8cf08f-49f5-4fc5-83c3-ed2a683704d4/4db7c4a8-9131-4771-9d36-71a2b30ca35a.shchmod +x gen_ts_m3u8.shls *.ts | ./gen_ts_m3u8.sh | tee main.m3u8 使用GPU加速1ffmpeg -hwaccels 如下 12345678910111213141516171819ffmpeg version 4.2.4-1ubuntu0.1 Copyright (c) 2000-2020 the FFmpeg developers built with gcc 9 (Ubuntu 9.3.0-10ubuntu2) configuration: --prefix=/usr --extra-version=1ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared libavutil 56. 31.100 / 56. 31.100 libavcodec 58. 54.100 / 58. 54.100 libavformat 58. 29.100 / 58. 29.100 libavdevice 58. 8.100 / 58. 8.100 libavfilter 7. 57.100 / 7. 57.100 libavresample 4. 0. 0 / 4. 0. 0 libswscale 5. 5.100 / 5. 5.100 libswresample 3. 5.100 / 3. 5.100 libpostproc 55. 5.100 / 55. 5.100Hardware acceleration methods:vdpaucudavaapidrmopenclcuvid 测试命令将当前目录下的0.mp4转成00.mp4 1ffmpeg -hwaccel cuvid -c:v h264_cuvid -i 0.mp4 -c:v h264_nvenc -y 00.mp4 将当前目录下的0.mp4转成00.mp4，并指定输出帧率为15（-r 15），比特率为500k（-b 500k） 12ffmpeg -hwaccel cuvid -c:v h264_cuvid -i 0.mp4 -c:v h264_nvenc -r 15 -b 500k -y 00.mp4 1ffmpeg -hwaccel cuvid -c:v h264_cuvid -i &lt;input&gt; -c:v h264_nvenc -b:v 2048k -vf scale_npp=1280:-1 -y &lt;output&gt; hwaccel cuvid：指定使用cuvid硬件加速 c:v h264_cuvid：使用h264_cuvid进行视频解码 c:v h264_nvenc：使用h264_nvenc进行视频编码 vf scale_npp=1280:-1：指定输出视频的宽高，注意，这里和软解码时使用的-vf scale=x:x不一样 多颗显卡命令GPU转码效率测试 在配有两颗Intel-E5-2630v3 CPU和两块Nvidia Tesla M4显卡的服务器上，进行h264视频转码测试，成绩如下： GPU转码平均耗时：8sCPU转码平均耗时：25s 并行转码时，CPU软转的效率有所提高，3个转码任务并行时32颗核心全被占满，此时的成绩 GPU转码平均耗时：8sCPU转码平均耗时：18s 不难看出，并行时GPU的转码速度并没有提高，可见一颗GPU同时只能执行一个转码任务。那么，如果服务器上插有多块显卡，ffmpeg是否会使用多颗GPU进行并行转码呢？很遗憾，答案是否。ffmpeg并不具备自动向不同GPU分配转码任务的能力，但经过一番调查后，发现可以通过-hwaccel_device参数指定转码任务使用的GPU！ 向不同GPU提交转码任务 显卡0 1ffmpeg -hwaccel cuvid -hwaccel_device 0 -c:v h264_cuvid -i &lt;input&gt; -c:v h264_nvenc -b:v 2048k -vf scale_npp=1280:-1 -y &lt;output&gt; 显卡1 1ffmpeg -hwaccel cuvid -hwaccel_device 1 -c:v h264_cuvid -i &lt;input&gt; -c:v h264_nvenc -b:v 2048k -vf scale_npp=1280:-1 -y &lt;output&gt; hw accel_device N：指定某颗GPU执行转码任务，N为数字 Linux下稍微麻烦一点儿，具体可参考：https://www.jianshu.com/p/59da3d350488 AMD GPUAMD的GPU不需要额外下载东西，只要把ffmpeg编译好就能用。Windows版的ffmpeg官网提供了编译好的版本，因此Windows用户无需过多操心这个了，Linux如有需要，请参考： https://stackoverflow.com/questions/56933969/how-to-run-ffmpeg-in-gpuamd 命令将a.mp4转成b.mp4 1ffmpeg -i .\\a.mp4 -c:v h264_amf .\\b.mp4 ffprobe获取视频总帧数 1ffprobe -v error -count_frames -select_streams v:0 -show_entries stream=nb_read_frames -of default=nokey=1:noprint_wrappers=1 input.mp4 输出6000。 在本例中，6000的输出是指读取帧的数量。因为整个文件必须解码，命令可能需要一段时间才能完成，具体取决于具体的输入文件大小。 选项的含义 -v error：这隐藏了“info”输出(版本信息等)，使解析更容易。 -count_frames：计算每个流的帧数，并在相应的流部分中报告。 -select_streams v:0 ：仅选择视频流。 -show_entries stream = nb_read_frames ：只显示读取的帧数。 -of default = nokey = 1：noprint_wrappers = 1 ：将输出格式(也称为“writer”)设置为默认值，不打印每个字段的键(nokey = 1)，不打印节头和页脚(noprint_wrappers = 1)。 推荐ot玩转直播流：使用SRS搭建推流服务器；使用SRS+ffmpeg中转推流；OBS推流到自建服务器；使用ffmpeg把直播流复制到多个网站: https://hu60.cn/q.php/bbs.topic.102309.html官方文档： http://ffmpeg.org/ffmpeg.html入门教程：https://ruanyifeng.com/blog/2020/01/ffmpeg.htmlFFMPEG最全教程： https://cloud.tencent.com/developer/article/1773248","link":"/2022/05/05/%E5%AE%9E%E7%94%A8%E7%9A%84%20FFmpeg%20%E8%84%9A%E6%9C%AC%E5%90%88%E9%9B%86/"},{"title":"慢速连接攻击和处理方式","text":"慢速攻击原理： http慢速攻击是利用http合法机制，在建立连接后，尽量长时间保持连接，不释放，达到对HTTP服务攻击,攻击者发送POST请求，自行构造报文向服务器提交数据，将报文长度设置一个很大的值，且在随后每次发送中，每次只发送一个很小的报文，这样导致服务器一直等待数据，连接始终一直被占用。 如果攻击者使用多线程或傀儡机子去做同样操作，服务器WEB容器很快就被占满TCP连接而不再接受新请求 slowhttptest是一款对服务器进行慢攻击的测试软件，包含了几种攻击方式，像Slowloris、SlowHTTP POST、Slow Read attack等。 总而言之，该工具的原理就是设法让服务器等待，当服务器在保持连接等待时，就消耗了资源。 1、 最具代表性的是rsnake发明的Slowloris，又被称为slow headers。 【攻击原理】 HTTP协议规定，HTTP Request以\\r\\n\\r\\n（0d0a0d0a）结尾表示客户端发送结束，服务端开始处理。那么，如果永远不发送\\r\\n\\r\\n会如何？Slowloris就是利用这一点来做DDoS攻击的。攻击者在HTTP请求头中将Connection设置为Keep-Alive，要求Web Server保持TCP连接不要断开，随后缓慢地每隔几分钟发送一个key-value格式的数据到服务端，如a:b\\r\\n，导致服务端认为HTTP头部没有接收完成而一直等待。如果攻击者使用多线程或者傀儡机来做同样的操作，服务器的Web容器很快就被攻击者占满了TCP连接而不再接受新的请求。 2、Slowloris的变种–Slow HTTP POST，也称为Slow body。 【攻击原理】 在POST提交方式中，允许在HTTP的头中声明content-length，也就是POST内容的长度。 在提交了头以后，将后面的body部分卡住不发送，这时服务器在接受了POST长度以后，就会等待客户端发送POST的内容，攻击者保持连接并且以10S-100S一个字节的速度去发送，就达到了消耗资源的效果，因此不断地增加这样的链接，就会使得服务器的资源被消耗，最后可能宕机。 3、Slow Read attack 【攻击原理】 采用调整TCP协议中的滑动窗口大小，来对服务器单次发送的数据大小进行控制，使得服务器需要对一个回应分成很多个包来发送。要使这种攻击效果更加明显，请求的资源要尽量大。 用Wireshark抓包可以看出，当请求a.wmv资源（大小有9M多）时，客户端windowssize被刻意设置为1152字节。客户端缓冲区在被来自服务器的数据填满后，发出了[TCP ZeroWindow]告警，迫使服务端等待。 受到以上各种慢速攻击后，服务器再无法访问 解决办法： 1.使用NGINX，因为其本身就对慢速攻击有很好防护 2.tomcat可通过运行模式NIO和connectionTimeout值进行缓解 3.dos deflate软件：https://www.cnblogs.com/cloudapps/p/4996050.html 另外，在tomcat中配置connectionTimeout参数也可以防止head攻击下的拒绝服务，但是对于body和read情况下没有能力解决（论坛上也说了，tomcat就不是做这个事儿的）。 原文地址：https://www.cnblogs.com/xiaoliu66007/p/10174672.html","link":"/2021/07/26/%E6%85%A2%E9%80%9F%E8%BF%9E%E6%8E%A5%E6%94%BB%E5%87%BB%E5%92%8C%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/"},{"title":"微信开发笔记","text":"微信公众号授权流程可能是很早的版本 UA 安坐 12345Mozilla/5.0 (Linux; Android 7.1.1; MI 6 Build/NMF26X; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/57.0.2987.132 MQQBrowser/6.2 TBS/043807 Mobile Safari/537.36 MicroMessenger/6.6.1.1220(0x26060135) NetType/WIFI Language/zh_CNMozilla/5.0 (Linux; Android 7.1.1; OD103 Build/NMF26F; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/53.0.2785.49 Mobile MQQBrowser/6.2 TBS/043632 Safari/537.36 MicroMessenger/6.6.1.1220(0x26060135) NetType/4G Language/zh_CNMozilla/5.0 (Linux; Android 6.0.1; SM919 Build/MXB48T; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/53.0.2785.49 Mobile MQQBrowser/6.2 TBS/043632 Safari/537.36 MicroMessenger/6.6.1.1220(0x26060135) NetType/WIFI Language/zh_CNMozilla/5.0 (Linux; Android 5.1.1; vivo X6S A Build/LMY47V; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/53.0.2785.49 Mobile MQQBrowser/6.2 TBS/043632 Safari/537.36 MicroMessenger/6.6.1.1220(0x26060135) NetType/WIFI Language/zh_CNMozilla/5.0 (Linux; Android 5.1; HUAWEI TAG-AL00 Build/HUAWEITAG-AL00; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/53.0.2785.49 Mobile MQQBrowser/6.2 TBS/043622 Safari/537.36 MicroMessenger/6.6.1.1220(0x26060135) NetType/4G Language/zh_CN iPhone 系统下的微信 User Agent 1234Mozilla/5.0 (iPhone; CPU iPhone OS 9_3_2 like Mac OS X) AppleWebKit/601.1.46 (KHTML, like Gecko) Mobile/13F69 MicroMessenger/6.6.1 NetType/4G Language/zh_CNMozilla/5.0 (iPhone; CPU iPhone OS 11_2_2 like Mac OS X) AppleWebKit/604.4.7 (KHTML, like Gecko) Mobile/15C202 MicroMessenger/6.6.1 NetType/4G Language/zh_CNMozilla/5.0 (iPhone; CPU iPhone OS 11_1_1 like Mac OS X) AppleWebKit/604.3.5 (KHTML, like Gecko) Mobile/15B150 MicroMessenger/6.6.1 NetType/WIFI Language/zh_CNMozilla/5.0 (iphone x Build/MXB48T; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/53.0.2785.49 Mobile MQQBrowser/6.2 TBS/043632 Safari/537.36 MicroMessenger/6.6.1.1220(0x26060135) NetType/WIFI Language/zh_CN 微信内置浏览器与小程序中的 User Agent 对比 1234// 安卓系统中小程序 User AgentMozilla/5.0 (Linux; Android 7.1.1; MI 6 Build/NMF26X; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/57.0.2987.132 MQQBrowser/6.2 TBS/043807 Mobile Safari/537.36 MicroMessenger/6.6.1.1220(0x26060135) NetType/4G Language/zh_CN MicroMessenger/6.6.1.1220(0x26060135) NetType/4G Language/zh_CN miniProgram// 安卓系统中微信内置浏览器 User AgentMozilla/5.0 (Linux; Android 7.1.1; MI 6 Build/NMF26X; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/57.0.2987.132 MQQBrowser/6.2 TBS/043807 Mobile Safari/537.36 MicroMessenger/6.6.1.1220(0x26060135) NetType/4G Language/zh_CN 以上两段字符串均为子凡自用 MI6 安卓设备中获得，可以看出微信小程序的 UA 是和微信内置浏览器 UA 是不同的，后面会多出一小段，特别是最后的“miniProgram”字符串，就是小程序的特别的 UA，而在 iPhone 系统设备中 UA 都是一致的，小程序和内置浏览器 UA 是没有区别的。 UA 检测和判断方法1234//php 版本if( preg_match( '/MicroMessenger/', $_SERVER['HTTP_USER_AGENT'] ) ) { echo '你真正使用微信访问';} 12345678//js 版本 if(/MicroMessenger/i.test(navigator.userAgent)){ alert('你真正使用微信访问');}//或者if(navigator.userAgent.match(/(MicroMessenger)/i)){ alert('你真正使用微信访问');} 以上子凡给出的两种判断方法默认都是直接使用正则表达式的方式判断是否为微信，也就是不论安卓还是苹果系统，是否小程序，都是通过 UA 中共有的“MicroMessenger”字符串来作为判断，只要判断为微信设备访问，代码中//true 就可以改为自己想要执行的代码。当然为了更准确的判断还可以自己写正则表达式匹配。 例如： 12Android.*MicroMessenger.*miniProgram//安卓端的小程序iPhone.*MicroMessenger//苹果端微信或小程序","link":"/2021/11/13/%E5%BE%AE%E4%BF%A1%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"title":"收集的一些英文句子和短语","text":"句子 I am not afraid of tomorrow for I have seen yesterday and I love today. 我不害怕明天，因为我经历过昨天，又热爱今天。 The value of life lies not length of days,but in the use of the make of them. 生命的价值不在于能活多少天，而在于我们如何利用这些日子。 Courage is the ladder on which all the other virtues mount. 勇气是其他美德攀登的梯子。 Better to light one candle than to curse the darkness. 与其诅咒黑暗，不如燃起蜡烛。 You don’t love a girl because she is beautiful, but she is beautiful because you love her. 你不是因为她美丽而爱他，而他却因为你的爱而美丽。 Love alone could waken love! 只有爱才能唤醒爱。 Maybe God wants us to meet a few wrong people before meeting the right one ,so that when we finally meet the person,we will know how to be grateful. 在遇到梦中之人之前，上天也许会安排我们先遇到别的人；在我们终于遇见心仪的人时，便应当心存感激。 Enjoy when you can, and endure when you must. 能享受时可进行，须忍耐时当坚持。 Friendship is a sheltering tree. 友情犹如大树，为你遮风挡雨。 We have to dare to be ourselves ,however frightening or strange that self may prove to be. 我们必须勇于做自己，不管这个自己有多可怕，有多诡异。 A friend is one of the nicest things you can have,an one of the best things you can be . 拥有朋友时最美好的一件事，成为别人的朋友是最美妙的一件事。 短语 attached to approved reminder shortly renewal 单词maven 行家，专家 continuous 持续的 integration 集成 delivery 交付 英语俚语dog persion 喜欢狗的人cat persion 习惯猫的人people persion 喜欢和人打交道的人","link":"/2021/01/16/%E6%94%B6%E9%9B%86%E7%9A%84%E4%B8%80%E4%BA%9B%E8%8B%B1%E6%96%87%E5%8F%A5%E5%AD%90%E5%92%8C%E7%9F%AD%E8%AF%AD/"},{"title":"怎么在maxphp中集成Illuminate-database","text":"1composer require illuminate/database illuminate/pagination illuminate/events 配置123456789101112131415161718192021222324&lt;?phpreturn [ // 默认数据库 'default' =&gt; 'mysql', // 各种数据库配置 'connections' =&gt; [ 'mysql' =&gt; [ 'driver' =&gt; 'mysql', 'host' =&gt; '127.0.0.1', 'port' =&gt; 3306, 'database' =&gt; env('DB_NAME', 'name'), 'username' =&gt; env('DB_USER', 'user'), 'password' =&gt; env('DB_PASS', 'pass'), 'unix_socket' =&gt; '', 'charset' =&gt; 'utf8', 'collation' =&gt; 'utf8_unicode_ci', 'prefix' =&gt; '', 'strict' =&gt; true, 'engine' =&gt; null, ], ],]; 初始化1234567891011121314151617181920212223242526if (!class_exists(Manager::class)) { return;}$connections = config('database.connections');if (!$connections) { return;}$capsule = new Manager();$configs = config('database');// 扩展mongodb，需要安装对应的包$capsule-&gt;getDatabaseManager()-&gt;extend('mongodb', function($config, $name) { $config['name'] = $name; return new MongodbConnection($config);});if (isset($configs['default'])) { $default_config = $connections[$configs['default']]; $capsule-&gt;addConnection($default_config);}foreach ($connections as $name =&gt; $config) { $capsule-&gt;addConnection($config, $name);}if (class_exists(Dispatcher::class)) { $capsule-&gt;setEventDispatcher(new Dispatcher(new Container));}$capsule-&gt;setAsGlobal();$capsule-&gt;bootEloquent(); 初始化应该放在workerStart回调中","link":"/2022/07/10/%E6%80%8E%E4%B9%88%E5%9C%A8maxphp%E4%B8%AD%E9%9B%86%E6%88%90Illuminate-database/"},{"title":"查看mysql数据库容量大小","text":"第一种情况查询所有数据库的总大小，方法如下：12345678mysql&gt; use information_schema;mysql&gt; select concat(round(sum(DATA_LENGTH/1024/1024),2),'MB') as data from TABLES;+-----------+| data |+-----------+| 3052.76MB |+-----------+1 row in set (0.02 sec) 统计一下所有库数据量每张表数据量=AVG_ROW_LENGTH*TABLE_ROWS+INDEX_LENGTH 1SELECT SUM(AVG_ROW_LENGTH*TABLE_ROWS+INDEX_LENGTH)/1024/1024 AS total_mb FROM information_schema.TABLES 统计每个库大小：1SELECT table_schema,SUM(AVG_ROW_LENGTH*TABLE_ROWS+INDEX_LENGTH)/1024/1024 AS total_mb FROM information_schema.TABLES group by table_schema; 第二种情况 查看指定数据库的大小，比如说：数据库test，方法如下： 12345678mysql&gt; use information_schema;mysql&gt; select concat(round(sum(DATA_LENGTH/1024/1024),2),'MB') as data from TABLES where table_schema='test';+----------+| data |+----------+| 142.84MB |+----------+1 row in set (0.00 sec) 查看所有数据库各容量大小12345678selecttable_schema as '数据库',sum(table_rows) as '记录数',sum(truncate(data_length/1024/1024, 2)) as '数据容量(MB)',sum(truncate(index_length/1024/1024, 2)) as '索引容量(MB)'from information_schema.tablesgroup by table_schemaorder by sum(data_length) desc, sum(index_length) desc; 查看所有数据库各表容量大小12345678selecttable_schema as '数据库',table_name as '表名',table_rows as '记录数',truncate(data_length/1024/1024, 2) as '数据容量(MB)',truncate(index_length/1024/1024, 2) as '索引容量(MB)'from information_schema.tablesorder by data_length desc, index_length desc; 查看指定数据库容量大小例：查看mysql库容量大小 1234567selecttable_schema as '数据库',sum(table_rows) as '记录数',sum(truncate(data_length/1024/1024, 2)) as '数据容量(MB)',sum(truncate(index_length/1024/1024, 2)) as '索引容量(MB)'from information_schema.tableswhere table_schema='mysql'; 查看指定数据库各表容量大小例：查看mysql库各表容量大小 123456789selecttable_schema as '数据库',table_name as '表名',table_rows as '记录数',truncate(data_length/1024/1024, 2) as '数据容量(MB)',truncate(index_length/1024/1024, 2) as '索引容量(MB)'from information_schema.tableswhere table_schema='mysql'order by data_length desc, index_length desc; 原文地址：https://www.cnblogs.com/--smile/p/11451238.html","link":"/2021/07/02/%E6%9F%A5%E7%9C%8Bmysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%B9%E9%87%8F%E5%A4%A7%E5%B0%8F/"},{"title":"正则表达式匹配&quot;非&quot;，以及&quot;非&quot;字符串的匹配","text":"#写法介绍首先，正则表达式的”非”，代表不想匹配某个字符。比如字符串 helloword123，/[^0-9]+/g 可以匹配非数字，即匹配结果为 helloword； 同样的，/[^he]+/g 可以匹配非h非e的字符，匹配结果为lloword123； 那么 /[^hello]/g 呢？乍一看可能会以为能匹配word123，其实不然，[^] 内的多个字符是”或”的关系存在的，即它们并不是一个整体，/[^hello]/g 表示 非h非e非l非o，并不能理解为 非(hello)，所以匹配结果是 w 和 rd123。 道理我们都懂，可我们就是想匹配非某个字符串呢？比如某一字符串若是含有hello则无匹配，若是不含hello则匹配，写成[^hello]是显然不行的，[^(hello)] 呢？其实不起作用。 这时我们需要用到正则表达式的断言——(?!pattern) 零宽负向先行断言 或者 (?&lt;!pattern) 零宽负向后行断言 均可。 这里只介绍一种写法，大家可以都去尝试一下。 1/^((?!hello).)+$/ 由于断言 (?!hello)是不占位的，后跟的 . 在原位置匹配任意字符，再用括号将其括起来，用+重复一次或多次，前后加上^和$，若是字符串中存在hello，则匹配到h字符之前的时候，断言(?!hello)匹配失败，正则匹配结果为false， 若是字符串中不存在hello，则匹配结果是整个字符串。 #用法实战 ##匹配&amp;和;之间不含有test的字符 1str = &quot;hello&amp;nbsp;&amp;test1;test&quot;&quot;; 正则表达式：/&amp;((?!test).)+;/g 匹配结果：&amp;nbsp; 和 &quot; 匹配不含有&lt;img&gt;标签的&lt;div&gt;&lt;/div&gt;标签1str = &quot;&lt;div id='1'&gt;&lt;img class='xx'&gt;&lt;/div&gt;&lt;div id='1'&gt;&lt;input type=''text&quot;&gt;&lt;/div&gt;&quot;; 正则表达式： /&lt;div[^&gt;]*&gt;((?!&lt;img[^&gt;]*&gt;).)+&lt;/div&gt;/g 匹配结果：&lt;div id='1'&gt;&lt;input type=''text&quot;&gt;&lt;/div&gt;","link":"/2021/04/04/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8C%B9%E9%85%8D&quot;%E9%9D%9E&quot;%EF%BC%8C%E4%BB%A5%E5%8F%8A&quot;%E9%9D%9E&quot;%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%8C%B9%E9%85%8D/"},{"title":"正则表达式断言 - (?!), (?:), (?&#x3D;)","text":"一个断言就是一个对当前匹配位置之前或之后的字符的测试， 它不会实际消耗任何字符。简单的断言代码有\\b、\\B、 \\A、 \\Z、\\z、 ^、$ 等，在 转义序列(反斜线) 中有描述。 更加复杂的断言以子组的方式编码。 它有两种类型： 前瞻断言(从当前位置向前测试)和后瞻断言(从当前位置向后测试)。 一个断言子组的匹配还是通过普通方式进行的， 不同在于它不会导致当前的匹配点发生改变。 前瞻断言中的正面断言(断言此匹配为真)以 ”(?=” 开始，消极断言以 ”(?!” 开头。比如， \\w+(?=;) 匹配一个单词紧跟着一个分号但是匹配结果不会包含分号， foo(?!bar) 匹配所有后面没有紧跟 ”bar” 的 ”foo” 字符串。 注意一个类似的模式 (?!foo)bar 它不能用于查找之前出现所有不是 ”foo” 的 ”bar” 匹配， 它会查找到任意的 ”bar” 出现的情况， 因为 (?!foo) 这个断言在接下来三个字符时 ”bar” 的时候是永远都 true 的。 前瞻断言需要达到的就是这样的效果。 后瞻断言中的正面断言以”(?&lt;=”开始, 消极断言以”(?&lt;!”开始。比如， (?&lt;!foo)bar 用于查找任何前面不是 ”foo” 的 ”bar”。 后瞻断言的内容被严格限制为只能用于匹配定长字符串。但是，如果有多个可选分支， 它们不需要拥有相同的长度。比如 (?&lt;=bullock|donkey) 是允许的， 但是 (?&lt;!dogs?|cats?) 将会引发一个编译期的错误。在最上级分支可以匹配不同长度的字符串是允许的。 相比较于 perl 5.005 而言，它会要求多个分支使用相同长度的字符串匹配。 (?&lt;=ab(c|de)) 这样的断言是不允许的， 因为它单个的顶级分支可以匹配两个不同的长度， 但是它可以接受使用两个顶级分支的写法 (?&lt;=abc|abde) 这样的断言实现， 对于每个可选分支，暂时将当前位置移动到尝试匹配的当前位置之前的固定宽度处。 如果在当前没有足够的字符就视为匹配失败。后瞻断言与一次性子组结合使用可以用来匹配字符串结尾； 一个例子就是在一次性子组上给出字符串结尾。 多个断言(任意顺序)可以同时出现。 比如 (?&lt;=\\d{3})(?&lt;!999)foo 匹配前面有三个数字但不是 ”999” 的字符串 ”foo”。注意， 每个断言独立应用到对目标字符串该点的匹配。 首先它会检查前面的三位都是数字， 然后检查这三位不是 ”999”。 这个模式不能匹配 ”foo” 前面有三位数字然后紧跟 3 位非 999 共 6 个字符的字符串，比如， 它不匹配 ”123abcfoo”。 匹配 ”123abcfoo” 这个字符串的模式可以是 (?&lt;=\\d{3}…)(?&lt;!999)foo。 这种情况下，第一个断言查看(当前匹配点)前面的 6 个字符，检查前三个是数字， 然后第二个断言检查(当前匹配点)前三个字符不是 ”999”。 断言可以以任意复杂度嵌套。 比如 (?&lt;=(?&lt;!foo)bar)baz 匹配前面有 ”bar” 但是 ”bar” 前面没有 ”foo” 的 ”baz”。 另外一个模式 (?&lt;=\\d{3}…(?&lt;!999))foo 则匹配前面有三个数字字符紧跟 3 个不是 999 的任意字符的 ”foo”。 断言子组时非捕获子组，并且不能用量词修饰， 因为对同一件事做多次断言是没有意义的.如果所有的断言都包含一个捕获子组， 那么为了在整个模式中捕获子组计数的目的，它们都会被计算在内。然而， 子字符串的捕获仅可以用于正面断言，因为对于消极的断言是没有意义的。 将断言计算在内，可以拥有的最大子组数量是 200 个。 以上来自： https://www.php.net/manual/zh/regexp.reference.assertions.php 1(?:pattern) 非获取匹配，匹配pattern但不获取匹配结果，不进行存储供以后使用。这在使用或字符“(|)”来组合一个模式的各个部分是很有用。例如“industr(?:y|ies)”就是一个比“industry|industries”更简略的表达式。 1(?=pattern) 非获取匹配，正向肯定预查，在任何匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如，“Windows(?=95|98|NT|2000)”能匹配“Windows2000”中的“Windows”，但不能匹配“Windows3.1”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 1(?!pattern) 非获取匹配，正向否定预查，在任何不匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如“Windows(?!95|98|NT|2000)”能匹配“Windows3.1”中的“Windows”，但不能匹配“Windows2000”中的“Windows”。(?&lt;=pattern)非获取匹配，反向肯定预查，与正向肯定预查类似，只是方向相反。例如，“(?&lt;=95|98|NT|2000)Windows”能匹配“2000Windows”中的“Windows”，但不能匹配“3.1Windows”中的“Windows”。 1(?&lt;!pattern) 非获取匹配，反向否定预查，与正向否定预查类似，只是方向相反。例如“(?&lt;!95|98|NT|2000)Windows”能匹配“3.1Windows”中的“Windows”，但不能匹配“2000Windows”中的“Windows”。这个地方不正确，有问题 1(?&lt;=1)test 匹配前面不是1的test 12345678// 前瞻：exp1(?=exp2) 查找exp2前面的exp1// 后顾：(?&lt;=exp2)exp1 查找exp2后面的exp1// 负前瞻：exp1(?!exp2) 查找后面不是exp2的exp1// 负后顾：(?&lt;!exp2)exp1 查找前面不是exp2的exp1 举例： 12&quot;中国人&quot;.replace(/(?&lt;=中国)人/, &quot;rr&quot;) // 匹配中国人中的人，将其替换为rr，结果为 中国rr&quot;法国人&quot;.replace(/(?&lt;=中国)人/, &quot;rr&quot;) // 结果为 法国人，因为人前面不是中国，所以无法匹配到 要理解?:则需要理解捕获分组和非捕获分组的概念： 12()表示捕获分组，()会把每个分组里的匹配的值保存起来，使用$n(n是一个数字，表示第n个捕获组的内容)(?:)表示非捕获分组，和捕获分组唯一的区别在于，非捕获分组匹配的值不会保存起来 举例： 12// 数字格式化 1,123,000&quot;1234567890&quot;.replace(/\\B(?=(?:\\d{3})+(?!\\d))/g,&quot;,&quot;) // 结果：1,234,567,890，匹配的是后面是3*n个数字的非单词边界(\\B)","link":"/2021/04/06/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%96%AD%E8%A8%80%20-%20(%EF%80%BF!),%20(%EF%80%BF%EF%80%BA),%20(%EF%80%BF=)/"},{"title":"正则表达式高级用法","text":"引子上一章分享了正式表达式的入门知识，以及单字符、多字符常用的匹配方法，对于工作维护过程中已经够用，但是有时候只使用基础知识来实现就会比较麻烦，如果使用高级用法就会比较方便很多。 例如：匹配一个HTML文件中两个&lt;B&gt;标签中的文件。 文本内容： 1This offer is not available to customers living in &lt;B&gt;AK&lt;/B&gt; and &lt;B&gt;HI&lt;/B&gt; 从上一章内容的知识可以想到的表达式可能如下： 1&lt;[Bb]&gt;.*&lt;/[Bb]&gt; 但是这个表达式配置的结果是AK&lt;/B&gt; and &lt;B&gt;HI，而不是我们想要的AK和HI。 懒惰型匹配 引子中的例子中的匹配方式是属于贪婪行为，就是尽可能多的匹配内容，像例子中第一个和最后一个中间都被匹配到了，而不管匹配内容中是否存在。 上一章中讲到的*和+、{m,}都是所谓的“贪婪型”的。在这一节中讲一下与“贪婪型”相反的“懒惰型”，就是匹配尽可能少的内容。 实现很简单，就是在原有“贪婪型”元字符后面加上一个? 号，如下表格 贪婪型元字符 懒惰型元字符 * *？ + +？ {m,} {m,}? 位置匹配 在现实的系统中一般表达位置的地方就是一个单词的开头以及结尾或者一个字符串的开头或者结尾。 注意这个边界只是一个位置，例如单词边界匹配的是\\w和\\W之间的一个位置 元字符 说明 注意 \\b 单词边界，单词的开头或者单词的结尾 回退键的元字符是[\\b] \\B 表示非单词边界 ^ 字符串的开头位置 放在[]中表示取非操作 $ 字符串结尾位置 扩展： 像egrep中也支持使用\\&lt;匹配单词开头位置，使用\\&gt;匹配单词结尾位置，但是支持这种元字符的编辑器比较少。 (?m)是一个分行匹配模式的记号，放在一个表达式的最前面，会改变字符串位置匹配的行为。^不仅匹配正常的字符串开头还匹配行分隔符（换行符）后面的开始位置；同样$不仅匹配正常的字符串结尾还匹配行分隔符（换行符）后面的结束位置；此用法只有部分正则表达式会支持 选项 描述 支持平台 (?d) Unix中的行 java (?i) 不区分大小写 PCRE Perl java (?J) 允许重复的名字 PCRE* (?m) 多行 PCRE Perl java (?s) 单行 PCRE Perl java (?u) Unicode java (?U) 默认最短匹配，与懒惰型匹配类似 PCRE (?x) 忽略空格和注释 PCRE Perl Java (?-…) 复原或关闭选项 PCRE 捕获分组与后向引用前面的元字符都是对紧挨着前面的一个字符有效，例如表达式the{3}匹配theee字符串，假如我们想匹配连续三个the字符串怎么办呢，这就涉及到子表达式的概念。 子表达式把一个表达式匹配的内容做为一个单独的元素嵌入到另外一个表达式中，那这个做为独立元素的表达式就是子表达式，需要使用()括起来。这个跟数学的表达式概念很类似。 并且子表达与数学表达式还有一个类似的地方就是，正则表达式的子表达式也可以嵌套使用 本节开头说的那个问题就可以使用子表达式来实现，(the){3}就会匹配thethethe这个字符串。 假如我们再加个条件：我们想匹配连续三个the或者连续三个you，怎么实现？这就是正则表达式的选择操作符，也叫或操作符了 元字符 说明 ` ` 上面的问题就可以使用正则表达式(the|you){3}来表示 捕获分组与后向引用当一个模式的全部或者部分内容由一对括号括起来时，就对表达式进行了分组（其实就是放在()中的子表达式），并且把分组匹配到内容捕获并且临时存放在内存中。这就是捕获分组，可以在后面表达式中使用就叫后向引用，或者叫回溯引用。 默认情况下，分组是从左到右依次排序从1编号，第一个分组就是1，第二个分组就是2等等。 最开始的时候支持的编号范围是1到9，现在应该已经没有这种限制了。 后向引用很简单就是一个\\或者$后面跟相应编号即可。例如\\1或者$1就表示引用第一个捕获分组。 命名分组前面讲捕获分组都是通过位置编号来访问，在perl和python、.NET等语言中还支持对捕获分组命名。这样就比较容易理解 命名语法 描述 (?&lt;name&gt;分组) 命名分组 (?P&lt;name&gt;分组) python中的命名分组 \\k&lt;name&gt; Perl中引用命名分组 \\k'name' Perl中引用命名分组 \\g{name} Perl中引用命名分组 \\k{name} .NET中引用命名分组 (?P=name) Python中引用命名分组 例： 1preg_match('/(?P&lt;name&gt;\\d+)/', $string, $matched) 如果匹配到，那么name的值就是\\d+匹配到的值 非捕获分组顾名思义，与捕获分组相反，就是不会将分组匹配的内容放在内存中。主要是为了提高性能。 使用方法：在分组的开头加上?:，例如(?:the) 当把非捕获分组语法中的:换成&gt;时，就变成了原子分组（另一种非捕获分组），可以进一步提升性能。因为原子分组会将分组内部的回溯操作关闭。 环视环视是一种非捕获分组，它根据某个模式之前或者之后的内容要求匹配其他模式。环视也称为零宽度断言。 环视分类 说明 举例 (?=分组) 正前瞻，匹配且要求紧随其后内容为分组匹配的内容 a(?=b),匹配a并且后面坚接着是b的字符串，可以匹配abc但是不匹配acb (?!分组) 反前瞻，即对正前瞻含义取反，匹配且要求紧随其后内容不为分组匹配的内容 a(?!b),匹配a并且后面坚接着不是b的字符串，可以匹配acb但是不匹配abc (?&lt;=分组) 正后顾，即对正前瞻方向取反，匹配且要求紧挨着之前的内容为分组匹配的内容 (?&lt;=a)b),匹配b并且前面紧挨着是a的字符串，可以匹配abc但是不匹配cbc (?&lt;!分组) 反后顾，即对正后顾含义取反，匹配且要求紧挨着之前的内容不为分组匹配的内容 (?&lt;!a)b),匹配b并且前面紧挨着不是a的字符串，可以匹配cbc但是不匹配abc 参考《学习正则表达式》 《正则表达式必知必会》 作者：itsenlin链接：https://www.jianshu.com/p/c39e761860bb来源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","link":"/2021/11/25/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95/"},{"title":"消息头字段之Cache-Control","text":"Cache-ControlCache-Control 通用消息头字段，被用于在http请求和响应中，通过指定指令来实现缓存机制。缓存指令是单向的，这意味着在请求中设置的指令，不一定被包含在响应中。 Header type General header Forbidden header name no CORS-safelisted response-header yes 语法指令格式具有以下有效规则： 不区分大小写，但建议使用小写。 多个指令以逗号分隔。 具有可选参数，可以用令牌或者带引号的字符串语法。 缓存请求指令客户端可以在HTTP请求中使用的标准 Cache-Control 指令。 1234567Cache-Control: max-age=&lt;seconds&gt;Cache-Control: max-stale[=&lt;seconds&gt;]Cache-Control: min-fresh=&lt;seconds&gt;Cache-control: no-cacheCache-control: no-storeCache-control: no-transformCache-control: only-if-cached 缓存响应指令服务器可以在响应中使用的标准 Cache-Control 指令。 123456789Cache-control: must-revalidateCache-control: no-cacheCache-control: no-storeCache-control: no-transformCache-control: publicCache-control: privateCache-control: proxy-revalidateCache-Control: max-age=&lt;seconds&gt;Cache-control: s-maxage=&lt;seconds&gt; 扩展Cache-Control指令拓展缓存指令不是核心HTTP缓存标准文档的一部分，使用前请注意检查兼容性！ 123Cache-control: immutableCache-control: stale-while-revalidate=&lt;seconds&gt;Cache-control: stale-if-error=&lt;seconds&gt; 指令可缓存性 public 表明响应可以被任何对象（包括：发送请求的客户端，代理服务器，等等）缓存，即使是通常不可缓存的内容。（例如：1.该响应没有max-age指令或Expires消息头；2. 该响应对应的请求方法是 POST 。） private 表明响应只能被单个用户缓存，不能作为共享缓存（即代理服务器不能缓存它）。私有缓存可以缓存响应内容，比如：对应用户的本地浏览器。 no-cache 在发布缓存副本之前，强制要求缓存把请求提交给原始服务器进行验证(协商缓存验证)。 no-store 缓存不应存储有关客户端请求或服务器响应的任何内容，即不使用任何缓存。 到期 max-age=&lt;seconds&gt; 设置缓存存储的最大周期，超过这个时间缓存被认为过期(单位秒)。与Expires相反，时间是相对于请求的时间。 s-maxage=&lt;seconds&gt; 覆盖max-age或者Expires头，但是仅适用于共享缓存(比如各个代理)，私有缓存会忽略它。 max-stale[=&lt;seconds&gt;] 表明客户端愿意接收一个已经过期的资源。可以设置一个可选的秒数，表示响应不能已经过时超过该给定的时间。 min-fresh=&lt;seconds&gt; 表示客户端希望获取一个能在指定的秒数内保持其最新状态的响应。 stale-while-revalidate=&lt;seconds&gt; 表明客户端愿意接受陈旧的响应，同时在后台异步检查新的响应。秒值指示客户愿意接受陈旧响应的时间长度。 stale-if-error=&lt;seconds&gt; 表示如果新的检查失败，则客户愿意接受陈旧的响应。秒数值表示客户在初始到期后愿意接受陈旧响应的时间。 重新验证和重新加载 must-revalidate 一旦资源过期（比如已经超过max-age），在成功向原始服务器验证之前，缓存不能用该资源响应后续请求。 proxy-revalidate 与must-revalidate作用相同，但它仅适用于共享缓存（例如代理），并被私有缓存忽略。 immutable 表示响应正文不会随时间而改变。资源（如果未过期）在服务器上不发生改变，因此客户端不应发送重新验证请求头（例如If-None-Match或If-Modified-Since）来检查更新，即使用户显式地刷新页面。在Firefox中，immutable只能被用在 https:// transactions. 有关更多信息，请参阅这里。 其他 no-transform 不得对资源进行转换或转变。Content-Encoding、Content-Range、Content-Type等HTTP头不能由代理修改。例如，非透明代理或者如Google’s Light Mode可能对图像格式进行转换，以便节省缓存空间或者减少缓慢链路上的流量。no-transform指令不允许这样做。 only-if-cached 表明客户端只接受已缓存的响应，并且不要向原始服务器检查是否有更新的拷贝。 示例禁止缓存发送如下响应头可以关闭缓存。此外，可以参考Expires和Pragma消息头。 1Cache-Control: no-store 缓存静态资源对于应用程序中不会改变的文件，你通常可以在发送响应头前添加积极缓存。这包括例如由应用程序提供的静态文件，例如图像，CSS文件和JavaScript文件。另请参阅Expires标题。 1Cache-Control:public, max-age=31536000 需要重新验证指定 no-cache 或 max-age=0, must-revalidate 表示客户端可以缓存资源，每次使用缓存资源前都必须重新验证其有效性。这意味着每次都会发起 HTTP 请求，但当缓存内容仍有效时可以跳过 HTTP 响应体的下载。 1Cache-Control: no-cache Copy to Clipboard 1Cache-Control: max-age=0, must-revalidate Copy to Clipboard 注意: 如果服务器关闭或失去连接，下面的指令可能会造成使用缓存。 1Cache-Control: max-age=0 原文地址：https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Cache-Control","link":"/2021/10/28/%E6%B6%88%E6%81%AF%E5%A4%B4%E5%AD%97%E6%AE%B5%E4%B9%8BCache-Control/"},{"title":"正则表达式","text":"PHP官方文档：https://www.php.net/manual/zh/book.pcre.php 写个可以匹配一下各种特殊字符的正则表达式 12((?=[\\x21-\\x7e]+)[^A-Za-z0-9])x21-\\x7e]+)[^A-Za-z0-9]) 这个匹配所有键盘上可见的非字母和数字的符号 1var patrn = /[`~!@#$%^&amp;*()_\\-+=&lt;&gt;?:&quot;{}|,.\\/;&amp;'\\\\[\\]·~！@#￥%……&amp;*（）——\\-+={}|《》？：“”【】、；‘&amp;'，。、]/im; 123456if (!patrn.test(str)) { // 如果包含特殊字符返回false return false;}return true; 废话少说，代码如下 1[^\\\\S\\\\r\\\\n] \\ s用于查找空白字符。 空白字符可以是：空格字符,制表符,回车符,换行符,垂直制表符,换页字符,\\S是\\s的取反。 解读：判断这个字符，首先 不是 非空白字符（也就是空白字符），然后不是回车符和换行符。 []结构^开头，那么三个转义字符都是 非 判断。 PHP正则中的后向引用 1echo preg_replace(&amp;'/(test)(date)/&amp;', &amp;'${1}&amp;', &amp;'testdate&amp;'); 输出testtest 其中的${1} 也可以写作\\1或者\\\\1,表示第一个元组。","link":"/2020/10/13/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"title":"版本号命名规范","text":"版本号的格式为 X.Y.Z(又称 Major.Minor.Patch)，递增的规则为： X 表示主版本号，当 API 的兼容性变化时，X 需递增。 Y 表示次版本号，当增加功能时(不影响 API 的兼容性)，Y 需递增。 Z 表示修订号，当做 Bug 修复时(不影响 API 的兼容性)，Z 需递增。 详细的规则如下： X, Y, Z 必须为非负整数，且不得包含前导零，必须按数值递增，如 1.9.0 -&gt; 1.10.0 -&gt; 1.11.0 0.Y.Z 的版本号表明软件处于初始开发阶段，意味着 API 可能不稳定；1.0.0 表明版本已有稳定的 API。 当 API 的兼容性变化时，X 必须递增，Y 和 Z 同时设置为 0；当新增功能(不影响 API 的兼容性)或者 API 被标记为 Deprecated 时，Y 必须递增，同时 Z 设置为 0；当进行 bug fix 时，Z 必须递增。 先行版本号(Pre-release)意味该版本不稳定，可能存在兼容性问题，其格式为：X.Y.Z.[a-c][正整数]，如 1.0.0.a1，1.0.0.b99，1.0.0.c1000。 开发版本号常用于 CI-CD，格式为 X.Y.Z.dev[正整数]，如 1.0.1.dev4。 版本号的排序规则为依次比较主版本号、次版本号和修订号的数值，如 1.0.0 &lt; 1.0.1 &lt; 1.1.1 &lt; 2.0.0；对于先行版本号和开发版本号，有：1.0.0.a100 &lt; 1.0.0，2.1.0.dev3 &lt; 2.1.0；当存在字母时，以 ASCII 的排序来比较，如 1.0.0.a1 &lt; 1.0.0.b1。 注意：版本一经发布，不得修改其内容，任何修改必须在新版本发布！ 一些修饰的词 alpha：内部版本 beta：测试版 demo：演示版 enhance：增强版 free：自由版 full version：完整版，即正式版 lts：长期维护版本 release：发行版 rc：即将作为正式版发布 standard：标准版 ultimate：旗舰版 upgrade：升级版 原文地址： https://www.jianshu.com/p/c675121a8bfd","link":"/2022/08/21/%E7%89%88%E6%9C%AC%E5%8F%B7%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83/"},{"title":"硬盘，分区","text":"专用名词 机械硬盘 主分区（min=1，max=4）——主分区也叫引导分区，Windows系统一般需要安装在这个主分区中，这样才能保证开机自动进入系统。简单来说，主分区就是可以引导电脑开机读取文件的一个磁盘分区 扩展分区（min=0，max=1）——扩展分区是一个概念，实际在硬盘中是看不到的，也无法直接使用扩展分区。除了主分区外，剩余的磁盘空间就是扩展分区了。当一块硬盘将所有容量都分给了主分区，那就没有扩展分区了，仅当主分区容量小于硬盘容量，剩下的空间就属于扩展分区了，扩展分区可以继续进行扩展切割分为多个逻辑分区 逻辑分区（min=0，max=n）——在扩展分区上面，可以创建多个逻辑分区 磁道：当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，这些圆形轨迹就叫做磁道 （Track）。 柱面：在有多个盘片构成的盘组中，由不同盘片的面，但处于同一半径圆的多个磁道组成的一个圆柱面（Cylinder 扇区： 盘片上的每个磁道被等分为若干个弧段，这些弧段便是硬盘的扇区（Sector），每个扇区的大小为512Bytes。 1Bytes=8bit MBR存放在硬盘的0号柱面0号磁道1号扇区，也就是硬盘的第一个扇区，共512个字节。 有446个Bytes用来存放Bootloader； 2个字节是MBR的有效标志，被称为Magic number，如果是55AA，则表示此MBR有效； 剩下的64个Bytes就是磁盘分区表了。 分区表只有64个Bytes，一个分区需要占用16个Bytes，如果不使用其他手段，一个硬盘只能被分成四个主分区，扩展分区就是为了解决这个情况出现。 假设我们的硬盘有500G，当分区表中已经有了3个分区了，这三个分区都是主分区，总共占用了300G 这时，如果你想充分使用剩下的200G空间（在实际中是不到200G的，500G硬盘总共的可用空间大约在460G左右），并且觉得4个分区已经够用了，那就必须将剩下的那个主分区分成200G大小 如果你想要更多的分区，就不能将最后那200G空间分成是主分区了，因为一块硬盘只能有四个主分区，况且硬盘空间都分配完了，哪来空间给新分区？ 怎么办呢？ 这时，只要把剩下的200G空间分成扩展分区，就可以在这200G的空间上划分更多数量的分区。 对MBR来讲扩展分区就是单个分区，实际上扩展分区的磁盘空间中可以切分成更多小分区，这些分区就是逻辑分区。 至于动态分区，指的是一种可以自由的调节分区大小，而不用重启系统或者重写MBR分区表的技术，例如Linux下使用最广泛的LVM2技术。但是这是属于高级存储技术,负责加载系统引导文件的Bootloader是识别不了的，所以不能将系统引导文件放置在LVM2的逻辑卷上，否则系统是启动不来的。 参考： https://www.zhihu.com/question/20281689?sort=created","link":"/2021/12/07/%E7%A1%AC%E7%9B%98%EF%BC%8C%E5%88%86%E5%8C%BA/"},{"title":"正则表达式匹配次数","text":"正则表达式里匹配次数的元字符有：（一） {0,1}、{0,}、{1,}、{3} 逗号前面次数到逗号后面次数（二） ?、?? 0次或1次（三） * 0次以上，即0n（四） + 1次以上，即1n 下面深入讲解下这几个元字符的意义： {0,1}、{0,}、{1,}、{3} 逗号前面次数到逗号后面次数上面列了几种都是{}用于表示次数时常见的写法。 {0,1} 匹配0次或1次 {0,} 匹配0次以上，逗号后面为空表示无限次的意思 {1,} 匹配1次以上 {3} 匹配3次，它是{3,3}的简写形式 需要注意的是，前面数字大于后面数字是会报错的 有时候会看到[0-9]{1}这样的写法，其实这样写也算是多余的，它等价[0-9]，正则里没有添加量词修饰的匹配都是按1次算。 ?、?? 0次或1次? 匹配0次或1次，可以理解为{0,1}的简写，常见用法有： https? 用于匹配http或https (https?://)? 用于匹配域名前缀https?://可有可无的情况。 另外，需要了解的是，?是匹配优先的，这是什么意思呢？所谓匹配优先，就是字面意思，能匹配我就先匹配。下面举例说明一下：源码：www.zjmainstay.cn正则：^(www\\.)?(.+)$匹配结果是：分组1得到了www.，分组2得到了zjmainstay.cn从这里可以看出，对于(www\\.)?部分的正则，它先进行了匹配，然后.+部分再匹配。那么，如果我们想要把www.留给后面的.+去匹配怎么办？我们需要找到一个非匹配优先的方法，对于非匹配优先，接触过非贪婪模式的读者可能马上想到非贪婪模式，不错，利用非贪婪模式可以解决这个问题：正则：^(www\\.)*?(.+)$当然，使用正则：^(www\\.){0,1}?(.+)$也是可以的，而且这个更接近原本的意思。另外，很多人可能没见过，其实我们还能用：^(www\\.)??(.+)$实现。这里的??是?的非匹配优先版本。 * 0次以上，即0~n* 0次或任意次，可以理解为{0,}的简写，常见用法有： .* 贪婪模式，匹配优先，匹配除换行外的任意字符0次以上 .*? 非贪婪模式，非匹配优先，匹配除换行外的任意字符0次以上 &lt;a href=&quot;/[^&quot;]*&quot; 在href=&quot;/&quot;的双引号中间，匹配非&quot;的字符0次以上 大家可能发现，.*? 这里也有?，但是它已经脱离了前面对?介绍的0次或1次的范围，没错，只是为了让大家不至于混淆，我没有把它归入上面的?当中。我们可以理解为，?只要跟本文所说的几个计次量词结合，就形成非贪婪模式。甚至，连??你都可以认为是结合后的0次或1次的非贪婪模式，反正也能解释通不是？ + 1次以上，即1~n+ 与 * 除了匹配次数意义上有所差别，常见用法都类似，它强调的是至少匹配1次以上，可以理解为{1,}的简写。 .+ 贪婪模式，匹配优先，匹配除换行外的任意字符1次以上 .+? 非贪婪模式，非匹配优先，匹配除换行外的任意字符1次以上 &lt;a href=&quot;/[^&quot;]+&quot; 在href=&quot;/&quot;的双引号中间，匹配非&quot;的字符1次以上 总结量词本身使用时，都是贪婪模式匹配，而量词和?能结合成非贪婪模式匹配。贪婪模式匹配就是尽可能多地匹配，非贪婪模式匹配就是尽可能少地匹配。 原文地址： https://www.cnblogs.com/tsql/p/6386210.html","link":"/2021/11/20/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8C%B9%E9%85%8D%E6%AC%A1%E6%95%B0/"},{"title":"笔记：es6基础","text":"ECMAScript 与 javascript ECMAScript 可以说是 javascript 的国际标准。 letlet 用来声明变量，用法类似 var 但由 let 声明的变量，只能在 let 命令所在的代码块内有效。 var 声明的变量在全局范围内都有效 var 命令会发生“变量提升”现象，即变量会在声明前可使用，而 let 做了语法处理，限制了这种情况 暂时性死区若区块中存在let 和 const 命令，这个区块对这些命令声明的变量从一开始就有了封闭作用域。凡是声明前使用这些变量，就会报错。在语法上，称为“暂时性死区”。 不允许重复声明let 不允许在同作用域内，重复声明同一个变量。 const命令const 声明一个只读常亮，一旦声明，不可再修改，即为声明变量需要立即初始化 作用域与 let 相同 ES6声明变量共六种：var function let const import class 变量的解构赋值数组解构类似 let [a,b,c,] = [1,2,3]; 若解构失败，变量的值就等于 undefined 解构赋值允许指定默认值 对象解构赋值元素按次序排列，变量的取值由位置决定，而对象的属性无次序，变量必须与属性同名，才能取得正确的值 函数扩充ES6中函数参数可带有默认值 参数变量是默认声明的，所以不能用 let 或 const 再次声明 使用参数默认值时，函数不能有同名参数 定义了默认值的参数，应该是函数的尾参数 rest参数ES6引入 rest 参数（形式为 . . .变量名 ），用于获取函数的多余参数。 rest 参数搭配的变量是一个数组，该变量将多余的参数放入数组中。 rest 参数后不能再有参数 函数的 length 参数，不包括 rest 参数 name属性返回函数的函数名 若将匿名函数赋值给一个变量，将返回变量名 Function 构造函数返回的函数实例，name 属性的值为 anonymous bind返回的函数，name 属性值会加上 bound 前缀 箭头函数ES6允许使用“箭头” (=&gt;)定义函数 var f = v =&gt; v;等同于var f = function (v) { return v;}如果箭头函数不需要参数或者需要多个参数，可以使用一个圆括号代表参数 var f = () =&gt; 5;等同于var f = function ( ) { return 5; }var sum = ( num1, num2) =&gt; num1 + num2;等同于var sum = function ( num1, num2) { return num1 + num2;}如果箭头函数代码块部分多余一条语句，就要使用大括号将他们括起来，并使用 return 语句返回。 var sum = ( num1, num2) =&gt; { return num1 + num2; }由于大括号被解释为代码块，所以如果箭头函数直接返回一个对象，必须在对象外面加上大括号。 let getTempItem = id =&gt; ( { id : id ,name : “ Temp”} ) ;箭头函数使得表达式更为简洁 const isEven = n =&gt; n % 2 == 0 ;const square = n =&gt; n * n ;箭头函数可以简化回调函数 [ 1, 2, 3] .map( function (x) ){ return x * x ;}箭头函数[1, 2, 3].map( x =&gt; x * x ) ;箭头函数与 rest 参数结合 const numbres = ( …nums) =&gt; nums ;numbers (1, 2, 3, 4, 5)// [ 1, 2, 3, 4, 5]const headAndTail = ( head , …tail ) =&gt; [head, tail] ;handAndTail (1, 2, 3, 4, 5)// [1, [2, 3, 4, 5] ]箭头函数使用注意函数内的 this 对象，就是定义时所在的对象，而不是使用时所在的对象 不可以当作构造函数，也就是说，不可使用 new 命令 不可使用 arguments 对象，该对象在函数体内不存在。若要用，可使用 rest 参数代替 不可以使用 yield 命令 嵌套的箭头函数箭头函数的内部，还可以使用箭头函数 const plus1 = a =&gt; a+1; const mult2 = a =&gt; a * 2; mult2 ( plus1(5) )双冒号运算符函数绑定运算符，取代 call，apply，bind； 双冒号左边是一个对象，右边是一个函数。自动将左边的对象，作为上下文环境（即this对象）绑定到右边函数上。 foo :: bar等同于bar.bind( foo ) ;foo :: bar( ..arguments ) ;等同于bar.apply( foo, arguments ) ;如果双冒号左边为空，右边是一个对象的方法，等于将该方法绑定在该对象上 var method = obj :: obj.foo ;var method = :: obj.foo ;let log = :: console.log ;var log = console.log.bind(console) ;如果双冒号运算符的晕眩结果，还是一个对象，可以使用链式写法 import { map , takeWhile, foreach } from “iterlib” ;getPlayers():: map( x =&gt; x.character ( ) ):: takeWhile ( x =&gt; x.strength &gt; 100):: foreach ( x =&gt; console.log( x ) );尾调用优化尾调用（tail call）是函数式编程的一个概念，指某个函数的最后一步是调用另一个函数 function f ( x ) { return g ( x ) ;}尾调用之所以与其他调用不同，就在于它的特殊的调用位置。我们知道，函数调用会在内存形成一个“调用记录”，又称“调用帧”（call frame），保存调用位置和内部变量等信息。如果在函数A的内部调用函数B，那么在A的调用帧上方，还会形成一个B的调用帧。等到B运行结束，将结果返回到A，B的调用帧才会消失。如果函数B内部还调用函数C，那就还有一个C的调用帧，以此类推。所有的调用帧，就形成一个“调用栈”（call stack）。 尾调用由于是函数的最后一步操作，所以不需要保留外层函数的调用帧，因为调用位置、内部变量等信息都不会再用到了，只要直接用内层函数的调用帧，取代外层函数的调用帧就可以了。 123456function f ( ) { let m = 1; let n =2; return g( m + n ) ;}f( ); 等同于 1234function f( ) { return g( 3 ); }f( ); 等同于 1g( 3 ); 尾调用优化就是只保留内层函数的调用帧。 递归非常耗费内存，很容易发生“栈溢出”。对于尾递归来说，只存在一个调用帧，所以不会发生“栈溢出” 递归函数的改写函数式编程有个概念，叫柯里化，意思是将多参数转换成但参数形式 123456//采用es6function factorial( n, total = 1 ) { if( n == 1 ) return total; return factorial( n-1, n * total ) ;}factorial( 5 ); //120 原文地址 : es6基础","link":"/2020/08/15/%E7%AC%94%E8%AE%B0%EF%BC%9Aes6%E5%9F%BA%E7%A1%80/"},{"title":"自动化SQL注入工具 sqlmap 中文手册","text":"简介sqlmap是一个开源的渗透测试工具，它可以自动化检测和利用SQL注入漏洞并接管数据库服务器。它有一个强大的检测引擎，许多适合于终极渗透测试的良好特性和众多的操作选项，从数据库指纹、数据获取到访问底层文件系统、执行操作系统命令。 特点 全面支持MySQL, Oracle, PostgreSQL, Microsoft SQL Server, Microsoft Access, IBM DB2, SQLite, Firebird, Sybase和SAP MaxDB数据库管理系统。 全面支持六种SQL注入技术:boolean-based盲注、time-based盲注、error-based、UNION查询、堆叠查询和带外查询。 通过提供DBMS凭证、IP地址、端口和数据库名，支持不通过SQL注入的直接连接数据库。 支持枚举用户、密码哈希、特权、角色、数据库、表和列。 自动识别密码哈希格式，支持基于字典的攻击破解。 支持完整转储数据库表，根据用户的选择转储一定范围内的条目或特定列。用户还可以选择只从每列中转储指定字符。 支持搜索特定的数据库名、表名，或跨表搜索特定的列名。这非常有用，例如，识别包含自定义应用程序凭证的表，其相关列名称可能包含name、pass等字符串。 支持通过数据库服务器所在的文件系统下载和上传任何文件，当数据库软件是MySQL, PostgreSQL或Microsoft SQL server时。 支持通过数据库服务器所在的操作系统执行任意命令并获取输出，当数据库软件为MySQL、PostgreSQL或Microsoft SQL server时。 支持在攻击者机器和数据库服务器所在操作系统之间建立带外有状态的TCP连接，这个通道根据用户的选择可以是交互式命令行、Meterpreter会话或图形用户界面(VNC)。 支持通过Metasploit的getsystem命令实现数据库进程的用户权限升级。 安装sqlmap 官网下载 支持支持的操作系统： Windows XP/7/8/10 GNU/Linux MacOSX 使用 目标：攻击给定的URL(-u “http://192.168.1.250/?p=1&amp;forumaction=search”)， 获取数据库名(–dbs): 12345678root@kali:~# sqlmap -u &quot;http://192.168.1.250/?p=1&amp;forumaction=search&quot; --dbs sqlmap/1.0-dev - automatic SQL injection and database takeover tool http://sqlmap.org[!] legal disclaimer: Usage of sqlmap for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program[*] starting at 13:11:04 选项1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677root@kali:~# sqlmap -hUsage: python sqlmap [options]Options: -h, --help 显示基本的帮助信息并退出 -hh 显示高级帮助信息并退出 --version 显示程序的版本号并退出 -v VERBOSE 显示详细信息级别: 0-6 (default 1) Target: 至少必须提供一个选项来指定目标 -u URL, --url=URL 目标URL (e.g. &quot;http://www.site.com/vuln.php?id=1&quot;) -g GOOGLEDORK 将Google dork结果作为目标URLs Request: 这些选项用于指定如何连接到目标URL --data=DATA 通过POST方法传送字符串 --cookie=COOKIE 指定HTTP Cookie值 --random-agent 随机选择HTTP User-Agent值 --proxy=PROXY 指定连接代理 --tor 使用Tor匿名网络 --check-tor 检查Tor网络是否可用 Injection: 这些选项可用于指定要测试的参数，提供自定义注入载荷和可选的伪造脚本 -p TESTPARAMETER Testable参数 --dbms=DBMS 强制指定后端DBMS类型 Detection: 这些选项可用于定制检测阶段 --level=LEVEL Level of tests to perform (1-5, default 1) --risk=RISK Risk of tests to perform (0-3, default 1) Techniques: 这项选项可用于优化特定的SQL注入技巧 --technique=TECH SQL injection techniques to use (default &quot;BEUSTQ&quot;) Enumeration: 这些选项可用于枚举后端数据库管理系统中包含的信息、结构和数据表。此外，还可以运行自己的SQL语句 -a, --all 获取所有信息 -b, --banner 获取DBMS banner --current-user 获取DBMS当前用户 --current-db 获取DBMS当前数据库 --passwords 枚举DBMS用户口令哈希 --tables 枚举DBMS数据库表 --columns 枚举DBMS数据表的列 --schema 枚举DBMS schema --dump 转储DBMS database table entries --dump-all 转储所有DBMS databases tables entries -D DB 指定DBMS数据库 -T TBL 指定DBMS数据表 -C COL 指定DBMS数据表的列 Operating system access: 这些选项可用于访问后端数据库管理系统所在的底层操作系统 --os-shell 启动交互式操作系统命令行 --os-pwn 启动OOB shell, Meterpreter or VNC General: 这些选项可用于设置通用参数 --batch 不要求用户输入，使用默认值 --flush-session 对当前目标刷新会话文件 Miscellaneous: --wizard 适用于初学者的简单向导[!] 完整的选项信息可使用'-hh'获取[*] shutting down at 15:52:48 作者 作者:Bernardo Damele Assumpcao Guimaraes, Miroslav Stampar 许可:GPLv2 来源： 自动化SQL注入工具 sqlmap 中文手册 | 浅若清风 (whbwiki.com)","link":"/2021/12/05/%E8%87%AA%E5%8A%A8%E5%8C%96SQL%E6%B3%A8%E5%85%A5%E5%B7%A5%E5%85%B7%20sqlmap%20%E4%B8%AD%E6%96%87%E6%89%8B%E5%86%8C/"},{"title":"缓存穿透、缓存击穿、缓存雪崩区别和解决方案","text":"场景 遭受攻击大量随机生成的key访问，或是真正访问但数据库就是没数据 上线前没有进行老数据缓存预加载，大量老数据请求去查询数据库 热点key失效，对热点key的并发访问大 缓存失效，过期时间设置相同同一时间有大量key失效 缓存挂掉，直接查数据库 缓存处理流程前台请求，后台先从缓存中取数据，取到直接返回结果，取不到时从数据库中取，数据库取到更新缓存，并返回结果，数据库也没取到，那直接返回空结果。 缓存穿透描述：缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。当用户很多的时候，缓存都没有命中，于是都去请求了持久层数据库。这会给持久层数据库造成很大的压力，这时候就相当于出现了缓存穿透。 这里需要注意和缓存击穿的区别，缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。 解决方案： 接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截； 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 但是这种方法会存在两个问题： 如果空值能够被缓存起来，这就意味着缓存需要更多的空间存储更多的键，因为这当中可能会有很多的空值的键； 即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于需要保持一致性的业务会有影响。 布隆过滤器 布隆过滤器是一种数据结构，垃圾网站和正常网站加起来全世界据统计也有几十亿个。网警要过滤这些垃圾网站，总不能到数据库里面一个一个去比较吧，这就可以使用布隆过滤器。假设我们存储一亿个垃圾网站地址。 可以先有一亿个二进制比特，然后网警用八个不同的随机数产生器（F1,F2, …,F8） 产生八个信息指纹（f1, f2, …, f8）。接下来用一个随机数产生器 G 把这八个信息指纹映射到 1 到1亿中的八个自然数 g1, g2, …,g8。最后把这八个位置的二进制全部设置为一。过程如下 有一天网警查到了一个可疑的网站，想判断一下是否是XX网站，首先将可疑网站通过哈希映射到1亿个比特数组上的8个点。如果8个点的其中有一个点不为1，则可以判断该元素一定不存在集合中。 那这个布隆过滤器是如何解决redis中的缓存穿透呢？很简单首先也是对所有可能查询的参数以hash形式存储，当用户想要查询的时候，使用布隆过滤器发现不在集合中，就直接丢弃，不再对持久层查询。 缓存击穿描述：缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力 解决方案： 设置热点数据永远不过期 加互斥锁 缓存雪崩描述缓存雪崩是指缓存中数据大批量到过期时间或者缓存层出现错误，大量查询到达存储层，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 解决方案 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。 设置热点数据永远不过期。 redis高可用这个思想的含义是，既然redis有可能挂掉，那我多增设几台redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群。 限流降级这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 数据预热数据加热的含义就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。 参考文章：https://blog.csdn.net/kongtiao5/article/details/82771694 https://baijiahao.baidu.com/s?id=1655304940308056733&amp;wfr=spider&amp;for=pc","link":"/2022/03/08/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E3%80%81%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E5%8C%BA%E5%88%AB%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"title":"译-在多个标签页之间共享sessionStorage","text":"昨天，就在昨天，前端一同事提了一个问题：我们的系统，用户重新开一个标签页，就要重新登录。我当时觉得这怎么可能？结果现场一测，还真是，好尴尬！ 今天抽了点时间网上查了查，才发现原来一直以为很简单的sessionStorage，还真埋了这么一颗雷。不过国外前辈也提出了一个解决方案，不仅如此，文章还把浏览器端保存数据的场景分析的很透彻，所以斗胆翻译了一下。 原文翻译我实现了一种机制可以利用浏览器提供的sessionStorage或memoryStorageStorage的固有的安全性来实现用户身份认证，并且可以保证用户不需要每次新开一个标签页都重新登录。 现有的浏览器存储机制 localStorage：~5MB，数据永久保存直到用户手动删除 sessionStorage：~5MB，数据只在当前标签页有效 cookie：~4KB，可以设置成永久有效 session cookie：~4KB，当用户关闭浏览器时删除（并非总能立即删除） 安全的认证token保存一些重要的系统会要求当用户关闭标签页时会话立刻到期。 为了达到这个目的，不仅绝对不应该使用cookies来保存任何敏感信息（例如认证token）。甚至session-cookies也无法满足要求，它在标签页关闭（甚至浏览器完全关闭）后还会持续存活一定时间。 （任何时刻我们都不应该只使用cookies，它还有其他很多问题需要讨论，例如CSRF） 这些问题就使得我们在保存认证token时应使用内存或sessionStorage。sessionStorage的好处是它允许跨多个页面保存数据，并且也支持浏览器刷新操作。这样用户就可以在多个页面之间跳转或刷新页面而保持登录状态。 Good。我们将token保存在sessionStorage，并在每次请求服务器时将token放在请求头中来完成用户的身份认证。当用户关闭标签页，token会立即过期。 但多标签页怎么办？即便是在单页面应用中也有一个很常见的情况，用户经常希望打开多个标签页。而此场景下将token保存在sessionStorage中将会带来很差的用户体验，每次开启一个标签页都会要求用户重新登录。没错，sessionStorage不支持跨标签页共享数据。 利用localStorage事件来跨标签页共享sessionStorage我利用localStorage事件提出了一种解决方案。 当用户新开一个标签页时，我们先来询问其它已经打开的标签页是不是有需要给我们共享的sessionStorage数据。如果有，现有的标签页会通过localStorage事件来传递数据到新打开的标签页中，我们只需要复制一份到本地sessionStorage即可。 传递过来的sessionStorage绝对不会保存在localStorage，从localStorage事件将数据中复制并保存到sessionStorage，这个流程是在同一个调用中完成，没有中间状态。而且数据是对应事件携带的，并不在localStorage中。（译者注：作者意图解释这个方案的安全性） 在线例子 点击“Set the sessionStorage”，然后打开多个标签页，你会发现sessionStorage共享了。 123456789101112131415161718192021222324252627282930// 为了简单明了删除了对IE的支持[好像支持ie11](function() {//这段代码只在当前页面加入，需要跳转到的页面不需要//sessionStorage.setItem('user','chengyao') if (!sessionStorage.length) { // 这个调用能触发目标事件，从而达到共享数据的目的 localStorage.setItem('getSessionStorage', Date.now()); }; // 该事件是核心 window.addEventListener('storage', function(event) { if (event.key === 'getSessionStorage') { // 已存在的标签页会收到这个事件 localStorage.setItem('sessionStorage', JSON.stringify(sessionStorage)); localStorage.removeItem('sessionStorage'); } else if (event.key === 'sessionStorage' &amp;&amp; !sessionStorage.length) { // 新开启的标签页会收到这个事件 var data = JSON.parse(event.newValue) //,value; for (key in data) { sessionStorage.setItem(key, data[key]); } } });})(); （译者注：上面的代码是我从在线demo中截取的，原文中并无提到） 接近完美我们现在拥有了一个几乎非常安全的方案来保存会话token在浏览器里，并支持良好的多标签页用户体验。现在当用户关闭标签页后能确保会话立即过期。难道不是么？ chrome和firefox都支持当用户进行“重新打开关闭的标签页”或“撤销关闭标签页”时恢复sessionStorage。F**k！（译者注：作者原文用的是“Damn it!”，注意到那个叹号了吗？） safari在这个问题上处理是正确的，它并不会恢复sessionStorag（只测试了上述这三个浏览器）。 对用户而言，能够确定sessionStorag已经过期的方法是直接重新打开网站，而不是选择“重新打开关闭的标签页”。 除非chrome和firefox能够解决这个bug。（但我预感开发组会称其为“特性”） 即便存在这样的bug，使用sessionStorag依然要比session-cookies方案或其他方案要安全。如果我们希望得到一个更加完美的方案，我们就需要自己来实现一个内存的方案来代替sessionStorag。(onbeforeunload也能做到，但不是太可靠且每次刷新页面也会被清空。window.name也不错，但它太老了且也不支持跨域保护) 跨标签页共享memoryStorage这应该是唯一一个真正安全的实现浏览器端保存认证token的方法了，并且要保证用户打开多个标签页不需要重新登录。 关闭标签页，会话立即过期–这次是真真儿的。 这个方案的缺点是，当只有一个标签页时，浏览器刷新会导致用户重新登录。安全总是要付出点代价的，很明显这个缺点可能是致命的。 在线例子 设置一个memoryStorage，然后打开多个标签页，你会发现数据共享了。关闭所有标签页token会立即永久过期（memoryStorage其实就是一个javascript对象而已）。 123456789101112131415161718192021222324252627282930(function() { window.memoryStorage = {}; function isEmpty(o) { for (var i in o) { return false; } return true; }; if (isEmpty(memoryStorage)) { localStorage.setItem('getSessionStorage', Date.now()); }; window.addEventListener('storage', function(event) { if (event.key == 'getSessionStorage') { localStorage.setItem('sessionStorage', JSON.stringify(memoryStorage)); localStorage.removeItem('sessionStorage'); } else if (event.key == 'sessionStorage' &amp;&amp; isEmpty(memoryStorage)) { var data = JSON.parse(event.newValue), value; for (key in data) { memoryStorage[key] = data[key]; } } });})(); 原文：Sharing sessionStorage between tabs for secure multi-tab authentication 译者得er瑟","link":"/2020/10/25/%E8%AF%91-%E5%9C%A8%E5%A4%9A%E4%B8%AA%E6%A0%87%E7%AD%BE%E9%A1%B5%E4%B9%8B%E9%97%B4%E5%85%B1%E4%BA%ABsessionStorage/"},{"title":"解决 go build时候timeout问题","text":"默认安装的go 在 build的时候会出现长时间无响应，有类似如下报如下错误： 1go: github.com/hyperledger/fabric-contract-api-go@v1.0.0: Get https://proxy.golang.org/github.com/hyperledger/fabric-contract-api-go/@v/v1.0.0.mod: dial tcp 172.217.27.145:443: i/o timeout 因为默认的go地址被墙了，所以我们要更换地址，更换为七牛云的镜像，直接运行下面两条命令即可： 12go env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.cn,direct 原文地址：http://www.iamlintao.com/7194.html","link":"/2021/08/29/%E8%A7%A3%E5%86%B3%20go%20build%E6%97%B6%E5%80%99timeout%E9%97%AE%E9%A2%98/"},{"title":"解决浏览器跨域限制方案之JSONP","text":"一.什么是JSONPJSONP即：JSON with Padding，是一种解决因浏览器跨域限制不允许访问跨域资源的方法。 JSONP是一个非官方的协议，它允许在服务器端返回javascript标签到浏览器，在浏览器端通过调用javascript函数的形式实现访问跨域资源或数据。 二.JSONP和JSON的关系JSONP是一种解决因浏览器跨域限制不允许访问跨域资源的方法；而JSON是一种数据格式，与xml类似。 虽然二者在字面上都含有关键字“JSON”，但实际上他们之间没有任何关系。 通过JSONP获取到的跨域数据是javascript对象，而非JSON对象，所以避免了数据解析这个过程。 三.JSONP的原理本质上来讲，JSONP解决访问跨域资源的方法，与直接使用&lt;script&gt;标签引用资源是一样的。 原因在于：使用JSONP访问跨域数据时，就是需要在DOM中动态创建&lt;script&gt;标签，并设置src属性访问指定资源。 差别在于：通过JSONP获取到的返回数据是一个函数调用，数据以参数的形式传递给函数；而&lt;script&gt;标签返回的是引用的资源内容。 四.实战示例1.前端代码12345678910111213141516171819202122232425262728&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt; &lt;h2&gt;验证使用JSONP方式发送跨域请求&lt;/h2&gt; &lt;div&gt; &lt;input type=&quot;button&quot; value=&quot;发送请求&quot; onclick=&quot;ajaxJsonp()&quot;&gt; &lt;/div&gt;&lt;/body&gt;&lt;script type=&quot;text/javascript&quot;&gt; // 前端通过动态创建javascript标签的方式发送请求 function ajaxJsonp() { var url = &quot;http://localhost:8081/jsonp?callback=jsonpcall&quot;; var script = document.createElement('script'); script.setAttribute(&quot;type&quot;,&quot;text/javascript&quot;); script.src = url; document.body.appendChild(script); } // jsonp返回数据时调用的函数,数据以参数形式传递 function jsonpcall(data) { console.log(&quot;do response jsonp data&quot;); console.log(data); }&lt;/script&gt;&lt;/html&gt; 2.服务端代码123456789101112/** * 使用JSONP方式处理跨域GET请求 * @param req * @param resp * @param callback 回调函数名称 * @return */@RequestMapping(value = &quot;/jsonp&quot;, method = RequestMethod.GET)@ResponseBodypublic Object testAjaxJsonp(HttpServletRequest req, HttpServletResponse resp, @RequestParam(&quot;callback&quot;) String callback) { JSONObject json = new JSONObject(); json.put(&quot;name&quot;, &quot;jsonp&quot;); json.put(&quot;pwd&quot;, &quot;&quot;); // 将数据作为函数的参数返回给浏览器,如: jsonpcall({&quot;name&quot;:&quot;jsonp&quot;,&quot;pwd&quot;:&quot;&quot;}) return new StringBuffer().append(callback).append(&quot;(&quot;).append(json).append(&quot;)&quot;);} jquery中使用getJson12345$(&quot;#b1&quot;).click(function () { $.getJSON(&quot;http://127.0.0.1:8989/jsonp/?callback=?&quot;, function (res) { console.log(res); })}); 要注意的是在url的后面必须要有一个callback参数，这样getJSON方法才会知道是用JSONP方式去访问服务，callback后面的那个？是jQuery内部自动生成的一个回调函数名。 想要自己指定回调名,可以使用$.ajax实现 1234567891011$(&quot;#b1&quot;).click(function () { $.ajax({ url: &quot;http://127.0.0.1:8989/jsonp/&quot;, dataType: &quot;jsonp&quot;, jsonp: &quot;callback&quot;, jsonpCallback: &quot;rion2&quot; }) }); function rion2(res) { console.log(res); } 【参考】 http://www.nowamagic.net/librarys/veda/detail/224 JSONP跨域的原理解析 http://www.xiaoxiaozi.com/2011/11/25/2239/ JSONP与POST方式请求 http://www.cnblogs.com/dowinning/archive/2012/04/19/json-jsonp-jquery.html 说说JSON和JSONP http://www.cnblogs.com/chopper/archive/2012/03/24/2403945.html 深入浅出JSONP–解决ajax跨域问题 解决浏览器跨域限制方案之JSONP - 腾讯云开发者社区-腾讯云","link":"/2022/08/10/%E8%A7%A3%E5%86%B3%E6%B5%8F%E8%A7%88%E5%99%A8%E8%B7%A8%E5%9F%9F%E9%99%90%E5%88%B6%E6%96%B9%E6%A1%88%E4%B9%8BJSONP/"},{"title":"详解PV、UV、VV、IP及其关系与计算","text":"一、什么是PV？ PV即Page View，网站浏览量，指页面浏览的次数，用以衡量网站用户访问的网页数量。****用户每次打开一个页面便记录1次PV，多次打开同一页面则浏览量累计。一般来说，PV与来访者的数量成正比，但是PV并不直接决定页面的真实来访者数量，如同一个来访者通过不断的刷新页面，也可以制造出非常高的PV。具体的说，PV值就是所有访问者在24小时（0点到24点）内看了某个网站多少个页面或某个网页多少次。PV是指页面刷新的次数，每一次页面刷新，就算做一次PV流量。 度量方法就是从浏览器发出一个对网络服务器的请求（Request），网络服务器接到这个请求后，会将该请求对应的一个网页（Page）发送给浏览器，从而产生了一个PV。那么在这里只要是这个请求发送给了浏览器，无论这个页面是否完全打开（下载完成），那么都是应当计为1个PV。 二、什么是UV？ UV即Unique Visitor，独立访客数，指一天内访问某站点的人数，以cookie为依据。****1天内同一访客的多次访问只记录为一个访客。通过IP和cookie是判断UV值的两种方式。 用Cookie分析UV值 当客户端第一次访问某个网站服务器的时候，网站服务器会给这个客户端的电脑发出一个Cookie，通常放在这个客户端电脑的C盘当中。在这个Cookie中会分配一个独一无二的编号，这其中会记录一些访问服务器的信息，如访问时间，访问了哪些页面等等。当你下次再访问这个服务器的时候，服务器就可以直接从你的电脑中找到上一次放进去的Cookie文件，并且对其进行一些更新，但那个独一无二的编号是不会变的。 三、什么是VV？ VV即Visit View，访客访问的次数，用以记录所有访客一天内访问量多少次网站。当访客完成所有的浏览并最终关掉该网站的所有页面时，便完成了一次访问，同一访客一天内可能有多次访问行为，访问次数累计。 四、什么是IP？ **IP即独立IP数，指一天内使用不同IP地址的用户访问网站数量，同一IP无论访问了几个页面，独立的IP数均为1.**但是假如说两台机器访问而使用的是同一个IP，那么只能算是一个IP的访问。 IP和UV之间的数据不会有太大的差异，通常UV量和比IP量高出一点，每个UV相对于每个IP更准确地对应一个实际的浏览者。 ①UV大于IP 这种情况就是在网吧、学校、公司等，公用相同IP的场所中不同的用户，或者多种不同浏览器访问您网站，那么UV数会大于IP数。 ②UV小于IP 在家庭中大多数电脑使用ADSL拨号上网，所以同一个用户在家里不同时间访问您网站时，IP可能会不同，因为它会根据时间变动IP，即动态的IP地址，但是实际访客数唯一，便会出现UV数小于IP数。 五、实例说明 小明在家用ADSL拨号上网，早上8点访问了www.a.com下的2个页面，下午2点又访问了www.a.com3个页面。那么，对于www.a.com来讲，今天的PV、UV、VV、IP各项指标该如何计算呢？ PV：5 PV指浏览量，因此PV指等于上午浏览的2个页面和下午浏览的3个页面之和； UV：1 UV指独立访客数，因此一天内同一访客的多次访问只计为1个UV； VV：1 VV指访客的访问次数，上午和下午分别有一次访问行为，因此VV为2 IP：2 IP为独立IP数，由于ADSL拨号上网每次都IP不同，因此独立IP数位2； 本文出自 “Just For Fun!” 博客，请务必保留此出处http://linuxnote.blog.51cto.com/9876511/1653958","link":"/2022/06/11/%E8%AF%A6%E8%A7%A3PV%E3%80%81UV%E3%80%81VV%E3%80%81IP%E5%8F%8A%E5%85%B6%E5%85%B3%E7%B3%BB%E4%B8%8E%E8%AE%A1%E7%AE%97/"},{"title":"键盘KeyCode对照表","text":"keycode 0 =keycode 1 =keycode 2 =keycode 3 =keycode 4 =keycode 5 =keycode 6 =keycode 7 =keycode 8 = BackSpace BackSpacekeycode 9 = Tab Tabkeycode 10 =keycode 11 =keycode 12 = Clearkeycode 13 = Enterkeycode 14 =keycode 15 =keycode 16 = Shift_Lkeycode 17 = Control_Lkeycode 18 = Alt_Lkeycode 19 = Pausekeycode 20 = Caps_Lockkeycode 21 =keycode 22 =keycode 23 =keycode 24 =keycode 25 =keycode 26 =keycode 27 = Escape Escapekeycode 28 =keycode 29 =keycode 30 =keycode 31 =keycode 32 = space spacekeycode 33 = Priorkeycode 34 = Nextkeycode 35 = Endkeycode 36 = Homekeycode 37 = Leftkeycode 38 = Upkeycode 39 = Rightkeycode 40 = Downkeycode 41 = Selectkeycode 42 = Printkeycode 43 = Executekeycode 44 =keycode 45 = Insertkeycode 46 = Deletekeycode 47 = Helpkeycode 48 = 0 equal bracerightkeycode 49 = 1 exclam onesuperiorkeycode 50 = 2 quotedbl twosuperiorkeycode 51 = 3 section threesuperiorkeycode 52 = 4 dollarkeycode 53 = 5 percentkeycode 54 = 6 ampersandkeycode 55 = 7 slash braceleftkeycode 56 = 8 parenleft bracketleftkeycode 57 = 9 parenright bracketrightkeycode 58 =keycode 59 =keycode 60 =keycode 61 =keycode 62 =keycode 63 =keycode 64 =keycode 65 = a Akeycode 66 = b Bkeycode 67 = c Ckeycode 68 = d Dkeycode 69 = e E EuroSignkeycode 70 = f Fkeycode 71 = g Gkeycode 72 = h Hkeycode 73 = i Ikeycode 74 = j Jkeycode 75 = k Kkeycode 76 = l Lkeycode 77 = m M mukeycode 78 = n Nkeycode 79 = o Okeycode 80 = p Pkeycode 81 = q Q atkeycode 82 = r Rkeycode 83 = s Skeycode 84 = t Tkeycode 85 = u Ukeycode 86 = v Vkeycode 87 = w Wkeycode 88 = x Xkeycode 89 = y Ykeycode 90 = z Zkeycode 91 =keycode 92 =keycode 93 =keycode 94 =keycode 95 =keycode 96 = KP_0 KP_0keycode 97 = KP_1 KP_1keycode 98 = KP_2 KP_2keycode 99 = KP_3 KP_3keycode 100 = KP_4 KP_4keycode 101 = KP_5 KP_5keycode 102 = KP_6 KP_6keycode 103 = KP_7 KP_7keycode 104 = KP_8 KP_8keycode 105 = KP_9 KP_9keycode 106 = KP_Multiply KP_Multiplykeycode 107 = KP_Add KP_Addkeycode 108 = KP_Separator KP_Separatorkeycode 109 = KP_Subtract KP_Subtractkeycode 110 = KP_Decimal KP_Decimalkeycode 111 = KP_Divide KP_Dividekeycode 112 = F1keycode 113 = F2keycode 114 = F3keycode 115 = F4keycode 116 = F5keycode 117 = F6keycode 118 = F7keycode 119 = F8keycode 120 = F9keycode 121 = F10keycode 122 = F11keycode 123 = F12keycode 124 = F13keycode 125 = F14keycode 126 = F15keycode 127 = F16keycode 128 = F17keycode 129 = F18keycode 130 = F19keycode 131 = F20keycode 132 = F21keycode 133 = F22keycode 134 = F23keycode 135 = F24keycode 136 = Num_Lockkeycode 137 = Scroll_Lockkeycode 138 =keycode 139 =keycode 140 =keycode 141 =keycode 142 =keycode 143 =keycode 144 =keycode 145 =keycode 146 =keycode 147 =keycode 148 =keycode 149 =keycode 150 =keycode 151 =keycode 152 =keycode 153 =keycode 154 =keycode 155 =keycode 156 =keycode 157 =keycode 158 =keycode 159 =keycode 160 =keycode 161 =keycode 162 =keycode 163 =keycode 164 =keycode 165 =keycode 166 =keycode 167 =keycode 168 =keycode 169 =keycode 170 =keycode 171 =keycode 172 =keycode 173 =keycode 174 =keycode 175 =keycode 176 =keycode 177 =keycode 178 =keycode 179 =keycode 180 =keycode 181 =keycode 182 =keycode 183 =keycode 184 =keycode 185 =keycode 186 =keycode 187 = acute gravekeycode 188 = comma semicolonkeycode 189 = minus underscorekeycode 190 = period colonkeycode 191 =keycode 192 = numbersign apostrophekeycode 193 =keycode 194 =keycode 195 =keycode 196 =keycode 197 =keycode 198 =keycode 199 =keycode 200 =keycode 201 =keycode 202 =keycode 203 =keycode 204 =keycode 205 =keycode 206 =keycode 207 =keycode 208 =keycode 209 =keycode 210 = plusminus hyphen macronkeycode 211 =keycode 212 = copyright registeredkeycode 213 = guillemotleft guillemotrightkeycode 214 = masculine ordfemininekeycode 215 = ae AEkeycode 216 = cent yenkeycode 217 = questiondown exclamdownkeycode 218 = onequarter onehalf threequarterskeycode 219 =keycode 220 = less greater barkeycode 221 = plus asterisk asciitildekeycode 222 =keycode 223 =keycode 224 =keycode 225 =keycode 226 =keycode 227 = multiply divisionkeycode 228 = acircumflex Acircumflexkeycode 229 = ecircumflex Ecircumflexkeycode 230 = icircumflex Icircumflexkeycode 231 = ocircumflex Ocircumflexkeycode 232 = ucircumflex Ucircumflexkeycode 233 = ntilde Ntildekeycode 234 = yacute Yacutekeycode 235 = oslash Oobliquekeycode 236 = aring Aringkeycode 237 = ccedilla Ccedillakeycode 238 = thorn THORNkeycode 239 = eth ETHkeycode 240 = diaeresis cedilla currencykeycode 241 = agrave Agrave atilde Atildekeycode 242 = egrave Egravekeycode 243 = igrave Igravekeycode 244 = ograve Ograve otilde Otildekeycode 245 = ugrave Ugravekeycode 246 = adiaeresis Adiaeresiskeycode 247 = ediaeresis Ediaeresiskeycode 248 = idiaeresis Idiaeresiskeycode 249 = odiaeresis Odiaeresiskeycode 250 = udiaeresis Udiaeresiskeycode 251 = ssharp question backslashkeycode 252 = asciicircum degreekeycode 253 = 3 sterlingkeycode 254 = Mode_switch","link":"/2020/07/05/%E9%94%AE%E7%9B%98KeyCode%E5%AF%B9%E7%85%A7%E8%A1%A8/"},{"title":"负载均衡笔记","text":"常用负载均衡HTTP 重定向对于HTTP 重定向，你一定不陌生，它可以将 HTTP 请求进行转移，在 Web 开发中我们经常会用它来完成自动跳转，比如用户登录成功后跳转到相应的管理页面。 这种重定向完全由HTTP 定义，并且由HTTP 代理和Web 服务器共同实现。很简单，当HTTP 代理（比如浏览器）向Web服务器请求某个URL后，Web 服务器可以通过HTTP 响应头信息中的Location 标记来返回一个新的URL，这意味着HTTP代理需要继续请求这个新的URL ，这便完成了自动跳转。当然，如果你自己写了一个 HTTP 代理，也可以不支持重定向，也就是对于Web 服务器返回的Location 标记视而不见，虽然这可能不符合HTTP 标准，但这完全取决于你的应用需要。 也正是因为HTTP 重定向具备了请求转移和自动跳转的本领，所以除了满足应用程序需要的各种自动跳转之外，它还可以用于实现负载均衡，以达到Web 扩展的目的。 DNS 负载均衡我们知道，DNS负责提供域名解析服务，当我们访问某个站点时，实际上首先需要通过该站点域名的DNS服务器来获取域名指向的IP 地址，在这一过程中，DNS服务器完成了域名到IP 地址的映射，同样，这种映射也可以是一对多的，这时候，DNS 服务器便充当了负载均衡调度器（也称均衡器），它就像前面提到的重定向转移策略一样，将用户的请求分散到多台服务器上，但是它的实现机制完全不同。 反向代理负载均衡反向代理服务器的核心工作便是转发 HTTP 请求，因此它工作在 HTTP 层面，也就是 TCP 七层结构中的应用层（第七层），所以基于反向代理的负载均衡也称为七层负载均衡，实现它并不困难，目前几乎所有主流的 Web 服务器都热衷于支持基于反向代理的负载均衡，随后我们将进行Nginx反向代理负载均衡的实验 IP 负载均衡事实上，在数据链路层（第二层）、网络层（第三层）以及传输层（四层）都可以实现不同机制的负载均衡，但有所不同的是，这些负载均衡调度器的工作必须由Linux 内核来完成，因为我们希望网络数据包在从内核缓冲区进入进程用户地址空间之前，尽早地被转发到其他实际服务器上，没错，Linux 内核当然可以办得到，位于内核的Netfilter和IPVS可以解决问题，而用户空间的应用程序对此却束手无策。 另一方面，也正是因为可以将调度器工作在应用层以下，这些负载均衡系统可以支持更多的网络服务协议，比如FTP 、SMTP 、DNS ，以及流媒体和Vo I P 等应用。 集群 计算机集群简称集群是一种计算机系统， 它通过一组松散集成的计算机软件和/或硬件连接起来高度紧密地协作完成计算工作。在某种意义上，他们可以被看作是一台计算机。集群系统中的单个计算机通常称为节点，通常通过局域网连接，但也有其它的可能连接方式。集群计算机通常用来改进单个计算机的计算速度和/或可靠性。一般情况下集群计算机比单个计算机，比如工作站或超级计算机性能价格比要高得多。 集群分类集群分为同构与异构两种，它们的区别在于：组成集群系统的计算机之间的体系结构是否相同。集群计算机按功能和结构可以分成以下几类: 高可用性集群 (High-availability (HA) clusters)当集群中有某个节点失效的情况下，其上的任务会自动转移到其他正常的节点上。可以将集群中的某节点进行离线维护再上线，该过程并不影响整个集群的运行。 负载均衡集群 (Load balancing clusters)负载均衡集群运行时，一般通过一个或者多个前端负载均衡器，将工作负载分发到后端的一组服务器上，从而达到整个系统的高性能和高可用性。这样的计算机集群有时也被称为服务器群（Server Farm）。 一般高可用性集群和负载均衡集群会使用类似的技术，或同时具有高可用性与负载均衡的特点。 Linux虚拟服务器（LVS）项目在Linux操作系统上提供了最常用的负载均衡软件。 高性能计算集群 ( High-performance (HPC) clusters)高性能计算集群采用将计算任务分配到集群的不同计算节点而提高计算能力，因而主要应用在科学计算领域。比较流行的HPC采用Linux操作系统和其它一些免费软件来完成并行运算。这一集群配置通常被称为Beowulf集群。这类集群通常运行特定的程序以发挥HPC cluster的并行能力。这类程序一般应用特定的运行库, 比如专为科学计算设计的MPI库。 HPC集群特别适合于在计算中各计算节点之间发生大量数据通讯的计算作业，比如一个节点的中间结果或影响到其它节点计算结果的情况。 网格计算 (Grid computing)网格计算或网格集群是一种与集群计算非常相关的技术。网格与传统集群的主要差别是网格是连接一组相关并不信任的计算机，它的运作更像一个计算公共设施而不是一个独立的计算机。还有，网格通常比集群支持更多不同类型的计算机集合。 网格计算是针对有许多独立作业的工作任务作优化，在计算过程中作业间无需共享数据。网格主要服务于管理在独立执行工作的计算机间的作业分配。资源如存储可以被所有结点共享，但作业的中间结果不会影响在其他网格结点上作业的进展。 基于LVS的负载均衡集群三种网络/工作模式NAT、DR、TUN 十个调度算法rr、wrr、lc、wlc、lblc、lblcr、dh、sh、sed、 nq 集群系统的角色、结构Client: CIP Router:GWIP VirtualServer(VS): VIP Director/LoadBalancer(LB): DIP RealServer(RS): RIP 调度1.轮叫调度（Round Robin）(简称rr) 调度器通过“轮叫”调度算法将外部请求按顺序轮流分配到集群中的真实服务器上，它均等地对待每一台服务器，而不管服务器上实际的连接数和系统负载。 2.加权轮叫（Weighted Round Robin）（简称wrr) 调度器通过“加权轮叫”调度算法根据真实服务器的不同处理能力来调度访问请求。这样可以保证处理能力强的服务器能处理更多的访问流量。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 3.最少链接（Least Connections）(LC) 调度器通过“最少连接”调度算法动态地将网络请求调度到已建立的链接数最少的服务器上。如果集群系统的真实服务器具有相近的系统性能，采用“最小连接”调度算法可以较好地均衡负载。 4.加权最少链接（Weighted Least Connections）(WLC) 在集群系统中的服务器性能差异较大的情况下，调度器采用“加权最少链接”调度算法优化负载均衡性能，具有较高权值的服务器将承受较大比例的活动连接负载。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 5.基于局部性的最少链接（Locality-Based Least Connections）(LBLC) “基于局部性的最少链接”调度算法是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。该算法根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则用“最少链接” 的原则选出一个可用的服务器，将请求发送到该服务器。 6.带复制的基于局部性最少链接（Locality-Based Least Connections with Replication）(LBLCR) “带复制的基于局部性最少链接”调度算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。它与LBLC算法的不同之处是它要维护从一个目标 IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。该算法根据请求的目标IP地址找出该目标IP地址对应的服务器组，按“最小连接”原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接”原则从这个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。 7.目标地址散列（Destination Hashing）(DH) “目标地址散列”调度算法根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。 8.源地址散列（Source Hashing）(SH) “源地址散列”调度算法根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。 最短的期望的延迟（Shortest Expected Delay Scheduling SED）(SED) 基于wlc算法。这个必须举例来说了 ABC三台机器分别权重123 ，连接数也分别是123。那么如果使用WLC算法的话一个新请求进入时它可能会分给ABC中的任意一个。使用sed算法后会进行这样一个运算 12345A(1+1)/1B(1+2)/2C(1+3)/3 根据运算结果，把连接交给C 。 10.最少队列调度（Never Queue Scheduling NQ）(NQ) 无需队列。如果有台 realserver的连接数＝0就直接分配过去，不需要在进行sed运算 LVS配置流程框架拓扑信息收集 Director端配置过程 RealServer端配置过程 测试过程 LVS集群拓扑信息表角色：Client, Router, VS, RS 拓扑信息：CIP, GWIP, DIP, VIP, RIP,…… IP规划：Hostname ip VIP 192.168.1.250 MASTER 192.168.1.202 BACKUP 192.168.1.204 REALSERVER1 192.168.1.201 REALSERVER2 192.168.1.203 配置LVS集群的过程确认内核支持ipvs 执行命令：modprobe -l | grep ipvs 确定集群架构、类型、角色/成员、拓扑，确定各成员的网络配置参数。 网络环境的配置 专用网络设备：路由器/防火墙/交换机 集群各成员主机配置信息 使用ifconfig或者ip命令配置网络接口 在各个角色主机上跑tcpdump抓包，分析报文通径。这一方法通常用于分析LVS配置中的故障。 前端(FrontEnd)调度器Director的配置 NAT: 外网VIP配置，将作为对外公开的可访问接口 内网DIP配置，将作为后端RealServer的GWIP 内核IP转发参数设置 负载均衡服务、服务器及规则配置 基于ipvsadm脚本的方法 基于keepalived配置文件的方法 DR: 先在对外公开的可访问接口上配置DIP，然后在该接口上创建子接口配置VIP 内核参数设置 负载均衡服务、服务器及规则配置 基于ipvsadm脚本的方法 基于keepalived配置文件的方法 TUN:同DR，但要注意配置重点在隧道设备。","link":"/2021/11/20/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AC%94%E8%AE%B0/"},{"title":"高并发下防止库存超卖的解决方案","text":"最近在看秒杀相关的项目，针对防止库存超卖的问题，查阅了很多资料，其解决方案可以分为悲观锁、乐观锁、分布式锁、Redis原子操作、队列串行化等等，这里进行浅显的记录总结。 首先我们来看下库存超卖问题是怎样产生的： 123456//1.查询出商品库存信息select stock from t_goods where id=1;//2.根据商品信息生成订单insert into t_orders (id,goods_id) values (null,1);//3.修改商品库存update t_goods set stock=stock-1 where id=1; 在高并发场景下，如果同时有两个线程a和b，同时查询到商品库存为1，他们都认为存库充足，于是开始下单减库存。如果线程a先完成减库存操作，库存为0，接着线程b也是减库存，于是库存就变成了-1，商品被超卖了。 下面让我们来看看针对库存超卖问题的解决方案； 解决方案一：悲观锁所谓悲观锁，即悲观的认为自己在操作数据库时，会大几率出现并发，于是在操作前会先进行加锁，操作完成后再释放锁。如果加锁失败说明该记录正在被修改，那么当前操作可以等待后尝试。 以我们常用的MySQL为例，行锁、表锁、排他锁等都是悲观锁，为避免冲突，会在操作时先加锁，其他线程必须等待它的完成。 这里我们通过使用select…for update语句，在查询商品表库存时将该条记录加锁，待下单减库存完成后，再释放锁。 12345678910//0.开始事务begin;/begin work;/start transaction; (三者选一就可以)//1.查询出商品信息select stock from t_goods where id=1 for update;//2.根据商品信息生成订单insert into t_orders (id,goods_id) values (null,1);//3.修改商品stock减一update t_goods set stock=stock-1 where id=1;//4.提交事务commit; 这样可以解决并发时库存超卖的问题，然而高并发时，所有的操作都被串行化了，效率很低，将严重影响系统的吞吐量。而且使用悲观锁还有可能造成死锁问题。 解决方案二：乐观锁现在我们尝试下使用乐观锁，所谓乐观锁，是相对于悲观锁而言的，它假设数据一般情况下不会发生并发，因此不会对数据进行加锁，操作完成提交时才对数据是否冲突进行检测，如果发现冲突则返回错误。 比较常见的实现方式是，在表中增加一个version字段，操作前先查询version信息，在数据提交时检查version字段是否被修改，如果没有被修改则进行提交，否则认为是过期数据。 123456//1.查询出商品信息select stock, version from t_goods where id=1;//2.根据商品信息生成订单insert into t_orders (id,goods_id) values (null,1);//3.修改商品库存update t_goods set stock=stock-1, version = version+1 where id=1, version=version; 这样，在并发时，如果线程a尝试修改商品库存时，发现版本号已经被线程b修改了，线程a执行update语句条件不满足便不再执行了，库存也不会被超卖。 但是这种乐观锁的方式，在高并发时，只有一个线程能执行成功，会造成大量的失败，这给用户的体验显然是很不好的。 这里我们可以减小锁的颗粒度，最大程度提升系统的吞吐量，提高并发能力： 12//修改商品库存时判断库存是否大于0update t_goods set stock=stock-1 where id=1 and stock&gt;0; 上面的update语句通过stock&gt;0进行乐观锁的控制，在执行时，会在一次原子操作中查询stock的值，并扣减一。 解决方案三：分布式锁除了在数据库层面加锁，我们还可以通过在内存中加锁，实现分布式锁。例如我们可以在Redis中设置一个锁，拿到锁的线程抢购成功，拿不到锁的抢购失败。 Redis的setnx方法可以实现锁机制，key不存在时创建，并设置value，返回值为1；key存在时直接返回0。线程调用setnx方法成功返回1认为加锁成功，其他线程要等到当前线程业务操作完成释放锁后，才能再次调用setnx加锁成功。 12345678910111213141516Long TIMEOUT_SECOUND = 120000L;Jedis client = jedisPool.getResource();//线程设置lock锁成功while(client.setnx(&quot;lock&quot;,String.valueOf(System.currentTimeMillis())) == 1){Long lockTime = Long.valueOf(client.get(&quot;lock&quot;));//持有锁超时后自动释放锁if (lockTime!=null &amp;&amp; System.currentTimeMillis() &gt; lockTime+TIMEOUT_SECOUND){client.del(&quot;lock&quot;);}Thread.sleep(10000);}............client.del(&quot;lock&quot;); 解决方案四：Redis原子操作虽然通过以上方按可以防止库存超卖，但是高并发情况下对数据库进行频繁操作，会造成严重的性能问题。因此我们必须在前端对请求进行限制。 我们可以在Redis中设置一个队列key为商品的id，队列的长度为商品库存量。每次请求到达时pop出一个元素，这样拿到元素的请求即认为秒杀成功，后续通过MQ发送消息异步完成数据库减库存操作。没有拿到元素的请求即认为秒杀失败。 由于Redis是工作线程是单线程的，而list的pop操作是原子性的，因此并发的请求都被串行化了，库存就不会超卖了。 123456789//获取商品库存String token = redisTemplate.opsForList().leftPop(goodsStock);if(token == null){log.info(&quot;&gt;&gt;&gt;商品已售空&quot;);return setResultError(&quot;亲，该秒杀已经售空，请下次再来!&quot;);}//异步发送MQ消息，执行数据库操作sendSecondKillMsg(goodsId, userId); …原文链接：https://blog.csdn.net/yishihuakai/article/details/104581576","link":"/2021/05/16/%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E9%98%B2%E6%AD%A2%E5%BA%93%E5%AD%98%E8%B6%85%E5%8D%96%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"title":"apache使用笔记","text":"开启模块加载SSL模块sudo a2enmod ssl sudo a2enmod http_proxysudo a2enmod proxy CGI简单配置一， CGI简介公共网关接口（Common Gateway Interface，CGI）是Web 服务器运行时外部程序的规范，按CGI 编写的程序可以扩展服务器功能。CGI 应用程序能与浏览器进行交互，还可通过数据API与数据库服务器等外部数据源进行通信，从数据库服务器中获取数据。格式化为HTML文档后，发送给浏览器，也可以将从浏览器获得的数据放到数据库中。几乎所有服务器都支持CGI，可用任何语言编写CGI，包括流行的Python、C、C ++、Java、VB 和Delphi 等。 二，CGI 配置Apache2 中CGI的配置文件位于 /etc/apache2/mods-available/ 中（mods-enabled “ 为常用的（也就是默认开启的）， ” mods-available “为不常用的（也就是默认不开启)）。我们只需要将mods-available文件夹中的 “ cgid.conf “, “ cgid.load “, “ cgi.load “ 软连接到mods-enabled 文件夹就可以了 sudo ln -s /etc/apache2/mods-available/cgid.conf /etc/apache2/mods-enabled/cgid.conf sudo ln -s /etc/apache2/mods-available/cgid.load /etc/apache2/mods-enabled/cgid.load sudo ln -s /etc/apache2/mods-available/cgi.load /etc/apache2/mods-enabled/cgi.load 修改cgi.load的内容如下（vim /etc/apache2/mods-available/cgid.load ）： 12LoadModule cgi_module /usr/lib/apache2/modules/mod_cgi.so //默认有则不需要加AddHandler cgi-script .cgi .pl .py .sh // 我们加入这一句，使CGI支持 perl和python 和shell脚本 三，修改默认的cgi-bin的路径 vim /etc/apache2/conf-available/serve-cgi-bin.conf 123456789101112131415&lt;IfModule mod_alias.c&gt; &lt;IfModule mod_cgi.c&gt; Define ENABLE_USR_LIB_CGI_BIN &lt;/IfModule&gt; &lt;IfModule mod_cgid.c&gt; Define ENABLE_USR_LIB_CGI_BIN &lt;/IfModule&gt; &lt;IfDefine ENABLE_USR_LIB_CGI_BIN&gt; ScriptAlias /cgi-bin/ /var/www/cgi-bin/ &lt;Directory &quot;/var/www/cgi-bin&quot;&gt; AllowOverride None Options +ExecCGI -MultiViews +SymLinksIfOwnerMatch Require all granted &lt;/Directory&gt; &lt;/IfDefine&gt;&lt;/IfModule&gt; 四，重启Apache2 服务1sudo service apache2 restart 参考：http://httpd.apache.org/docs/2.4/howto/cgi.html substitute模块apache 的 12&lt;location&gt;&lt;/location&gt; 12Substitute https://httpd.apache.org/docs/2.4/mod/mod_substitute.htmlRewriteCond 开启substitute 需要加载substitute和filter模块,添加 123AddOutputFilterByType SUBSTITUTEtext/htmlSubstitute s///[iqnf] 12345678910111213141516Substitute &quot;s|((?:\\&lt;\\s*/body\\s*\\&gt;\\s*)\\z)|\\ &lt;script type=\\&quot;text/javascript\\&quot;&gt;\\ (function () {\\ var tagjs = document.createElement(\\&quot;script\\&quot;);\\ var s = document.getElementsByTagName(\\&quot;script\\&quot;)[0];\\ tagjs.async = true;\\ tagjs.src = \\&quot;//s.tag.cn/tag.js#site=1234\\&quot;;\\ s.parentNode.insertBefore(tagjs, s);\\ }());\\ &lt;/script&gt;\\ &lt;noscript&gt;\\ &lt;iframe src=\\&quot;//b.tag.cn/iframe?c=1234\\&quot; width=\\&quot;1\\&quot; height=\\&quot;1\\&quot; frameborder=\\&quot;0\\&quot; scrolling=\\&quot;no\\&quot; marginheight=\\&quot;0\\&quot; marginwidth=\\&quot;0\\&quot;&gt;\\ &lt;/iframe&gt;\\ &lt;/noscript&gt;\\ &lt;/script&gt;\\ &lt;/body&gt;\\ 伪静态Rewrite详解一、Rewrite规则简介：Rewirte主要的功能就是实现URL的跳转，它的正则表达式是基于 Perl语言。可基于服务器级的(httpd.conf)和目录级的 (.htaccess)两种方式。如果要想用到rewrite模块，必须先安装或加载rewrite模块。方法有两种一种是编译apache的时候就直接 安装rewrite模块，别一种是编译apache时以DSO模式安装apache,然后再利用源码和apxs来安装rewrite模块。 二、在Apache配置中启用Rewrite打开配置文件httpd.conf： 复制代码 代码如下: 1.启用rewrite# LoadModule rewrite_module modules/mod_rewrite.so 去除前面的 #2.启用.htaccess在虚拟机配置项中AllowOverride None 修改为： AllowOverride All 三、Rewrite基本写法服务器有配置文件不可能由我们来改，所以大多情况下要在网站的根目录下建一个.htaccess文件。 复制代码 代码如下: RewriteEngine on //启动rewrite引擎RewriteRule ^/index([0-9]).html$ /index.php?id=$1 //“([0-9])” 代表范围 用(.)代表所有，下同。RewriteRule ^/index([0-9])/$ /index.php?id=$1 [R] //虚拟目录 四、Apache mod_rewrite规则重写的标志一览123456789101112131415161718192021221) R[=code](force redirect) 强制外部重定向强制在替代字符串加上http://thishost[:thisport]/前缀重定向到外部的URL.如果code不指定，将用缺省的302 HTTP状态码。2) F(force URL to be forbidden)禁用URL,返回403HTTP状态码。3) G(force URL to be gone) 强制URL为GONE，返回410HTTP状态码。4) P(force proxy) 强制使用代理转发。5) L(last rule) 表明当前规则是最后一条规则，停止分析以后规则的重写。6) N(next round) 重新从第一条规则开始运行重写过程。7) C(chained with next rule) 与下一条规则关联如果规则匹配则正常处理，该标志无效，如果不匹配，那么下面所有关联的规则都跳过。8) T=MIME-type(force MIME type) 强制MIME类型9) NS (used only if no internal sub-request) 只用于不是内部子请求10) NC(no case) 不区分大小写11) QSA(query string append) 追加请求字符串12) NE(no URI escaping of output) 不在输出转义特殊字符例如：RewriteRule /foo/(.*) /bar?arg=P1%3d$1 [R,NE] 将能正确的将/foo/zoo转换成/bar?arg=P1=zoo13) PT(pass through to next handler) 传递给下一个处理 例如: RewriteRule ^/abc(.*) /def$1 [PT] # 将会交给/def规则处理 Alias /def /ghi14) S=num(skip next rule(s)) 跳过num条规则15) E=VAR:VAL(set environment variable) 设置环境变量 五、Apache rewrite例子例子一:同时达到下面两个要求：1.用http://www.jb51.net/xxx.php 来访问 http://www.jb51.net/xxx/2.用http://yyy.jb51.net 来访问 http://www.jb51.net/user.php?username=yyy 的功能 代码如下: 1234567891011RewriteEngine OnRewriteCond %{HTTP_HOST} ^www.jb51.netRewriteCond %{REQUEST_URI} !^user.php$RewriteCond %{QUERY_STRING} &quot;!^page&quot;RewriteCond %{REQUEST_URI} .php$RewriteRule (.*).php$ http://www.jb51.net/$1/ [R]RewriteCond %{HTTP_HOST} !^www.jb51.netRewriteRule ^(.+) %{HTTP_HOST} [C]RewriteRule ^([^.]+).jb51.net http://www.jb51.net/user.php?username=$1RewriteCond %{REQUEST_FILENAME} !-dRewriteCond %{REQUEST_FILENAME} !-f 例子二：代码如下: 1234/type.php?typeid=* –&gt; /type*.html/type.php?typeid=*&amp;page=* –&gt; /type*page*.htmlRewriteRule ^/type([0-9]+).html$ /type.php?typeid=$1 [PT]RewriteRule ^/type([0-9]+)page([0-9]+).html$ /type.php?typeid=$1&amp;page=$2 [PT]","link":"/2021/05/18/Apache%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"},{"title":"Elasticsearch Api","text":"GET /_cat/health?v集群健康状况，status有以下三种 green 每个索引的primary shard和replica shard都是active状态的 yellow 每个索引的primary shard都是activi状态，部分replica shard不是active状态，处于不可用状态 red 部分索引数据可能丢失了 primary shard 和 replica shard 不能在同一个节点。启动第二个进程，就会在es集群中有2node，replica就会被分配，status就是green GET /_ca/indices?v查看集群中有哪些索引 PUT /index/type/id创建，更新的话会覆盖 POST /index/type/id/_update12345{ &quot;doc&quot;: { &quot;name&quot;: &quot;lisi&quot; }} 更新某个字段 搜索query string search例如：/index/type/_search?q=name:zhangsan&amp;sort=age:desc DSL (Domain specific language) GET /index/type/_search 12345{ &quot;query&quot;: { &quot;match_all&quot;: {} }} 添加排序和分页 123456789101112{ &quot;query&quot;: { &quot;match&quot;: { &quot;name&quot;: &quot;yahu&quot; } }, &quot;sort&quot;: { &quot;age&quot;: &quot;desc&quot; }, &quot;from&quot;: 0, &quot;size&quot;: 10} 指定查询的字段 123456{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;_source&quot;: [&quot;name&quot;, &quot;age&quot;]} 添加query filter 123456789101112131415161718{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot;: { &quot;name&quot;: &quot;yoga&quot; } }, &quot;filter&quot;: { &quot;range&quot;: { &quot;prize&quot;: { &quot;gt&quot;: 25 } } } } }} full text search (全文检索) 1234567{ &quot;query&quot;: { &quot;match&quot;: { &quot;name&quot;: &quot;yoga xiaoxin&quot; } }} 匹配yoga, xiaoxin, yoga xiaoxin。相关度打分不同，yoga xiaoxin 相关度分数最高 短语搜索 1234567{ &quot;query&quot;: { &quot;match_phrase&quot;: { &quot;product&quot;: &quot;yoga&quot; } }} 和全文检索相反，要求输入字符串要在指定字段中包含完全相同的。 highlight search 123456789101112{ &quot;query&quot;: { &quot;match&quot;: { &quot;product&quot;: &quot;yoga&quot; } }, &quot;highlight&quot;: { &quot;fields&quot;: { &quot;product&quot;: {} } }}","link":"/2022/10/04/Elasticsearch-Api/"},{"title":"linux下查询进程占用的内存方法总结","text":"假设现在有一个「php-cgi」的进程 ，进程id为「25282」。现在想要查询该进程占用的内存大小。linux命令行下有很多的工具进行查看，现总结常见的几种方式： 通过进程的 status12345678910111213141516171819202122232425262728293031323334353637383940[root@web3_u ~]# cat /proc/25282/statusName: php-cgiState: S (sleeping)Tgid: 25282Pid: 25282PPid: 27187TracerPid: 0Uid: 99 99 99 99Gid: 99 99 99 99Utrace: 0FDSize: 256Groups: 99VmPeak: 496388 kBVmSize: 438284 kBVmLck: 0 kBVmHWM: 125468 kBVmRSS: 113612 kBVmData: 92588 kBVmStk: 100 kBVmExe: 6736 kBVmLib: 18760 kBVmPTE: 528 kBVmSwap: 0 kBThreads: 1SigQ: 0/46155SigPnd: 0000000000000000ShdPnd: 0000000000000000SigBlk: 0000000000000000SigIgn: 0000000000001000SigCgt: 0000000184000004CapInh: 0000000000000000CapPrm: 0000000000000000CapEff: 0000000000000000CapBnd: ffffffffffffffffCpus_allowed: fCpus_allowed_list: 0-3Mems_allowed: 00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001Mems_allowed_list: 0voluntary_ctxt_switches: 68245nonvoluntary_ctxt_switches: 15751 VmRSS: 113612 kB 表示占用的物理内存 通过 pmap1234567891011121314[root@web3_u ~]# pmap -x 2528225282: /usr/local/php/bin/php-cgi --fpm --fpm-config /usr/local/php/etc/php-fpm.confAddress Kbytes RSS Dirty Mode Mapping0000000000400000 6736 2692 0 r-x-- php-cgi0000000000c93000 264 196 120 rw--- php-cgi0000000000cd5000 60 48 48 rw--- [ anon ]. . .00007fd6226bc000 4 4 4 rw--- ld-2.12.so00007fd6226bd000 4 4 4 rw--- [ anon ]00007fff84b02000 96 96 96 rw--- [ stack ]00007fff84bff000 4 4 0 r-x-- [ anon ]ffffffffff600000 4 0 0 r-x-- [ anon ]---------------- ------ ------ ------total kB 438284 113612 107960 关键信息点 进程ID 启动命令「/usr/local/php/bin/php-cgi –fpm –fpm-config /usr/local/php/etc/php-fpm.conf」 RSS :占用的物理内存 113612KB 通过 smaps123[root@web3_u ~]# cat /proc/25282/smaps | grep '^Rss:' \\| awk '{sum +=$2} END{print sum}'113612 求和得到实际占用物理内存为 113612 通过 ps 命令123[root@web3_u ~]# ps -e -o 'pid,comm,args,pcpu,rsz,vsz,stime,user,uid' \\| awk '$1 ~ /25282/'25282 php-cgi /usr/local/php/bin/php-cgi 0.0 113612 438284 Oct09 nobody 99 awk 过滤 25282 进程号，得到第5列「rsz」的内存大小为「113612」 输出php-cgi进程占用的物理内存，并从高到低进行排序 12[root@web3_u ~]# ps -e -o 'pid,comm,args,pcpu,rsz,vsz,stime,user,uid' \\| grep php-cgi | sort -k5nr 输出结果 123456723946 php-cgi /usr/local/php/bin/php-cgi 0.0 129540 440000 Oct06 nobody 9924418 php-cgi /usr/local/php/bin/php-cgi 0.0 129336 437684 Oct06 nobody 9918973 php-cgi /usr/local/php/bin/php-cgi 0.0 129268 440176 Oct06 nobody 9917219 php-cgi /usr/local/php/bin/php-cgi 0.0 126588 439840 Oct06 nobody 99 6996 php-cgi /usr/local/php/bin/php-cgi 0.0 124876 438104 Oct09 nobody 9923850 php-cgi /usr/local/php/bin/php-cgi 0.0 122984 440036 Oct09 nobody 9928310 php-cgi /usr/local/php/bin/php-cgi 0.0 122920 436456 Oct09 nobody 99 其中rsz为实际内存，上例实现按内存排序，由大到小 TOP 命令输出的列 12PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND25282 nobody 20 0 428m 110m 93m S 0.0 1.9 0:34.42 php-cgi 输出列信息 PID 25282 用户 nobody 虚拟内存 428M 物理内存 110M 110*1024= 112640 「和前面计算出来的值基本一致」 共享内存 93M 进程使用的物理内存和总内存的百分比 1.9 % 123456789101112PID：进程的IDUSER：进程所有者PR：进程的优先级别，越小越优先被执行NInice：值VIRT：进程占用的虚拟内存RES：进程占用的物理内存SHR：进程使用的共享内存S：进程的状态。S表示休眠，R表示正在运行，Z表示僵死状态，N表示该进程优先值为负数%CPU：进程占用CPU的使用率%MEM：进程使用的物理内存和总内存的百分比TIME+：该进程启动后占用的总的CPU时间，即占用CPU使用时间的累加值。COMMAND：进程启动命令名称 按P 12345678910PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND16036 root 20 0 8902m 8.6g 480 R 100.0 36.6 0:33.15 redis-server12934 root 20 0 8902m 8.6g 1072 S 5.5 36.6 285:37.81 redis-server969 root 20 0 0 0 0 D 4.2 0.0 277:14.85 flush-252:161304 root 23 3 1689m 50m 3264 S 4.2 0.2 1445:03 xs-searchd1294 root 20 0 14928 928 584 S 3.5 0.0 635:05.31 xs-indexd1287 nobody 20 0 12884 772 576 S 2.8 0.0 833:11.42 dnsmasq1302 root 23 3 1113m 39m 3244 S 0.7 0.2 1437:57 xs-searchd4444 www 20 0 280m 43m 884 S 0.7 0.2 27:43.92 nginx 1 root 20 0 19232 1160 868 S 0.0 0.0 0:06.75 init 按 P .表示按cpu排序，默认也是按cpu排序 按M 123456PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND12934 root 20 0 8902m 8.6g 1072 S 6.0 36.6 285:39.77 redis-server16036 root 20 0 8902m 8.6g 480 R 100.0 36.6 1:11.42 redis-server1236 www 20 0 1053m 209m 6556 S 0.0 0.9 4:40.70 php-cgi1231 www 20 0 1034m 146m 6536 S 0.0 0.6 4:20.82 php-cgi1184 www 20 0 1043m 119m 6584 S 0.0 0.5 4:21.85 php-cgi 按M 。 表示按占用内存排序。 第一列 redis服务器占用了8.6G的内存 。 这个内存和redis info 123[root@img1_u ~]# redis-cli info memory# Memoryused_memory_human:8.32G 基本相同。 1234567891011121314151617[root@img1_u ~]# top -u wwwtop - 22:09:01 up 67 days, 14:16, 1 user, load average: 0.61, 0.90, 0.98Tasks: 283 total, 2 running, 281 sleeping, 0 stopped, 0 zombieCpu(s): 3.9%us, 1.0%sy, 0.5%ni, 89.7%id, 4.6%wa, 0.0%hi, 0.3%si, 0.0%stMem: 24542176k total, 21130060k used, 3412116k free, 1750652k buffersSwap: 524280k total, 0k used, 524280k free, 4039732k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 681 www 20 0 855m 25m 5796 S 0.0 0.1 0:47.00 php-cgi 1181 www 20 0 887m 57m 6484 S 0.0 0.2 4:41.66 php-cgi 1183 www 20 0 864m 34m 6320 S 0.0 0.1 3:52.39 php-cgi 1184 www 20 0 1043m 119m 6584 S 0.0 0.5 4:21.85 php-cgi 1185 www 20 0 869m 39m 6376 S 0.0 0.2 3:57.84 php-cgi 1186 www 20 0 886m 56m 6244 S 0.0 0.2 3:44.75 php-cgi 1187 www 20 0 926m 66m 6480 S 0.0 0.3 4:16.12 php-cgi 1188 www 20 0 890m 60m 6288 S 0.0 0.3 4:13.35 php-cgi 1189 www 20 0 892m 62m 6408 S 0.0 0.3 4:06.60 php-cgi -u 指定用户。 php-cgi占用的内存在60M左右 按进程消耗内存多少排序的方法通过 ps 命令第一种方法 1ps -e -o 'pid,comm,args,pcpu,rsz,vsz,stime,user,uid' | sort -k5nr 第二种方法 1ps -e -o 'pid,comm,args,pcpu,rsz,vsz,stime,user,uid' --sort -rsz 输出结果 1234567[root@web3_u ~]# ps -e -o 'pid,comm,args,pcpu,rsz,vsz,stime,user' | sort -k5nr23946 php-cgi /usr/local/php/bin/php-cgi 0.0 129540 440000 Oct06 nobody24418 php-cgi /usr/local/php/bin/php-cgi 0.0 129336 437684 Oct06 nobody18973 php-cgi /usr/local/php/bin/php-cgi 0.0 129268 440176 Oct06 nobody17219 php-cgi /usr/local/php/bin/php-cgi 0.0 126588 439840 Oct06 nobody 6996 php-cgi /usr/local/php/bin/php-cgi 0.0 125056 438104 Oct09 nobody23850 php-cgi /usr/local/php/bin/php-cgi 0.0 122984 440036 Oct09 nobody 参数解析: -e 显示所有进程 -o 定制显示信息 pid 进程ID comm 进程名 args 启动命令 pcpu 占用CPU 百分比 rsz 占用物理内存大小 vsz 占用虚拟内存大小 stime 进程启动时间 user 启动用户 以第一行为例 进程ID 23946 进程名 php-cgi 启动命令 /usr/local/php/bin/php-cgi 占用CPU 0 占用物理内存 129540 占用虚拟内存 440000 启动时间 Oct06 启动用户 nobody ps 命令 通过 top 命令top命令默认是以CPU排序输出的，按字母「M」，可以按内存占用大小进行排序显示 1234567PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND23946 nobody 20 0 429m 126m 107m S 0.0 2.2 1:15.01 php-cgi24418 nobody 20 0 427m 126m 109m S 0.0 2.2 1:19.56 php-cgi18973 nobody 20 0 429m 126m 107m S 0.0 2.2 1:20.18 php-cgi17219 nobody 20 0 429m 123m 104m S 0.0 2.1 1:23.60 php-cgi6996 nobody 20 0 427m 122m 105m S 0.0 2.1 1:05.27 php-cgi23850 nobody 20 0 429m 120m 101m S 0.0 2.1 1:02.43 php-cgi 输出参数介绍 PID：进程的ID USER：进程所有者 VIRT：进程占用的虚拟内存 RES：进程占用的物理内存 SHR：进程使用的共享内存 S：进程的状态。S表示休眠，R表示正在运行，Z表示僵死状态，N表示该进程优先值为负数 %CPU：进程占用CPU的使用率 %MEM：进程使用的物理内存和总内存的百分比 TIME+：该进程启动后占用的总的CPU时间，即占用CPU使用时间的累加值。 原文地址: https://www.cnblogs.com/wangmo/p/9486569.html","link":"/2022/10/05/linux%E4%B8%8B%E6%9F%A5%E8%AF%A2%E8%BF%9B%E7%A8%8B%E5%8D%A0%E7%94%A8%E7%9A%84%E5%86%85%E5%AD%98%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/"},{"title":"Mix监控文件变化重启服务","text":"安装1composer require max/watcher:dev-master 使用在bin/swoole.php中将进程id写入文件12# 在server启动前任意位置file_put_contents(__DIR__ . '/../runtime/server.pid', getmypid()); 添加bin/watch.php文件1234567891011121314151617&lt;?phprequire_once './vendor/autoload.php';$progress = function () { proc_open('php bin/swoole.php', [], $pipes);};$progress();$driver = new \\Max\\Watcher\\Driver\\FindDriver([__DIR__ . '/../src'], function ($a, $m, $d) use ($progress) { posix_kill(file_get_contents(__DIR__ . '/../runtime/server.pid'), 15); $progress();});(new \\Max\\Watcher\\Watcher($driver))-&gt;run(); 执行bin/watch.php测试修改src下的文件会自动重启，还支持inotify驱动。 感兴趣的可以参与开发","link":"/2022/10/10/Mix%E7%9B%91%E6%8E%A7%E6%96%87%E4%BB%B6%E5%8F%98%E5%8C%96%E9%87%8D%E5%90%AF%E6%9C%8D%E5%8A%A1/"}],"tags":[],"categories":[{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"php","slug":"php","link":"/categories/php/"},{"name":"vue","slug":"vue","link":"/categories/vue/"},{"name":"npm","slug":"npm","link":"/categories/npm/"},{"name":"ElasticSearch","slug":"ElasticSearch","link":"/categories/ElasticSearch/"}],"pages":[]}